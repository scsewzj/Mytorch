{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MyTensor as MT\n",
    "inputtensor=MT.mytensor([[3,4,2],[1,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': 0, 'to': 2, 'forward': {'op': 'mytensor.__rtruediv__', 'with': 1}}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/inputtensor\n",
    "MT.mytensor.computegraph._edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MyNN as MN \n",
    "layer1=MN.my_linear_layer(in_feature=3,out_feature=4)\n",
    "#layer2=MN.my_linear_layer(in_feature=4,out_feature=6)\n",
    "#layer3=MN.my_linear_layer(in_feature=6,out_feature=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1=layer1(inputtensor)\n",
    "#pred2=layer2(pred1)\n",
    "#pred3=layer3(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': 0, 'to': 2, 'forward': {'op': 'dot', 'with': 1, 'pos': 'right'}},\n",
       " {'from': 1, 'to': 2, 'forward': {'op': 'dot', 'with': 0, 'pos': 'left'}},\n",
       " {'from': 3, 'to': 5, 'forward': {'op': 'dot', 'with': 4, 'pos': 'right'}},\n",
       " {'from': 4, 'to': 5, 'forward': {'op': 'dot', 'with': 3, 'pos': 'left'}},\n",
       " {'from': 2, 'to': 6, 'forward': {'op': 'add', 'with': 5, 'pos': 'right'}},\n",
       " {'from': 5, 'to': 6, 'forward': {'op': 'add', 'with': 2, 'pos': 'left'}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MT.mytensor.computegraph._edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_true=MT.mytensor([[0,1,1,2],[2,1,3,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor32([[0. 1. 1. 2.]\n",
       " [2. 1. 3. 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MT.mytensor.computegraph._edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = Loss.L1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.984853"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1(pred1,label_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor32([[0.5]])\n"
     ]
    }
   ],
   "source": [
    "L1.backward(mode = 'force')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = MT.mytensor.computegraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tensortype': 'tensor32',\n",
       " 'with_grad': True,\n",
       " '_cg_descend': [2],\n",
       " '_cg_ascend': [],\n",
       " '_grad_f': tensor32([[-2.          1.9999999  -1.9999999   0.9999999 ]\n",
       "  [-3.          2.9999998  -3.          0.9999999 ]\n",
       "  [-2.5         2.4999998  -2.5        -0.50000006]]),\n",
       " 'grad': tensor32([[-2.          1.9999999  -1.9999999   0.9999999 ]\n",
       "  [-3.          2.9999998  -3.          0.9999999 ]\n",
       "  [-2.5         2.4999998  -2.5        -0.50000006]]),\n",
       " 'npar_data': array([[-0.5165363 ,  0.04542432, -0.975878  ,  0.19529498],\n",
       "        [-0.44510156,  0.87301093,  0.04951663,  0.8299451 ],\n",
       "        [-0.2578847 ,  0.06004273, -0.7708808 , -0.71225375]],\n",
       "       dtype=float32),\n",
       " 'shape': (3, 4),\n",
       " '_is_para': True}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._nodelist[1].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'MyTensor.mytensor'>\n",
      "<class 'MyPara.myparameter'>\n",
      "<class 'MyTensor.mytensor'>\n",
      "<class 'MyTensor.mytensor'>\n",
      "<class 'MyPara.myparameter'>\n",
      "<class 'MyTensor.mytensor'>\n",
      "<class 'MyTensor.mytensor'>\n",
      "<class 'MyTensor.mytensor'>\n",
      "<class 'int'>\n",
      "<class 'MyTensor.mytensor'>\n",
      "<class 'MyTensor.mytensor'>\n",
      "<class 'int'>\n",
      "<class 'MyTensor.mytensor'>\n",
      "<class 'float'>\n",
      "<class 'MyTensor.mytensor'>\n",
      "<class 'MyTensor.mytensor'>\n",
      "<class 'MyTensor.mytensor'>\n",
      "<class 'MyTensor.mytensor'>\n",
      "<class 'MyTensor.mytensor'>\n",
      "<class 'MyTensor.mytensor'>\n"
     ]
    }
   ],
   "source": [
    "for i in cg._nodelist:\n",
    "    print(type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor32([[3. 4. 2.]\n",
      " [1. 2. 3.]])\n",
      "myparameter([[-0.5165363   0.04542432 -0.975878    0.19529498]\n",
      " [-0.44510156  0.87301093  0.04951663  0.8299451 ]\n",
      " [-0.2578847   0.06004273 -0.7708808  -0.71225375]], tensor32)\n",
      "tensor32([[-3.8457847  3.748402  -4.271329   2.4811578]\n",
      " [-2.1803937  1.9715744 -3.1894872 -0.2815761]])\n",
      "tensor32([[1.]\n",
      " [1.]])\n",
      "myparameter([[0. 0. 0. 0.]], tensor32)\n",
      "tensor32([[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]])\n",
      "tensor32([[-3.8457847  3.748402  -4.271329   2.4811578]\n",
      " [-2.1803937  1.9715744 -3.1894872 -0.2815761]])\n",
      "tensor32([[0. 1. 1. 2.]\n",
      " [2. 1. 3. 0.]])\n",
      "-1\n",
      "tensor32([[-0. -1. -1. -2.]\n",
      " [-2. -1. -3. -0.]])\n",
      "tensor32([[-3.8457847   2.748402   -5.271329    0.48115778]\n",
      " [-4.1803937   0.9715744  -6.1894875  -0.2815761 ]])\n",
      "2\n",
      "tensor32([[14.79006     7.5537143  27.78691     0.23151281]\n",
      " [17.47569     0.94395685 38.309753    0.0792851 ]])\n",
      "0.5\n",
      "tensor32([[3.8457847  2.748402   5.271329   0.48115778]\n",
      " [4.1803937  0.9715744  6.1894875  0.2815761 ]])\n",
      "tensor32([[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]])\n",
      "tensor32([[12.346674]\n",
      " [11.623032]])\n",
      "tensor32([[1. 1.]])\n",
      "tensor32([[23.969706]])\n",
      "tensor32([[11.984853]])\n"
     ]
    }
   ],
   "source": [
    "for i in cg._nodelist:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor32([[11.984853]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1._tensorloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MT.mytensor.computegraph._lossnodes_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MT.mytensor.computegraph._edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg=MT.mytensor.computegraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._lossnodes_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_DiG=nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tensortype': 'tensor32',\n",
       " 'with_grad': True,\n",
       " '_cg_descend': [2],\n",
       " '_cg_ascend': [],\n",
       " '_grad_f': tensor32([[0.8665668  1.0492704  0.18827723]\n",
       "  [0.67127186 0.21932536 0.90053105]]),\n",
       " 'grad': tensor32([[0.8665668  1.0492704  0.18827723]\n",
       "  [0.67127186 0.21932536 0.90053105]]),\n",
       " 'npar_data': array([[3., 4., 2.],\n",
       "        [1., 2., 3.]], dtype=float32),\n",
       " 'shape': (2, 3)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._nodelist[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cg._edgelist:\n",
    "    simple_DiG.add_edge(i['from'],i['to'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw_networkx(simple_DiG,pos=nx.spring_layout(simple_DiG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [2], '_cg_ascend': [], '_grad_f': tensor32([[0.8665668  1.0492704  0.18827723]\n",
      " [0.67127186 0.21932536 0.90053105]]), 'grad': tensor32([[0.8665668  1.0492704  0.18827723]\n",
      " [0.67127186 0.21932536 0.90053105]]), 'npar_data': array([[3., 4., 2.],\n",
      "       [1., 2., 3.]], dtype=float32), 'shape': (2, 3)}\n",
      "==================================\n",
      "1\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [2], '_cg_ascend': [], '_grad_f': tensor32([[-2.          1.9999999  -1.9999999   0.9999999 ]\n",
      " [-3.          2.9999998  -3.          0.9999999 ]\n",
      " [-2.5         2.4999998  -2.5        -0.50000006]]), 'grad': tensor32([[-2.          1.9999999  -1.9999999   0.9999999 ]\n",
      " [-3.          2.9999998  -3.          0.9999999 ]\n",
      " [-2.5         2.4999998  -2.5        -0.50000006]]), 'npar_data': array([[-0.5165363 ,  0.04542432, -0.975878  ,  0.19529498],\n",
      "       [-0.44510156,  0.87301093,  0.04951663,  0.8299451 ],\n",
      "       [-0.2578847 ,  0.06004273, -0.7708808 , -0.71225375]],\n",
      "      dtype=float32), 'shape': (3, 4), '_is_para': True}\n",
      "==================================\n",
      "2\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [6], '_cg_ascend': [0, 1], '_grad_f': tensor32([[-0.5         0.49999997 -0.49999997  0.49999997]\n",
      " [-0.5         0.49999997 -0.5        -0.5       ]]), 'grad': tensor32([[-0.5         0.49999997 -0.49999997  0.49999997]\n",
      " [-0.5         0.49999997 -0.5        -0.5       ]]), 'npar_data': array([[-3.8457847,  3.748402 , -4.271329 ,  2.4811578],\n",
      "       [-2.1803937,  1.9715744, -3.1894872, -0.2815761]], dtype=float32), 'shape': (2, 4)}\n",
      "==================================\n",
      "3\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [5], '_cg_ascend': [], '_grad_f': tensor32([[0.]\n",
      " [0.]]), 'grad': tensor32([[0.]\n",
      " [0.]]), 'npar_data': array([[1.],\n",
      "       [1.]], dtype=float32), 'shape': (2, 1)}\n",
      "==================================\n",
      "4\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [5], '_cg_ascend': [], '_grad_f': tensor32([[-1.0000000e+00  9.9999994e-01 -1.0000000e+00 -2.9802322e-08]]), 'grad': tensor32([[-1.0000000e+00  9.9999994e-01 -1.0000000e+00 -2.9802322e-08]]), 'npar_data': array([[0., 0., 0., 0.]], dtype=float32), 'shape': (1, 4), '_is_para': True}\n",
      "==================================\n",
      "5\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [6], '_cg_ascend': [3, 4], '_grad_f': tensor32([[-0.5         0.49999997 -0.49999997  0.49999997]\n",
      " [-0.5         0.49999997 -0.5        -0.5       ]]), 'grad': tensor32([[-0.5         0.49999997 -0.49999997  0.49999997]\n",
      " [-0.5         0.49999997 -0.5        -0.5       ]]), 'npar_data': array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]], dtype=float32), 'shape': (2, 4)}\n",
      "==================================\n",
      "6\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [10], '_cg_ascend': [2, 5], '_grad_f': tensor32([[-0.5         0.49999997 -0.49999997  0.49999997]\n",
      " [-0.5         0.49999997 -0.5        -0.5       ]]), 'grad': tensor32([[-0.5         0.49999997 -0.49999997  0.49999997]\n",
      " [-0.5         0.49999997 -0.5        -0.5       ]]), 'npar_data': array([[-3.8457847,  3.748402 , -4.271329 ,  2.4811578],\n",
      "       [-2.1803937,  1.9715744, -3.1894872, -0.2815761]], dtype=float32), 'shape': (2, 4)}\n",
      "==================================\n",
      "7\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [9], '_cg_ascend': [], '_grad_f': tensor32([[ 0.5        -0.49999997  0.49999997 -0.49999997]\n",
      " [ 0.5        -0.49999997  0.5         0.5       ]]), 'grad': tensor32([[ 0.5        -0.49999997  0.49999997 -0.49999997]\n",
      " [ 0.5        -0.49999997  0.5         0.5       ]]), 'npar_data': array([[0., 1., 1., 2.],\n",
      "       [2., 1., 3., 0.]], dtype=float32), 'shape': (2, 4)}\n",
      "==================================\n",
      "8\n",
      "-1\n",
      "==================================\n",
      "9\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [10], '_cg_ascend': [7], '_grad_f': tensor32([[-0.5         0.49999997 -0.49999997  0.49999997]\n",
      " [-0.5         0.49999997 -0.5        -0.5       ]]), 'grad': tensor32([[-0.5         0.49999997 -0.49999997  0.49999997]\n",
      " [-0.5         0.49999997 -0.5        -0.5       ]]), 'npar_data': array([[-0., -1., -1., -2.],\n",
      "       [-2., -1., -3., -0.]], dtype=float32), 'shape': (2, 4)}\n",
      "==================================\n",
      "10\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [12], '_cg_ascend': [6, 9], '_grad_f': tensor32([[-0.5         0.49999997 -0.49999997  0.49999997]\n",
      " [-0.5         0.49999997 -0.5        -0.5       ]]), 'grad': tensor32([[-0.5         0.49999997 -0.49999997  0.49999997]\n",
      " [-0.5         0.49999997 -0.5        -0.5       ]]), 'npar_data': array([[-3.8457847 ,  2.748402  , -5.271329  ,  0.48115778],\n",
      "       [-4.1803937 ,  0.9715744 , -6.1894875 , -0.2815761 ]],\n",
      "      dtype=float32), 'shape': (2, 4)}\n",
      "==================================\n",
      "11\n",
      "2\n",
      "==================================\n",
      "12\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [14], '_cg_ascend': [10], '_grad_f': tensor32([[0.06500624 0.09096194 0.04742637 0.51958007]\n",
      " [0.05980298 0.2573143  0.04039107 0.88785946]]), 'grad': tensor32([[0.06500624 0.09096194 0.04742637 0.51958007]\n",
      " [0.05980298 0.2573143  0.04039107 0.88785946]]), 'npar_data': array([[14.79006   ,  7.5537143 , 27.78691   ,  0.23151281],\n",
      "       [17.47569   ,  0.94395685, 38.309753  ,  0.0792851 ]],\n",
      "      dtype=float32), 'shape': (2, 4)}\n",
      "==================================\n",
      "13\n",
      "0.5\n",
      "==================================\n",
      "14\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [16], '_cg_ascend': [12], '_grad_f': tensor32([[0.5 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 0.5]]), 'grad': tensor32([[0.5 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 0.5]]), 'npar_data': array([[3.8457847 , 2.748402  , 5.271329  , 0.48115778],\n",
      "       [4.1803937 , 0.9715744 , 6.1894875 , 0.2815761 ]], dtype=float32), 'shape': (2, 4)}\n",
      "==================================\n",
      "15\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [16], '_cg_ascend': [], '_grad_f': tensor32([[4.013089  ]\n",
      " [1.8599882 ]\n",
      " [5.730408  ]\n",
      " [0.38136694]]), 'grad': tensor32([[4.013089  ]\n",
      " [1.8599882 ]\n",
      " [5.730408  ]\n",
      " [0.38136694]]), 'npar_data': array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]], dtype=float32), 'shape': (4, 1)}\n",
      "==================================\n",
      "16\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [18], '_cg_ascend': [14, 15], '_grad_f': tensor32([[0.5]\n",
      " [0.5]]), 'grad': tensor32([[0.5]\n",
      " [0.5]]), 'npar_data': array([[12.346674],\n",
      "       [11.623032]], dtype=float32), 'shape': (2, 1)}\n",
      "==================================\n",
      "17\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [18], '_cg_ascend': [], '_grad_f': tensor32([[6.173337 5.811516]]), 'grad': tensor32([[6.173337 5.811516]]), 'npar_data': array([[1., 1.]], dtype=float32), 'shape': (1, 2)}\n",
      "==================================\n",
      "18\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [19], '_cg_ascend': [17, 16], '_grad_f': tensor32([[0.5]]), 'grad': tensor32([[0.5]]), 'npar_data': array([[23.969706]], dtype=float32), 'shape': (1, 1)}\n",
      "==================================\n",
      "19\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [], '_cg_ascend': [18], '_grad_f': tensor32([[1.]]), 'grad': tensor32([[1.]]), 'npar_data': array([[11.984853]], dtype=float32), 'shape': (1, 1)}\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for i in cg._nodelist:\n",
    "    print(counter)\n",
    "    counter+=1\n",
    "    if type(i).__name__ == 'mytensor' or type(i).__name__ == 'mytensorloss' or type(i).__name__ == 'myparameter':\n",
    "        print(i.__dict__)\n",
    "        print('==================================')\n",
    "    else:\n",
    "        print(i)\n",
    "        print('==================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from': 10, 'to': 12, 'forward': {'op': 'mytensor.__pow__', 'with': 11}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._computegraph__find_edges(10,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.379904"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1.scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._nodelist[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor32([[ 8.522778   -2.5620975   2.4791775   0.94780594]\n",
       " [ 6.703035   -2.2524216  -3.5722506  -1.2421455 ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._nodelist[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor32([[3. 4. 2.]\n",
       " [1. 2. 3.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._nodelist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for the longest path\n",
    "def longest():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 7, 10, 13, 16]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._parameternodes_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths=[]\n",
    "for i in cg._parameternodes_index:\n",
    "    for j in cg._valid_path_reversed:\n",
    "        if j['pointer']==i:\n",
    "            paths.append(j)\n",
    "longest=None\n",
    "length=0\n",
    "for i in paths:\n",
    "    if len(i['path'])>length:\n",
    "        longest=i\n",
    "        length=len(i['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Gradlib as GL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tensortype': 'tensor32',\n",
       " 'with_grad': False,\n",
       " '_cg_descend': [28],\n",
       " '_cg_ascend': [24],\n",
       " '_grad': tensor32([[61.784706 61.784706 61.784706 61.784706]\n",
       "  [55.208027 55.208027 55.208027 55.208027]]),\n",
       " 'npar_data': array([[ 9.02311   ,  0.33579683, 17.236443  , 35.189354  ],\n",
       "        [ 5.5673065 , 13.829675  ,  6.153961  , 29.657085  ]],\n",
       "       dtype=float32),\n",
       " 'grad': None,\n",
       " 'shape': (2, 4)}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._nodelist[26].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'from': 26, 'to': 28, 'forward': {'op': 'dot', 'with': 27, 'pos': 'right'}}\n",
      "{'from': 24, 'to': 26, 'forward': {'op': 'mytensor.__pow__', 'with': 25}}\n",
      "{'from': 22, 'to': 24, 'forward': {'op': 'mytensor.__pow__', 'with': 23}}\n",
      "{'from': 18, 'to': 22, 'forward': {'op': 'add', 'with': 21, 'pos': 'right'}}\n",
      "{'from': 14, 'to': 18, 'forward': {'op': 'add', 'with': 17, 'pos': 'right'}}\n",
      "{'from': 12, 'to': 14, 'forward': {'op': 'dot', 'with': 13, 'pos': 'right'}}\n",
      "{'from': 8, 'to': 12, 'forward': {'op': 'add', 'with': 11, 'pos': 'right'}}\n",
      "{'from': 6, 'to': 8, 'forward': {'op': 'dot', 'with': 7, 'pos': 'right'}}\n",
      "{'from': 5, 'to': 6, 'forward': {'op': 'add', 'with': 2, 'pos': 'left'}}\n",
      "{'from': 4, 'to': 5, 'forward': {'op': 'dot', 'with': 3, 'pos': 'left'}}\n"
     ]
    }
   ],
   "source": [
    "### exmaple of backpropagation, for dot\n",
    "for i in paths[1]['path']:\n",
    "    path = cg._edgelist[i]\n",
    "    print(path)\n",
    "    op = path['forward']['op']\n",
    "    last_grad = cg._nodelist[path['to']]._grad\n",
    "    local_grad = GL.grad_basic(op,cg._nodelist[path['from']],cg._nodelist[path['forward']['with']])\n",
    "    if op == 'dot':\n",
    "        if path['forward']['pos']=='right':\n",
    "            cg._nodelist[path['from']]._grad = MT.dot.__wrapped__(last_grad,local_grad)\n",
    "        else:\n",
    "            cg._nodelist[path['from']]._grad = MT.dot.__wrapped__(local_grad,last_grad)\n",
    "    else:\n",
    "        cg._nodelist[path['from']]._grad = MT.hadamard.__wrapped__(last_grad,local_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 7, 10, 13, 16]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._parameternodes_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._nodelist[0]._cg_descend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg._nodelist[28]._grad=L1._tensorloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_edges(cg, nodefrom, nodeto):\n",
    "    for i in cg._edgelist:\n",
    "        if i['from']==nodefrom and i['to']==nodeto:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_recursive(paranode):\n",
    "    if paranode._grad is None:\n",
    "        paranode._grad = MT.zeros(paranode.shape)\n",
    "    for i in paranode._cg_descend:\n",
    "        edge = find_edges(cg,cg._nodelist.index(paranode),i)\n",
    "        #return edge\n",
    "        local_grad = GL.grad_basic(edge['forward']['op'],cg._nodelist[edge['from']],cg._nodelist[edge['forward']['with']])\n",
    "        if cg._nodelist[i]._grad is None:\n",
    "            cg._nodelist[i]._grad = grad_recursive(cg._nodelist[i])\n",
    "        previous_grad = cg._nodelist[i]._grad\n",
    "        if edge['forward']['pos']=='right':\n",
    "            paranode._grad = MT.add.__wrapped__(paranode._grad,MT.dot.__wrapped__(previous_grad,local_grad))\n",
    "        else:\n",
    "            paranode._grad = MT.add.__wrapped__(paranode._grad,MT.dot.__wrapped__(local_grad,previous_grad))\n",
    "    return paranode._grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor32([[  357.46106  -938.38104  -162.70618 -1001.444  ]\n",
       " [  506.40335 -1116.0652   -112.39728 -1289.011  ]\n",
       " [  342.56757  -152.70386   257.43417  -505.76257]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg.grad_recursive(cg._nodelist[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tensortype': 'tensor32',\n",
       " 'with_grad': False,\n",
       " '_cg_descend': [],\n",
       " '_cg_ascend': [26, 27],\n",
       " '_grad': tensor32([[53.27053]\n",
       "  [32.18875]]),\n",
       " 'npar_data': array([[53.27053],\n",
       "        [32.18875]], dtype=float32),\n",
       " 'grad': None,\n",
       " 'shape': (2, 1)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._nodelist[28].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1._tensorloss._grad==L1._tensorloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg._nodelist[28]._grad=L1._tensorloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._nodelist[1].npar_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._nodelist[1].npar_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sort paths by length\n",
    "def sort_paths_bylen(paths):\n",
    "    insert=[]\n",
    "    if len(paths)==0:\n",
    "        return paths\n",
    "    else:\n",
    "        path0 = paths[0]\n",
    "        path1 = paths[1]\n",
    "        if len(path0['path'])>len(path1['path']):\n",
    "            insert.append(path1)\n",
    "            insert.append(path0)\n",
    "        else:\n",
    "            insert.append(path0)\n",
    "            insert.append(path1)\n",
    "        for i in range(2,len(paths)):\n",
    "            for j in range(len(insert)):\n",
    "                if len(paths[i]['path'])<=len(insert[0]['path']):\n",
    "                    insert.insert(0,paths[i])\n",
    "                    break\n",
    "                elif j == len(insert)-1:\n",
    "                    insert.append(paths[i])\n",
    "                    break\n",
    "                elif len(paths[i]['path'])>len(insert[j]['path']) and len(paths[i]['path'])<=len(insert[j+1]['path']):\n",
    "                    insert.insert(j+1,paths[i])\n",
    "                    break\n",
    "        return insert\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sort_paths_bylen(\u001b[43mpaths\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'paths' is not defined"
     ]
    }
   ],
   "source": [
    "sort_paths_bylen(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tensortype': 'tensor32',\n",
       " 'with_grad': True,\n",
       " 'npar_data': array([[-0.60681846, -0.38946284,  0.02273534,  0.49508417],\n",
       "        [-0.41089079,  0.85162298, -1.69011198, -1.65052802],\n",
       "        [ 0.3508718 , -0.50972841, -3.06099516,  0.03814447]]),\n",
       " 'grad': None,\n",
       " 'shape': (),\n",
       " '_is_para': True,\n",
       " '_grad': tensor32([[-3336.024  -3397.6953 -2276.1594 -2986.0913]\n",
       "  [-4911.2915 -5002.084  -3350.96   -4396.1206]\n",
       "  [-3845.4243 -3916.5122 -2623.7217 -3442.0576]])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._nodelist[1].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tensortype': 'tensor32',\n",
       " 'with_grad': False,\n",
       " 'npar_data': array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], dtype=float32),\n",
       " 'grad': None,\n",
       " 'shape': (4, 1)}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._nodelist[27].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 28, 'pointer': 13, 'path': [23, 22, 21, 19, 16, 13], 'flag': True},\n",
       " {'loss': 28, 'pointer': 15, 'path': [23, 22, 21, 19, 17, 14], 'flag': True},\n",
       " {'loss': 28, 'pointer': 16, 'path': [23, 22, 21, 19, 17, 15], 'flag': True},\n",
       " {'loss': 28,\n",
       "  'pointer': 7,\n",
       "  'path': [23, 22, 21, 19, 16, 12, 10, 7],\n",
       "  'flag': True},\n",
       " {'loss': 28,\n",
       "  'pointer': 9,\n",
       "  'path': [23, 22, 21, 19, 16, 12, 11, 8],\n",
       "  'flag': True},\n",
       " {'loss': 28,\n",
       "  'pointer': 10,\n",
       "  'path': [23, 22, 21, 19, 16, 12, 11, 9],\n",
       "  'flag': True},\n",
       " {'loss': 28,\n",
       "  'pointer': 0,\n",
       "  'path': [23, 22, 21, 19, 16, 12, 10, 6, 4, 0],\n",
       "  'flag': True},\n",
       " {'loss': 28,\n",
       "  'pointer': 1,\n",
       "  'path': [23, 22, 21, 19, 16, 12, 10, 6, 4, 1],\n",
       "  'flag': True},\n",
       " {'loss': 28,\n",
       "  'pointer': 3,\n",
       "  'path': [23, 22, 21, 19, 16, 12, 10, 6, 5, 2],\n",
       "  'flag': True},\n",
       " {'loss': 28,\n",
       "  'pointer': 4,\n",
       "  'path': [23, 22, 21, 19, 16, 12, 10, 6, 5, 3],\n",
       "  'flag': True}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._valid_path_reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._valid_path_reversed[-2]['path']==cg._valid_path_reversed[0]['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._flow_reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 28,\n",
       "  'pointer': 27,\n",
       "  'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]\n",
       "     [1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[43.864197  40.097336 ]\n",
       "     [56.40194   49.18397  ]\n",
       "     [ 3.6946754  3.7637796]\n",
       "     [48.213287  40.774857 ]])},\n",
       "   {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "    'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "     [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "   {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "    'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "     [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "   {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[0. 1. 1. 2.]\n",
       "     [2. 1. 3. 0.]]),\n",
       "    'to': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "    'grad': tensor32([[-1. -1. -1. -1.]\n",
       "     [-1. -1. -1. -1.]])},\n",
       "   {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "     [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "     [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "     [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "   {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "     [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "     [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "     [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "     [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "     [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "     [ -9.142022   -9.295835 ]\n",
       "     [  6.307816    3.4044743]\n",
       "     [ 13.965539   10.759737 ]\n",
       "     [-19.731525  -18.588627 ]\n",
       "     [-16.068378  -14.705788 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.931317  ]\n",
       "     [ 0.25348568]\n",
       "     [-2.0256736 ]\n",
       "     [-1.8860062 ]])},\n",
       "   {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "     [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "     [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "     [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "     [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "     [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "   {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "     [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "     [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "     [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[-2.909926  -2.9052634]\n",
       "     [-6.658105  -4.9792333]\n",
       "     [ 2.3443272  1.9698756]\n",
       "     [ 2.2487833  3.089097 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.3112482 ]\n",
       "     [-0.06415135]\n",
       "     [ 0.46190712]\n",
       "     [-0.9451939 ]\n",
       "     [-1.6935313 ]\n",
       "     [-1.6012375 ]])},\n",
       "   {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[3. 4. 2.]\n",
       "     [1. 2. 3.]]),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "     [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "     [ 0.2974406   0.34778696  0.9160031 ]\n",
       "     [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "   {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "     [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "     [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[3. 1.]\n",
       "     [4. 2.]\n",
       "     [2. 3.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-2.1875005 ]\n",
       "     [ 0.36007312]\n",
       "     [-1.7711484 ]\n",
       "     [ 1.2654616 ]])},\n",
       "   {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])}],\n",
       "  'flag': True},\n",
       " {'loss': 28,\n",
       "  'pointer': 19,\n",
       "  'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]\n",
       "     [1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[43.864197  40.097336 ]\n",
       "     [56.40194   49.18397  ]\n",
       "     [ 3.6946754  3.7637796]\n",
       "     [48.213287  40.774857 ]])},\n",
       "   {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "    'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "     [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "   {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "    'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "     [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "   {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[0. 1. 1. 2.]\n",
       "     [2. 1. 3. 0.]]),\n",
       "    'to': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "    'grad': tensor32([[-1. -1. -1. -1.]\n",
       "     [-1. -1. -1. -1.]])},\n",
       "   {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "     [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "     [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "     [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "   {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "     [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "     [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "     [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "     [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "     [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "     [ -9.142022   -9.295835 ]\n",
       "     [  6.307816    3.4044743]\n",
       "     [ 13.965539   10.759737 ]\n",
       "     [-19.731525  -18.588627 ]\n",
       "     [-16.068378  -14.705788 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.931317  ]\n",
       "     [ 0.25348568]\n",
       "     [-2.0256736 ]\n",
       "     [-1.8860062 ]])},\n",
       "   {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "     [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "     [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "     [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "     [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "     [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "   {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "     [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "     [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "     [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[-2.909926  -2.9052634]\n",
       "     [-6.658105  -4.9792333]\n",
       "     [ 2.3443272  1.9698756]\n",
       "     [ 2.2487833  3.089097 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.3112482 ]\n",
       "     [-0.06415135]\n",
       "     [ 0.46190712]\n",
       "     [-0.9451939 ]\n",
       "     [-1.6935313 ]\n",
       "     [-1.6012375 ]])},\n",
       "   {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[3. 4. 2.]\n",
       "     [1. 2. 3.]]),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "     [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "     [ 0.2974406   0.34778696  0.9160031 ]\n",
       "     [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "   {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "     [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "     [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[3. 1.]\n",
       "     [4. 2.]\n",
       "     [2. 3.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-2.1875005 ]\n",
       "     [ 0.36007312]\n",
       "     [-1.7711484 ]\n",
       "     [ 1.2654616 ]])},\n",
       "   {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])}],\n",
       "  'flag': True},\n",
       " {'loss': 28,\n",
       "  'pointer': 13,\n",
       "  'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]\n",
       "     [1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[43.864197  40.097336 ]\n",
       "     [56.40194   49.18397  ]\n",
       "     [ 3.6946754  3.7637796]\n",
       "     [48.213287  40.774857 ]])},\n",
       "   {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "    'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "     [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "   {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "    'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "     [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "   {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[0. 1. 1. 2.]\n",
       "     [2. 1. 3. 0.]]),\n",
       "    'to': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "    'grad': tensor32([[-1. -1. -1. -1.]\n",
       "     [-1. -1. -1. -1.]])},\n",
       "   {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "     [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "     [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "     [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "   {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "     [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "     [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "     [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "     [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "     [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "     [ -9.142022   -9.295835 ]\n",
       "     [  6.307816    3.4044743]\n",
       "     [ 13.965539   10.759737 ]\n",
       "     [-19.731525  -18.588627 ]\n",
       "     [-16.068378  -14.705788 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.931317  ]\n",
       "     [ 0.25348568]\n",
       "     [-2.0256736 ]\n",
       "     [-1.8860062 ]])},\n",
       "   {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "     [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "     [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "     [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "     [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "     [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "   {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "     [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "     [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "     [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[-2.909926  -2.9052634]\n",
       "     [-6.658105  -4.9792333]\n",
       "     [ 2.3443272  1.9698756]\n",
       "     [ 2.2487833  3.089097 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.3112482 ]\n",
       "     [-0.06415135]\n",
       "     [ 0.46190712]\n",
       "     [-0.9451939 ]\n",
       "     [-1.6935313 ]\n",
       "     [-1.6012375 ]])},\n",
       "   {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[3. 4. 2.]\n",
       "     [1. 2. 3.]]),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "     [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "     [ 0.2974406   0.34778696  0.9160031 ]\n",
       "     [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "   {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "     [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "     [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[3. 1.]\n",
       "     [4. 2.]\n",
       "     [2. 3.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-2.1875005 ]\n",
       "     [ 0.36007312]\n",
       "     [-1.7711484 ]\n",
       "     [ 1.2654616 ]])},\n",
       "   {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])}],\n",
       "  'flag': True},\n",
       " {'loss': 28,\n",
       "  'pointer': 15,\n",
       "  'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]\n",
       "     [1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[43.864197  40.097336 ]\n",
       "     [56.40194   49.18397  ]\n",
       "     [ 3.6946754  3.7637796]\n",
       "     [48.213287  40.774857 ]])},\n",
       "   {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "    'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "     [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "   {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "    'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "     [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "   {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[0. 1. 1. 2.]\n",
       "     [2. 1. 3. 0.]]),\n",
       "    'to': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "    'grad': tensor32([[-1. -1. -1. -1.]\n",
       "     [-1. -1. -1. -1.]])},\n",
       "   {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "     [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "     [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "     [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "   {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "     [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "     [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "     [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "     [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "     [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "     [ -9.142022   -9.295835 ]\n",
       "     [  6.307816    3.4044743]\n",
       "     [ 13.965539   10.759737 ]\n",
       "     [-19.731525  -18.588627 ]\n",
       "     [-16.068378  -14.705788 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.931317  ]\n",
       "     [ 0.25348568]\n",
       "     [-2.0256736 ]\n",
       "     [-1.8860062 ]])},\n",
       "   {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "     [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "     [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "     [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "     [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "     [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "   {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "     [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "     [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "     [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[-2.909926  -2.9052634]\n",
       "     [-6.658105  -4.9792333]\n",
       "     [ 2.3443272  1.9698756]\n",
       "     [ 2.2487833  3.089097 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.3112482 ]\n",
       "     [-0.06415135]\n",
       "     [ 0.46190712]\n",
       "     [-0.9451939 ]\n",
       "     [-1.6935313 ]\n",
       "     [-1.6012375 ]])},\n",
       "   {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[3. 4. 2.]\n",
       "     [1. 2. 3.]]),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "     [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "     [ 0.2974406   0.34778696  0.9160031 ]\n",
       "     [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "   {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "     [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "     [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[3. 1.]\n",
       "     [4. 2.]\n",
       "     [2. 3.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-2.1875005 ]\n",
       "     [ 0.36007312]\n",
       "     [-1.7711484 ]\n",
       "     [ 1.2654616 ]])},\n",
       "   {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])}],\n",
       "  'flag': True},\n",
       " {'loss': 28,\n",
       "  'pointer': 16,\n",
       "  'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]\n",
       "     [1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[43.864197  40.097336 ]\n",
       "     [56.40194   49.18397  ]\n",
       "     [ 3.6946754  3.7637796]\n",
       "     [48.213287  40.774857 ]])},\n",
       "   {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "    'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "     [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "   {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "    'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "     [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "   {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[0. 1. 1. 2.]\n",
       "     [2. 1. 3. 0.]]),\n",
       "    'to': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "    'grad': tensor32([[-1. -1. -1. -1.]\n",
       "     [-1. -1. -1. -1.]])},\n",
       "   {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "     [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "     [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "     [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "   {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "     [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "     [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "     [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "     [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "     [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "     [ -9.142022   -9.295835 ]\n",
       "     [  6.307816    3.4044743]\n",
       "     [ 13.965539   10.759737 ]\n",
       "     [-19.731525  -18.588627 ]\n",
       "     [-16.068378  -14.705788 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.931317  ]\n",
       "     [ 0.25348568]\n",
       "     [-2.0256736 ]\n",
       "     [-1.8860062 ]])},\n",
       "   {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "     [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "     [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "     [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "     [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "     [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "   {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "     [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "     [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "     [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[-2.909926  -2.9052634]\n",
       "     [-6.658105  -4.9792333]\n",
       "     [ 2.3443272  1.9698756]\n",
       "     [ 2.2487833  3.089097 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.3112482 ]\n",
       "     [-0.06415135]\n",
       "     [ 0.46190712]\n",
       "     [-0.9451939 ]\n",
       "     [-1.6935313 ]\n",
       "     [-1.6012375 ]])},\n",
       "   {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[3. 4. 2.]\n",
       "     [1. 2. 3.]]),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "     [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "     [ 0.2974406   0.34778696  0.9160031 ]\n",
       "     [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "   {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "     [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "     [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[3. 1.]\n",
       "     [4. 2.]\n",
       "     [2. 3.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-2.1875005 ]\n",
       "     [ 0.36007312]\n",
       "     [-1.7711484 ]\n",
       "     [ 1.2654616 ]])},\n",
       "   {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])}],\n",
       "  'flag': True},\n",
       " {'loss': 28,\n",
       "  'pointer': 7,\n",
       "  'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]\n",
       "     [1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[43.864197  40.097336 ]\n",
       "     [56.40194   49.18397  ]\n",
       "     [ 3.6946754  3.7637796]\n",
       "     [48.213287  40.774857 ]])},\n",
       "   {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "    'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "     [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "   {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "    'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "     [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "   {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[0. 1. 1. 2.]\n",
       "     [2. 1. 3. 0.]]),\n",
       "    'to': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "    'grad': tensor32([[-1. -1. -1. -1.]\n",
       "     [-1. -1. -1. -1.]])},\n",
       "   {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "     [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "     [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "     [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "   {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "     [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "     [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "     [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "     [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "     [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "     [ -9.142022   -9.295835 ]\n",
       "     [  6.307816    3.4044743]\n",
       "     [ 13.965539   10.759737 ]\n",
       "     [-19.731525  -18.588627 ]\n",
       "     [-16.068378  -14.705788 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.931317  ]\n",
       "     [ 0.25348568]\n",
       "     [-2.0256736 ]\n",
       "     [-1.8860062 ]])},\n",
       "   {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "     [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "     [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "     [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "     [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "     [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "   {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "     [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "     [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "     [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[-2.909926  -2.9052634]\n",
       "     [-6.658105  -4.9792333]\n",
       "     [ 2.3443272  1.9698756]\n",
       "     [ 2.2487833  3.089097 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.3112482 ]\n",
       "     [-0.06415135]\n",
       "     [ 0.46190712]\n",
       "     [-0.9451939 ]\n",
       "     [-1.6935313 ]\n",
       "     [-1.6012375 ]])},\n",
       "   {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[3. 4. 2.]\n",
       "     [1. 2. 3.]]),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "     [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "     [ 0.2974406   0.34778696  0.9160031 ]\n",
       "     [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "   {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "     [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "     [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[3. 1.]\n",
       "     [4. 2.]\n",
       "     [2. 3.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-2.1875005 ]\n",
       "     [ 0.36007312]\n",
       "     [-1.7711484 ]\n",
       "     [ 1.2654616 ]])},\n",
       "   {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])}],\n",
       "  'flag': True},\n",
       " {'loss': 28,\n",
       "  'pointer': 9,\n",
       "  'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]\n",
       "     [1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[43.864197  40.097336 ]\n",
       "     [56.40194   49.18397  ]\n",
       "     [ 3.6946754  3.7637796]\n",
       "     [48.213287  40.774857 ]])},\n",
       "   {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "    'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "     [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "   {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "    'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "     [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "   {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[0. 1. 1. 2.]\n",
       "     [2. 1. 3. 0.]]),\n",
       "    'to': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "    'grad': tensor32([[-1. -1. -1. -1.]\n",
       "     [-1. -1. -1. -1.]])},\n",
       "   {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "     [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "     [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "     [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "   {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "     [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "     [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "     [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "     [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "     [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "     [ -9.142022   -9.295835 ]\n",
       "     [  6.307816    3.4044743]\n",
       "     [ 13.965539   10.759737 ]\n",
       "     [-19.731525  -18.588627 ]\n",
       "     [-16.068378  -14.705788 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.931317  ]\n",
       "     [ 0.25348568]\n",
       "     [-2.0256736 ]\n",
       "     [-1.8860062 ]])},\n",
       "   {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "     [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "     [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "     [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "     [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "     [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "   {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "     [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "     [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "     [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[-2.909926  -2.9052634]\n",
       "     [-6.658105  -4.9792333]\n",
       "     [ 2.3443272  1.9698756]\n",
       "     [ 2.2487833  3.089097 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.3112482 ]\n",
       "     [-0.06415135]\n",
       "     [ 0.46190712]\n",
       "     [-0.9451939 ]\n",
       "     [-1.6935313 ]\n",
       "     [-1.6012375 ]])},\n",
       "   {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[3. 4. 2.]\n",
       "     [1. 2. 3.]]),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "     [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "     [ 0.2974406   0.34778696  0.9160031 ]\n",
       "     [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "   {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "     [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "     [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[3. 1.]\n",
       "     [4. 2.]\n",
       "     [2. 3.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-2.1875005 ]\n",
       "     [ 0.36007312]\n",
       "     [-1.7711484 ]\n",
       "     [ 1.2654616 ]])},\n",
       "   {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])}],\n",
       "  'flag': True},\n",
       " {'loss': 28,\n",
       "  'pointer': 10,\n",
       "  'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]\n",
       "     [1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[43.864197  40.097336 ]\n",
       "     [56.40194   49.18397  ]\n",
       "     [ 3.6946754  3.7637796]\n",
       "     [48.213287  40.774857 ]])},\n",
       "   {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "    'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "     [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "   {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "    'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "     [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "   {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[0. 1. 1. 2.]\n",
       "     [2. 1. 3. 0.]]),\n",
       "    'to': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "    'grad': tensor32([[-1. -1. -1. -1.]\n",
       "     [-1. -1. -1. -1.]])},\n",
       "   {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "     [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "     [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "     [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "   {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "     [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "     [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "     [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "     [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "     [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "     [ -9.142022   -9.295835 ]\n",
       "     [  6.307816    3.4044743]\n",
       "     [ 13.965539   10.759737 ]\n",
       "     [-19.731525  -18.588627 ]\n",
       "     [-16.068378  -14.705788 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.931317  ]\n",
       "     [ 0.25348568]\n",
       "     [-2.0256736 ]\n",
       "     [-1.8860062 ]])},\n",
       "   {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "     [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "     [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "     [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "     [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "     [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "   {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "     [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "     [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "     [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[-2.909926  -2.9052634]\n",
       "     [-6.658105  -4.9792333]\n",
       "     [ 2.3443272  1.9698756]\n",
       "     [ 2.2487833  3.089097 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.3112482 ]\n",
       "     [-0.06415135]\n",
       "     [ 0.46190712]\n",
       "     [-0.9451939 ]\n",
       "     [-1.6935313 ]\n",
       "     [-1.6012375 ]])},\n",
       "   {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[3. 4. 2.]\n",
       "     [1. 2. 3.]]),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "     [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "     [ 0.2974406   0.34778696  0.9160031 ]\n",
       "     [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "   {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "     [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "     [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[3. 1.]\n",
       "     [4. 2.]\n",
       "     [2. 3.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-2.1875005 ]\n",
       "     [ 0.36007312]\n",
       "     [-1.7711484 ]\n",
       "     [ 1.2654616 ]])},\n",
       "   {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])}],\n",
       "  'flag': True},\n",
       " {'loss': 28,\n",
       "  'pointer': 0,\n",
       "  'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]\n",
       "     [1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[43.864197  40.097336 ]\n",
       "     [56.40194   49.18397  ]\n",
       "     [ 3.6946754  3.7637796]\n",
       "     [48.213287  40.774857 ]])},\n",
       "   {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "    'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "     [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "   {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "    'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "     [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "   {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[0. 1. 1. 2.]\n",
       "     [2. 1. 3. 0.]]),\n",
       "    'to': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "    'grad': tensor32([[-1. -1. -1. -1.]\n",
       "     [-1. -1. -1. -1.]])},\n",
       "   {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "     [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "     [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "     [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "   {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "     [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "     [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "     [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "     [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "     [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "     [ -9.142022   -9.295835 ]\n",
       "     [  6.307816    3.4044743]\n",
       "     [ 13.965539   10.759737 ]\n",
       "     [-19.731525  -18.588627 ]\n",
       "     [-16.068378  -14.705788 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.931317  ]\n",
       "     [ 0.25348568]\n",
       "     [-2.0256736 ]\n",
       "     [-1.8860062 ]])},\n",
       "   {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "     [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "     [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "     [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "     [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "     [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "   {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "     [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "     [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "     [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[-2.909926  -2.9052634]\n",
       "     [-6.658105  -4.9792333]\n",
       "     [ 2.3443272  1.9698756]\n",
       "     [ 2.2487833  3.089097 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.3112482 ]\n",
       "     [-0.06415135]\n",
       "     [ 0.46190712]\n",
       "     [-0.9451939 ]\n",
       "     [-1.6935313 ]\n",
       "     [-1.6012375 ]])},\n",
       "   {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[3. 4. 2.]\n",
       "     [1. 2. 3.]]),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "     [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "     [ 0.2974406   0.34778696  0.9160031 ]\n",
       "     [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "   {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "     [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "     [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[3. 1.]\n",
       "     [4. 2.]\n",
       "     [2. 3.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-2.1875005 ]\n",
       "     [ 0.36007312]\n",
       "     [-1.7711484 ]\n",
       "     [ 1.2654616 ]])},\n",
       "   {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])}],\n",
       "  'flag': True},\n",
       " {'loss': 28,\n",
       "  'pointer': 1,\n",
       "  'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]\n",
       "     [1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[43.864197  40.097336 ]\n",
       "     [56.40194   49.18397  ]\n",
       "     [ 3.6946754  3.7637796]\n",
       "     [48.213287  40.774857 ]])},\n",
       "   {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "    'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "     [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "   {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "    'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "     [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "   {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[0. 1. 1. 2.]\n",
       "     [2. 1. 3. 0.]]),\n",
       "    'to': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "    'grad': tensor32([[-1. -1. -1. -1.]\n",
       "     [-1. -1. -1. -1.]])},\n",
       "   {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "     [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "     [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "     [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "   {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "     [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "     [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "     [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "     [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "     [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "     [ -9.142022   -9.295835 ]\n",
       "     [  6.307816    3.4044743]\n",
       "     [ 13.965539   10.759737 ]\n",
       "     [-19.731525  -18.588627 ]\n",
       "     [-16.068378  -14.705788 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.931317  ]\n",
       "     [ 0.25348568]\n",
       "     [-2.0256736 ]\n",
       "     [-1.8860062 ]])},\n",
       "   {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "     [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "     [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "     [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "     [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "     [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "   {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "     [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "     [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "     [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[-2.909926  -2.9052634]\n",
       "     [-6.658105  -4.9792333]\n",
       "     [ 2.3443272  1.9698756]\n",
       "     [ 2.2487833  3.089097 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.3112482 ]\n",
       "     [-0.06415135]\n",
       "     [ 0.46190712]\n",
       "     [-0.9451939 ]\n",
       "     [-1.6935313 ]\n",
       "     [-1.6012375 ]])},\n",
       "   {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[3. 4. 2.]\n",
       "     [1. 2. 3.]]),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "     [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "     [ 0.2974406   0.34778696  0.9160031 ]\n",
       "     [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "   {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "     [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "     [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[3. 1.]\n",
       "     [4. 2.]\n",
       "     [2. 3.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-2.1875005 ]\n",
       "     [ 0.36007312]\n",
       "     [-1.7711484 ]\n",
       "     [ 1.2654616 ]])},\n",
       "   {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])}],\n",
       "  'flag': True},\n",
       " {'loss': 28,\n",
       "  'pointer': 3,\n",
       "  'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]\n",
       "     [1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[43.864197  40.097336 ]\n",
       "     [56.40194   49.18397  ]\n",
       "     [ 3.6946754  3.7637796]\n",
       "     [48.213287  40.774857 ]])},\n",
       "   {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "    'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "     [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "   {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "    'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "     [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "   {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[0. 1. 1. 2.]\n",
       "     [2. 1. 3. 0.]]),\n",
       "    'to': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "    'grad': tensor32([[-1. -1. -1. -1.]\n",
       "     [-1. -1. -1. -1.]])},\n",
       "   {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "     [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "     [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "     [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "   {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "     [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "     [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "     [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "     [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "     [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "     [ -9.142022   -9.295835 ]\n",
       "     [  6.307816    3.4044743]\n",
       "     [ 13.965539   10.759737 ]\n",
       "     [-19.731525  -18.588627 ]\n",
       "     [-16.068378  -14.705788 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.931317  ]\n",
       "     [ 0.25348568]\n",
       "     [-2.0256736 ]\n",
       "     [-1.8860062 ]])},\n",
       "   {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "     [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "     [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "     [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "     [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "     [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "   {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "     [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "     [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "     [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[-2.909926  -2.9052634]\n",
       "     [-6.658105  -4.9792333]\n",
       "     [ 2.3443272  1.9698756]\n",
       "     [ 2.2487833  3.089097 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.3112482 ]\n",
       "     [-0.06415135]\n",
       "     [ 0.46190712]\n",
       "     [-0.9451939 ]\n",
       "     [-1.6935313 ]\n",
       "     [-1.6012375 ]])},\n",
       "   {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[3. 4. 2.]\n",
       "     [1. 2. 3.]]),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "     [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "     [ 0.2974406   0.34778696  0.9160031 ]\n",
       "     [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "   {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "     [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "     [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[3. 1.]\n",
       "     [4. 2.]\n",
       "     [2. 3.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-2.1875005 ]\n",
       "     [ 0.36007312]\n",
       "     [-1.7711484 ]\n",
       "     [ 1.2654616 ]])},\n",
       "   {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])}],\n",
       "  'flag': True},\n",
       " {'loss': 28,\n",
       "  'pointer': 4,\n",
       "  'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]\n",
       "     [1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[152.1741 ]\n",
       "     [133.81995]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[43.864197  40.097336 ]\n",
       "     [56.40194   49.18397  ]\n",
       "     [ 3.6946754  3.7637796]\n",
       "     [48.213287  40.774857 ]])},\n",
       "   {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "    'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "     [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "   {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "     [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "    'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "    'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "     [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "   {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "     [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[0. 1. 1. 2.]\n",
       "     [2. 1. 3. 0.]]),\n",
       "    'to': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "    'grad': tensor32([[-1. -1. -1. -1.]\n",
       "     [-1. -1. -1. -1.]])},\n",
       "   {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "     [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "     [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "     [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "   {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "     [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "     [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "     [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "     [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "     [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "    'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "     [ -9.142022   -9.295835 ]\n",
       "     [  6.307816    3.4044743]\n",
       "     [ 13.965539   10.759737 ]\n",
       "     [-19.731525  -18.588627 ]\n",
       "     [-16.068378  -14.705788 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.931317  ]\n",
       "     [ 0.25348568]\n",
       "     [-2.0256736 ]\n",
       "     [-1.8860062 ]])},\n",
       "   {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "    'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "     [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "     [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "     [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "     [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "     [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "   {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "     [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "     [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "     [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "    'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[-2.909926  -2.9052634]\n",
       "     [-6.658105  -4.9792333]\n",
       "     [ 2.3443272  1.9698756]\n",
       "     [ 2.2487833  3.089097 ]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.3112482 ]\n",
       "     [-0.06415135]\n",
       "     [ 0.46190712]\n",
       "     [-0.9451939 ]\n",
       "     [-1.6935313 ]\n",
       "     [-1.6012375 ]])},\n",
       "   {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "    'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])},\n",
       "   {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "    'forward': {'op': 'add',\n",
       "     'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1. 1. 1.]\n",
       "     [1. 1. 1. 1.]])},\n",
       "   {'from': tensor32([[3. 4. 2.]\n",
       "     [1. 2. 3.]]),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "     [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "     [ 0.2974406   0.34778696  0.9160031 ]\n",
       "     [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "   {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "     [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "     [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "    'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[3. 1.]\n",
       "     [4. 2.]\n",
       "     [2. 3.]])},\n",
       "   {'from': tensor32([[1.]\n",
       "     [1.]]),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'pos': 'right'},\n",
       "    'grad': tensor32([[-2.1875005 ]\n",
       "     [ 0.36007312]\n",
       "     [-1.7711484 ]\n",
       "     [ 1.2654616 ]])},\n",
       "   {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "    'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'forward': {'op': 'dot',\n",
       "     'with': tensor32([[1.]\n",
       "      [1.]])},\n",
       "    'pos': 'left',\n",
       "    'grad': tensor32([[1. 1.]])}],\n",
       "  'flag': True}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._valid_path_reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_nodelist': [tensor32([[3. 4. 2.]\n",
       "   [1. 2. 3.]]),\n",
       "  myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "   [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "   [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "  tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "   [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "  tensor32([[1.]\n",
       "   [1.]]),\n",
       "  myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "  tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "   [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "  tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "   [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "  myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "   [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "   [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "   [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "  tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "   [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "  tensor32([[1.]\n",
       "   [1.]]),\n",
       "  myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "  tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "   [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "  tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "   [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "  myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "   [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "   [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "   [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "   [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "   [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "  tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "   [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "  tensor32([[1.]\n",
       "   [1.]]),\n",
       "  myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "  tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "   [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "  tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "   [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "  tensor32([[0. 1. 1. 2.]\n",
       "   [2. 1. 3. 0.]]),\n",
       "  -1,\n",
       "  tensor32([[-0. -1. -1. -2.]\n",
       "   [-2. -1. -3. -0.]]),\n",
       "  tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "   [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "  2,\n",
       "  tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "   [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "  0.5,\n",
       "  tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "   [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "  tensor32([[1.]\n",
       "   [1.]\n",
       "   [1.]\n",
       "   [1.]]),\n",
       "  tensor32([[152.1741 ]\n",
       "   [133.81995]])],\n",
       " '_edgelist': [{'from': tensor32([[3. 4. 2.]\n",
       "    [1. 2. 3.]]),\n",
       "   'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "    [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "   'forward': {'op': 'dot',\n",
       "    'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "     [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "     [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "    'pos': 'right'},\n",
       "   'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "    [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "    [ 0.2974406   0.34778696  0.9160031 ]\n",
       "    [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "  {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "    [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "    [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "   'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "    [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "   'forward': {'op': 'dot',\n",
       "    'with': tensor32([[3. 4. 2.]\n",
       "     [1. 2. 3.]])},\n",
       "   'pos': 'left',\n",
       "   'grad': tensor32([[3. 1.]\n",
       "    [4. 2.]\n",
       "    [2. 3.]])},\n",
       "  {'from': tensor32([[1.]\n",
       "    [1.]]),\n",
       "   'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "    [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "   'forward': {'op': 'dot',\n",
       "    'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "    'pos': 'right'},\n",
       "   'grad': tensor32([[-2.1875005 ]\n",
       "    [ 0.36007312]\n",
       "    [-1.7711484 ]\n",
       "    [ 1.2654616 ]])},\n",
       "  {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "   'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "    [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "   'forward': {'op': 'dot',\n",
       "    'with': tensor32([[1.]\n",
       "     [1.]])},\n",
       "   'pos': 'left',\n",
       "   'grad': tensor32([[1. 1.]])},\n",
       "  {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "    [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "   'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "    [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "   'forward': {'op': 'add',\n",
       "    'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "     [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "    'pos': 'right'},\n",
       "   'grad': tensor32([[1. 1. 1. 1.]\n",
       "    [1. 1. 1. 1.]])},\n",
       "  {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "    [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "   'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "    [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "   'forward': {'op': 'add',\n",
       "    'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "     [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "   'pos': 'left',\n",
       "   'grad': tensor32([[1. 1. 1. 1.]\n",
       "    [1. 1. 1. 1.]])},\n",
       "  {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "    [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "   'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "    [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "   'forward': {'op': 'dot',\n",
       "    'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "     [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "     [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "     [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "    'pos': 'right'},\n",
       "   'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "    [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "    [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "    [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "    [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "    [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "  {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "    [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "    [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "    [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "   'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "    [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "   'forward': {'op': 'dot',\n",
       "    'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "     [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "   'pos': 'left',\n",
       "   'grad': tensor32([[-2.909926  -2.9052634]\n",
       "    [-6.658105  -4.9792333]\n",
       "    [ 2.3443272  1.9698756]\n",
       "    [ 2.2487833  3.089097 ]])},\n",
       "  {'from': tensor32([[1.]\n",
       "    [1.]]),\n",
       "   'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "    [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "   'forward': {'op': 'dot',\n",
       "    'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "    'pos': 'right'},\n",
       "   'grad': tensor32([[-0.3112482 ]\n",
       "    [-0.06415135]\n",
       "    [ 0.46190712]\n",
       "    [-0.9451939 ]\n",
       "    [-1.6935313 ]\n",
       "    [-1.6012375 ]])},\n",
       "  {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "   'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "    [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "   'forward': {'op': 'dot',\n",
       "    'with': tensor32([[1.]\n",
       "     [1.]])},\n",
       "   'pos': 'left',\n",
       "   'grad': tensor32([[1. 1.]])},\n",
       "  {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "    [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "   'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "    [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "   'forward': {'op': 'add',\n",
       "    'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "     [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "    'pos': 'right'},\n",
       "   'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "    [1. 1. 1. 1. 1. 1.]])},\n",
       "  {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "    [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "   'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "    [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "   'forward': {'op': 'add',\n",
       "    'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "     [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "   'pos': 'left',\n",
       "   'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "    [1. 1. 1. 1. 1. 1.]])},\n",
       "  {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "    [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "   'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "    [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "   'forward': {'op': 'dot',\n",
       "    'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "     [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "     [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "     [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "     [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "     [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "    'pos': 'right'},\n",
       "   'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "    [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "    [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "    [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "  {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "    [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "    [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "    [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "    [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "    [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "   'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "    [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "   'forward': {'op': 'dot',\n",
       "    'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "     [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "   'pos': 'left',\n",
       "   'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "    [ -9.142022   -9.295835 ]\n",
       "    [  6.307816    3.4044743]\n",
       "    [ 13.965539   10.759737 ]\n",
       "    [-19.731525  -18.588627 ]\n",
       "    [-16.068378  -14.705788 ]])},\n",
       "  {'from': tensor32([[1.]\n",
       "    [1.]]),\n",
       "   'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "    [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "   'forward': {'op': 'dot',\n",
       "    'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "    'pos': 'right'},\n",
       "   'grad': tensor32([[ 0.931317  ]\n",
       "    [ 0.25348568]\n",
       "    [-2.0256736 ]\n",
       "    [-1.8860062 ]])},\n",
       "  {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "   'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "    [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "   'forward': {'op': 'dot',\n",
       "    'with': tensor32([[1.]\n",
       "     [1.]])},\n",
       "   'pos': 'left',\n",
       "   'grad': tensor32([[1. 1.]])},\n",
       "  {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "    [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "   'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "    [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "   'forward': {'op': 'add',\n",
       "    'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "     [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "    'pos': 'right'},\n",
       "   'grad': tensor32([[1. 1. 1. 1.]\n",
       "    [1. 1. 1. 1.]])},\n",
       "  {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "    [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "   'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "    [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "   'forward': {'op': 'add',\n",
       "    'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "     [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "   'pos': 'left',\n",
       "   'grad': tensor32([[1. 1. 1. 1.]\n",
       "    [1. 1. 1. 1.]])},\n",
       "  {'from': tensor32([[0. 1. 1. 2.]\n",
       "    [2. 1. 3. 0.]]),\n",
       "   'to': tensor32([[-0. -1. -1. -2.]\n",
       "    [-2. -1. -3. -0.]]),\n",
       "   'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "   'grad': tensor32([[-1. -1. -1. -1.]\n",
       "    [-1. -1. -1. -1.]])},\n",
       "  {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "    [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "   'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "    [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "   'forward': {'op': 'add',\n",
       "    'with': tensor32([[-0. -1. -1. -2.]\n",
       "     [-2. -1. -3. -0.]]),\n",
       "    'pos': 'right'},\n",
       "   'grad': tensor32([[1. 1. 1. 1.]\n",
       "    [1. 1. 1. 1.]])},\n",
       "  {'from': tensor32([[-0. -1. -1. -2.]\n",
       "    [-2. -1. -3. -0.]]),\n",
       "   'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "    [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "   'forward': {'op': 'add',\n",
       "    'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "     [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "   'pos': 'left',\n",
       "   'grad': tensor32([[1. 1. 1. 1.]\n",
       "    [1. 1. 1. 1.]])},\n",
       "  {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "    [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "   'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "    [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "   'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "   'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "    [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "  {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "    [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "   'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "    [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "   'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "   'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "    [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "  {'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "    [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "   'to': tensor32([[152.1741 ]\n",
       "    [133.81995]]),\n",
       "   'forward': {'op': 'dot',\n",
       "    'with': tensor32([[1.]\n",
       "     [1.]\n",
       "     [1.]\n",
       "     [1.]]),\n",
       "    'pos': 'right'},\n",
       "   'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "  {'from': tensor32([[1.]\n",
       "    [1.]\n",
       "    [1.]\n",
       "    [1.]]),\n",
       "   'to': tensor32([[152.1741 ]\n",
       "    [133.81995]]),\n",
       "   'forward': {'op': 'dot',\n",
       "    'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "     [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "   'pos': 'left',\n",
       "   'grad': tensor32([[43.864197  40.097336 ]\n",
       "    [56.40194   49.18397  ]\n",
       "    [ 3.6946754  3.7637796]\n",
       "    [48.213287  40.774857 ]])}],\n",
       " '_lossnodes_index': [28],\n",
       " '_parameternodes_index': [],\n",
       " '_flow_reversed': [],\n",
       " '_valid_path_reversed': [{'loss': 28,\n",
       "   'pointer': 27,\n",
       "   'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]\n",
       "       [1.]\n",
       "       [1.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "       [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[43.864197  40.097336 ]\n",
       "      [56.40194   49.18397  ]\n",
       "      [ 3.6946754  3.7637796]\n",
       "      [48.213287  40.774857 ]])},\n",
       "    {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "     'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "      [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "    {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "     'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "      [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "    {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0. -1. -1. -2.]\n",
       "       [-2. -1. -3. -0.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "       [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "       [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "       [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[0. 1. 1. 2.]\n",
       "      [2. 1. 3. 0.]]),\n",
       "     'to': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "     'grad': tensor32([[-1. -1. -1. -1.]\n",
       "      [-1. -1. -1. -1.]])},\n",
       "    {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "       [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "       [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "       [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "       [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "       [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "      [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "      [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "      [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "    {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "       [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "      [ -9.142022   -9.295835 ]\n",
       "      [  6.307816    3.4044743]\n",
       "      [ 13.965539   10.759737 ]\n",
       "      [-19.731525  -18.588627 ]\n",
       "      [-16.068378  -14.705788 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.931317  ]\n",
       "      [ 0.25348568]\n",
       "      [-2.0256736 ]\n",
       "      [-1.8860062 ]])},\n",
       "    {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "       [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "       [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "       [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "       [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "       [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "      [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "      [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "      [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "      [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "      [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "    {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "       [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[-2.909926  -2.9052634]\n",
       "      [-6.658105  -4.9792333]\n",
       "      [ 2.3443272  1.9698756]\n",
       "      [ 2.2487833  3.089097 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.3112482 ]\n",
       "      [-0.06415135]\n",
       "      [ 0.46190712]\n",
       "      [-0.9451939 ]\n",
       "      [-1.6935313 ]\n",
       "      [-1.6012375 ]])},\n",
       "    {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "       [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "       [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]]),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "       [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "       [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "      [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "      [ 0.2974406   0.34778696  0.9160031 ]\n",
       "      [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "    {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[3. 4. 2.]\n",
       "       [1. 2. 3.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[3. 1.]\n",
       "      [4. 2.]\n",
       "      [2. 3.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-2.1875005 ]\n",
       "      [ 0.36007312]\n",
       "      [-1.7711484 ]\n",
       "      [ 1.2654616 ]])},\n",
       "    {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])}],\n",
       "   'flag': True},\n",
       "  {'loss': 28,\n",
       "   'pointer': 19,\n",
       "   'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]\n",
       "       [1.]\n",
       "       [1.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "       [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[43.864197  40.097336 ]\n",
       "      [56.40194   49.18397  ]\n",
       "      [ 3.6946754  3.7637796]\n",
       "      [48.213287  40.774857 ]])},\n",
       "    {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "     'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "      [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "    {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "     'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "      [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "    {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0. -1. -1. -2.]\n",
       "       [-2. -1. -3. -0.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "       [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "       [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "       [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[0. 1. 1. 2.]\n",
       "      [2. 1. 3. 0.]]),\n",
       "     'to': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "     'grad': tensor32([[-1. -1. -1. -1.]\n",
       "      [-1. -1. -1. -1.]])},\n",
       "    {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "       [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "       [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "       [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "       [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "       [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "      [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "      [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "      [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "    {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "       [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "      [ -9.142022   -9.295835 ]\n",
       "      [  6.307816    3.4044743]\n",
       "      [ 13.965539   10.759737 ]\n",
       "      [-19.731525  -18.588627 ]\n",
       "      [-16.068378  -14.705788 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.931317  ]\n",
       "      [ 0.25348568]\n",
       "      [-2.0256736 ]\n",
       "      [-1.8860062 ]])},\n",
       "    {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "       [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "       [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "       [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "       [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "       [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "      [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "      [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "      [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "      [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "      [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "    {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "       [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[-2.909926  -2.9052634]\n",
       "      [-6.658105  -4.9792333]\n",
       "      [ 2.3443272  1.9698756]\n",
       "      [ 2.2487833  3.089097 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.3112482 ]\n",
       "      [-0.06415135]\n",
       "      [ 0.46190712]\n",
       "      [-0.9451939 ]\n",
       "      [-1.6935313 ]\n",
       "      [-1.6012375 ]])},\n",
       "    {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "       [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "       [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]]),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "       [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "       [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "      [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "      [ 0.2974406   0.34778696  0.9160031 ]\n",
       "      [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "    {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[3. 4. 2.]\n",
       "       [1. 2. 3.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[3. 1.]\n",
       "      [4. 2.]\n",
       "      [2. 3.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-2.1875005 ]\n",
       "      [ 0.36007312]\n",
       "      [-1.7711484 ]\n",
       "      [ 1.2654616 ]])},\n",
       "    {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])}],\n",
       "   'flag': True},\n",
       "  {'loss': 28,\n",
       "   'pointer': 13,\n",
       "   'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]\n",
       "       [1.]\n",
       "       [1.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "       [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[43.864197  40.097336 ]\n",
       "      [56.40194   49.18397  ]\n",
       "      [ 3.6946754  3.7637796]\n",
       "      [48.213287  40.774857 ]])},\n",
       "    {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "     'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "      [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "    {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "     'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "      [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "    {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0. -1. -1. -2.]\n",
       "       [-2. -1. -3. -0.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "       [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "       [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "       [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[0. 1. 1. 2.]\n",
       "      [2. 1. 3. 0.]]),\n",
       "     'to': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "     'grad': tensor32([[-1. -1. -1. -1.]\n",
       "      [-1. -1. -1. -1.]])},\n",
       "    {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "       [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "       [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "       [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "       [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "       [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "      [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "      [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "      [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "    {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "       [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "      [ -9.142022   -9.295835 ]\n",
       "      [  6.307816    3.4044743]\n",
       "      [ 13.965539   10.759737 ]\n",
       "      [-19.731525  -18.588627 ]\n",
       "      [-16.068378  -14.705788 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.931317  ]\n",
       "      [ 0.25348568]\n",
       "      [-2.0256736 ]\n",
       "      [-1.8860062 ]])},\n",
       "    {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "       [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "       [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "       [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "       [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "       [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "      [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "      [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "      [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "      [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "      [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "    {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "       [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[-2.909926  -2.9052634]\n",
       "      [-6.658105  -4.9792333]\n",
       "      [ 2.3443272  1.9698756]\n",
       "      [ 2.2487833  3.089097 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.3112482 ]\n",
       "      [-0.06415135]\n",
       "      [ 0.46190712]\n",
       "      [-0.9451939 ]\n",
       "      [-1.6935313 ]\n",
       "      [-1.6012375 ]])},\n",
       "    {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "       [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "       [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]]),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "       [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "       [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "      [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "      [ 0.2974406   0.34778696  0.9160031 ]\n",
       "      [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "    {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[3. 4. 2.]\n",
       "       [1. 2. 3.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[3. 1.]\n",
       "      [4. 2.]\n",
       "      [2. 3.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-2.1875005 ]\n",
       "      [ 0.36007312]\n",
       "      [-1.7711484 ]\n",
       "      [ 1.2654616 ]])},\n",
       "    {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])}],\n",
       "   'flag': True},\n",
       "  {'loss': 28,\n",
       "   'pointer': 15,\n",
       "   'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]\n",
       "       [1.]\n",
       "       [1.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "       [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[43.864197  40.097336 ]\n",
       "      [56.40194   49.18397  ]\n",
       "      [ 3.6946754  3.7637796]\n",
       "      [48.213287  40.774857 ]])},\n",
       "    {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "     'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "      [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "    {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "     'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "      [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "    {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0. -1. -1. -2.]\n",
       "       [-2. -1. -3. -0.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "       [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "       [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "       [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[0. 1. 1. 2.]\n",
       "      [2. 1. 3. 0.]]),\n",
       "     'to': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "     'grad': tensor32([[-1. -1. -1. -1.]\n",
       "      [-1. -1. -1. -1.]])},\n",
       "    {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "       [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "       [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "       [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "       [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "       [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "      [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "      [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "      [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "    {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "       [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "      [ -9.142022   -9.295835 ]\n",
       "      [  6.307816    3.4044743]\n",
       "      [ 13.965539   10.759737 ]\n",
       "      [-19.731525  -18.588627 ]\n",
       "      [-16.068378  -14.705788 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.931317  ]\n",
       "      [ 0.25348568]\n",
       "      [-2.0256736 ]\n",
       "      [-1.8860062 ]])},\n",
       "    {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "       [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "       [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "       [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "       [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "       [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "      [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "      [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "      [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "      [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "      [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "    {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "       [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[-2.909926  -2.9052634]\n",
       "      [-6.658105  -4.9792333]\n",
       "      [ 2.3443272  1.9698756]\n",
       "      [ 2.2487833  3.089097 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.3112482 ]\n",
       "      [-0.06415135]\n",
       "      [ 0.46190712]\n",
       "      [-0.9451939 ]\n",
       "      [-1.6935313 ]\n",
       "      [-1.6012375 ]])},\n",
       "    {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "       [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "       [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]]),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "       [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "       [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "      [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "      [ 0.2974406   0.34778696  0.9160031 ]\n",
       "      [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "    {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[3. 4. 2.]\n",
       "       [1. 2. 3.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[3. 1.]\n",
       "      [4. 2.]\n",
       "      [2. 3.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-2.1875005 ]\n",
       "      [ 0.36007312]\n",
       "      [-1.7711484 ]\n",
       "      [ 1.2654616 ]])},\n",
       "    {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])}],\n",
       "   'flag': True},\n",
       "  {'loss': 28,\n",
       "   'pointer': 16,\n",
       "   'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]\n",
       "       [1.]\n",
       "       [1.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "       [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[43.864197  40.097336 ]\n",
       "      [56.40194   49.18397  ]\n",
       "      [ 3.6946754  3.7637796]\n",
       "      [48.213287  40.774857 ]])},\n",
       "    {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "     'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "      [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "    {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "     'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "      [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "    {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0. -1. -1. -2.]\n",
       "       [-2. -1. -3. -0.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "       [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "       [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "       [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[0. 1. 1. 2.]\n",
       "      [2. 1. 3. 0.]]),\n",
       "     'to': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "     'grad': tensor32([[-1. -1. -1. -1.]\n",
       "      [-1. -1. -1. -1.]])},\n",
       "    {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "       [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "       [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "       [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "       [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "       [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "      [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "      [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "      [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "    {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "       [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "      [ -9.142022   -9.295835 ]\n",
       "      [  6.307816    3.4044743]\n",
       "      [ 13.965539   10.759737 ]\n",
       "      [-19.731525  -18.588627 ]\n",
       "      [-16.068378  -14.705788 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.931317  ]\n",
       "      [ 0.25348568]\n",
       "      [-2.0256736 ]\n",
       "      [-1.8860062 ]])},\n",
       "    {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "       [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "       [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "       [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "       [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "       [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "      [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "      [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "      [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "      [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "      [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "    {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "       [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[-2.909926  -2.9052634]\n",
       "      [-6.658105  -4.9792333]\n",
       "      [ 2.3443272  1.9698756]\n",
       "      [ 2.2487833  3.089097 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.3112482 ]\n",
       "      [-0.06415135]\n",
       "      [ 0.46190712]\n",
       "      [-0.9451939 ]\n",
       "      [-1.6935313 ]\n",
       "      [-1.6012375 ]])},\n",
       "    {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "       [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "       [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]]),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "       [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "       [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "      [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "      [ 0.2974406   0.34778696  0.9160031 ]\n",
       "      [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "    {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[3. 4. 2.]\n",
       "       [1. 2. 3.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[3. 1.]\n",
       "      [4. 2.]\n",
       "      [2. 3.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-2.1875005 ]\n",
       "      [ 0.36007312]\n",
       "      [-1.7711484 ]\n",
       "      [ 1.2654616 ]])},\n",
       "    {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])}],\n",
       "   'flag': True},\n",
       "  {'loss': 28,\n",
       "   'pointer': 7,\n",
       "   'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]\n",
       "       [1.]\n",
       "       [1.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "       [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[43.864197  40.097336 ]\n",
       "      [56.40194   49.18397  ]\n",
       "      [ 3.6946754  3.7637796]\n",
       "      [48.213287  40.774857 ]])},\n",
       "    {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "     'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "      [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "    {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "     'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "      [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "    {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0. -1. -1. -2.]\n",
       "       [-2. -1. -3. -0.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "       [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "       [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "       [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[0. 1. 1. 2.]\n",
       "      [2. 1. 3. 0.]]),\n",
       "     'to': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "     'grad': tensor32([[-1. -1. -1. -1.]\n",
       "      [-1. -1. -1. -1.]])},\n",
       "    {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "       [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "       [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "       [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "       [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "       [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "      [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "      [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "      [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "    {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "       [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "      [ -9.142022   -9.295835 ]\n",
       "      [  6.307816    3.4044743]\n",
       "      [ 13.965539   10.759737 ]\n",
       "      [-19.731525  -18.588627 ]\n",
       "      [-16.068378  -14.705788 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.931317  ]\n",
       "      [ 0.25348568]\n",
       "      [-2.0256736 ]\n",
       "      [-1.8860062 ]])},\n",
       "    {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "       [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "       [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "       [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "       [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "       [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "      [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "      [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "      [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "      [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "      [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "    {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "       [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[-2.909926  -2.9052634]\n",
       "      [-6.658105  -4.9792333]\n",
       "      [ 2.3443272  1.9698756]\n",
       "      [ 2.2487833  3.089097 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.3112482 ]\n",
       "      [-0.06415135]\n",
       "      [ 0.46190712]\n",
       "      [-0.9451939 ]\n",
       "      [-1.6935313 ]\n",
       "      [-1.6012375 ]])},\n",
       "    {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "       [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "       [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]]),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "       [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "       [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "      [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "      [ 0.2974406   0.34778696  0.9160031 ]\n",
       "      [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "    {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[3. 4. 2.]\n",
       "       [1. 2. 3.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[3. 1.]\n",
       "      [4. 2.]\n",
       "      [2. 3.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-2.1875005 ]\n",
       "      [ 0.36007312]\n",
       "      [-1.7711484 ]\n",
       "      [ 1.2654616 ]])},\n",
       "    {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])}],\n",
       "   'flag': True},\n",
       "  {'loss': 28,\n",
       "   'pointer': 9,\n",
       "   'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]\n",
       "       [1.]\n",
       "       [1.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "       [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[43.864197  40.097336 ]\n",
       "      [56.40194   49.18397  ]\n",
       "      [ 3.6946754  3.7637796]\n",
       "      [48.213287  40.774857 ]])},\n",
       "    {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "     'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "      [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "    {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "     'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "      [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "    {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0. -1. -1. -2.]\n",
       "       [-2. -1. -3. -0.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "       [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "       [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "       [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[0. 1. 1. 2.]\n",
       "      [2. 1. 3. 0.]]),\n",
       "     'to': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "     'grad': tensor32([[-1. -1. -1. -1.]\n",
       "      [-1. -1. -1. -1.]])},\n",
       "    {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "       [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "       [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "       [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "       [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "       [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "      [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "      [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "      [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "    {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "       [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "      [ -9.142022   -9.295835 ]\n",
       "      [  6.307816    3.4044743]\n",
       "      [ 13.965539   10.759737 ]\n",
       "      [-19.731525  -18.588627 ]\n",
       "      [-16.068378  -14.705788 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.931317  ]\n",
       "      [ 0.25348568]\n",
       "      [-2.0256736 ]\n",
       "      [-1.8860062 ]])},\n",
       "    {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "       [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "       [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "       [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "       [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "       [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "      [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "      [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "      [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "      [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "      [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "    {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "       [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[-2.909926  -2.9052634]\n",
       "      [-6.658105  -4.9792333]\n",
       "      [ 2.3443272  1.9698756]\n",
       "      [ 2.2487833  3.089097 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.3112482 ]\n",
       "      [-0.06415135]\n",
       "      [ 0.46190712]\n",
       "      [-0.9451939 ]\n",
       "      [-1.6935313 ]\n",
       "      [-1.6012375 ]])},\n",
       "    {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "       [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "       [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]]),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "       [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "       [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "      [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "      [ 0.2974406   0.34778696  0.9160031 ]\n",
       "      [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "    {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[3. 4. 2.]\n",
       "       [1. 2. 3.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[3. 1.]\n",
       "      [4. 2.]\n",
       "      [2. 3.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-2.1875005 ]\n",
       "      [ 0.36007312]\n",
       "      [-1.7711484 ]\n",
       "      [ 1.2654616 ]])},\n",
       "    {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])}],\n",
       "   'flag': True},\n",
       "  {'loss': 28,\n",
       "   'pointer': 10,\n",
       "   'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]\n",
       "       [1.]\n",
       "       [1.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "       [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[43.864197  40.097336 ]\n",
       "      [56.40194   49.18397  ]\n",
       "      [ 3.6946754  3.7637796]\n",
       "      [48.213287  40.774857 ]])},\n",
       "    {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "     'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "      [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "    {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "     'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "      [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "    {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0. -1. -1. -2.]\n",
       "       [-2. -1. -3. -0.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "       [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "       [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "       [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[0. 1. 1. 2.]\n",
       "      [2. 1. 3. 0.]]),\n",
       "     'to': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "     'grad': tensor32([[-1. -1. -1. -1.]\n",
       "      [-1. -1. -1. -1.]])},\n",
       "    {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "       [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "       [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "       [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "       [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "       [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "      [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "      [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "      [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "    {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "       [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "      [ -9.142022   -9.295835 ]\n",
       "      [  6.307816    3.4044743]\n",
       "      [ 13.965539   10.759737 ]\n",
       "      [-19.731525  -18.588627 ]\n",
       "      [-16.068378  -14.705788 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.931317  ]\n",
       "      [ 0.25348568]\n",
       "      [-2.0256736 ]\n",
       "      [-1.8860062 ]])},\n",
       "    {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "       [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "       [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "       [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "       [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "       [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "      [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "      [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "      [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "      [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "      [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "    {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "       [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[-2.909926  -2.9052634]\n",
       "      [-6.658105  -4.9792333]\n",
       "      [ 2.3443272  1.9698756]\n",
       "      [ 2.2487833  3.089097 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.3112482 ]\n",
       "      [-0.06415135]\n",
       "      [ 0.46190712]\n",
       "      [-0.9451939 ]\n",
       "      [-1.6935313 ]\n",
       "      [-1.6012375 ]])},\n",
       "    {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "       [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "       [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]]),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "       [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "       [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "      [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "      [ 0.2974406   0.34778696  0.9160031 ]\n",
       "      [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "    {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[3. 4. 2.]\n",
       "       [1. 2. 3.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[3. 1.]\n",
       "      [4. 2.]\n",
       "      [2. 3.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-2.1875005 ]\n",
       "      [ 0.36007312]\n",
       "      [-1.7711484 ]\n",
       "      [ 1.2654616 ]])},\n",
       "    {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])}],\n",
       "   'flag': True},\n",
       "  {'loss': 28,\n",
       "   'pointer': 0,\n",
       "   'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]\n",
       "       [1.]\n",
       "       [1.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "       [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[43.864197  40.097336 ]\n",
       "      [56.40194   49.18397  ]\n",
       "      [ 3.6946754  3.7637796]\n",
       "      [48.213287  40.774857 ]])},\n",
       "    {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "     'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "      [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "    {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "     'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "      [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "    {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0. -1. -1. -2.]\n",
       "       [-2. -1. -3. -0.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "       [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "       [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "       [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[0. 1. 1. 2.]\n",
       "      [2. 1. 3. 0.]]),\n",
       "     'to': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "     'grad': tensor32([[-1. -1. -1. -1.]\n",
       "      [-1. -1. -1. -1.]])},\n",
       "    {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "       [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "       [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "       [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "       [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "       [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "      [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "      [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "      [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "    {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "       [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "      [ -9.142022   -9.295835 ]\n",
       "      [  6.307816    3.4044743]\n",
       "      [ 13.965539   10.759737 ]\n",
       "      [-19.731525  -18.588627 ]\n",
       "      [-16.068378  -14.705788 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.931317  ]\n",
       "      [ 0.25348568]\n",
       "      [-2.0256736 ]\n",
       "      [-1.8860062 ]])},\n",
       "    {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "       [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "       [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "       [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "       [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "       [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "      [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "      [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "      [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "      [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "      [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "    {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "       [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[-2.909926  -2.9052634]\n",
       "      [-6.658105  -4.9792333]\n",
       "      [ 2.3443272  1.9698756]\n",
       "      [ 2.2487833  3.089097 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.3112482 ]\n",
       "      [-0.06415135]\n",
       "      [ 0.46190712]\n",
       "      [-0.9451939 ]\n",
       "      [-1.6935313 ]\n",
       "      [-1.6012375 ]])},\n",
       "    {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "       [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "       [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]]),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "       [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "       [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "      [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "      [ 0.2974406   0.34778696  0.9160031 ]\n",
       "      [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "    {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[3. 4. 2.]\n",
       "       [1. 2. 3.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[3. 1.]\n",
       "      [4. 2.]\n",
       "      [2. 3.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-2.1875005 ]\n",
       "      [ 0.36007312]\n",
       "      [-1.7711484 ]\n",
       "      [ 1.2654616 ]])},\n",
       "    {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])}],\n",
       "   'flag': True},\n",
       "  {'loss': 28,\n",
       "   'pointer': 1,\n",
       "   'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]\n",
       "       [1.]\n",
       "       [1.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "       [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[43.864197  40.097336 ]\n",
       "      [56.40194   49.18397  ]\n",
       "      [ 3.6946754  3.7637796]\n",
       "      [48.213287  40.774857 ]])},\n",
       "    {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "     'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "      [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "    {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "     'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "      [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "    {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0. -1. -1. -2.]\n",
       "       [-2. -1. -3. -0.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "       [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "       [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "       [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[0. 1. 1. 2.]\n",
       "      [2. 1. 3. 0.]]),\n",
       "     'to': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "     'grad': tensor32([[-1. -1. -1. -1.]\n",
       "      [-1. -1. -1. -1.]])},\n",
       "    {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "       [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "       [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "       [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "       [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "       [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "      [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "      [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "      [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "    {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "       [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "      [ -9.142022   -9.295835 ]\n",
       "      [  6.307816    3.4044743]\n",
       "      [ 13.965539   10.759737 ]\n",
       "      [-19.731525  -18.588627 ]\n",
       "      [-16.068378  -14.705788 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.931317  ]\n",
       "      [ 0.25348568]\n",
       "      [-2.0256736 ]\n",
       "      [-1.8860062 ]])},\n",
       "    {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "       [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "       [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "       [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "       [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "       [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "      [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "      [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "      [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "      [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "      [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "    {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "       [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[-2.909926  -2.9052634]\n",
       "      [-6.658105  -4.9792333]\n",
       "      [ 2.3443272  1.9698756]\n",
       "      [ 2.2487833  3.089097 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.3112482 ]\n",
       "      [-0.06415135]\n",
       "      [ 0.46190712]\n",
       "      [-0.9451939 ]\n",
       "      [-1.6935313 ]\n",
       "      [-1.6012375 ]])},\n",
       "    {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "       [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "       [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]]),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "       [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "       [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "      [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "      [ 0.2974406   0.34778696  0.9160031 ]\n",
       "      [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "    {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[3. 4. 2.]\n",
       "       [1. 2. 3.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[3. 1.]\n",
       "      [4. 2.]\n",
       "      [2. 3.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-2.1875005 ]\n",
       "      [ 0.36007312]\n",
       "      [-1.7711484 ]\n",
       "      [ 1.2654616 ]])},\n",
       "    {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])}],\n",
       "   'flag': True},\n",
       "  {'loss': 28,\n",
       "   'pointer': 3,\n",
       "   'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]\n",
       "       [1.]\n",
       "       [1.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "       [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[43.864197  40.097336 ]\n",
       "      [56.40194   49.18397  ]\n",
       "      [ 3.6946754  3.7637796]\n",
       "      [48.213287  40.774857 ]])},\n",
       "    {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "     'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "      [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "    {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "     'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "      [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "    {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0. -1. -1. -2.]\n",
       "       [-2. -1. -3. -0.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "       [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "       [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "       [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[0. 1. 1. 2.]\n",
       "      [2. 1. 3. 0.]]),\n",
       "     'to': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "     'grad': tensor32([[-1. -1. -1. -1.]\n",
       "      [-1. -1. -1. -1.]])},\n",
       "    {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "       [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "       [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "       [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "       [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "       [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "      [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "      [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "      [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "    {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "       [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "      [ -9.142022   -9.295835 ]\n",
       "      [  6.307816    3.4044743]\n",
       "      [ 13.965539   10.759737 ]\n",
       "      [-19.731525  -18.588627 ]\n",
       "      [-16.068378  -14.705788 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.931317  ]\n",
       "      [ 0.25348568]\n",
       "      [-2.0256736 ]\n",
       "      [-1.8860062 ]])},\n",
       "    {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "       [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "       [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "       [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "       [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "       [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "      [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "      [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "      [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "      [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "      [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "    {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "       [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[-2.909926  -2.9052634]\n",
       "      [-6.658105  -4.9792333]\n",
       "      [ 2.3443272  1.9698756]\n",
       "      [ 2.2487833  3.089097 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.3112482 ]\n",
       "      [-0.06415135]\n",
       "      [ 0.46190712]\n",
       "      [-0.9451939 ]\n",
       "      [-1.6935313 ]\n",
       "      [-1.6012375 ]])},\n",
       "    {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "       [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "       [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]]),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "       [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "       [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "      [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "      [ 0.2974406   0.34778696  0.9160031 ]\n",
       "      [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "    {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[3. 4. 2.]\n",
       "       [1. 2. 3.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[3. 1.]\n",
       "      [4. 2.]\n",
       "      [2. 3.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-2.1875005 ]\n",
       "      [ 0.36007312]\n",
       "      [-1.7711484 ]\n",
       "      [ 1.2654616 ]])},\n",
       "    {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])}],\n",
       "   'flag': True},\n",
       "  {'loss': 28,\n",
       "   'pointer': 4,\n",
       "   'path': [{'from': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]\n",
       "       [1.]\n",
       "       [1.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]\n",
       "      [1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[152.1741 ]\n",
       "      [133.81995]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "       [40.097336  49.18397    3.7637796 40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[43.864197  40.097336 ]\n",
       "      [56.40194   49.18397  ]\n",
       "      [ 3.6946754  3.7637796]\n",
       "      [48.213287  40.774857 ]])},\n",
       "    {'from': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'to': tensor32([[43.864197  56.40194    3.6946754 48.213287 ]\n",
       "      [40.097336  49.18397    3.7637796 40.774857 ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 0.5},\n",
       "     'grad': tensor32([[0.01139882 0.00886494 0.13532989 0.01037059]\n",
       "      [0.01246966 0.01016591 0.13284518 0.01226246]])},\n",
       "    {'from': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[1924.0677   3181.1787     13.650626 2324.521   ]\n",
       "      [1607.7964   2419.063      14.166038 1662.5889  ]]),\n",
       "     'forward': {'op': 'mytensor.__pow__', 'with': 2},\n",
       "     'grad': tensor32([[ -87.72839   -112.80388      7.389351   -96.426575 ]\n",
       "      [ -80.19467    -98.36794      7.5275593  -81.54971  ]])},\n",
       "    {'from': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0. -1. -1. -2.]\n",
       "       [-2. -1. -3. -0.]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'to': tensor32([[-43.864197  -56.40194     3.6946754 -48.213287 ]\n",
       "      [-40.097336  -49.18397     3.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "       [-38.097336  -48.18397     6.7637796 -40.774857 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "       [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'to': tensor32([[-43.864197  -55.40194     4.6946754 -46.213287 ]\n",
       "      [-38.097336  -48.18397     6.7637796 -40.774857 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "       [-39.028652  -48.437458    8.7894535 -38.88885  ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[0. 1. 1. 2.]\n",
       "      [2. 1. 3. 0.]]),\n",
       "     'to': tensor32([[-0. -1. -1. -2.]\n",
       "      [-2. -1. -3. -0.]]),\n",
       "     'forward': {'op': 'mytensor.__rmul__', 'with': -1},\n",
       "     'grad': tensor32([[-1. -1. -1. -1.]\n",
       "      [-1. -1. -1. -1.]])},\n",
       "    {'from': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "       [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "       [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "       [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "       [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "       [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.38057157  0.6966178   0.0797236  -1.5859255   0.9819933   0.01528107]\n",
       "      [-0.18337241 -0.07475661 -1.7302519   0.41822192  1.6611227   1.2358087 ]\n",
       "      [ 0.71488374 -1.2697316  -0.0728564  -0.5874025  -0.60886055  0.1806803 ]\n",
       "      [ 2.7802854  -1.1022089   0.667218   -1.6236616   0.3338686   0.5352319 ]])},\n",
       "    {'from': myparameter([[-0.38057156 -0.18337241  0.71488377  2.78028539]\n",
       "      [ 0.69661777 -0.0747566  -1.26973164 -1.10220885]\n",
       "      [ 0.07972359 -1.73025194 -0.0728564   0.667218  ]\n",
       "      [-1.58592542  0.41822191 -0.58740251 -1.6236616 ]\n",
       "      [ 0.98199332  1.6611227  -0.60886056  0.3338686 ]\n",
       "      [ 0.01528107  1.23580874  0.18068031  0.53523186]], tensor32),\n",
       "     'to': tensor32([[-44.795513  -55.655426    6.720349  -44.327282 ]\n",
       "      [-39.028652  -48.437458    8.7894535 -38.88885  ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "       [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[ -7.4629145  -7.1427884]\n",
       "      [ -9.142022   -9.295835 ]\n",
       "      [  6.307816    3.4044743]\n",
       "      [ 13.965539   10.759737 ]\n",
       "      [-19.731525  -18.588627 ]\n",
       "      [-16.068378  -14.705788 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.931317  ]\n",
       "      [ 0.25348568]\n",
       "      [-2.0256736 ]\n",
       "      [-1.8860062 ]])},\n",
       "    {'from': myparameter([[ 0.93131696  0.25348567 -2.02567352 -1.88600623]], tensor32),\n",
       "     'to': tensor32([[ 0.931317    0.25348568 -2.0256736  -1.8860062 ]\n",
       "      [ 0.931317    0.25348568 -2.0256736  -1.8860062 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "       [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'to': tensor32([[ -7.4629145  -9.142022    6.307816   13.965539  -19.731525  -16.068378 ]\n",
       "      [ -7.1427884  -9.295835    3.4044743  10.759737  -18.588627  -14.705788 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "       [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "       [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "       [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "       [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[ 0.4753799   0.4475574  -0.48661467 -0.73269737]\n",
       "      [ 2.8629222  -0.02464044 -0.171647   -0.226185  ]\n",
       "      [ 0.33876553 -1.1975815   0.37395972 -0.89764804]\n",
       "      [-0.71922874 -1.6647655   0.8439574  -0.10888761]\n",
       "      [ 2.2485518   1.2091229  -0.31151596 -1.2069249 ]\n",
       "      [ 2.831389    0.5908243  -0.97145337 -0.00748609]])},\n",
       "    {'from': myparameter([[ 0.47537992  2.86292214  0.33876554 -0.71922877  2.2485518   2.83138896]\n",
       "      [ 0.4475574  -0.02464044 -1.19758158 -1.66476543  1.20912294  0.59082431]\n",
       "      [-0.48661469 -0.17164699  0.37395972  0.8439574  -0.31151595 -0.97145338]\n",
       "      [-0.73269735 -0.226185   -0.89764802 -0.10888761 -1.20692493 -0.00748609]], tensor32),\n",
       "     'to': tensor32([[ -7.151666  -9.07787    5.845909  14.910733 -18.037994 -14.467141]\n",
       "      [ -6.83154   -9.231683   2.942567  11.704931 -16.895096 -13.10455 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "       [-2.9052634 -4.9792333  1.9698756  3.089097 ]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[-2.909926  -2.9052634]\n",
       "      [-6.658105  -4.9792333]\n",
       "      [ 2.3443272  1.9698756]\n",
       "      [ 2.2487833  3.089097 ]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.3112482 ]\n",
       "      [-0.06415135]\n",
       "      [ 0.46190712]\n",
       "      [-0.9451939 ]\n",
       "      [-1.6935313 ]\n",
       "      [-1.6012375 ]])},\n",
       "    {'from': myparameter([[-0.31124822 -0.06415135  0.4619071  -0.94519389 -1.69353125 -1.60123755]], tensor32),\n",
       "     'to': tensor32([[-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]\n",
       "      [-0.3112482  -0.06415135  0.46190712 -0.9451939  -1.6935313  -1.6012375 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])},\n",
       "    {'from': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "       [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'to': tensor32([[-2.909926  -6.658105   2.3443272  2.2487833]\n",
       "      [-2.9052634 -4.9792333  1.9698756  3.089097 ]]),\n",
       "     'forward': {'op': 'add',\n",
       "      'with': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "       [-0.717763  -5.3393064  3.741024   1.8236356]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1. 1. 1.]\n",
       "      [1. 1. 1. 1.]])},\n",
       "    {'from': tensor32([[3. 4. 2.]\n",
       "      [1. 2. 3.]]),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "       [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "       [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-0.7896763   0.5994979  -0.37569416]\n",
       "      [-0.38064477 -0.96392596 -1.0102699 ]\n",
       "      [ 0.2974406   0.34778696  0.9160031 ]\n",
       "      [ 0.49221405 -0.5178505   0.78904086]])},\n",
       "    {'from': myparameter([[-0.7896763  -0.38064478  0.29744059  0.49221405]\n",
       "      [ 0.59949791 -0.96392597  0.34778695 -0.51785053]\n",
       "      [-0.37569417 -1.01026983  0.91600314  0.78904087]], tensor32),\n",
       "     'to': tensor32([[-0.7224256 -7.018178   4.1154757  0.9833218]\n",
       "      [-0.717763  -5.3393064  3.741024   1.8236356]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[3. 4. 2.]\n",
       "       [1. 2. 3.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[3. 1.]\n",
       "      [4. 2.]\n",
       "      [2. 3.]])},\n",
       "    {'from': tensor32([[1.]\n",
       "      [1.]]),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "      'pos': 'right'},\n",
       "     'grad': tensor32([[-2.1875005 ]\n",
       "      [ 0.36007312]\n",
       "      [-1.7711484 ]\n",
       "      [ 1.2654616 ]])},\n",
       "    {'from': myparameter([[-2.18750058  0.36007312 -1.7711485   1.2654616 ]], tensor32),\n",
       "     'to': tensor32([[-2.1875005   0.36007312 -1.7711484   1.2654616 ]\n",
       "      [-2.1875005   0.36007312 -1.7711484   1.2654616 ]]),\n",
       "     'forward': {'op': 'dot',\n",
       "      'with': tensor32([[1.]\n",
       "       [1.]])},\n",
       "     'pos': 'left',\n",
       "     'grad': tensor32([[1. 1.]])}],\n",
       "   'flag': True}]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MT.mytensor.computegraph.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.75642188e+00, -2.69136440e-05, -1.06604683e+00,\n",
       "        -3.86076890e-01],\n",
       "       [-9.67319923e-01,  1.28977872e+00, -5.93348696e-01,\n",
       "         1.79582046e+00],\n",
       "       [ 1.85981494e-01,  8.83868846e-01,  7.20115020e-01,\n",
       "        -4.36366714e-01]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=MT.mytensor(np.array([[1,2,3],[2,3,2],[2,1,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=MT.dot(x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=MT.add(x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "cpcg=deepcopy(MT.mytensor.computegraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_pths=[]\n",
    "for i in cpcg._valid_path_reversed:\n",
    "    if i['loss']==cpcg._lossnodes_index[0]:\n",
    "        trace_pths.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 28, 'pointer': 13, 'path': [23, 22, 21, 19, 16, 13], 'flag': True}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_pths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from': 26, 'to': 28, 'forward': {'op': 'dot', 'with': 27, 'pos': 'right'}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpcg._edgelist[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Gradlib as GL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1=GL.grad_basic(cpcg._edgelist[23]['forward']['op'],cpcg._nodelist[cpcg._edgelist[23]['from']],cpcg._nodelist[cpcg._edgelist[23]['forward']['with']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2=MT.dot(cpcg._nodelist[28],g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2=GL.grad_basic(cpcg._edgelist[22]['forward']['op'],cpcg._nodelist[cpcg._edgelist[22]['from']],cpcg._nodelist[cpcg._edgelist[22]['forward']['with']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3=MT.hadamard(l2,g2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mytensor.__pow__',\n",
       " tensor32([[12.949063  14.94606   15.7291355  7.5474877]\n",
       "  [17.802298   2.12394    1.9277796 32.483654 ]]),\n",
       " 0.5)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpcg._edgelist[22]['forward']['op'],cpcg._nodelist[cpcg._edgelist[22]['from']],cpcg._nodelist[cpcg._edgelist[22]['forward']['with']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load Iris\n",
    "data = load_iris()\n",
    "X = data.data  # features\n",
    "y = data.target  # labels\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def dataload(X,Y,batch_size):\n",
    "    trainbatch = []\n",
    "    labels = []\n",
    "    for i in range(batch_size):\n",
    "        random_index = random.randint(0,len(X)-1)\n",
    "        trainbatch.append(X[random_index])\n",
    "        labels.append(Y[random_index])\n",
    "    return trainbatch,labels\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def one_hot_encoding(y,max_value):\n",
    "    one_hot = np.zeros((len(y),max_value))\n",
    "    for i in range(len(y)):\n",
    "        one_hot[i][y[i]]=1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 10/200 [00:00<00:02, 87.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'Loss.CrossEntropy'>: 1.0724623\n",
      "(75, 77)\n",
      "(74, 75)\n",
      "(73, 75)\n",
      "(72, 73)\n",
      "(70, 72)\n",
      "(71, 72)\n",
      "(69, 70)\n",
      "(68, 70)\n",
      "(67, 68)\n",
      "(66, 67)\n",
      "(65, 66)\n",
      "(64, 66)\n",
      "(58, 65)\n",
      "(63, 64)\n",
      "(61, 63)\n",
      "(62, 63)\n",
      "(59, 61)\n",
      "(60, 61)\n",
      "(58, 59)\n",
      "(54, 58)\n",
      "(57, 58)\n",
      "(52, 54)\n",
      "(53, 54)\n",
      "(55, 57)\n",
      "(56, 57)\n",
      "(50, 52)\n",
      "(51, 52)\n",
      "(46, 50)\n",
      "(49, 50)\n",
      "(44, 46)\n",
      "(45, 46)\n",
      "(47, 49)\n",
      "(48, 49)\n",
      "(42, 44)\n",
      "(43, 44)\n",
      "(38, 42)\n",
      "(41, 42)\n",
      "(37, 38)\n",
      "(39, 41)\n",
      "(40, 41)\n",
      "<class 'Loss.CrossEntropy'>: 1.1968906\n",
      "(111, 112)\n",
      "(110, 111)\n",
      "(109, 111)\n",
      "(108, 109)\n",
      "(106, 108)\n",
      "(107, 108)\n",
      "(105, 106)\n",
      "(104, 106)\n",
      "(103, 104)\n",
      "(102, 103)\n",
      "(101, 102)\n",
      "(100, 102)\n",
      "(94, 101)\n",
      "(99, 100)\n",
      "(97, 99)\n",
      "(98, 99)\n",
      "(95, 97)\n",
      "(96, 97)\n",
      "(94, 95)\n",
      "(91, 94)\n",
      "(93, 94)\n",
      "(90, 91)\n",
      "(53, 91)\n",
      "(92, 93)\n",
      "(56, 93)\n",
      "(88, 90)\n",
      "(89, 90)\n",
      "(85, 88)\n",
      "(87, 88)\n",
      "(84, 85)\n",
      "(45, 85)\n",
      "(86, 87)\n",
      "(48, 87)\n",
      "(82, 84)\n",
      "(83, 84)\n",
      "(79, 82)\n",
      "(81, 82)\n",
      "(37, 79)\n",
      "(80, 81)\n",
      "(40, 81)\n",
      "<class 'Loss.CrossEntropy'>: 1.0964323\n",
      "(146, 147)\n",
      "(145, 146)\n",
      "(144, 146)\n",
      "(143, 144)\n",
      "(141, 143)\n",
      "(142, 143)\n",
      "(140, 141)\n",
      "(139, 141)\n",
      "(138, 139)\n",
      "(137, 138)\n",
      "(136, 137)\n",
      "(135, 137)\n",
      "(129, 136)\n",
      "(134, 135)\n",
      "(132, 134)\n",
      "(133, 134)\n",
      "(130, 132)\n",
      "(131, 132)\n",
      "(129, 130)\n",
      "(126, 129)\n",
      "(128, 129)\n",
      "(125, 126)\n",
      "(53, 126)\n",
      "(127, 128)\n",
      "(56, 128)\n",
      "(123, 125)\n",
      "(124, 125)\n",
      "(120, 123)\n",
      "(122, 123)\n",
      "(119, 120)\n",
      "(45, 120)\n",
      "(121, 122)\n",
      "(48, 122)\n",
      "(117, 119)\n",
      "(118, 119)\n",
      "(114, 117)\n",
      "(116, 117)\n",
      "(37, 114)\n",
      "(115, 116)\n",
      "(40, 116)\n",
      "<class 'Loss.CrossEntropy'>: 1.2162279\n",
      "(181, 182)\n",
      "(180, 181)\n",
      "(179, 181)\n",
      "(178, 179)\n",
      "(176, 178)\n",
      "(177, 178)\n",
      "(175, 176)\n",
      "(174, 176)\n",
      "(173, 174)\n",
      "(172, 173)\n",
      "(171, 172)\n",
      "(170, 172)\n",
      "(164, 171)\n",
      "(169, 170)\n",
      "(167, 169)\n",
      "(168, 169)\n",
      "(165, 167)\n",
      "(166, 167)\n",
      "(164, 165)\n",
      "(161, 164)\n",
      "(163, 164)\n",
      "(160, 161)\n",
      "(53, 161)\n",
      "(162, 163)\n",
      "(56, 163)\n",
      "(158, 160)\n",
      "(159, 160)\n",
      "(155, 158)\n",
      "(157, 158)\n",
      "(154, 155)\n",
      "(45, 155)\n",
      "(156, 157)\n",
      "(48, 157)\n",
      "(152, 154)\n",
      "(153, 154)\n",
      "(149, 152)\n",
      "(151, 152)\n",
      "(37, 149)\n",
      "(150, 151)\n",
      "(40, 151)\n",
      "<class 'Loss.CrossEntropy'>: 1.0303513\n",
      "(216, 217)\n",
      "(215, 216)\n",
      "(214, 216)\n",
      "(213, 214)\n",
      "(211, 213)\n",
      "(212, 213)\n",
      "(210, 211)\n",
      "(209, 211)\n",
      "(208, 209)\n",
      "(207, 208)\n",
      "(206, 207)\n",
      "(205, 207)\n",
      "(199, 206)\n",
      "(204, 205)\n",
      "(202, 204)\n",
      "(203, 204)\n",
      "(200, 202)\n",
      "(201, 202)\n",
      "(199, 200)\n",
      "(196, 199)\n",
      "(198, 199)\n",
      "(195, 196)\n",
      "(53, 196)\n",
      "(197, 198)\n",
      "(56, 198)\n",
      "(193, 195)\n",
      "(194, 195)\n",
      "(190, 193)\n",
      "(192, 193)\n",
      "(189, 190)\n",
      "(45, 190)\n",
      "(191, 192)\n",
      "(48, 192)\n",
      "(187, 189)\n",
      "(188, 189)\n",
      "(184, 187)\n",
      "(186, 187)\n",
      "(37, 184)\n",
      "(185, 186)\n",
      "(40, 186)\n",
      "<class 'Loss.CrossEntropy'>: 1.0623863\n",
      "(251, 252)\n",
      "(250, 251)\n",
      "(249, 251)\n",
      "(248, 249)\n",
      "(246, 248)\n",
      "(247, 248)\n",
      "(245, 246)\n",
      "(244, 246)\n",
      "(243, 244)\n",
      "(242, 243)\n",
      "(241, 242)\n",
      "(240, 242)\n",
      "(234, 241)\n",
      "(239, 240)\n",
      "(237, 239)\n",
      "(238, 239)\n",
      "(235, 237)\n",
      "(236, 237)\n",
      "(234, 235)\n",
      "(231, 234)\n",
      "(233, 234)\n",
      "(230, 231)\n",
      "(53, 231)\n",
      "(232, 233)\n",
      "(56, 233)\n",
      "(228, 230)\n",
      "(229, 230)\n",
      "(225, 228)\n",
      "(227, 228)\n",
      "(224, 225)\n",
      "(45, 225)\n",
      "(226, 227)\n",
      "(48, 227)\n",
      "(222, 224)\n",
      "(223, 224)\n",
      "(219, 222)\n",
      "(221, 222)\n",
      "(37, 219)\n",
      "(220, 221)\n",
      "(40, 221)\n",
      "<class 'Loss.CrossEntropy'>: 1.2771618\n",
      "(286, 287)\n",
      "(285, 286)\n",
      "(284, 286)\n",
      "(283, 284)\n",
      "(281, 283)\n",
      "(282, 283)\n",
      "(280, 281)\n",
      "(279, 281)\n",
      "(278, 279)\n",
      "(277, 278)\n",
      "(276, 277)\n",
      "(275, 277)\n",
      "(269, 276)\n",
      "(274, 275)\n",
      "(272, 274)\n",
      "(273, 274)\n",
      "(270, 272)\n",
      "(271, 272)\n",
      "(269, 270)\n",
      "(266, 269)\n",
      "(268, 269)\n",
      "(265, 266)\n",
      "(53, 266)\n",
      "(267, 268)\n",
      "(56, 268)\n",
      "(263, 265)\n",
      "(264, 265)\n",
      "(260, 263)\n",
      "(262, 263)\n",
      "(259, 260)\n",
      "(45, 260)\n",
      "(261, 262)\n",
      "(48, 262)\n",
      "(257, 259)\n",
      "(258, 259)\n",
      "(254, 257)\n",
      "(256, 257)\n",
      "(37, 254)\n",
      "(255, 256)\n",
      "(40, 256)\n",
      "<class 'Loss.CrossEntropy'>: 0.94372773\n",
      "(321, 322)\n",
      "(320, 321)\n",
      "(319, 321)\n",
      "(318, 319)\n",
      "(316, 318)\n",
      "(317, 318)\n",
      "(315, 316)\n",
      "(314, 316)\n",
      "(313, 314)\n",
      "(312, 313)\n",
      "(311, 312)\n",
      "(310, 312)\n",
      "(304, 311)\n",
      "(309, 310)\n",
      "(307, 309)\n",
      "(308, 309)\n",
      "(305, 307)\n",
      "(306, 307)\n",
      "(304, 305)\n",
      "(301, 304)\n",
      "(303, 304)\n",
      "(300, 301)\n",
      "(53, 301)\n",
      "(302, 303)\n",
      "(56, 303)\n",
      "(298, 300)\n",
      "(299, 300)\n",
      "(295, 298)\n",
      "(297, 298)\n",
      "(294, 295)\n",
      "(45, 295)\n",
      "(296, 297)\n",
      "(48, 297)\n",
      "(292, 294)\n",
      "(293, 294)\n",
      "(289, 292)\n",
      "(291, 292)\n",
      "(37, 289)\n",
      "(290, 291)\n",
      "(40, 291)\n",
      "<class 'Loss.CrossEntropy'>: 1.2885274\n",
      "(356, 357)\n",
      "(355, 356)\n",
      "(354, 356)\n",
      "(353, 354)\n",
      "(351, 353)\n",
      "(352, 353)\n",
      "(350, 351)\n",
      "(349, 351)\n",
      "(348, 349)\n",
      "(347, 348)\n",
      "(346, 347)\n",
      "(345, 347)\n",
      "(339, 346)\n",
      "(344, 345)\n",
      "(342, 344)\n",
      "(343, 344)\n",
      "(340, 342)\n",
      "(341, 342)\n",
      "(339, 340)\n",
      "(336, 339)\n",
      "(338, 339)\n",
      "(335, 336)\n",
      "(53, 336)\n",
      "(337, 338)\n",
      "(56, 338)\n",
      "(333, 335)\n",
      "(334, 335)\n",
      "(330, 333)\n",
      "(332, 333)\n",
      "(329, 330)\n",
      "(45, 330)\n",
      "(331, 332)\n",
      "(48, 332)\n",
      "(327, 329)\n",
      "(328, 329)\n",
      "(324, 327)\n",
      "(326, 327)\n",
      "(37, 324)\n",
      "(325, 326)\n",
      "(40, 326)\n",
      "<class 'Loss.CrossEntropy'>: 1.1699896\n",
      "(391, 392)\n",
      "(390, 391)\n",
      "(389, 391)\n",
      "(388, 389)\n",
      "(386, 388)\n",
      "(387, 388)\n",
      "(385, 386)\n",
      "(384, 386)\n",
      "(383, 384)\n",
      "(382, 383)\n",
      "(381, 382)\n",
      "(380, 382)\n",
      "(374, 381)\n",
      "(379, 380)\n",
      "(377, 379)\n",
      "(378, 379)\n",
      "(375, 377)\n",
      "(376, 377)\n",
      "(374, 375)\n",
      "(371, 374)\n",
      "(373, 374)\n",
      "(370, 371)\n",
      "(53, 371)\n",
      "(372, 373)\n",
      "(56, 373)\n",
      "(368, 370)\n",
      "(369, 370)\n",
      "(365, 368)\n",
      "(367, 368)\n",
      "(364, 365)\n",
      "(45, 365)\n",
      "(366, 367)\n",
      "(48, 367)\n",
      "(362, 364)\n",
      "(363, 364)\n",
      "(359, 362)\n",
      "(361, 362)\n",
      "(37, 359)\n",
      "(360, 361)\n",
      "(40, 361)\n",
      "<class 'Loss.CrossEntropy'>: 1.0771103\n",
      "(426, 427)\n",
      "(425, 426)\n",
      "(424, 426)\n",
      "(423, 424)\n",
      "(421, 423)\n",
      "(422, 423)\n",
      "(420, 421)\n",
      "(419, 421)\n",
      "(418, 419)\n",
      "(417, 418)\n",
      "(416, 417)\n",
      "(415, 417)\n",
      "(409, 416)\n",
      "(414, 415)\n",
      "(412, 414)\n",
      "(413, 414)\n",
      "(410, 412)\n",
      "(411, 412)\n",
      "(409, 410)\n",
      "(406, 409)\n",
      "(408, 409)\n",
      "(405, 406)\n",
      "(53, 406)\n",
      "(407, 408)\n",
      "(56, 408)\n",
      "(403, 405)\n",
      "(404, 405)\n",
      "(400, 403)\n",
      "(402, 403)\n",
      "(399, 400)\n",
      "(45, 400)\n",
      "(401, 402)\n",
      "(48, 402)\n",
      "(397, 399)\n",
      "(398, 399)\n",
      "(394, 397)\n",
      "(396, 397)\n",
      "(37, 394)\n",
      "(395, 396)\n",
      "(40, 396)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 19/200 [00:00<00:05, 35.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'Loss.CrossEntropy'>: 1.2870247\n",
      "(461, 462)\n",
      "(460, 461)\n",
      "(459, 461)\n",
      "(458, 459)\n",
      "(456, 458)\n",
      "(457, 458)\n",
      "(455, 456)\n",
      "(454, 456)\n",
      "(453, 454)\n",
      "(452, 453)\n",
      "(451, 452)\n",
      "(450, 452)\n",
      "(444, 451)\n",
      "(449, 450)\n",
      "(447, 449)\n",
      "(448, 449)\n",
      "(445, 447)\n",
      "(446, 447)\n",
      "(444, 445)\n",
      "(441, 444)\n",
      "(443, 444)\n",
      "(440, 441)\n",
      "(53, 441)\n",
      "(442, 443)\n",
      "(56, 443)\n",
      "(438, 440)\n",
      "(439, 440)\n",
      "(435, 438)\n",
      "(437, 438)\n",
      "(434, 435)\n",
      "(45, 435)\n",
      "(436, 437)\n",
      "(48, 437)\n",
      "(432, 434)\n",
      "(433, 434)\n",
      "(429, 432)\n",
      "(431, 432)\n",
      "(37, 429)\n",
      "(430, 431)\n",
      "(40, 431)\n",
      "<class 'Loss.CrossEntropy'>: 1.0331738\n",
      "(496, 497)\n",
      "(495, 496)\n",
      "(494, 496)\n",
      "(493, 494)\n",
      "(491, 493)\n",
      "(492, 493)\n",
      "(490, 491)\n",
      "(489, 491)\n",
      "(488, 489)\n",
      "(487, 488)\n",
      "(486, 487)\n",
      "(485, 487)\n",
      "(479, 486)\n",
      "(484, 485)\n",
      "(482, 484)\n",
      "(483, 484)\n",
      "(480, 482)\n",
      "(481, 482)\n",
      "(479, 480)\n",
      "(476, 479)\n",
      "(478, 479)\n",
      "(475, 476)\n",
      "(53, 476)\n",
      "(477, 478)\n",
      "(56, 478)\n",
      "(473, 475)\n",
      "(474, 475)\n",
      "(470, 473)\n",
      "(472, 473)\n",
      "(469, 470)\n",
      "(45, 470)\n",
      "(471, 472)\n",
      "(48, 472)\n",
      "(467, 469)\n",
      "(468, 469)\n",
      "(464, 467)\n",
      "(466, 467)\n",
      "(37, 464)\n",
      "(465, 466)\n",
      "(40, 466)\n",
      "<class 'Loss.CrossEntropy'>: 1.3588618\n",
      "(531, 532)\n",
      "(530, 531)\n",
      "(529, 531)\n",
      "(528, 529)\n",
      "(526, 528)\n",
      "(527, 528)\n",
      "(525, 526)\n",
      "(524, 526)\n",
      "(523, 524)\n",
      "(522, 523)\n",
      "(521, 522)\n",
      "(520, 522)\n",
      "(514, 521)\n",
      "(519, 520)\n",
      "(517, 519)\n",
      "(518, 519)\n",
      "(515, 517)\n",
      "(516, 517)\n",
      "(514, 515)\n",
      "(511, 514)\n",
      "(513, 514)\n",
      "(510, 511)\n",
      "(53, 511)\n",
      "(512, 513)\n",
      "(56, 513)\n",
      "(508, 510)\n",
      "(509, 510)\n",
      "(505, 508)\n",
      "(507, 508)\n",
      "(504, 505)\n",
      "(45, 505)\n",
      "(506, 507)\n",
      "(48, 507)\n",
      "(502, 504)\n",
      "(503, 504)\n",
      "(499, 502)\n",
      "(501, 502)\n",
      "(37, 499)\n",
      "(500, 501)\n",
      "(40, 501)\n",
      "<class 'Loss.CrossEntropy'>: 0.8524072\n",
      "(566, 567)\n",
      "(565, 566)\n",
      "(564, 566)\n",
      "(563, 564)\n",
      "(561, 563)\n",
      "(562, 563)\n",
      "(560, 561)\n",
      "(559, 561)\n",
      "(558, 559)\n",
      "(557, 558)\n",
      "(556, 557)\n",
      "(555, 557)\n",
      "(549, 556)\n",
      "(554, 555)\n",
      "(552, 554)\n",
      "(553, 554)\n",
      "(550, 552)\n",
      "(551, 552)\n",
      "(549, 550)\n",
      "(546, 549)\n",
      "(548, 549)\n",
      "(545, 546)\n",
      "(53, 546)\n",
      "(547, 548)\n",
      "(56, 548)\n",
      "(543, 545)\n",
      "(544, 545)\n",
      "(540, 543)\n",
      "(542, 543)\n",
      "(539, 540)\n",
      "(45, 540)\n",
      "(541, 542)\n",
      "(48, 542)\n",
      "(537, 539)\n",
      "(538, 539)\n",
      "(534, 537)\n",
      "(536, 537)\n",
      "(37, 534)\n",
      "(535, 536)\n",
      "(40, 536)\n",
      "<class 'Loss.CrossEntropy'>: 1.2902031\n",
      "(601, 602)\n",
      "(600, 601)\n",
      "(599, 601)\n",
      "(598, 599)\n",
      "(596, 598)\n",
      "(597, 598)\n",
      "(595, 596)\n",
      "(594, 596)\n",
      "(593, 594)\n",
      "(592, 593)\n",
      "(591, 592)\n",
      "(590, 592)\n",
      "(584, 591)\n",
      "(589, 590)\n",
      "(587, 589)\n",
      "(588, 589)\n",
      "(585, 587)\n",
      "(586, 587)\n",
      "(584, 585)\n",
      "(581, 584)\n",
      "(583, 584)\n",
      "(580, 581)\n",
      "(53, 581)\n",
      "(582, 583)\n",
      "(56, 583)\n",
      "(578, 580)\n",
      "(579, 580)\n",
      "(575, 578)\n",
      "(577, 578)\n",
      "(574, 575)\n",
      "(45, 575)\n",
      "(576, 577)\n",
      "(48, 577)\n",
      "(572, 574)\n",
      "(573, 574)\n",
      "(569, 572)\n",
      "(571, 572)\n",
      "(37, 569)\n",
      "(570, 571)\n",
      "(40, 571)\n",
      "<class 'Loss.CrossEntropy'>: 1.2958317\n",
      "(636, 637)\n",
      "(635, 636)\n",
      "(634, 636)\n",
      "(633, 634)\n",
      "(631, 633)\n",
      "(632, 633)\n",
      "(630, 631)\n",
      "(629, 631)\n",
      "(628, 629)\n",
      "(627, 628)\n",
      "(626, 627)\n",
      "(625, 627)\n",
      "(619, 626)\n",
      "(624, 625)\n",
      "(622, 624)\n",
      "(623, 624)\n",
      "(620, 622)\n",
      "(621, 622)\n",
      "(619, 620)\n",
      "(616, 619)\n",
      "(618, 619)\n",
      "(615, 616)\n",
      "(53, 616)\n",
      "(617, 618)\n",
      "(56, 618)\n",
      "(613, 615)\n",
      "(614, 615)\n",
      "(610, 613)\n",
      "(612, 613)\n",
      "(609, 610)\n",
      "(45, 610)\n",
      "(611, 612)\n",
      "(48, 612)\n",
      "(607, 609)\n",
      "(608, 609)\n",
      "(604, 607)\n",
      "(606, 607)\n",
      "(37, 604)\n",
      "(605, 606)\n",
      "(40, 606)\n",
      "<class 'Loss.CrossEntropy'>: 1.1985638\n",
      "(671, 672)\n",
      "(670, 671)\n",
      "(669, 671)\n",
      "(668, 669)\n",
      "(666, 668)\n",
      "(667, 668)\n",
      "(665, 666)\n",
      "(664, 666)\n",
      "(663, 664)\n",
      "(662, 663)\n",
      "(661, 662)\n",
      "(660, 662)\n",
      "(654, 661)\n",
      "(659, 660)\n",
      "(657, 659)\n",
      "(658, 659)\n",
      "(655, 657)\n",
      "(656, 657)\n",
      "(654, 655)\n",
      "(651, 654)\n",
      "(653, 654)\n",
      "(650, 651)\n",
      "(53, 651)\n",
      "(652, 653)\n",
      "(56, 653)\n",
      "(648, 650)\n",
      "(649, 650)\n",
      "(645, 648)\n",
      "(647, 648)\n",
      "(644, 645)\n",
      "(45, 645)\n",
      "(646, 647)\n",
      "(48, 647)\n",
      "(642, 644)\n",
      "(643, 644)\n",
      "(639, 642)\n",
      "(641, 642)\n",
      "(37, 639)\n",
      "(640, 641)\n",
      "(40, 641)\n",
      "<class 'Loss.CrossEntropy'>: 1.1273749\n",
      "(706, 707)\n",
      "(705, 706)\n",
      "(704, 706)\n",
      "(703, 704)\n",
      "(701, 703)\n",
      "(702, 703)\n",
      "(700, 701)\n",
      "(699, 701)\n",
      "(698, 699)\n",
      "(697, 698)\n",
      "(696, 697)\n",
      "(695, 697)\n",
      "(689, 696)\n",
      "(694, 695)\n",
      "(692, 694)\n",
      "(693, 694)\n",
      "(690, 692)\n",
      "(691, 692)\n",
      "(689, 690)\n",
      "(686, 689)\n",
      "(688, 689)\n",
      "(685, 686)\n",
      "(53, 686)\n",
      "(687, 688)\n",
      "(56, 688)\n",
      "(683, 685)\n",
      "(684, 685)\n",
      "(680, 683)\n",
      "(682, 683)\n",
      "(679, 680)\n",
      "(45, 680)\n",
      "(681, 682)\n",
      "(48, 682)\n",
      "(677, 679)\n",
      "(678, 679)\n",
      "(674, 677)\n",
      "(676, 677)\n",
      "(37, 674)\n",
      "(675, 676)\n",
      "(40, 676)\n",
      "<class 'Loss.CrossEntropy'>: 1.2038459\n",
      "(741, 742)\n",
      "(740, 741)\n",
      "(739, 741)\n",
      "(738, 739)\n",
      "(736, 738)\n",
      "(737, 738)\n",
      "(735, 736)\n",
      "(734, 736)\n",
      "(733, 734)\n",
      "(732, 733)\n",
      "(731, 732)\n",
      "(730, 732)\n",
      "(724, 731)\n",
      "(729, 730)\n",
      "(727, 729)\n",
      "(728, 729)\n",
      "(725, 727)\n",
      "(726, 727)\n",
      "(724, 725)\n",
      "(721, 724)\n",
      "(723, 724)\n",
      "(720, 721)\n",
      "(53, 721)\n",
      "(722, 723)\n",
      "(56, 723)\n",
      "(718, 720)\n",
      "(719, 720)\n",
      "(715, 718)\n",
      "(717, 718)\n",
      "(714, 715)\n",
      "(45, 715)\n",
      "(716, 717)\n",
      "(48, 717)\n",
      "(712, 714)\n",
      "(713, 714)\n",
      "(709, 712)\n",
      "(711, 712)\n",
      "(37, 709)\n",
      "(710, 711)\n",
      "(40, 711)\n",
      "<class 'Loss.CrossEntropy'>: 1.0949333\n",
      "(776, 777)\n",
      "(775, 776)\n",
      "(774, 776)\n",
      "(773, 774)\n",
      "(771, 773)\n",
      "(772, 773)\n",
      "(770, 771)\n",
      "(769, 771)\n",
      "(768, 769)\n",
      "(767, 768)\n",
      "(766, 767)\n",
      "(765, 767)\n",
      "(759, 766)\n",
      "(764, 765)\n",
      "(762, 764)\n",
      "(763, 764)\n",
      "(760, 762)\n",
      "(761, 762)\n",
      "(759, 760)\n",
      "(756, 759)\n",
      "(758, 759)\n",
      "(755, 756)\n",
      "(53, 756)\n",
      "(757, 758)\n",
      "(56, 758)\n",
      "(753, 755)\n",
      "(754, 755)\n",
      "(750, 753)\n",
      "(752, 753)\n",
      "(749, 750)\n",
      "(45, 750)\n",
      "(751, 752)\n",
      "(48, 752)\n",
      "(747, 749)\n",
      "(748, 749)\n",
      "(744, 747)\n",
      "(746, 747)\n",
      "(37, 744)\n",
      "(745, 746)\n",
      "(40, 746)\n",
      "<class 'Loss.CrossEntropy'>: 1.3772061\n",
      "(811, 812)\n",
      "(810, 811)\n",
      "(809, 811)\n",
      "(808, 809)\n",
      "(806, 808)\n",
      "(807, 808)\n",
      "(805, 806)\n",
      "(804, 806)\n",
      "(803, 804)\n",
      "(802, 803)\n",
      "(801, 802)\n",
      "(800, 802)\n",
      "(794, 801)\n",
      "(799, 800)\n",
      "(797, 799)\n",
      "(798, 799)\n",
      "(795, 797)\n",
      "(796, 797)\n",
      "(794, 795)\n",
      "(791, 794)\n",
      "(793, 794)\n",
      "(790, 791)\n",
      "(53, 791)\n",
      "(792, 793)\n",
      "(56, 793)\n",
      "(788, 790)\n",
      "(789, 790)\n",
      "(785, 788)\n",
      "(787, 788)\n",
      "(784, 785)\n",
      "(45, 785)\n",
      "(786, 787)\n",
      "(48, 787)\n",
      "(782, 784)\n",
      "(783, 784)\n",
      "(779, 782)\n",
      "(781, 782)\n",
      "(37, 779)\n",
      "(780, 781)\n",
      "(40, 781)\n",
      "<class 'Loss.CrossEntropy'>: 1.4474328\n",
      "(846, 847)\n",
      "(845, 846)\n",
      "(844, 846)\n",
      "(843, 844)\n",
      "(841, 843)\n",
      "(842, 843)\n",
      "(840, 841)\n",
      "(839, 841)\n",
      "(838, 839)\n",
      "(837, 838)\n",
      "(836, 837)\n",
      "(835, 837)\n",
      "(829, 836)\n",
      "(834, 835)\n",
      "(832, 834)\n",
      "(833, 834)\n",
      "(830, 832)\n",
      "(831, 832)\n",
      "(829, 830)\n",
      "(826, 829)\n",
      "(828, 829)\n",
      "(825, 826)\n",
      "(53, 826)\n",
      "(827, 828)\n",
      "(56, 828)\n",
      "(823, 825)\n",
      "(824, 825)\n",
      "(820, 823)\n",
      "(822, 823)\n",
      "(819, 820)\n",
      "(45, 820)\n",
      "(821, 822)\n",
      "(48, 822)\n",
      "(817, 819)\n",
      "(818, 819)\n",
      "(814, 817)\n",
      "(816, 817)\n",
      "(37, 814)\n",
      "(815, 816)\n",
      "(40, 816)\n",
      "<class 'Loss.CrossEntropy'>: 1.2600003\n",
      "(881, 882)\n",
      "(880, 881)\n",
      "(879, 881)\n",
      "(878, 879)\n",
      "(876, 878)\n",
      "(877, 878)\n",
      "(875, 876)\n",
      "(874, 876)\n",
      "(873, 874)\n",
      "(872, 873)\n",
      "(871, 872)\n",
      "(870, 872)\n",
      "(864, 871)\n",
      "(869, 870)\n",
      "(867, 869)\n",
      "(868, 869)\n",
      "(865, 867)\n",
      "(866, 867)\n",
      "(864, 865)\n",
      "(861, 864)\n",
      "(863, 864)\n",
      "(860, 861)\n",
      "(53, 861)\n",
      "(862, 863)\n",
      "(56, 863)\n",
      "(858, 860)\n",
      "(859, 860)\n",
      "(855, 858)\n",
      "(857, 858)\n",
      "(854, 855)\n",
      "(45, 855)\n",
      "(856, 857)\n",
      "(48, 857)\n",
      "(852, 854)\n",
      "(853, 854)\n",
      "(849, 852)\n",
      "(851, 852)\n",
      "(37, 849)\n",
      "(850, 851)\n",
      "(40, 851)\n",
      "<class 'Loss.CrossEntropy'>: 1.3048065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 31/200 [00:00<00:04, 41.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(916, 917)\n",
      "(915, 916)\n",
      "(914, 916)\n",
      "(913, 914)\n",
      "(911, 913)\n",
      "(912, 913)\n",
      "(910, 911)\n",
      "(909, 911)\n",
      "(908, 909)\n",
      "(907, 908)\n",
      "(906, 907)\n",
      "(905, 907)\n",
      "(899, 906)\n",
      "(904, 905)\n",
      "(902, 904)\n",
      "(903, 904)\n",
      "(900, 902)\n",
      "(901, 902)\n",
      "(899, 900)\n",
      "(896, 899)\n",
      "(898, 899)\n",
      "(895, 896)\n",
      "(53, 896)\n",
      "(897, 898)\n",
      "(56, 898)\n",
      "(893, 895)\n",
      "(894, 895)\n",
      "(890, 893)\n",
      "(892, 893)\n",
      "(889, 890)\n",
      "(45, 890)\n",
      "(891, 892)\n",
      "(48, 892)\n",
      "(887, 889)\n",
      "(888, 889)\n",
      "(884, 887)\n",
      "(886, 887)\n",
      "(37, 884)\n",
      "(885, 886)\n",
      "(40, 886)\n",
      "<class 'Loss.CrossEntropy'>: 1.0505915\n",
      "(951, 952)\n",
      "(950, 951)\n",
      "(949, 951)\n",
      "(948, 949)\n",
      "(946, 948)\n",
      "(947, 948)\n",
      "(945, 946)\n",
      "(944, 946)\n",
      "(943, 944)\n",
      "(942, 943)\n",
      "(941, 942)\n",
      "(940, 942)\n",
      "(934, 941)\n",
      "(939, 940)\n",
      "(937, 939)\n",
      "(938, 939)\n",
      "(935, 937)\n",
      "(936, 937)\n",
      "(934, 935)\n",
      "(931, 934)\n",
      "(933, 934)\n",
      "(930, 931)\n",
      "(53, 931)\n",
      "(932, 933)\n",
      "(56, 933)\n",
      "(928, 930)\n",
      "(929, 930)\n",
      "(925, 928)\n",
      "(927, 928)\n",
      "(924, 925)\n",
      "(45, 925)\n",
      "(926, 927)\n",
      "(48, 927)\n",
      "(922, 924)\n",
      "(923, 924)\n",
      "(919, 922)\n",
      "(921, 922)\n",
      "(37, 919)\n",
      "(920, 921)\n",
      "(40, 921)\n",
      "<class 'Loss.CrossEntropy'>: 1.2205988\n",
      "(986, 987)\n",
      "(985, 986)\n",
      "(984, 986)\n",
      "(983, 984)\n",
      "(981, 983)\n",
      "(982, 983)\n",
      "(980, 981)\n",
      "(979, 981)\n",
      "(978, 979)\n",
      "(977, 978)\n",
      "(976, 977)\n",
      "(975, 977)\n",
      "(969, 976)\n",
      "(974, 975)\n",
      "(972, 974)\n",
      "(973, 974)\n",
      "(970, 972)\n",
      "(971, 972)\n",
      "(969, 970)\n",
      "(966, 969)\n",
      "(968, 969)\n",
      "(965, 966)\n",
      "(53, 966)\n",
      "(967, 968)\n",
      "(56, 968)\n",
      "(963, 965)\n",
      "(964, 965)\n",
      "(960, 963)\n",
      "(962, 963)\n",
      "(959, 960)\n",
      "(45, 960)\n",
      "(961, 962)\n",
      "(48, 962)\n",
      "(957, 959)\n",
      "(958, 959)\n",
      "(954, 957)\n",
      "(956, 957)\n",
      "(37, 954)\n",
      "(955, 956)\n",
      "(40, 956)\n",
      "<class 'Loss.CrossEntropy'>: 1.2678249\n",
      "(1021, 1022)\n",
      "(1020, 1021)\n",
      "(1019, 1021)\n",
      "(1018, 1019)\n",
      "(1016, 1018)\n",
      "(1017, 1018)\n",
      "(1015, 1016)\n",
      "(1014, 1016)\n",
      "(1013, 1014)\n",
      "(1012, 1013)\n",
      "(1011, 1012)\n",
      "(1010, 1012)\n",
      "(1004, 1011)\n",
      "(1009, 1010)\n",
      "(1007, 1009)\n",
      "(1008, 1009)\n",
      "(1005, 1007)\n",
      "(1006, 1007)\n",
      "(1004, 1005)\n",
      "(1001, 1004)\n",
      "(1003, 1004)\n",
      "(1000, 1001)\n",
      "(53, 1001)\n",
      "(1002, 1003)\n",
      "(56, 1003)\n",
      "(998, 1000)\n",
      "(999, 1000)\n",
      "(995, 998)\n",
      "(997, 998)\n",
      "(994, 995)\n",
      "(45, 995)\n",
      "(996, 997)\n",
      "(48, 997)\n",
      "(992, 994)\n",
      "(993, 994)\n",
      "(989, 992)\n",
      "(991, 992)\n",
      "(37, 989)\n",
      "(990, 991)\n",
      "(40, 991)\n",
      "<class 'Loss.CrossEntropy'>: 1.1922948\n",
      "(1056, 1057)\n",
      "(1055, 1056)\n",
      "(1054, 1056)\n",
      "(1053, 1054)\n",
      "(1051, 1053)\n",
      "(1052, 1053)\n",
      "(1050, 1051)\n",
      "(1049, 1051)\n",
      "(1048, 1049)\n",
      "(1047, 1048)\n",
      "(1046, 1047)\n",
      "(1045, 1047)\n",
      "(1039, 1046)\n",
      "(1044, 1045)\n",
      "(1042, 1044)\n",
      "(1043, 1044)\n",
      "(1040, 1042)\n",
      "(1041, 1042)\n",
      "(1039, 1040)\n",
      "(1036, 1039)\n",
      "(1038, 1039)\n",
      "(1035, 1036)\n",
      "(53, 1036)\n",
      "(1037, 1038)\n",
      "(56, 1038)\n",
      "(1033, 1035)\n",
      "(1034, 1035)\n",
      "(1030, 1033)\n",
      "(1032, 1033)\n",
      "(1029, 1030)\n",
      "(45, 1030)\n",
      "(1031, 1032)\n",
      "(48, 1032)\n",
      "(1027, 1029)\n",
      "(1028, 1029)\n",
      "(1024, 1027)\n",
      "(1026, 1027)\n",
      "(37, 1024)\n",
      "(1025, 1026)\n",
      "(40, 1026)\n",
      "<class 'Loss.CrossEntropy'>: 1.3193465\n",
      "(1091, 1092)\n",
      "(1090, 1091)\n",
      "(1089, 1091)\n",
      "(1088, 1089)\n",
      "(1086, 1088)\n",
      "(1087, 1088)\n",
      "(1085, 1086)\n",
      "(1084, 1086)\n",
      "(1083, 1084)\n",
      "(1082, 1083)\n",
      "(1081, 1082)\n",
      "(1080, 1082)\n",
      "(1074, 1081)\n",
      "(1079, 1080)\n",
      "(1077, 1079)\n",
      "(1078, 1079)\n",
      "(1075, 1077)\n",
      "(1076, 1077)\n",
      "(1074, 1075)\n",
      "(1071, 1074)\n",
      "(1073, 1074)\n",
      "(1070, 1071)\n",
      "(53, 1071)\n",
      "(1072, 1073)\n",
      "(56, 1073)\n",
      "(1068, 1070)\n",
      "(1069, 1070)\n",
      "(1065, 1068)\n",
      "(1067, 1068)\n",
      "(1064, 1065)\n",
      "(45, 1065)\n",
      "(1066, 1067)\n",
      "(48, 1067)\n",
      "(1062, 1064)\n",
      "(1063, 1064)\n",
      "(1059, 1062)\n",
      "(1061, 1062)\n",
      "(37, 1059)\n",
      "(1060, 1061)\n",
      "(40, 1061)\n",
      "<class 'Loss.CrossEntropy'>: 1.2485132\n",
      "(1126, 1127)\n",
      "(1125, 1126)\n",
      "(1124, 1126)\n",
      "(1123, 1124)\n",
      "(1121, 1123)\n",
      "(1122, 1123)\n",
      "(1120, 1121)\n",
      "(1119, 1121)\n",
      "(1118, 1119)\n",
      "(1117, 1118)\n",
      "(1116, 1117)\n",
      "(1115, 1117)\n",
      "(1109, 1116)\n",
      "(1114, 1115)\n",
      "(1112, 1114)\n",
      "(1113, 1114)\n",
      "(1110, 1112)\n",
      "(1111, 1112)\n",
      "(1109, 1110)\n",
      "(1106, 1109)\n",
      "(1108, 1109)\n",
      "(1105, 1106)\n",
      "(53, 1106)\n",
      "(1107, 1108)\n",
      "(56, 1108)\n",
      "(1103, 1105)\n",
      "(1104, 1105)\n",
      "(1100, 1103)\n",
      "(1102, 1103)\n",
      "(1099, 1100)\n",
      "(45, 1100)\n",
      "(1101, 1102)\n",
      "(48, 1102)\n",
      "(1097, 1099)\n",
      "(1098, 1099)\n",
      "(1094, 1097)\n",
      "(1096, 1097)\n",
      "(37, 1094)\n",
      "(1095, 1096)\n",
      "(40, 1096)\n",
      "<class 'Loss.CrossEntropy'>: 1.2066492\n",
      "(1161, 1162)\n",
      "(1160, 1161)\n",
      "(1159, 1161)\n",
      "(1158, 1159)\n",
      "(1156, 1158)\n",
      "(1157, 1158)\n",
      "(1155, 1156)\n",
      "(1154, 1156)\n",
      "(1153, 1154)\n",
      "(1152, 1153)\n",
      "(1151, 1152)\n",
      "(1150, 1152)\n",
      "(1144, 1151)\n",
      "(1149, 1150)\n",
      "(1147, 1149)\n",
      "(1148, 1149)\n",
      "(1145, 1147)\n",
      "(1146, 1147)\n",
      "(1144, 1145)\n",
      "(1141, 1144)\n",
      "(1143, 1144)\n",
      "(1140, 1141)\n",
      "(53, 1141)\n",
      "(1142, 1143)\n",
      "(56, 1143)\n",
      "(1138, 1140)\n",
      "(1139, 1140)\n",
      "(1135, 1138)\n",
      "(1137, 1138)\n",
      "(1134, 1135)\n",
      "(45, 1135)\n",
      "(1136, 1137)\n",
      "(48, 1137)\n",
      "(1132, 1134)\n",
      "(1133, 1134)\n",
      "(1129, 1132)\n",
      "(1131, 1132)\n",
      "(37, 1129)\n",
      "(1130, 1131)\n",
      "(40, 1131)\n",
      "<class 'Loss.CrossEntropy'>: 0.92719746\n",
      "(1196, 1197)\n",
      "(1195, 1196)\n",
      "(1194, 1196)\n",
      "(1193, 1194)\n",
      "(1191, 1193)\n",
      "(1192, 1193)\n",
      "(1190, 1191)\n",
      "(1189, 1191)\n",
      "(1188, 1189)\n",
      "(1187, 1188)\n",
      "(1186, 1187)\n",
      "(1185, 1187)\n",
      "(1179, 1186)\n",
      "(1184, 1185)\n",
      "(1182, 1184)\n",
      "(1183, 1184)\n",
      "(1180, 1182)\n",
      "(1181, 1182)\n",
      "(1179, 1180)\n",
      "(1176, 1179)\n",
      "(1178, 1179)\n",
      "(1175, 1176)\n",
      "(53, 1176)\n",
      "(1177, 1178)\n",
      "(56, 1178)\n",
      "(1173, 1175)\n",
      "(1174, 1175)\n",
      "(1170, 1173)\n",
      "(1172, 1173)\n",
      "(1169, 1170)\n",
      "(45, 1170)\n",
      "(1171, 1172)\n",
      "(48, 1172)\n",
      "(1167, 1169)\n",
      "(1168, 1169)\n",
      "(1164, 1167)\n",
      "(1166, 1167)\n",
      "(37, 1164)\n",
      "(1165, 1166)\n",
      "(40, 1166)\n",
      "<class 'Loss.CrossEntropy'>: 0.8267523\n",
      "(1231, 1232)\n",
      "(1230, 1231)\n",
      "(1229, 1231)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 36/200 [00:00<00:04, 40.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1228, 1229)\n",
      "(1226, 1228)\n",
      "(1227, 1228)\n",
      "(1225, 1226)\n",
      "(1224, 1226)\n",
      "(1223, 1224)\n",
      "(1222, 1223)\n",
      "(1221, 1222)\n",
      "(1220, 1222)\n",
      "(1214, 1221)\n",
      "(1219, 1220)\n",
      "(1217, 1219)\n",
      "(1218, 1219)\n",
      "(1215, 1217)\n",
      "(1216, 1217)\n",
      "(1214, 1215)\n",
      "(1211, 1214)\n",
      "(1213, 1214)\n",
      "(1210, 1211)\n",
      "(53, 1211)\n",
      "(1212, 1213)\n",
      "(56, 1213)\n",
      "(1208, 1210)\n",
      "(1209, 1210)\n",
      "(1205, 1208)\n",
      "(1207, 1208)\n",
      "(1204, 1205)\n",
      "(45, 1205)\n",
      "(1206, 1207)\n",
      "(48, 1207)\n",
      "(1202, 1204)\n",
      "(1203, 1204)\n",
      "(1199, 1202)\n",
      "(1201, 1202)\n",
      "(37, 1199)\n",
      "(1200, 1201)\n",
      "(40, 1201)\n",
      "<class 'Loss.CrossEntropy'>: 1.1644534\n",
      "(1266, 1267)\n",
      "(1265, 1266)\n",
      "(1264, 1266)\n",
      "(1263, 1264)\n",
      "(1261, 1263)\n",
      "(1262, 1263)\n",
      "(1260, 1261)\n",
      "(1259, 1261)\n",
      "(1258, 1259)\n",
      "(1257, 1258)\n",
      "(1256, 1257)\n",
      "(1255, 1257)\n",
      "(1249, 1256)\n",
      "(1254, 1255)\n",
      "(1252, 1254)\n",
      "(1253, 1254)\n",
      "(1250, 1252)\n",
      "(1251, 1252)\n",
      "(1249, 1250)\n",
      "(1246, 1249)\n",
      "(1248, 1249)\n",
      "(1245, 1246)\n",
      "(53, 1246)\n",
      "(1247, 1248)\n",
      "(56, 1248)\n",
      "(1243, 1245)\n",
      "(1244, 1245)\n",
      "(1240, 1243)\n",
      "(1242, 1243)\n",
      "(1239, 1240)\n",
      "(45, 1240)\n",
      "(1241, 1242)\n",
      "(48, 1242)\n",
      "(1237, 1239)\n",
      "(1238, 1239)\n",
      "(1234, 1237)\n",
      "(1236, 1237)\n",
      "(37, 1234)\n",
      "(1235, 1236)\n",
      "(40, 1236)\n",
      "<class 'Loss.CrossEntropy'>: 1.023618\n",
      "(1301, 1302)\n",
      "(1300, 1301)\n",
      "(1299, 1301)\n",
      "(1298, 1299)\n",
      "(1296, 1298)\n",
      "(1297, 1298)\n",
      "(1295, 1296)\n",
      "(1294, 1296)\n",
      "(1293, 1294)\n",
      "(1292, 1293)\n",
      "(1291, 1292)\n",
      "(1290, 1292)\n",
      "(1284, 1291)\n",
      "(1289, 1290)\n",
      "(1287, 1289)\n",
      "(1288, 1289)\n",
      "(1285, 1287)\n",
      "(1286, 1287)\n",
      "(1284, 1285)\n",
      "(1281, 1284)\n",
      "(1283, 1284)\n",
      "(1280, 1281)\n",
      "(53, 1281)\n",
      "(1282, 1283)\n",
      "(56, 1283)\n",
      "(1278, 1280)\n",
      "(1279, 1280)\n",
      "(1275, 1278)\n",
      "(1277, 1278)\n",
      "(1274, 1275)\n",
      "(45, 1275)\n",
      "(1276, 1277)\n",
      "(48, 1277)\n",
      "(1272, 1274)\n",
      "(1273, 1274)\n",
      "(1269, 1272)\n",
      "(1271, 1272)\n",
      "(37, 1269)\n",
      "(1270, 1271)\n",
      "(40, 1271)\n",
      "<class 'Loss.CrossEntropy'>: 1.403655\n",
      "(1336, 1337)\n",
      "(1335, 1336)\n",
      "(1334, 1336)\n",
      "(1333, 1334)\n",
      "(1331, 1333)\n",
      "(1332, 1333)\n",
      "(1330, 1331)\n",
      "(1329, 1331)\n",
      "(1328, 1329)\n",
      "(1327, 1328)\n",
      "(1326, 1327)\n",
      "(1325, 1327)\n",
      "(1319, 1326)\n",
      "(1324, 1325)\n",
      "(1322, 1324)\n",
      "(1323, 1324)\n",
      "(1320, 1322)\n",
      "(1321, 1322)\n",
      "(1319, 1320)\n",
      "(1316, 1319)\n",
      "(1318, 1319)\n",
      "(1315, 1316)\n",
      "(53, 1316)\n",
      "(1317, 1318)\n",
      "(56, 1318)\n",
      "(1313, 1315)\n",
      "(1314, 1315)\n",
      "(1310, 1313)\n",
      "(1312, 1313)\n",
      "(1309, 1310)\n",
      "(45, 1310)\n",
      "(1311, 1312)\n",
      "(48, 1312)\n",
      "(1307, 1309)\n",
      "(1308, 1309)\n",
      "(1304, 1307)\n",
      "(1306, 1307)\n",
      "(37, 1304)\n",
      "(1305, 1306)\n",
      "(40, 1306)\n",
      "<class 'Loss.CrossEntropy'>: 1.2249227\n",
      "(1371, 1372)\n",
      "(1370, 1371)\n",
      "(1369, 1371)\n",
      "(1368, 1369)\n",
      "(1366, 1368)\n",
      "(1367, 1368)\n",
      "(1365, 1366)\n",
      "(1364, 1366)\n",
      "(1363, 1364)\n",
      "(1362, 1363)\n",
      "(1361, 1362)\n",
      "(1360, 1362)\n",
      "(1354, 1361)\n",
      "(1359, 1360)\n",
      "(1357, 1359)\n",
      "(1358, 1359)\n",
      "(1355, 1357)\n",
      "(1356, 1357)\n",
      "(1354, 1355)\n",
      "(1351, 1354)\n",
      "(1353, 1354)\n",
      "(1350, 1351)\n",
      "(53, 1351)\n",
      "(1352, 1353)\n",
      "(56, 1353)\n",
      "(1348, 1350)\n",
      "(1349, 1350)\n",
      "(1345, 1348)\n",
      "(1347, 1348)\n",
      "(1344, 1345)\n",
      "(45, 1345)\n",
      "(1346, 1347)\n",
      "(48, 1347)\n",
      "(1342, 1344)\n",
      "(1343, 1344)\n",
      "(1339, 1342)\n",
      "(1341, 1342)\n",
      "(37, 1339)\n",
      "(1340, 1341)\n",
      "(40, 1341)\n",
      "<class 'Loss.CrossEntropy'>: 1.3976197\n",
      "(1406, 1407)\n",
      "(1405, 1406)\n",
      "(1404, 1406)\n",
      "(1403, 1404)\n",
      "(1401, 1403)\n",
      "(1402, 1403)\n",
      "(1400, 1401)\n",
      "(1399, 1401)\n",
      "(1398, 1399)\n",
      "(1397, 1398)\n",
      "(1396, 1397)\n",
      "(1395, 1397)\n",
      "(1389, 1396)\n",
      "(1394, 1395)\n",
      "(1392, 1394)\n",
      "(1393, 1394)\n",
      "(1390, 1392)\n",
      "(1391, 1392)\n",
      "(1389, 1390)\n",
      "(1386, 1389)\n",
      "(1388, 1389)\n",
      "(1385, 1386)\n",
      "(53, 1386)\n",
      "(1387, 1388)\n",
      "(56, 1388)\n",
      "(1383, 1385)\n",
      "(1384, 1385)\n",
      "(1380, 1383)\n",
      "(1382, 1383)\n",
      "(1379, 1380)\n",
      "(45, 1380)\n",
      "(1381, 1382)\n",
      "(48, 1382)\n",
      "(1377, 1379)\n",
      "(1378, 1379)\n",
      "(1374, 1377)\n",
      "(1376, 1377)\n",
      "(37, 1374)\n",
      "(1375, 1376)\n",
      "(40, 1376)\n",
      "<class 'Loss.CrossEntropy'>: 1.1799078\n",
      "(1441, 1442)\n",
      "(1440, 1441)\n",
      "(1439, 1441)\n",
      "(1438, 1439)\n",
      "(1436, 1438)\n",
      "(1437, 1438)\n",
      "(1435, 1436)\n",
      "(1434, 1436)\n",
      "(1433, 1434)\n",
      "(1432, 1433)\n",
      "(1431, 1432)\n",
      "(1430, 1432)\n",
      "(1424, 1431)\n",
      "(1429, 1430)\n",
      "(1427, 1429)\n",
      "(1428, 1429)\n",
      "(1425, 1427)\n",
      "(1426, 1427)\n",
      "(1424, 1425)\n",
      "(1421, 1424)\n",
      "(1423, 1424)\n",
      "(1420, 1421)\n",
      "(53, 1421)\n",
      "(1422, 1423)\n",
      "(56, 1423)\n",
      "(1418, 1420)\n",
      "(1419, 1420)\n",
      "(1415, 1418)\n",
      "(1417, 1418)\n",
      "(1414, 1415)\n",
      "(45, 1415)\n",
      "(1416, 1417)\n",
      "(48, 1417)\n",
      "(1412, 1414)\n",
      "(1413, 1414)\n",
      "(1409, 1412)\n",
      "(1411, 1412)\n",
      "(37, 1409)\n",
      "(1410, 1411)\n",
      "(40, 1411)\n",
      "<class 'Loss.CrossEntropy'>: 1.0065601\n",
      "(1476, 1477)\n",
      "(1475, 1476)\n",
      "(1474, 1476)\n",
      "(1473, 1474)\n",
      "(1471, 1473)\n",
      "(1472, 1473)\n",
      "(1470, 1471)\n",
      "(1469, 1471)\n",
      "(1468, 1469)\n",
      "(1467, 1468)\n",
      "(1466, 1467)\n",
      "(1465, 1467)\n",
      "(1459, 1466)\n",
      "(1464, 1465)\n",
      "(1462, 1464)\n",
      "(1463, 1464)\n",
      "(1460, 1462)\n",
      "(1461, 1462)\n",
      "(1459, 1460)\n",
      "(1456, 1459)\n",
      "(1458, 1459)\n",
      "(1455, 1456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 46/200 [00:01<00:04, 34.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 1456)\n",
      "(1457, 1458)\n",
      "(56, 1458)\n",
      "(1453, 1455)\n",
      "(1454, 1455)\n",
      "(1450, 1453)\n",
      "(1452, 1453)\n",
      "(1449, 1450)\n",
      "(45, 1450)\n",
      "(1451, 1452)\n",
      "(48, 1452)\n",
      "(1447, 1449)\n",
      "(1448, 1449)\n",
      "(1444, 1447)\n",
      "(1446, 1447)\n",
      "(37, 1444)\n",
      "(1445, 1446)\n",
      "(40, 1446)\n",
      "<class 'Loss.CrossEntropy'>: 1.0425128\n",
      "(1511, 1512)\n",
      "(1510, 1511)\n",
      "(1509, 1511)\n",
      "(1508, 1509)\n",
      "(1506, 1508)\n",
      "(1507, 1508)\n",
      "(1505, 1506)\n",
      "(1504, 1506)\n",
      "(1503, 1504)\n",
      "(1502, 1503)\n",
      "(1501, 1502)\n",
      "(1500, 1502)\n",
      "(1494, 1501)\n",
      "(1499, 1500)\n",
      "(1497, 1499)\n",
      "(1498, 1499)\n",
      "(1495, 1497)\n",
      "(1496, 1497)\n",
      "(1494, 1495)\n",
      "(1491, 1494)\n",
      "(1493, 1494)\n",
      "(1490, 1491)\n",
      "(53, 1491)\n",
      "(1492, 1493)\n",
      "(56, 1493)\n",
      "(1488, 1490)\n",
      "(1489, 1490)\n",
      "(1485, 1488)\n",
      "(1487, 1488)\n",
      "(1484, 1485)\n",
      "(45, 1485)\n",
      "(1486, 1487)\n",
      "(48, 1487)\n",
      "(1482, 1484)\n",
      "(1483, 1484)\n",
      "(1479, 1482)\n",
      "(1481, 1482)\n",
      "(37, 1479)\n",
      "(1480, 1481)\n",
      "(40, 1481)\n",
      "<class 'Loss.CrossEntropy'>: 1.1793175\n",
      "(1546, 1547)\n",
      "(1545, 1546)\n",
      "(1544, 1546)\n",
      "(1543, 1544)\n",
      "(1541, 1543)\n",
      "(1542, 1543)\n",
      "(1540, 1541)\n",
      "(1539, 1541)\n",
      "(1538, 1539)\n",
      "(1537, 1538)\n",
      "(1536, 1537)\n",
      "(1535, 1537)\n",
      "(1529, 1536)\n",
      "(1534, 1535)\n",
      "(1532, 1534)\n",
      "(1533, 1534)\n",
      "(1530, 1532)\n",
      "(1531, 1532)\n",
      "(1529, 1530)\n",
      "(1526, 1529)\n",
      "(1528, 1529)\n",
      "(1525, 1526)\n",
      "(53, 1526)\n",
      "(1527, 1528)\n",
      "(56, 1528)\n",
      "(1523, 1525)\n",
      "(1524, 1525)\n",
      "(1520, 1523)\n",
      "(1522, 1523)\n",
      "(1519, 1520)\n",
      "(45, 1520)\n",
      "(1521, 1522)\n",
      "(48, 1522)\n",
      "(1517, 1519)\n",
      "(1518, 1519)\n",
      "(1514, 1517)\n",
      "(1516, 1517)\n",
      "(37, 1514)\n",
      "(1515, 1516)\n",
      "(40, 1516)\n",
      "<class 'Loss.CrossEntropy'>: 1.3282468\n",
      "(1581, 1582)\n",
      "(1580, 1581)\n",
      "(1579, 1581)\n",
      "(1578, 1579)\n",
      "(1576, 1578)\n",
      "(1577, 1578)\n",
      "(1575, 1576)\n",
      "(1574, 1576)\n",
      "(1573, 1574)\n",
      "(1572, 1573)\n",
      "(1571, 1572)\n",
      "(1570, 1572)\n",
      "(1564, 1571)\n",
      "(1569, 1570)\n",
      "(1567, 1569)\n",
      "(1568, 1569)\n",
      "(1565, 1567)\n",
      "(1566, 1567)\n",
      "(1564, 1565)\n",
      "(1561, 1564)\n",
      "(1563, 1564)\n",
      "(1560, 1561)\n",
      "(53, 1561)\n",
      "(1562, 1563)\n",
      "(56, 1563)\n",
      "(1558, 1560)\n",
      "(1559, 1560)\n",
      "(1555, 1558)\n",
      "(1557, 1558)\n",
      "(1554, 1555)\n",
      "(45, 1555)\n",
      "(1556, 1557)\n",
      "(48, 1557)\n",
      "(1552, 1554)\n",
      "(1553, 1554)\n",
      "(1549, 1552)\n",
      "(1551, 1552)\n",
      "(37, 1549)\n",
      "(1550, 1551)\n",
      "(40, 1551)\n",
      "<class 'Loss.CrossEntropy'>: 0.9809667\n",
      "(1616, 1617)\n",
      "(1615, 1616)\n",
      "(1614, 1616)\n",
      "(1613, 1614)\n",
      "(1611, 1613)\n",
      "(1612, 1613)\n",
      "(1610, 1611)\n",
      "(1609, 1611)\n",
      "(1608, 1609)\n",
      "(1607, 1608)\n",
      "(1606, 1607)\n",
      "(1605, 1607)\n",
      "(1599, 1606)\n",
      "(1604, 1605)\n",
      "(1602, 1604)\n",
      "(1603, 1604)\n",
      "(1600, 1602)\n",
      "(1601, 1602)\n",
      "(1599, 1600)\n",
      "(1596, 1599)\n",
      "(1598, 1599)\n",
      "(1595, 1596)\n",
      "(53, 1596)\n",
      "(1597, 1598)\n",
      "(56, 1598)\n",
      "(1593, 1595)\n",
      "(1594, 1595)\n",
      "(1590, 1593)\n",
      "(1592, 1593)\n",
      "(1589, 1590)\n",
      "(45, 1590)\n",
      "(1591, 1592)\n",
      "(48, 1592)\n",
      "(1587, 1589)\n",
      "(1588, 1589)\n",
      "(1584, 1587)\n",
      "(1586, 1587)\n",
      "(37, 1584)\n",
      "(1585, 1586)\n",
      "(40, 1586)\n",
      "<class 'Loss.CrossEntropy'>: 0.9372688\n",
      "(1651, 1652)\n",
      "(1650, 1651)\n",
      "(1649, 1651)\n",
      "(1648, 1649)\n",
      "(1646, 1648)\n",
      "(1647, 1648)\n",
      "(1645, 1646)\n",
      "(1644, 1646)\n",
      "(1643, 1644)\n",
      "(1642, 1643)\n",
      "(1641, 1642)\n",
      "(1640, 1642)\n",
      "(1634, 1641)\n",
      "(1639, 1640)\n",
      "(1637, 1639)\n",
      "(1638, 1639)\n",
      "(1635, 1637)\n",
      "(1636, 1637)\n",
      "(1634, 1635)\n",
      "(1631, 1634)\n",
      "(1633, 1634)\n",
      "(1630, 1631)\n",
      "(53, 1631)\n",
      "(1632, 1633)\n",
      "(56, 1633)\n",
      "(1628, 1630)\n",
      "(1629, 1630)\n",
      "(1625, 1628)\n",
      "(1627, 1628)\n",
      "(1624, 1625)\n",
      "(45, 1625)\n",
      "(1626, 1627)\n",
      "(48, 1627)\n",
      "(1622, 1624)\n",
      "(1623, 1624)\n",
      "(1619, 1622)\n",
      "(1621, 1622)\n",
      "(37, 1619)\n",
      "(1620, 1621)\n",
      "(40, 1621)\n",
      "<class 'Loss.CrossEntropy'>: 0.95142514\n",
      "(1686, 1687)\n",
      "(1685, 1686)\n",
      "(1684, 1686)\n",
      "(1683, 1684)\n",
      "(1681, 1683)\n",
      "(1682, 1683)\n",
      "(1680, 1681)\n",
      "(1679, 1681)\n",
      "(1678, 1679)\n",
      "(1677, 1678)\n",
      "(1676, 1677)\n",
      "(1675, 1677)\n",
      "(1669, 1676)\n",
      "(1674, 1675)\n",
      "(1672, 1674)\n",
      "(1673, 1674)\n",
      "(1670, 1672)\n",
      "(1671, 1672)\n",
      "(1669, 1670)\n",
      "(1666, 1669)\n",
      "(1668, 1669)\n",
      "(1665, 1666)\n",
      "(53, 1666)\n",
      "(1667, 1668)\n",
      "(56, 1668)\n",
      "(1663, 1665)\n",
      "(1664, 1665)\n",
      "(1660, 1663)\n",
      "(1662, 1663)\n",
      "(1659, 1660)\n",
      "(45, 1660)\n",
      "(1661, 1662)\n",
      "(48, 1662)\n",
      "(1657, 1659)\n",
      "(1658, 1659)\n",
      "(1654, 1657)\n",
      "(1656, 1657)\n",
      "(37, 1654)\n",
      "(1655, 1656)\n",
      "(40, 1656)\n",
      "<class 'Loss.CrossEntropy'>: 1.2154794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 50/200 [00:01<00:06, 24.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1721, 1722)\n",
      "(1720, 1721)\n",
      "(1719, 1721)\n",
      "(1718, 1719)\n",
      "(1716, 1718)\n",
      "(1717, 1718)\n",
      "(1715, 1716)\n",
      "(1714, 1716)\n",
      "(1713, 1714)\n",
      "(1712, 1713)\n",
      "(1711, 1712)\n",
      "(1710, 1712)\n",
      "(1704, 1711)\n",
      "(1709, 1710)\n",
      "(1707, 1709)\n",
      "(1708, 1709)\n",
      "(1705, 1707)\n",
      "(1706, 1707)\n",
      "(1704, 1705)\n",
      "(1701, 1704)\n",
      "(1703, 1704)\n",
      "(1700, 1701)\n",
      "(53, 1701)\n",
      "(1702, 1703)\n",
      "(56, 1703)\n",
      "(1698, 1700)\n",
      "(1699, 1700)\n",
      "(1695, 1698)\n",
      "(1697, 1698)\n",
      "(1694, 1695)\n",
      "(45, 1695)\n",
      "(1696, 1697)\n",
      "(48, 1697)\n",
      "(1692, 1694)\n",
      "(1693, 1694)\n",
      "(1689, 1692)\n",
      "(1691, 1692)\n",
      "(37, 1689)\n",
      "(1690, 1691)\n",
      "(40, 1691)\n",
      "<class 'Loss.CrossEntropy'>: 0.9677149\n",
      "(1756, 1757)\n",
      "(1755, 1756)\n",
      "(1754, 1756)\n",
      "(1753, 1754)\n",
      "(1751, 1753)\n",
      "(1752, 1753)\n",
      "(1750, 1751)\n",
      "(1749, 1751)\n",
      "(1748, 1749)\n",
      "(1747, 1748)\n",
      "(1746, 1747)\n",
      "(1745, 1747)\n",
      "(1739, 1746)\n",
      "(1744, 1745)\n",
      "(1742, 1744)\n",
      "(1743, 1744)\n",
      "(1740, 1742)\n",
      "(1741, 1742)\n",
      "(1739, 1740)\n",
      "(1736, 1739)\n",
      "(1738, 1739)\n",
      "(1735, 1736)\n",
      "(53, 1736)\n",
      "(1737, 1738)\n",
      "(56, 1738)\n",
      "(1733, 1735)\n",
      "(1734, 1735)\n",
      "(1730, 1733)\n",
      "(1732, 1733)\n",
      "(1729, 1730)\n",
      "(45, 1730)\n",
      "(1731, 1732)\n",
      "(48, 1732)\n",
      "(1727, 1729)\n",
      "(1728, 1729)\n",
      "(1724, 1727)\n",
      "(1726, 1727)\n",
      "(37, 1724)\n",
      "(1725, 1726)\n",
      "(40, 1726)\n",
      "<class 'Loss.CrossEntropy'>: 1.0616348\n",
      "(1791, 1792)\n",
      "(1790, 1791)\n",
      "(1789, 1791)\n",
      "(1788, 1789)\n",
      "(1786, 1788)\n",
      "(1787, 1788)\n",
      "(1785, 1786)\n",
      "(1784, 1786)\n",
      "(1783, 1784)\n",
      "(1782, 1783)\n",
      "(1781, 1782)\n",
      "(1780, 1782)\n",
      "(1774, 1781)\n",
      "(1779, 1780)\n",
      "(1777, 1779)\n",
      "(1778, 1779)\n",
      "(1775, 1777)\n",
      "(1776, 1777)\n",
      "(1774, 1775)\n",
      "(1771, 1774)\n",
      "(1773, 1774)\n",
      "(1770, 1771)\n",
      "(53, 1771)\n",
      "(1772, 1773)\n",
      "(56, 1773)\n",
      "(1768, 1770)\n",
      "(1769, 1770)\n",
      "(1765, 1768)\n",
      "(1767, 1768)\n",
      "(1764, 1765)\n",
      "(45, 1765)\n",
      "(1766, 1767)\n",
      "(48, 1767)\n",
      "(1762, 1764)\n",
      "(1763, 1764)\n",
      "(1759, 1762)\n",
      "(1761, 1762)\n",
      "(37, 1759)\n",
      "(1760, 1761)\n",
      "(40, 1761)\n",
      "<class 'Loss.CrossEntropy'>: 1.2134764\n",
      "(1826, 1827)\n",
      "(1825, 1826)\n",
      "(1824, 1826)\n",
      "(1823, 1824)\n",
      "(1821, 1823)\n",
      "(1822, 1823)\n",
      "(1820, 1821)\n",
      "(1819, 1821)\n",
      "(1818, 1819)\n",
      "(1817, 1818)\n",
      "(1816, 1817)\n",
      "(1815, 1817)\n",
      "(1809, 1816)\n",
      "(1814, 1815)\n",
      "(1812, 1814)\n",
      "(1813, 1814)\n",
      "(1810, 1812)\n",
      "(1811, 1812)\n",
      "(1809, 1810)\n",
      "(1806, 1809)\n",
      "(1808, 1809)\n",
      "(1805, 1806)\n",
      "(53, 1806)\n",
      "(1807, 1808)\n",
      "(56, 1808)\n",
      "(1803, 1805)\n",
      "(1804, 1805)\n",
      "(1800, 1803)\n",
      "(1802, 1803)\n",
      "(1799, 1800)\n",
      "(45, 1800)\n",
      "(1801, 1802)\n",
      "(48, 1802)\n",
      "(1797, 1799)\n",
      "(1798, 1799)\n",
      "(1794, 1797)\n",
      "(1796, 1797)\n",
      "(37, 1794)\n",
      "(1795, 1796)\n",
      "(40, 1796)\n",
      "<class 'Loss.CrossEntropy'>: 0.79573226\n",
      "(1861, 1862)\n",
      "(1860, 1861)\n",
      "(1859, 1861)\n",
      "(1858, 1859)\n",
      "(1856, 1858)\n",
      "(1857, 1858)\n",
      "(1855, 1856)\n",
      "(1854, 1856)\n",
      "(1853, 1854)\n",
      "(1852, 1853)\n",
      "(1851, 1852)\n",
      "(1850, 1852)\n",
      "(1844, 1851)\n",
      "(1849, 1850)\n",
      "(1847, 1849)\n",
      "(1848, 1849)\n",
      "(1845, 1847)\n",
      "(1846, 1847)\n",
      "(1844, 1845)\n",
      "(1841, 1844)\n",
      "(1843, 1844)\n",
      "(1840, 1841)\n",
      "(53, 1841)\n",
      "(1842, 1843)\n",
      "(56, 1843)\n",
      "(1838, 1840)\n",
      "(1839, 1840)\n",
      "(1835, 1838)\n",
      "(1837, 1838)\n",
      "(1834, 1835)\n",
      "(45, 1835)\n",
      "(1836, 1837)\n",
      "(48, 1837)\n",
      "(1832, 1834)\n",
      "(1833, 1834)\n",
      "(1829, 1832)\n",
      "(1831, 1832)\n",
      "(37, 1829)\n",
      "(1830, 1831)\n",
      "(40, 1831)\n",
      "<class 'Loss.CrossEntropy'>: 1.2247865\n",
      "(1896, 1897)\n",
      "(1895, 1896)\n",
      "(1894, 1896)\n",
      "(1893, 1894)\n",
      "(1891, 1893)\n",
      "(1892, 1893)\n",
      "(1890, 1891)\n",
      "(1889, 1891)\n",
      "(1888, 1889)\n",
      "(1887, 1888)\n",
      "(1886, 1887)\n",
      "(1885, 1887)\n",
      "(1879, 1886)\n",
      "(1884, 1885)\n",
      "(1882, 1884)\n",
      "(1883, 1884)\n",
      "(1880, 1882)\n",
      "(1881, 1882)\n",
      "(1879, 1880)\n",
      "(1876, 1879)\n",
      "(1878, 1879)\n",
      "(1875, 1876)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 56/200 [00:01<00:05, 24.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 1876)\n",
      "(1877, 1878)\n",
      "(56, 1878)\n",
      "(1873, 1875)\n",
      "(1874, 1875)\n",
      "(1870, 1873)\n",
      "(1872, 1873)\n",
      "(1869, 1870)\n",
      "(45, 1870)\n",
      "(1871, 1872)\n",
      "(48, 1872)\n",
      "(1867, 1869)\n",
      "(1868, 1869)\n",
      "(1864, 1867)\n",
      "(1866, 1867)\n",
      "(37, 1864)\n",
      "(1865, 1866)\n",
      "(40, 1866)\n",
      "<class 'Loss.CrossEntropy'>: 0.8018501\n",
      "(1931, 1932)\n",
      "(1930, 1931)\n",
      "(1929, 1931)\n",
      "(1928, 1929)\n",
      "(1926, 1928)\n",
      "(1927, 1928)\n",
      "(1925, 1926)\n",
      "(1924, 1926)\n",
      "(1923, 1924)\n",
      "(1922, 1923)\n",
      "(1921, 1922)\n",
      "(1920, 1922)\n",
      "(1914, 1921)\n",
      "(1919, 1920)\n",
      "(1917, 1919)\n",
      "(1918, 1919)\n",
      "(1915, 1917)\n",
      "(1916, 1917)\n",
      "(1914, 1915)\n",
      "(1911, 1914)\n",
      "(1913, 1914)\n",
      "(1910, 1911)\n",
      "(53, 1911)\n",
      "(1912, 1913)\n",
      "(56, 1913)\n",
      "(1908, 1910)\n",
      "(1909, 1910)\n",
      "(1905, 1908)\n",
      "(1907, 1908)\n",
      "(1904, 1905)\n",
      "(45, 1905)\n",
      "(1906, 1907)\n",
      "(48, 1907)\n",
      "(1902, 1904)\n",
      "(1903, 1904)\n",
      "(1899, 1902)\n",
      "(1901, 1902)\n",
      "(37, 1899)\n",
      "(1900, 1901)\n",
      "(40, 1901)\n",
      "<class 'Loss.CrossEntropy'>: 1.423969\n",
      "(1966, 1967)\n",
      "(1965, 1966)\n",
      "(1964, 1966)\n",
      "(1963, 1964)\n",
      "(1961, 1963)\n",
      "(1962, 1963)\n",
      "(1960, 1961)\n",
      "(1959, 1961)\n",
      "(1958, 1959)\n",
      "(1957, 1958)\n",
      "(1956, 1957)\n",
      "(1955, 1957)\n",
      "(1949, 1956)\n",
      "(1954, 1955)\n",
      "(1952, 1954)\n",
      "(1953, 1954)\n",
      "(1950, 1952)\n",
      "(1951, 1952)\n",
      "(1949, 1950)\n",
      "(1946, 1949)\n",
      "(1948, 1949)\n",
      "(1945, 1946)\n",
      "(53, 1946)\n",
      "(1947, 1948)\n",
      "(56, 1948)\n",
      "(1943, 1945)\n",
      "(1944, 1945)\n",
      "(1940, 1943)\n",
      "(1942, 1943)\n",
      "(1939, 1940)\n",
      "(45, 1940)\n",
      "(1941, 1942)\n",
      "(48, 1942)\n",
      "(1937, 1939)\n",
      "(1938, 1939)\n",
      "(1934, 1937)\n",
      "(1936, 1937)\n",
      "(37, 1934)\n",
      "(1935, 1936)\n",
      "(40, 1936)\n",
      "<class 'Loss.CrossEntropy'>: 1.1713996\n",
      "(2001, 2002)\n",
      "(2000, 2001)\n",
      "(1999, 2001)\n",
      "(1998, 1999)\n",
      "(1996, 1998)\n",
      "(1997, 1998)\n",
      "(1995, 1996)\n",
      "(1994, 1996)\n",
      "(1993, 1994)\n",
      "(1992, 1993)\n",
      "(1991, 1992)\n",
      "(1990, 1992)\n",
      "(1984, 1991)\n",
      "(1989, 1990)\n",
      "(1987, 1989)\n",
      "(1988, 1989)\n",
      "(1985, 1987)\n",
      "(1986, 1987)\n",
      "(1984, 1985)\n",
      "(1981, 1984)\n",
      "(1983, 1984)\n",
      "(1980, 1981)\n",
      "(53, 1981)\n",
      "(1982, 1983)\n",
      "(56, 1983)\n",
      "(1978, 1980)\n",
      "(1979, 1980)\n",
      "(1975, 1978)\n",
      "(1977, 1978)\n",
      "(1974, 1975)\n",
      "(45, 1975)\n",
      "(1976, 1977)\n",
      "(48, 1977)\n",
      "(1972, 1974)\n",
      "(1973, 1974)\n",
      "(1969, 1972)\n",
      "(1971, 1972)\n",
      "(37, 1969)\n",
      "(1970, 1971)\n",
      "(40, 1971)\n",
      "<class 'Loss.CrossEntropy'>: 1.1839623\n",
      "(2036, 2037)\n",
      "(2035, 2036)\n",
      "(2034, 2036)\n",
      "(2033, 2034)\n",
      "(2031, 2033)\n",
      "(2032, 2033)\n",
      "(2030, 2031)\n",
      "(2029, 2031)\n",
      "(2028, 2029)\n",
      "(2027, 2028)\n",
      "(2026, 2027)\n",
      "(2025, 2027)\n",
      "(2019, 2026)\n",
      "(2024, 2025)\n",
      "(2022, 2024)\n",
      "(2023, 2024)\n",
      "(2020, 2022)\n",
      "(2021, 2022)\n",
      "(2019, 2020)\n",
      "(2016, 2019)\n",
      "(2018, 2019)\n",
      "(2015, 2016)\n",
      "(53, 2016)\n",
      "(2017, 2018)\n",
      "(56, 2018)\n",
      "(2013, 2015)\n",
      "(2014, 2015)\n",
      "(2010, 2013)\n",
      "(2012, 2013)\n",
      "(2009, 2010)\n",
      "(45, 2010)\n",
      "(2011, 2012)\n",
      "(48, 2012)\n",
      "(2007, 2009)\n",
      "(2008, 2009)\n",
      "(2004, 2007)\n",
      "(2006, 2007)\n",
      "(37, 2004)\n",
      "(2005, 2006)\n",
      "(40, 2006)\n",
      "<class 'Loss.CrossEntropy'>: 1.3336716\n",
      "(2071, 2072)\n",
      "(2070, 2071)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 59/200 [00:01<00:05, 24.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2069, 2071)\n",
      "(2068, 2069)\n",
      "(2066, 2068)\n",
      "(2067, 2068)\n",
      "(2065, 2066)\n",
      "(2064, 2066)\n",
      "(2063, 2064)\n",
      "(2062, 2063)\n",
      "(2061, 2062)\n",
      "(2060, 2062)\n",
      "(2054, 2061)\n",
      "(2059, 2060)\n",
      "(2057, 2059)\n",
      "(2058, 2059)\n",
      "(2055, 2057)\n",
      "(2056, 2057)\n",
      "(2054, 2055)\n",
      "(2051, 2054)\n",
      "(2053, 2054)\n",
      "(2050, 2051)\n",
      "(53, 2051)\n",
      "(2052, 2053)\n",
      "(56, 2053)\n",
      "(2048, 2050)\n",
      "(2049, 2050)\n",
      "(2045, 2048)\n",
      "(2047, 2048)\n",
      "(2044, 2045)\n",
      "(45, 2045)\n",
      "(2046, 2047)\n",
      "(48, 2047)\n",
      "(2042, 2044)\n",
      "(2043, 2044)\n",
      "(2039, 2042)\n",
      "(2041, 2042)\n",
      "(37, 2039)\n",
      "(2040, 2041)\n",
      "(40, 2041)\n",
      "<class 'Loss.CrossEntropy'>: 1.56784\n",
      "(2106, 2107)\n",
      "(2105, 2106)\n",
      "(2104, 2106)\n",
      "(2103, 2104)\n",
      "(2101, 2103)\n",
      "(2102, 2103)\n",
      "(2100, 2101)\n",
      "(2099, 2101)\n",
      "(2098, 2099)\n",
      "(2097, 2098)\n",
      "(2096, 2097)\n",
      "(2095, 2097)\n",
      "(2089, 2096)\n",
      "(2094, 2095)\n",
      "(2092, 2094)\n",
      "(2093, 2094)\n",
      "(2090, 2092)\n",
      "(2091, 2092)\n",
      "(2089, 2090)\n",
      "(2086, 2089)\n",
      "(2088, 2089)\n",
      "(2085, 2086)\n",
      "(53, 2086)\n",
      "(2087, 2088)\n",
      "(56, 2088)\n",
      "(2083, 2085)\n",
      "(2084, 2085)\n",
      "(2080, 2083)\n",
      "(2082, 2083)\n",
      "(2079, 2080)\n",
      "(45, 2080)\n",
      "(2081, 2082)\n",
      "(48, 2082)\n",
      "(2077, 2079)\n",
      "(2078, 2079)\n",
      "(2074, 2077)\n",
      "(2076, 2077)\n",
      "(37, 2074)\n",
      "(2075, 2076)\n",
      "(40, 2076)\n",
      "<class 'Loss.CrossEntropy'>: 1.0239289\n",
      "(2141, 2142)\n",
      "(2140, 2141)\n",
      "(2139, 2141)\n",
      "(2138, 2139)\n",
      "(2136, 2138)\n",
      "(2137, 2138)\n",
      "(2135, 2136)\n",
      "(2134, 2136)\n",
      "(2133, 2134)\n",
      "(2132, 2133)\n",
      "(2131, 2132)\n",
      "(2130, 2132)\n",
      "(2124, 2131)\n",
      "(2129, 2130)\n",
      "(2127, 2129)\n",
      "(2128, 2129)\n",
      "(2125, 2127)\n",
      "(2126, 2127)\n",
      "(2124, 2125)\n",
      "(2121, 2124)\n",
      "(2123, 2124)\n",
      "(2120, 2121)\n",
      "(53, 2121)\n",
      "(2122, 2123)\n",
      "(56, 2123)\n",
      "(2118, 2120)\n",
      "(2119, 2120)\n",
      "(2115, 2118)\n",
      "(2117, 2118)\n",
      "(2114, 2115)\n",
      "(45, 2115)\n",
      "(2116, 2117)\n",
      "(48, 2117)\n",
      "(2112, 2114)\n",
      "(2113, 2114)\n",
      "(2109, 2112)\n",
      "(2111, 2112)\n",
      "(37, 2109)\n",
      "(2110, 2111)\n",
      "(40, 2111)\n",
      "<class 'Loss.CrossEntropy'>: 1.1199824\n",
      "(2176, 2177)\n",
      "(2175, 2176)\n",
      "(2174, 2176)\n",
      "(2173, 2174)\n",
      "(2171, 2173)\n",
      "(2172, 2173)\n",
      "(2170, 2171)\n",
      "(2169, 2171)\n",
      "(2168, 2169)\n",
      "(2167, 2168)\n",
      "(2166, 2167)\n",
      "(2165, 2167)\n",
      "(2159, 2166)\n",
      "(2164, 2165)\n",
      "(2162, 2164)\n",
      "(2163, 2164)\n",
      "(2160, 2162)\n",
      "(2161, 2162)\n",
      "(2159, 2160)\n",
      "(2156, 2159)\n",
      "(2158, 2159)\n",
      "(2155, 2156)\n",
      "(53, 2156)\n",
      "(2157, 2158)\n",
      "(56, 2158)\n",
      "(2153, 2155)\n",
      "(2154, 2155)\n",
      "(2150, 2153)\n",
      "(2152, 2153)\n",
      "(2149, 2150)\n",
      "(45, 2150)\n",
      "(2151, 2152)\n",
      "(48, 2152)\n",
      "(2147, 2149)\n",
      "(2148, 2149)\n",
      "(2144, 2147)\n",
      "(2146, 2147)\n",
      "(37, 2144)\n",
      "(2145, 2146)\n",
      "(40, 2146)\n",
      "<class 'Loss.CrossEntropy'>: 1.0802951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 65/200 [00:02<00:07, 19.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2211, 2212)\n",
      "(2210, 2211)\n",
      "(2209, 2211)\n",
      "(2208, 2209)\n",
      "(2206, 2208)\n",
      "(2207, 2208)\n",
      "(2205, 2206)\n",
      "(2204, 2206)\n",
      "(2203, 2204)\n",
      "(2202, 2203)\n",
      "(2201, 2202)\n",
      "(2200, 2202)\n",
      "(2194, 2201)\n",
      "(2199, 2200)\n",
      "(2197, 2199)\n",
      "(2198, 2199)\n",
      "(2195, 2197)\n",
      "(2196, 2197)\n",
      "(2194, 2195)\n",
      "(2191, 2194)\n",
      "(2193, 2194)\n",
      "(2190, 2191)\n",
      "(53, 2191)\n",
      "(2192, 2193)\n",
      "(56, 2193)\n",
      "(2188, 2190)\n",
      "(2189, 2190)\n",
      "(2185, 2188)\n",
      "(2187, 2188)\n",
      "(2184, 2185)\n",
      "(45, 2185)\n",
      "(2186, 2187)\n",
      "(48, 2187)\n",
      "(2182, 2184)\n",
      "(2183, 2184)\n",
      "(2179, 2182)\n",
      "(2181, 2182)\n",
      "(37, 2179)\n",
      "(2180, 2181)\n",
      "(40, 2181)\n",
      "<class 'Loss.CrossEntropy'>: 1.1407695\n",
      "(2246, 2247)\n",
      "(2245, 2246)\n",
      "(2244, 2246)\n",
      "(2243, 2244)\n",
      "(2241, 2243)\n",
      "(2242, 2243)\n",
      "(2240, 2241)\n",
      "(2239, 2241)\n",
      "(2238, 2239)\n",
      "(2237, 2238)\n",
      "(2236, 2237)\n",
      "(2235, 2237)\n",
      "(2229, 2236)\n",
      "(2234, 2235)\n",
      "(2232, 2234)\n",
      "(2233, 2234)\n",
      "(2230, 2232)\n",
      "(2231, 2232)\n",
      "(2229, 2230)\n",
      "(2226, 2229)\n",
      "(2228, 2229)\n",
      "(2225, 2226)\n",
      "(53, 2226)\n",
      "(2227, 2228)\n",
      "(56, 2228)\n",
      "(2223, 2225)\n",
      "(2224, 2225)\n",
      "(2220, 2223)\n",
      "(2222, 2223)\n",
      "(2219, 2220)\n",
      "(45, 2220)\n",
      "(2221, 2222)\n",
      "(48, 2222)\n",
      "(2217, 2219)\n",
      "(2218, 2219)\n",
      "(2214, 2217)\n",
      "(2216, 2217)\n",
      "(37, 2214)\n",
      "(2215, 2216)\n",
      "(40, 2216)\n",
      "<class 'Loss.CrossEntropy'>: 1.0688618\n",
      "(2281, 2282)\n",
      "(2280, 2281)\n",
      "(2279, 2281)\n",
      "(2278, 2279)\n",
      "(2276, 2278)\n",
      "(2277, 2278)\n",
      "(2275, 2276)\n",
      "(2274, 2276)\n",
      "(2273, 2274)\n",
      "(2272, 2273)\n",
      "(2271, 2272)\n",
      "(2270, 2272)\n",
      "(2264, 2271)\n",
      "(2269, 2270)\n",
      "(2267, 2269)\n",
      "(2268, 2269)\n",
      "(2265, 2267)\n",
      "(2266, 2267)\n",
      "(2264, 2265)\n",
      "(2261, 2264)\n",
      "(2263, 2264)\n",
      "(2260, 2261)\n",
      "(53, 2261)\n",
      "(2262, 2263)\n",
      "(56, 2263)\n",
      "(2258, 2260)\n",
      "(2259, 2260)\n",
      "(2255, 2258)\n",
      "(2257, 2258)\n",
      "(2254, 2255)\n",
      "(45, 2255)\n",
      "(2256, 2257)\n",
      "(48, 2257)\n",
      "(2252, 2254)\n",
      "(2253, 2254)\n",
      "(2249, 2252)\n",
      "(2251, 2252)\n",
      "(37, 2249)\n",
      "(2250, 2251)\n",
      "(40, 2251)\n",
      "<class 'Loss.CrossEntropy'>: 1.2650857\n",
      "(2316, 2317)\n",
      "(2315, 2316)\n",
      "(2314, 2316)\n",
      "(2313, 2314)\n",
      "(2311, 2313)\n",
      "(2312, 2313)\n",
      "(2310, 2311)\n",
      "(2309, 2311)\n",
      "(2308, 2309)\n",
      "(2307, 2308)\n",
      "(2306, 2307)\n",
      "(2305, 2307)\n",
      "(2299, 2306)\n",
      "(2304, 2305)\n",
      "(2302, 2304)\n",
      "(2303, 2304)\n",
      "(2300, 2302)\n",
      "(2301, 2302)\n",
      "(2299, 2300)\n",
      "(2296, 2299)\n",
      "(2298, 2299)\n",
      "(2295, 2296)\n",
      "(53, 2296)\n",
      "(2297, 2298)\n",
      "(56, 2298)\n",
      "(2293, 2295)\n",
      "(2294, 2295)\n",
      "(2290, 2293)\n",
      "(2292, 2293)\n",
      "(2289, 2290)\n",
      "(45, 2290)\n",
      "(2291, 2292)\n",
      "(48, 2292)\n",
      "(2287, 2289)\n",
      "(2288, 2289)\n",
      "(2284, 2287)\n",
      "(2286, 2287)\n",
      "(37, 2284)\n",
      "(2285, 2286)\n",
      "(40, 2286)\n",
      "<class 'Loss.CrossEntropy'>: 1.1602588\n",
      "(2351, 2352)\n",
      "(2350, 2351)\n",
      "(2349, 2351)\n",
      "(2348, 2349)\n",
      "(2346, 2348)\n",
      "(2347, 2348)\n",
      "(2345, 2346)\n",
      "(2344, 2346)\n",
      "(2343, 2344)\n",
      "(2342, 2343)\n",
      "(2341, 2342)\n",
      "(2340, 2342)\n",
      "(2334, 2341)\n",
      "(2339, 2340)\n",
      "(2337, 2339)\n",
      "(2338, 2339)\n",
      "(2335, 2337)\n",
      "(2336, 2337)\n",
      "(2334, 2335)\n",
      "(2331, 2334)\n",
      "(2333, 2334)\n",
      "(2330, 2331)\n",
      "(53, 2331)\n",
      "(2332, 2333)\n",
      "(56, 2333)\n",
      "(2328, 2330)\n",
      "(2329, 2330)\n",
      "(2325, 2328)\n",
      "(2327, 2328)\n",
      "(2324, 2325)\n",
      "(45, 2325)\n",
      "(2326, 2327)\n",
      "(48, 2327)\n",
      "(2322, 2324)\n",
      "(2323, 2324)\n",
      "(2319, 2322)\n",
      "(2321, 2322)\n",
      "(37, 2319)\n",
      "(2320, 2321)\n",
      "(40, 2321)\n",
      "<class 'Loss.CrossEntropy'>: 1.308892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 68/200 [00:02<00:06, 19.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2386, 2387)\n",
      "(2385, 2386)\n",
      "(2384, 2386)\n",
      "(2383, 2384)\n",
      "(2381, 2383)\n",
      "(2382, 2383)\n",
      "(2380, 2381)\n",
      "(2379, 2381)\n",
      "(2378, 2379)\n",
      "(2377, 2378)\n",
      "(2376, 2377)\n",
      "(2375, 2377)\n",
      "(2369, 2376)\n",
      "(2374, 2375)\n",
      "(2372, 2374)\n",
      "(2373, 2374)\n",
      "(2370, 2372)\n",
      "(2371, 2372)\n",
      "(2369, 2370)\n",
      "(2366, 2369)\n",
      "(2368, 2369)\n",
      "(2365, 2366)\n",
      "(53, 2366)\n",
      "(2367, 2368)\n",
      "(56, 2368)\n",
      "(2363, 2365)\n",
      "(2364, 2365)\n",
      "(2360, 2363)\n",
      "(2362, 2363)\n",
      "(2359, 2360)\n",
      "(45, 2360)\n",
      "(2361, 2362)\n",
      "(48, 2362)\n",
      "(2357, 2359)\n",
      "(2358, 2359)\n",
      "(2354, 2357)\n",
      "(2356, 2357)\n",
      "(37, 2354)\n",
      "(2355, 2356)\n",
      "(40, 2356)\n",
      "<class 'Loss.CrossEntropy'>: 1.0163963\n",
      "(2421, 2422)\n",
      "(2420, 2421)\n",
      "(2419, 2421)\n",
      "(2418, 2419)\n",
      "(2416, 2418)\n",
      "(2417, 2418)\n",
      "(2415, 2416)\n",
      "(2414, 2416)\n",
      "(2413, 2414)\n",
      "(2412, 2413)\n",
      "(2411, 2412)\n",
      "(2410, 2412)\n",
      "(2404, 2411)\n",
      "(2409, 2410)\n",
      "(2407, 2409)\n",
      "(2408, 2409)\n",
      "(2405, 2407)\n",
      "(2406, 2407)\n",
      "(2404, 2405)\n",
      "(2401, 2404)\n",
      "(2403, 2404)\n",
      "(2400, 2401)\n",
      "(53, 2401)\n",
      "(2402, 2403)\n",
      "(56, 2403)\n",
      "(2398, 2400)\n",
      "(2399, 2400)\n",
      "(2395, 2398)\n",
      "(2397, 2398)\n",
      "(2394, 2395)\n",
      "(45, 2395)\n",
      "(2396, 2397)\n",
      "(48, 2397)\n",
      "(2392, 2394)\n",
      "(2393, 2394)\n",
      "(2389, 2392)\n",
      "(2391, 2392)\n",
      "(37, 2389)\n",
      "(2390, 2391)\n",
      "(40, 2391)\n",
      "<class 'Loss.CrossEntropy'>: 1.2032366\n",
      "(2456, 2457)\n",
      "(2455, 2456)\n",
      "(2454, 2456)\n",
      "(2453, 2454)\n",
      "(2451, 2453)\n",
      "(2452, 2453)\n",
      "(2450, 2451)\n",
      "(2449, 2451)\n",
      "(2448, 2449)\n",
      "(2447, 2448)\n",
      "(2446, 2447)\n",
      "(2445, 2447)\n",
      "(2439, 2446)\n",
      "(2444, 2445)\n",
      "(2442, 2444)\n",
      "(2443, 2444)\n",
      "(2440, 2442)\n",
      "(2441, 2442)\n",
      "(2439, 2440)\n",
      "(2436, 2439)\n",
      "(2438, 2439)\n",
      "(2435, 2436)\n",
      "(53, 2436)\n",
      "(2437, 2438)\n",
      "(56, 2438)\n",
      "(2433, 2435)\n",
      "(2434, 2435)\n",
      "(2430, 2433)\n",
      "(2432, 2433)\n",
      "(2429, 2430)\n",
      "(45, 2430)\n",
      "(2431, 2432)\n",
      "(48, 2432)\n",
      "(2427, 2429)\n",
      "(2428, 2429)\n",
      "(2424, 2427)\n",
      "(2426, 2427)\n",
      "(37, 2424)\n",
      "(2425, 2426)\n",
      "(40, 2426)\n",
      "<class 'Loss.CrossEntropy'>: 1.2672548\n",
      "(2491, 2492)\n",
      "(2490, 2491)\n",
      "(2489, 2491)\n",
      "(2488, 2489)\n",
      "(2486, 2488)\n",
      "(2487, 2488)\n",
      "(2485, 2486)\n",
      "(2484, 2486)\n",
      "(2483, 2484)\n",
      "(2482, 2483)\n",
      "(2481, 2482)\n",
      "(2480, 2482)\n",
      "(2474, 2481)\n",
      "(2479, 2480)\n",
      "(2477, 2479)\n",
      "(2478, 2479)\n",
      "(2475, 2477)\n",
      "(2476, 2477)\n",
      "(2474, 2475)\n",
      "(2471, 2474)\n",
      "(2473, 2474)\n",
      "(2470, 2471)\n",
      "(53, 2471)\n",
      "(2472, 2473)\n",
      "(56, 2473)\n",
      "(2468, 2470)\n",
      "(2469, 2470)\n",
      "(2465, 2468)\n",
      "(2467, 2468)\n",
      "(2464, 2465)\n",
      "(45, 2465)\n",
      "(2466, 2467)\n",
      "(48, 2467)\n",
      "(2462, 2464)\n",
      "(2463, 2464)\n",
      "(2459, 2462)\n",
      "(2461, 2462)\n",
      "(37, 2459)\n",
      "(2460, 2461)\n",
      "(40, 2461)\n",
      "<class 'Loss.CrossEntropy'>: 1.1551411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 71/200 [00:02<00:06, 19.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2526, 2527)\n",
      "(2525, 2526)\n",
      "(2524, 2526)\n",
      "(2523, 2524)\n",
      "(2521, 2523)\n",
      "(2522, 2523)\n",
      "(2520, 2521)\n",
      "(2519, 2521)\n",
      "(2518, 2519)\n",
      "(2517, 2518)\n",
      "(2516, 2517)\n",
      "(2515, 2517)\n",
      "(2509, 2516)\n",
      "(2514, 2515)\n",
      "(2512, 2514)\n",
      "(2513, 2514)\n",
      "(2510, 2512)\n",
      "(2511, 2512)\n",
      "(2509, 2510)\n",
      "(2506, 2509)\n",
      "(2508, 2509)\n",
      "(2505, 2506)\n",
      "(53, 2506)\n",
      "(2507, 2508)\n",
      "(56, 2508)\n",
      "(2503, 2505)\n",
      "(2504, 2505)\n",
      "(2500, 2503)\n",
      "(2502, 2503)\n",
      "(2499, 2500)\n",
      "(45, 2500)\n",
      "(2501, 2502)\n",
      "(48, 2502)\n",
      "(2497, 2499)\n",
      "(2498, 2499)\n",
      "(2494, 2497)\n",
      "(2496, 2497)\n",
      "(37, 2494)\n",
      "(2495, 2496)\n",
      "(40, 2496)\n",
      "<class 'Loss.CrossEntropy'>: 1.239825\n",
      "(2561, 2562)\n",
      "(2560, 2561)\n",
      "(2559, 2561)\n",
      "(2558, 2559)\n",
      "(2556, 2558)\n",
      "(2557, 2558)\n",
      "(2555, 2556)\n",
      "(2554, 2556)\n",
      "(2553, 2554)\n",
      "(2552, 2553)\n",
      "(2551, 2552)\n",
      "(2550, 2552)\n",
      "(2544, 2551)\n",
      "(2549, 2550)\n",
      "(2547, 2549)\n",
      "(2548, 2549)\n",
      "(2545, 2547)\n",
      "(2546, 2547)\n",
      "(2544, 2545)\n",
      "(2541, 2544)\n",
      "(2543, 2544)\n",
      "(2540, 2541)\n",
      "(53, 2541)\n",
      "(2542, 2543)\n",
      "(56, 2543)\n",
      "(2538, 2540)\n",
      "(2539, 2540)\n",
      "(2535, 2538)\n",
      "(2537, 2538)\n",
      "(2534, 2535)\n",
      "(45, 2535)\n",
      "(2536, 2537)\n",
      "(48, 2537)\n",
      "(2532, 2534)\n",
      "(2533, 2534)\n",
      "(2529, 2532)\n",
      "(2531, 2532)\n",
      "(37, 2529)\n",
      "(2530, 2531)\n",
      "(40, 2531)\n",
      "<class 'Loss.CrossEntropy'>: 1.1489624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 76/200 [00:03<00:08, 15.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2596, 2597)\n",
      "(2595, 2596)\n",
      "(2594, 2596)\n",
      "(2593, 2594)\n",
      "(2591, 2593)\n",
      "(2592, 2593)\n",
      "(2590, 2591)\n",
      "(2589, 2591)\n",
      "(2588, 2589)\n",
      "(2587, 2588)\n",
      "(2586, 2587)\n",
      "(2585, 2587)\n",
      "(2579, 2586)\n",
      "(2584, 2585)\n",
      "(2582, 2584)\n",
      "(2583, 2584)\n",
      "(2580, 2582)\n",
      "(2581, 2582)\n",
      "(2579, 2580)\n",
      "(2576, 2579)\n",
      "(2578, 2579)\n",
      "(2575, 2576)\n",
      "(53, 2576)\n",
      "(2577, 2578)\n",
      "(56, 2578)\n",
      "(2573, 2575)\n",
      "(2574, 2575)\n",
      "(2570, 2573)\n",
      "(2572, 2573)\n",
      "(2569, 2570)\n",
      "(45, 2570)\n",
      "(2571, 2572)\n",
      "(48, 2572)\n",
      "(2567, 2569)\n",
      "(2568, 2569)\n",
      "(2564, 2567)\n",
      "(2566, 2567)\n",
      "(37, 2564)\n",
      "(2565, 2566)\n",
      "(40, 2566)\n",
      "<class 'Loss.CrossEntropy'>: 0.87906396\n",
      "(2631, 2632)\n",
      "(2630, 2631)\n",
      "(2629, 2631)\n",
      "(2628, 2629)\n",
      "(2626, 2628)\n",
      "(2627, 2628)\n",
      "(2625, 2626)\n",
      "(2624, 2626)\n",
      "(2623, 2624)\n",
      "(2622, 2623)\n",
      "(2621, 2622)\n",
      "(2620, 2622)\n",
      "(2614, 2621)\n",
      "(2619, 2620)\n",
      "(2617, 2619)\n",
      "(2618, 2619)\n",
      "(2615, 2617)\n",
      "(2616, 2617)\n",
      "(2614, 2615)\n",
      "(2611, 2614)\n",
      "(2613, 2614)\n",
      "(2610, 2611)\n",
      "(53, 2611)\n",
      "(2612, 2613)\n",
      "(56, 2613)\n",
      "(2608, 2610)\n",
      "(2609, 2610)\n",
      "(2605, 2608)\n",
      "(2607, 2608)\n",
      "(2604, 2605)\n",
      "(45, 2605)\n",
      "(2606, 2607)\n",
      "(48, 2607)\n",
      "(2602, 2604)\n",
      "(2603, 2604)\n",
      "(2599, 2602)\n",
      "(2601, 2602)\n",
      "(37, 2599)\n",
      "(2600, 2601)\n",
      "(40, 2601)\n",
      "<class 'Loss.CrossEntropy'>: 0.68278617\n",
      "(2666, 2667)\n",
      "(2665, 2666)\n",
      "(2664, 2666)\n",
      "(2663, 2664)\n",
      "(2661, 2663)\n",
      "(2662, 2663)\n",
      "(2660, 2661)\n",
      "(2659, 2661)\n",
      "(2658, 2659)\n",
      "(2657, 2658)\n",
      "(2656, 2657)\n",
      "(2655, 2657)\n",
      "(2649, 2656)\n",
      "(2654, 2655)\n",
      "(2652, 2654)\n",
      "(2653, 2654)\n",
      "(2650, 2652)\n",
      "(2651, 2652)\n",
      "(2649, 2650)\n",
      "(2646, 2649)\n",
      "(2648, 2649)\n",
      "(2645, 2646)\n",
      "(53, 2646)\n",
      "(2647, 2648)\n",
      "(56, 2648)\n",
      "(2643, 2645)\n",
      "(2644, 2645)\n",
      "(2640, 2643)\n",
      "(2642, 2643)\n",
      "(2639, 2640)\n",
      "(45, 2640)\n",
      "(2641, 2642)\n",
      "(48, 2642)\n",
      "(2637, 2639)\n",
      "(2638, 2639)\n",
      "(2634, 2637)\n",
      "(2636, 2637)\n",
      "(37, 2634)\n",
      "(2635, 2636)\n",
      "(40, 2636)\n",
      "<class 'Loss.CrossEntropy'>: 1.2211173\n",
      "(2701, 2702)\n",
      "(2700, 2701)\n",
      "(2699, 2701)\n",
      "(2698, 2699)\n",
      "(2696, 2698)\n",
      "(2697, 2698)\n",
      "(2695, 2696)\n",
      "(2694, 2696)\n",
      "(2693, 2694)\n",
      "(2692, 2693)\n",
      "(2691, 2692)\n",
      "(2690, 2692)\n",
      "(2684, 2691)\n",
      "(2689, 2690)\n",
      "(2687, 2689)\n",
      "(2688, 2689)\n",
      "(2685, 2687)\n",
      "(2686, 2687)\n",
      "(2684, 2685)\n",
      "(2681, 2684)\n",
      "(2683, 2684)\n",
      "(2680, 2681)\n",
      "(53, 2681)\n",
      "(2682, 2683)\n",
      "(56, 2683)\n",
      "(2678, 2680)\n",
      "(2679, 2680)\n",
      "(2675, 2678)\n",
      "(2677, 2678)\n",
      "(2674, 2675)\n",
      "(45, 2675)\n",
      "(2676, 2677)\n",
      "(48, 2677)\n",
      "(2672, 2674)\n",
      "(2673, 2674)\n",
      "(2669, 2672)\n",
      "(2671, 2672)\n",
      "(37, 2669)\n",
      "(2670, 2671)\n",
      "(40, 2671)\n",
      "<class 'Loss.CrossEntropy'>: 1.0991368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 80/200 [00:03<00:07, 15.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2736, 2737)\n",
      "(2735, 2736)\n",
      "(2734, 2736)\n",
      "(2733, 2734)\n",
      "(2731, 2733)\n",
      "(2732, 2733)\n",
      "(2730, 2731)\n",
      "(2729, 2731)\n",
      "(2728, 2729)\n",
      "(2727, 2728)\n",
      "(2726, 2727)\n",
      "(2725, 2727)\n",
      "(2719, 2726)\n",
      "(2724, 2725)\n",
      "(2722, 2724)\n",
      "(2723, 2724)\n",
      "(2720, 2722)\n",
      "(2721, 2722)\n",
      "(2719, 2720)\n",
      "(2716, 2719)\n",
      "(2718, 2719)\n",
      "(2715, 2716)\n",
      "(53, 2716)\n",
      "(2717, 2718)\n",
      "(56, 2718)\n",
      "(2713, 2715)\n",
      "(2714, 2715)\n",
      "(2710, 2713)\n",
      "(2712, 2713)\n",
      "(2709, 2710)\n",
      "(45, 2710)\n",
      "(2711, 2712)\n",
      "(48, 2712)\n",
      "(2707, 2709)\n",
      "(2708, 2709)\n",
      "(2704, 2707)\n",
      "(2706, 2707)\n",
      "(37, 2704)\n",
      "(2705, 2706)\n",
      "(40, 2706)\n",
      "<class 'Loss.CrossEntropy'>: 1.2003455\n",
      "(2771, 2772)\n",
      "(2770, 2771)\n",
      "(2769, 2771)\n",
      "(2768, 2769)\n",
      "(2766, 2768)\n",
      "(2767, 2768)\n",
      "(2765, 2766)\n",
      "(2764, 2766)\n",
      "(2763, 2764)\n",
      "(2762, 2763)\n",
      "(2761, 2762)\n",
      "(2760, 2762)\n",
      "(2754, 2761)\n",
      "(2759, 2760)\n",
      "(2757, 2759)\n",
      "(2758, 2759)\n",
      "(2755, 2757)\n",
      "(2756, 2757)\n",
      "(2754, 2755)\n",
      "(2751, 2754)\n",
      "(2753, 2754)\n",
      "(2750, 2751)\n",
      "(53, 2751)\n",
      "(2752, 2753)\n",
      "(56, 2753)\n",
      "(2748, 2750)\n",
      "(2749, 2750)\n",
      "(2745, 2748)\n",
      "(2747, 2748)\n",
      "(2744, 2745)\n",
      "(45, 2745)\n",
      "(2746, 2747)\n",
      "(48, 2747)\n",
      "(2742, 2744)\n",
      "(2743, 2744)\n",
      "(2739, 2742)\n",
      "(2741, 2742)\n",
      "(37, 2739)\n",
      "(2740, 2741)\n",
      "(40, 2741)\n",
      "<class 'Loss.CrossEntropy'>: 1.1707993\n",
      "(2806, 2807)\n",
      "(2805, 2806)\n",
      "(2804, 2806)\n",
      "(2803, 2804)\n",
      "(2801, 2803)\n",
      "(2802, 2803)\n",
      "(2800, 2801)\n",
      "(2799, 2801)\n",
      "(2798, 2799)\n",
      "(2797, 2798)\n",
      "(2796, 2797)\n",
      "(2795, 2797)\n",
      "(2789, 2796)\n",
      "(2794, 2795)\n",
      "(2792, 2794)\n",
      "(2793, 2794)\n",
      "(2790, 2792)\n",
      "(2791, 2792)\n",
      "(2789, 2790)\n",
      "(2786, 2789)\n",
      "(2788, 2789)\n",
      "(2785, 2786)\n",
      "(53, 2786)\n",
      "(2787, 2788)\n",
      "(56, 2788)\n",
      "(2783, 2785)\n",
      "(2784, 2785)\n",
      "(2780, 2783)\n",
      "(2782, 2783)\n",
      "(2779, 2780)\n",
      "(45, 2780)\n",
      "(2781, 2782)\n",
      "(48, 2782)\n",
      "(2777, 2779)\n",
      "(2778, 2779)\n",
      "(2774, 2777)\n",
      "(2776, 2777)\n",
      "(37, 2774)\n",
      "(2775, 2776)\n",
      "(40, 2776)\n",
      "<class 'Loss.CrossEntropy'>: 1.1825467\n",
      "(2841, 2842)\n",
      "(2840, 2841)\n",
      "(2839, 2841)\n",
      "(2838, 2839)\n",
      "(2836, 2838)\n",
      "(2837, 2838)\n",
      "(2835, 2836)\n",
      "(2834, 2836)\n",
      "(2833, 2834)\n",
      "(2832, 2833)\n",
      "(2831, 2832)\n",
      "(2830, 2832)\n",
      "(2824, 2831)\n",
      "(2829, 2830)\n",
      "(2827, 2829)\n",
      "(2828, 2829)\n",
      "(2825, 2827)\n",
      "(2826, 2827)\n",
      "(2824, 2825)\n",
      "(2821, 2824)\n",
      "(2823, 2824)\n",
      "(2820, 2821)\n",
      "(53, 2821)\n",
      "(2822, 2823)\n",
      "(56, 2823)\n",
      "(2818, 2820)\n",
      "(2819, 2820)\n",
      "(2815, 2818)\n",
      "(2817, 2818)\n",
      "(2814, 2815)\n",
      "(45, 2815)\n",
      "(2816, 2817)\n",
      "(48, 2817)\n",
      "(2812, 2814)\n",
      "(2813, 2814)\n",
      "(2809, 2812)\n",
      "(2811, 2812)\n",
      "(37, 2809)\n",
      "(2810, 2811)\n",
      "(40, 2811)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 82/200 [00:03<00:07, 15.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'Loss.CrossEntropy'>: 1.36744\n",
      "(2876, 2877)\n",
      "(2875, 2876)\n",
      "(2874, 2876)\n",
      "(2873, 2874)\n",
      "(2871, 2873)\n",
      "(2872, 2873)\n",
      "(2870, 2871)\n",
      "(2869, 2871)\n",
      "(2868, 2869)\n",
      "(2867, 2868)\n",
      "(2866, 2867)\n",
      "(2865, 2867)\n",
      "(2859, 2866)\n",
      "(2864, 2865)\n",
      "(2862, 2864)\n",
      "(2863, 2864)\n",
      "(2860, 2862)\n",
      "(2861, 2862)\n",
      "(2859, 2860)\n",
      "(2856, 2859)\n",
      "(2858, 2859)\n",
      "(2855, 2856)\n",
      "(53, 2856)\n",
      "(2857, 2858)\n",
      "(56, 2858)\n",
      "(2853, 2855)\n",
      "(2854, 2855)\n",
      "(2850, 2853)\n",
      "(2852, 2853)\n",
      "(2849, 2850)\n",
      "(45, 2850)\n",
      "(2851, 2852)\n",
      "(48, 2852)\n",
      "(2847, 2849)\n",
      "(2848, 2849)\n",
      "(2844, 2847)\n",
      "(2846, 2847)\n",
      "(37, 2844)\n",
      "(2845, 2846)\n",
      "(40, 2846)\n",
      "<class 'Loss.CrossEntropy'>: 1.1099784\n",
      "(2911, 2912)\n",
      "(2910, 2911)\n",
      "(2909, 2911)\n",
      "(2908, 2909)\n",
      "(2906, 2908)\n",
      "(2907, 2908)\n",
      "(2905, 2906)\n",
      "(2904, 2906)\n",
      "(2903, 2904)\n",
      "(2902, 2903)\n",
      "(2901, 2902)\n",
      "(2900, 2902)\n",
      "(2894, 2901)\n",
      "(2899, 2900)\n",
      "(2897, 2899)\n",
      "(2898, 2899)\n",
      "(2895, 2897)\n",
      "(2896, 2897)\n",
      "(2894, 2895)\n",
      "(2891, 2894)\n",
      "(2893, 2894)\n",
      "(2890, 2891)\n",
      "(53, 2891)\n",
      "(2892, 2893)\n",
      "(56, 2893)\n",
      "(2888, 2890)\n",
      "(2889, 2890)\n",
      "(2885, 2888)\n",
      "(2887, 2888)\n",
      "(2884, 2885)\n",
      "(45, 2885)\n",
      "(2886, 2887)\n",
      "(48, 2887)\n",
      "(2882, 2884)\n",
      "(2883, 2884)\n",
      "(2879, 2882)\n",
      "(2881, 2882)\n",
      "(37, 2879)\n",
      "(2880, 2881)\n",
      "(40, 2881)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 84/200 [00:03<00:11, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'Loss.CrossEntropy'>: 1.3279276\n",
      "(2946, 2947)\n",
      "(2945, 2946)\n",
      "(2944, 2946)\n",
      "(2943, 2944)\n",
      "(2941, 2943)\n",
      "(2942, 2943)\n",
      "(2940, 2941)\n",
      "(2939, 2941)\n",
      "(2938, 2939)\n",
      "(2937, 2938)\n",
      "(2936, 2937)\n",
      "(2935, 2937)\n",
      "(2929, 2936)\n",
      "(2934, 2935)\n",
      "(2932, 2934)\n",
      "(2933, 2934)\n",
      "(2930, 2932)\n",
      "(2931, 2932)\n",
      "(2929, 2930)\n",
      "(2926, 2929)\n",
      "(2928, 2929)\n",
      "(2925, 2926)\n",
      "(53, 2926)\n",
      "(2927, 2928)\n",
      "(56, 2928)\n",
      "(2923, 2925)\n",
      "(2924, 2925)\n",
      "(2920, 2923)\n",
      "(2922, 2923)\n",
      "(2919, 2920)\n",
      "(45, 2920)\n",
      "(2921, 2922)\n",
      "(48, 2922)\n",
      "(2917, 2919)\n",
      "(2918, 2919)\n",
      "(2914, 2917)\n",
      "(2916, 2917)\n",
      "(37, 2914)\n",
      "(2915, 2916)\n",
      "(40, 2916)\n",
      "<class 'Loss.CrossEntropy'>: 1.0928459\n",
      "(2981, 2982)\n",
      "(2980, 2981)\n",
      "(2979, 2981)\n",
      "(2978, 2979)\n",
      "(2976, 2978)\n",
      "(2977, 2978)\n",
      "(2975, 2976)\n",
      "(2974, 2976)\n",
      "(2973, 2974)\n",
      "(2972, 2973)\n",
      "(2971, 2972)\n",
      "(2970, 2972)\n",
      "(2964, 2971)\n",
      "(2969, 2970)\n",
      "(2967, 2969)\n",
      "(2968, 2969)\n",
      "(2965, 2967)\n",
      "(2966, 2967)\n",
      "(2964, 2965)\n",
      "(2961, 2964)\n",
      "(2963, 2964)\n",
      "(2960, 2961)\n",
      "(53, 2961)\n",
      "(2962, 2963)\n",
      "(56, 2963)\n",
      "(2958, 2960)\n",
      "(2959, 2960)\n",
      "(2955, 2958)\n",
      "(2957, 2958)\n",
      "(2954, 2955)\n",
      "(45, 2955)\n",
      "(2956, 2957)\n",
      "(48, 2957)\n",
      "(2952, 2954)\n",
      "(2953, 2954)\n",
      "(2949, 2952)\n",
      "(2951, 2952)\n",
      "(37, 2949)\n",
      "(2950, 2951)\n",
      "(40, 2951)\n",
      "<class 'Loss.CrossEntropy'>: 1.1337192\n",
      "(3016, 3017)\n",
      "(3015, 3016)\n",
      "(3014, 3016)\n",
      "(3013, 3014)\n",
      "(3011, 3013)\n",
      "(3012, 3013)\n",
      "(3010, 3011)\n",
      "(3009, 3011)\n",
      "(3008, 3009)\n",
      "(3007, 3008)\n",
      "(3006, 3007)\n",
      "(3005, 3007)\n",
      "(2999, 3006)\n",
      "(3004, 3005)\n",
      "(3002, 3004)\n",
      "(3003, 3004)\n",
      "(3000, 3002)\n",
      "(3001, 3002)\n",
      "(2999, 3000)\n",
      "(2996, 2999)\n",
      "(2998, 2999)\n",
      "(2995, 2996)\n",
      "(53, 2996)\n",
      "(2997, 2998)\n",
      "(56, 2998)\n",
      "(2993, 2995)\n",
      "(2994, 2995)\n",
      "(2990, 2993)\n",
      "(2992, 2993)\n",
      "(2989, 2990)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 88/200 [00:04<00:09, 12.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 2990)\n",
      "(2991, 2992)\n",
      "(48, 2992)\n",
      "(2987, 2989)\n",
      "(2988, 2989)\n",
      "(2984, 2987)\n",
      "(2986, 2987)\n",
      "(37, 2984)\n",
      "(2985, 2986)\n",
      "(40, 2986)\n",
      "<class 'Loss.CrossEntropy'>: 1.027327\n",
      "(3051, 3052)\n",
      "(3050, 3051)\n",
      "(3049, 3051)\n",
      "(3048, 3049)\n",
      "(3046, 3048)\n",
      "(3047, 3048)\n",
      "(3045, 3046)\n",
      "(3044, 3046)\n",
      "(3043, 3044)\n",
      "(3042, 3043)\n",
      "(3041, 3042)\n",
      "(3040, 3042)\n",
      "(3034, 3041)\n",
      "(3039, 3040)\n",
      "(3037, 3039)\n",
      "(3038, 3039)\n",
      "(3035, 3037)\n",
      "(3036, 3037)\n",
      "(3034, 3035)\n",
      "(3031, 3034)\n",
      "(3033, 3034)\n",
      "(3030, 3031)\n",
      "(53, 3031)\n",
      "(3032, 3033)\n",
      "(56, 3033)\n",
      "(3028, 3030)\n",
      "(3029, 3030)\n",
      "(3025, 3028)\n",
      "(3027, 3028)\n",
      "(3024, 3025)\n",
      "(45, 3025)\n",
      "(3026, 3027)\n",
      "(48, 3027)\n",
      "(3022, 3024)\n",
      "(3023, 3024)\n",
      "(3019, 3022)\n",
      "(3021, 3022)\n",
      "(37, 3019)\n",
      "(3020, 3021)\n",
      "(40, 3021)\n",
      "<class 'Loss.CrossEntropy'>: 1.0643773\n",
      "(3086, 3087)\n",
      "(3085, 3086)\n",
      "(3084, 3086)\n",
      "(3083, 3084)\n",
      "(3081, 3083)\n",
      "(3082, 3083)\n",
      "(3080, 3081)\n",
      "(3079, 3081)\n",
      "(3078, 3079)\n",
      "(3077, 3078)\n",
      "(3076, 3077)\n",
      "(3075, 3077)\n",
      "(3069, 3076)\n",
      "(3074, 3075)\n",
      "(3072, 3074)\n",
      "(3073, 3074)\n",
      "(3070, 3072)\n",
      "(3071, 3072)\n",
      "(3069, 3070)\n",
      "(3066, 3069)\n",
      "(3068, 3069)\n",
      "(3065, 3066)\n",
      "(53, 3066)\n",
      "(3067, 3068)\n",
      "(56, 3068)\n",
      "(3063, 3065)\n",
      "(3064, 3065)\n",
      "(3060, 3063)\n",
      "(3062, 3063)\n",
      "(3059, 3060)\n",
      "(45, 3060)\n",
      "(3061, 3062)\n",
      "(48, 3062)\n",
      "(3057, 3059)\n",
      "(3058, 3059)\n",
      "(3054, 3057)\n",
      "(3056, 3057)\n",
      "(37, 3054)\n",
      "(3055, 3056)\n",
      "(40, 3056)\n",
      "<class 'Loss.CrossEntropy'>: 1.3093257\n",
      "(3121, 3122)\n",
      "(3120, 3121)\n",
      "(3119, 3121)\n",
      "(3118, 3119)\n",
      "(3116, 3118)\n",
      "(3117, 3118)\n",
      "(3115, 3116)\n",
      "(3114, 3116)\n",
      "(3113, 3114)\n",
      "(3112, 3113)\n",
      "(3111, 3112)\n",
      "(3110, 3112)\n",
      "(3104, 3111)\n",
      "(3109, 3110)\n",
      "(3107, 3109)\n",
      "(3108, 3109)\n",
      "(3105, 3107)\n",
      "(3106, 3107)\n",
      "(3104, 3105)\n",
      "(3101, 3104)\n",
      "(3103, 3104)\n",
      "(3100, 3101)\n",
      "(53, 3101)\n",
      "(3102, 3103)\n",
      "(56, 3103)\n",
      "(3098, 3100)\n",
      "(3099, 3100)\n",
      "(3095, 3098)\n",
      "(3097, 3098)\n",
      "(3094, 3095)\n",
      "(45, 3095)\n",
      "(3096, 3097)\n",
      "(48, 3097)\n",
      "(3092, 3094)\n",
      "(3093, 3094)\n",
      "(3089, 3092)\n",
      "(3091, 3092)\n",
      "(37, 3089)\n",
      "(3090, 3091)\n",
      "(40, 3091)\n",
      "<class 'Loss.CrossEntropy'>: 1.2493942\n",
      "(3156, 3157)\n",
      "(3155, 3156)\n",
      "(3154, 3156)\n",
      "(3153, 3154)\n",
      "(3151, 3153)\n",
      "(3152, 3153)\n",
      "(3150, 3151)\n",
      "(3149, 3151)\n",
      "(3148, 3149)\n",
      "(3147, 3148)\n",
      "(3146, 3147)\n",
      "(3145, 3147)\n",
      "(3139, 3146)\n",
      "(3144, 3145)\n",
      "(3142, 3144)\n",
      "(3143, 3144)\n",
      "(3140, 3142)\n",
      "(3141, 3142)\n",
      "(3139, 3140)\n",
      "(3136, 3139)\n",
      "(3138, 3139)\n",
      "(3135, 3136)\n",
      "(53, 3136)\n",
      "(3137, 3138)\n",
      "(56, 3138)\n",
      "(3133, 3135)\n",
      "(3134, 3135)\n",
      "(3130, 3133)\n",
      "(3132, 3133)\n",
      "(3129, 3130)\n",
      "(45, 3130)\n",
      "(3131, 3132)\n",
      "(48, 3132)\n",
      "(3127, 3129)\n",
      "(3128, 3129)\n",
      "(3124, 3127)\n",
      "(3126, 3127)\n",
      "(37, 3124)\n",
      "(3125, 3126)\n",
      "(40, 3126)\n",
      "<class 'Loss.CrossEntropy'>: 1.2707746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 92/200 [00:04<00:10, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3191, 3192)\n",
      "(3190, 3191)\n",
      "(3189, 3191)\n",
      "(3188, 3189)\n",
      "(3186, 3188)\n",
      "(3187, 3188)\n",
      "(3185, 3186)\n",
      "(3184, 3186)\n",
      "(3183, 3184)\n",
      "(3182, 3183)\n",
      "(3181, 3182)\n",
      "(3180, 3182)\n",
      "(3174, 3181)\n",
      "(3179, 3180)\n",
      "(3177, 3179)\n",
      "(3178, 3179)\n",
      "(3175, 3177)\n",
      "(3176, 3177)\n",
      "(3174, 3175)\n",
      "(3171, 3174)\n",
      "(3173, 3174)\n",
      "(3170, 3171)\n",
      "(53, 3171)\n",
      "(3172, 3173)\n",
      "(56, 3173)\n",
      "(3168, 3170)\n",
      "(3169, 3170)\n",
      "(3165, 3168)\n",
      "(3167, 3168)\n",
      "(3164, 3165)\n",
      "(45, 3165)\n",
      "(3166, 3167)\n",
      "(48, 3167)\n",
      "(3162, 3164)\n",
      "(3163, 3164)\n",
      "(3159, 3162)\n",
      "(3161, 3162)\n",
      "(37, 3159)\n",
      "(3160, 3161)\n",
      "(40, 3161)\n",
      "<class 'Loss.CrossEntropy'>: 0.99406606\n",
      "(3226, 3227)\n",
      "(3225, 3226)\n",
      "(3224, 3226)\n",
      "(3223, 3224)\n",
      "(3221, 3223)\n",
      "(3222, 3223)\n",
      "(3220, 3221)\n",
      "(3219, 3221)\n",
      "(3218, 3219)\n",
      "(3217, 3218)\n",
      "(3216, 3217)\n",
      "(3215, 3217)\n",
      "(3209, 3216)\n",
      "(3214, 3215)\n",
      "(3212, 3214)\n",
      "(3213, 3214)\n",
      "(3210, 3212)\n",
      "(3211, 3212)\n",
      "(3209, 3210)\n",
      "(3206, 3209)\n",
      "(3208, 3209)\n",
      "(3205, 3206)\n",
      "(53, 3206)\n",
      "(3207, 3208)\n",
      "(56, 3208)\n",
      "(3203, 3205)\n",
      "(3204, 3205)\n",
      "(3200, 3203)\n",
      "(3202, 3203)\n",
      "(3199, 3200)\n",
      "(45, 3200)\n",
      "(3201, 3202)\n",
      "(48, 3202)\n",
      "(3197, 3199)\n",
      "(3198, 3199)\n",
      "(3194, 3197)\n",
      "(3196, 3197)\n",
      "(37, 3194)\n",
      "(3195, 3196)\n",
      "(40, 3196)\n",
      "<class 'Loss.CrossEntropy'>: 1.2593932\n",
      "(3261, 3262)\n",
      "(3260, 3261)\n",
      "(3259, 3261)\n",
      "(3258, 3259)\n",
      "(3256, 3258)\n",
      "(3257, 3258)\n",
      "(3255, 3256)\n",
      "(3254, 3256)\n",
      "(3253, 3254)\n",
      "(3252, 3253)\n",
      "(3251, 3252)\n",
      "(3250, 3252)\n",
      "(3244, 3251)\n",
      "(3249, 3250)\n",
      "(3247, 3249)\n",
      "(3248, 3249)\n",
      "(3245, 3247)\n",
      "(3246, 3247)\n",
      "(3244, 3245)\n",
      "(3241, 3244)\n",
      "(3243, 3244)\n",
      "(3240, 3241)\n",
      "(53, 3241)\n",
      "(3242, 3243)\n",
      "(56, 3243)\n",
      "(3238, 3240)\n",
      "(3239, 3240)\n",
      "(3235, 3238)\n",
      "(3237, 3238)\n",
      "(3234, 3235)\n",
      "(45, 3235)\n",
      "(3236, 3237)\n",
      "(48, 3237)\n",
      "(3232, 3234)\n",
      "(3233, 3234)\n",
      "(3229, 3232)\n",
      "(3231, 3232)\n",
      "(37, 3229)\n",
      "(3230, 3231)\n",
      "(40, 3231)\n",
      "<class 'Loss.CrossEntropy'>: 1.165638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 94/200 [00:04<00:09, 11.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3296, 3297)\n",
      "(3295, 3296)\n",
      "(3294, 3296)\n",
      "(3293, 3294)\n",
      "(3291, 3293)\n",
      "(3292, 3293)\n",
      "(3290, 3291)\n",
      "(3289, 3291)\n",
      "(3288, 3289)\n",
      "(3287, 3288)\n",
      "(3286, 3287)\n",
      "(3285, 3287)\n",
      "(3279, 3286)\n",
      "(3284, 3285)\n",
      "(3282, 3284)\n",
      "(3283, 3284)\n",
      "(3280, 3282)\n",
      "(3281, 3282)\n",
      "(3279, 3280)\n",
      "(3276, 3279)\n",
      "(3278, 3279)\n",
      "(3275, 3276)\n",
      "(53, 3276)\n",
      "(3277, 3278)\n",
      "(56, 3278)\n",
      "(3273, 3275)\n",
      "(3274, 3275)\n",
      "(3270, 3273)\n",
      "(3272, 3273)\n",
      "(3269, 3270)\n",
      "(45, 3270)\n",
      "(3271, 3272)\n",
      "(48, 3272)\n",
      "(3267, 3269)\n",
      "(3268, 3269)\n",
      "(3264, 3267)\n",
      "(3266, 3267)\n",
      "(37, 3264)\n",
      "(3265, 3266)\n",
      "(40, 3266)\n",
      "<class 'Loss.CrossEntropy'>: 0.91192365\n",
      "(3331, 3332)\n",
      "(3330, 3331)\n",
      "(3329, 3331)\n",
      "(3328, 3329)\n",
      "(3326, 3328)\n",
      "(3327, 3328)\n",
      "(3325, 3326)\n",
      "(3324, 3326)\n",
      "(3323, 3324)\n",
      "(3322, 3323)\n",
      "(3321, 3322)\n",
      "(3320, 3322)\n",
      "(3314, 3321)\n",
      "(3319, 3320)\n",
      "(3317, 3319)\n",
      "(3318, 3319)\n",
      "(3315, 3317)\n",
      "(3316, 3317)\n",
      "(3314, 3315)\n",
      "(3311, 3314)\n",
      "(3313, 3314)\n",
      "(3310, 3311)\n",
      "(53, 3311)\n",
      "(3312, 3313)\n",
      "(56, 3313)\n",
      "(3308, 3310)\n",
      "(3309, 3310)\n",
      "(3305, 3308)\n",
      "(3307, 3308)\n",
      "(3304, 3305)\n",
      "(45, 3305)\n",
      "(3306, 3307)\n",
      "(48, 3307)\n",
      "(3302, 3304)\n",
      "(3303, 3304)\n",
      "(3299, 3302)\n",
      "(3301, 3302)\n",
      "(37, 3299)\n",
      "(3300, 3301)\n",
      "(40, 3301)\n",
      "<class 'Loss.CrossEntropy'>: 1.2968196\n",
      "(3366, 3367)\n",
      "(3365, 3366)\n",
      "(3364, 3366)\n",
      "(3363, 3364)\n",
      "(3361, 3363)\n",
      "(3362, 3363)\n",
      "(3360, 3361)\n",
      "(3359, 3361)\n",
      "(3358, 3359)\n",
      "(3357, 3358)\n",
      "(3356, 3357)\n",
      "(3355, 3357)\n",
      "(3349, 3356)\n",
      "(3354, 3355)\n",
      "(3352, 3354)\n",
      "(3353, 3354)\n",
      "(3350, 3352)\n",
      "(3351, 3352)\n",
      "(3349, 3350)\n",
      "(3346, 3349)\n",
      "(3348, 3349)\n",
      "(3345, 3346)\n",
      "(53, 3346)\n",
      "(3347, 3348)\n",
      "(56, 3348)\n",
      "(3343, 3345)\n",
      "(3344, 3345)\n",
      "(3340, 3343)\n",
      "(3342, 3343)\n",
      "(3339, 3340)\n",
      "(45, 3340)\n",
      "(3341, 3342)\n",
      "(48, 3342)\n",
      "(3337, 3339)\n",
      "(3338, 3339)\n",
      "(3334, 3337)\n",
      "(3336, 3337)\n",
      "(37, 3334)\n",
      "(3335, 3336)\n",
      "(40, 3336)\n",
      "<class 'Loss.CrossEntropy'>: 1.2918637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 96/200 [00:04<00:08, 12.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3401, 3402)\n",
      "(3400, 3401)\n",
      "(3399, 3401)\n",
      "(3398, 3399)\n",
      "(3396, 3398)\n",
      "(3397, 3398)\n",
      "(3395, 3396)\n",
      "(3394, 3396)\n",
      "(3393, 3394)\n",
      "(3392, 3393)\n",
      "(3391, 3392)\n",
      "(3390, 3392)\n",
      "(3384, 3391)\n",
      "(3389, 3390)\n",
      "(3387, 3389)\n",
      "(3388, 3389)\n",
      "(3385, 3387)\n",
      "(3386, 3387)\n",
      "(3384, 3385)\n",
      "(3381, 3384)\n",
      "(3383, 3384)\n",
      "(3380, 3381)\n",
      "(53, 3381)\n",
      "(3382, 3383)\n",
      "(56, 3383)\n",
      "(3378, 3380)\n",
      "(3379, 3380)\n",
      "(3375, 3378)\n",
      "(3377, 3378)\n",
      "(3374, 3375)\n",
      "(45, 3375)\n",
      "(3376, 3377)\n",
      "(48, 3377)\n",
      "(3372, 3374)\n",
      "(3373, 3374)\n",
      "(3369, 3372)\n",
      "(3371, 3372)\n",
      "(37, 3369)\n",
      "(3370, 3371)\n",
      "(40, 3371)\n",
      "<class 'Loss.CrossEntropy'>: 1.2588888\n",
      "(3436, 3437)\n",
      "(3435, 3436)\n",
      "(3434, 3436)\n",
      "(3433, 3434)\n",
      "(3431, 3433)\n",
      "(3432, 3433)\n",
      "(3430, 3431)\n",
      "(3429, 3431)\n",
      "(3428, 3429)\n",
      "(3427, 3428)\n",
      "(3426, 3427)\n",
      "(3425, 3427)\n",
      "(3419, 3426)\n",
      "(3424, 3425)\n",
      "(3422, 3424)\n",
      "(3423, 3424)\n",
      "(3420, 3422)\n",
      "(3421, 3422)\n",
      "(3419, 3420)\n",
      "(3416, 3419)\n",
      "(3418, 3419)\n",
      "(3415, 3416)\n",
      "(53, 3416)\n",
      "(3417, 3418)\n",
      "(56, 3418)\n",
      "(3413, 3415)\n",
      "(3414, 3415)\n",
      "(3410, 3413)\n",
      "(3412, 3413)\n",
      "(3409, 3410)\n",
      "(45, 3410)\n",
      "(3411, 3412)\n",
      "(48, 3412)\n",
      "(3407, 3409)\n",
      "(3408, 3409)\n",
      "(3404, 3407)\n",
      "(3406, 3407)\n",
      "(37, 3404)\n",
      "(3405, 3406)\n",
      "(40, 3406)\n",
      "<class 'Loss.CrossEntropy'>: 1.0554177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 100/200 [00:05<00:09, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3471, 3472)\n",
      "(3470, 3471)\n",
      "(3469, 3471)\n",
      "(3468, 3469)\n",
      "(3466, 3468)\n",
      "(3467, 3468)\n",
      "(3465, 3466)\n",
      "(3464, 3466)\n",
      "(3463, 3464)\n",
      "(3462, 3463)\n",
      "(3461, 3462)\n",
      "(3460, 3462)\n",
      "(3454, 3461)\n",
      "(3459, 3460)\n",
      "(3457, 3459)\n",
      "(3458, 3459)\n",
      "(3455, 3457)\n",
      "(3456, 3457)\n",
      "(3454, 3455)\n",
      "(3451, 3454)\n",
      "(3453, 3454)\n",
      "(3450, 3451)\n",
      "(53, 3451)\n",
      "(3452, 3453)\n",
      "(56, 3453)\n",
      "(3448, 3450)\n",
      "(3449, 3450)\n",
      "(3445, 3448)\n",
      "(3447, 3448)\n",
      "(3444, 3445)\n",
      "(45, 3445)\n",
      "(3446, 3447)\n",
      "(48, 3447)\n",
      "(3442, 3444)\n",
      "(3443, 3444)\n",
      "(3439, 3442)\n",
      "(3441, 3442)\n",
      "(37, 3439)\n",
      "(3440, 3441)\n",
      "(40, 3441)\n",
      "<class 'Loss.CrossEntropy'>: 1.0169156\n",
      "(3506, 3507)\n",
      "(3505, 3506)\n",
      "(3504, 3506)\n",
      "(3503, 3504)\n",
      "(3501, 3503)\n",
      "(3502, 3503)\n",
      "(3500, 3501)\n",
      "(3499, 3501)\n",
      "(3498, 3499)\n",
      "(3497, 3498)\n",
      "(3496, 3497)\n",
      "(3495, 3497)\n",
      "(3489, 3496)\n",
      "(3494, 3495)\n",
      "(3492, 3494)\n",
      "(3493, 3494)\n",
      "(3490, 3492)\n",
      "(3491, 3492)\n",
      "(3489, 3490)\n",
      "(3486, 3489)\n",
      "(3488, 3489)\n",
      "(3485, 3486)\n",
      "(53, 3486)\n",
      "(3487, 3488)\n",
      "(56, 3488)\n",
      "(3483, 3485)\n",
      "(3484, 3485)\n",
      "(3480, 3483)\n",
      "(3482, 3483)\n",
      "(3479, 3480)\n",
      "(45, 3480)\n",
      "(3481, 3482)\n",
      "(48, 3482)\n",
      "(3477, 3479)\n",
      "(3478, 3479)\n",
      "(3474, 3477)\n",
      "(3476, 3477)\n",
      "(37, 3474)\n",
      "(3475, 3476)\n",
      "(40, 3476)\n",
      "<class 'Loss.CrossEntropy'>: 1.1265513\n",
      "(3541, 3542)\n",
      "(3540, 3541)\n",
      "(3539, 3541)\n",
      "(3538, 3539)\n",
      "(3536, 3538)\n",
      "(3537, 3538)\n",
      "(3535, 3536)\n",
      "(3534, 3536)\n",
      "(3533, 3534)\n",
      "(3532, 3533)\n",
      "(3531, 3532)\n",
      "(3530, 3532)\n",
      "(3524, 3531)\n",
      "(3529, 3530)\n",
      "(3527, 3529)\n",
      "(3528, 3529)\n",
      "(3525, 3527)\n",
      "(3526, 3527)\n",
      "(3524, 3525)\n",
      "(3521, 3524)\n",
      "(3523, 3524)\n",
      "(3520, 3521)\n",
      "(53, 3521)\n",
      "(3522, 3523)\n",
      "(56, 3523)\n",
      "(3518, 3520)\n",
      "(3519, 3520)\n",
      "(3515, 3518)\n",
      "(3517, 3518)\n",
      "(3514, 3515)\n",
      "(45, 3515)\n",
      "(3516, 3517)\n",
      "(48, 3517)\n",
      "(3512, 3514)\n",
      "(3513, 3514)\n",
      "(3509, 3512)\n",
      "(3511, 3512)\n",
      "(37, 3509)\n",
      "(3510, 3511)\n",
      "(40, 3511)\n",
      "<class 'Loss.CrossEntropy'>: 1.390323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 102/200 [00:05<00:08, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3576, 3577)\n",
      "(3575, 3576)\n",
      "(3574, 3576)\n",
      "(3573, 3574)\n",
      "(3571, 3573)\n",
      "(3572, 3573)\n",
      "(3570, 3571)\n",
      "(3569, 3571)\n",
      "(3568, 3569)\n",
      "(3567, 3568)\n",
      "(3566, 3567)\n",
      "(3565, 3567)\n",
      "(3559, 3566)\n",
      "(3564, 3565)\n",
      "(3562, 3564)\n",
      "(3563, 3564)\n",
      "(3560, 3562)\n",
      "(3561, 3562)\n",
      "(3559, 3560)\n",
      "(3556, 3559)\n",
      "(3558, 3559)\n",
      "(3555, 3556)\n",
      "(53, 3556)\n",
      "(3557, 3558)\n",
      "(56, 3558)\n",
      "(3553, 3555)\n",
      "(3554, 3555)\n",
      "(3550, 3553)\n",
      "(3552, 3553)\n",
      "(3549, 3550)\n",
      "(45, 3550)\n",
      "(3551, 3552)\n",
      "(48, 3552)\n",
      "(3547, 3549)\n",
      "(3548, 3549)\n",
      "(3544, 3547)\n",
      "(3546, 3547)\n",
      "(37, 3544)\n",
      "(3545, 3546)\n",
      "(40, 3546)\n",
      "<class 'Loss.CrossEntropy'>: 1.021928\n",
      "(3611, 3612)\n",
      "(3610, 3611)\n",
      "(3609, 3611)\n",
      "(3608, 3609)\n",
      "(3606, 3608)\n",
      "(3607, 3608)\n",
      "(3605, 3606)\n",
      "(3604, 3606)\n",
      "(3603, 3604)\n",
      "(3602, 3603)\n",
      "(3601, 3602)\n",
      "(3600, 3602)\n",
      "(3594, 3601)\n",
      "(3599, 3600)\n",
      "(3597, 3599)\n",
      "(3598, 3599)\n",
      "(3595, 3597)\n",
      "(3596, 3597)\n",
      "(3594, 3595)\n",
      "(3591, 3594)\n",
      "(3593, 3594)\n",
      "(3590, 3591)\n",
      "(53, 3591)\n",
      "(3592, 3593)\n",
      "(56, 3593)\n",
      "(3588, 3590)\n",
      "(3589, 3590)\n",
      "(3585, 3588)\n",
      "(3587, 3588)\n",
      "(3584, 3585)\n",
      "(45, 3585)\n",
      "(3586, 3587)\n",
      "(48, 3587)\n",
      "(3582, 3584)\n",
      "(3583, 3584)\n",
      "(3579, 3582)\n",
      "(3581, 3582)\n",
      "(37, 3579)\n",
      "(3580, 3581)\n",
      "(40, 3581)\n",
      "<class 'Loss.CrossEntropy'>: 1.3333584\n",
      "(3646, 3647)\n",
      "(3645, 3646)\n",
      "(3644, 3646)\n",
      "(3643, 3644)\n",
      "(3641, 3643)\n",
      "(3642, 3643)\n",
      "(3640, 3641)\n",
      "(3639, 3641)\n",
      "(3638, 3639)\n",
      "(3637, 3638)\n",
      "(3636, 3637)\n",
      "(3635, 3637)\n",
      "(3629, 3636)\n",
      "(3634, 3635)\n",
      "(3632, 3634)\n",
      "(3633, 3634)\n",
      "(3630, 3632)\n",
      "(3631, 3632)\n",
      "(3629, 3630)\n",
      "(3626, 3629)\n",
      "(3628, 3629)\n",
      "(3625, 3626)\n",
      "(53, 3626)\n",
      "(3627, 3628)\n",
      "(56, 3628)\n",
      "(3623, 3625)\n",
      "(3624, 3625)\n",
      "(3620, 3623)\n",
      "(3622, 3623)\n",
      "(3619, 3620)\n",
      "(45, 3620)\n",
      "(3621, 3622)\n",
      "(48, 3622)\n",
      "(3617, 3619)\n",
      "(3618, 3619)\n",
      "(3614, 3617)\n",
      "(3616, 3617)\n",
      "(37, 3614)\n",
      "(3615, 3616)\n",
      "(40, 3616)\n",
      "<class 'Loss.CrossEntropy'>: 1.1840327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 106/200 [00:05<00:09,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3681, 3682)\n",
      "(3680, 3681)\n",
      "(3679, 3681)\n",
      "(3678, 3679)\n",
      "(3676, 3678)\n",
      "(3677, 3678)\n",
      "(3675, 3676)\n",
      "(3674, 3676)\n",
      "(3673, 3674)\n",
      "(3672, 3673)\n",
      "(3671, 3672)\n",
      "(3670, 3672)\n",
      "(3664, 3671)\n",
      "(3669, 3670)\n",
      "(3667, 3669)\n",
      "(3668, 3669)\n",
      "(3665, 3667)\n",
      "(3666, 3667)\n",
      "(3664, 3665)\n",
      "(3661, 3664)\n",
      "(3663, 3664)\n",
      "(3660, 3661)\n",
      "(53, 3661)\n",
      "(3662, 3663)\n",
      "(56, 3663)\n",
      "(3658, 3660)\n",
      "(3659, 3660)\n",
      "(3655, 3658)\n",
      "(3657, 3658)\n",
      "(3654, 3655)\n",
      "(45, 3655)\n",
      "(3656, 3657)\n",
      "(48, 3657)\n",
      "(3652, 3654)\n",
      "(3653, 3654)\n",
      "(3649, 3652)\n",
      "(3651, 3652)\n",
      "(37, 3649)\n",
      "(3650, 3651)\n",
      "(40, 3651)\n",
      "<class 'Loss.CrossEntropy'>: 1.1826301\n",
      "(3716, 3717)\n",
      "(3715, 3716)\n",
      "(3714, 3716)\n",
      "(3713, 3714)\n",
      "(3711, 3713)\n",
      "(3712, 3713)\n",
      "(3710, 3711)\n",
      "(3709, 3711)\n",
      "(3708, 3709)\n",
      "(3707, 3708)\n",
      "(3706, 3707)\n",
      "(3705, 3707)\n",
      "(3699, 3706)\n",
      "(3704, 3705)\n",
      "(3702, 3704)\n",
      "(3703, 3704)\n",
      "(3700, 3702)\n",
      "(3701, 3702)\n",
      "(3699, 3700)\n",
      "(3696, 3699)\n",
      "(3698, 3699)\n",
      "(3695, 3696)\n",
      "(53, 3696)\n",
      "(3697, 3698)\n",
      "(56, 3698)\n",
      "(3693, 3695)\n",
      "(3694, 3695)\n",
      "(3690, 3693)\n",
      "(3692, 3693)\n",
      "(3689, 3690)\n",
      "(45, 3690)\n",
      "(3691, 3692)\n",
      "(48, 3692)\n",
      "(3687, 3689)\n",
      "(3688, 3689)\n",
      "(3684, 3687)\n",
      "(3686, 3687)\n",
      "(37, 3684)\n",
      "(3685, 3686)\n",
      "(40, 3686)\n",
      "<class 'Loss.CrossEntropy'>: 1.2161484\n",
      "(3751, 3752)\n",
      "(3750, 3751)\n",
      "(3749, 3751)\n",
      "(3748, 3749)\n",
      "(3746, 3748)\n",
      "(3747, 3748)\n",
      "(3745, 3746)\n",
      "(3744, 3746)\n",
      "(3743, 3744)\n",
      "(3742, 3743)\n",
      "(3741, 3742)\n",
      "(3740, 3742)\n",
      "(3734, 3741)\n",
      "(3739, 3740)\n",
      "(3737, 3739)\n",
      "(3738, 3739)\n",
      "(3735, 3737)\n",
      "(3736, 3737)\n",
      "(3734, 3735)\n",
      "(3731, 3734)\n",
      "(3733, 3734)\n",
      "(3730, 3731)\n",
      "(53, 3731)\n",
      "(3732, 3733)\n",
      "(56, 3733)\n",
      "(3728, 3730)\n",
      "(3729, 3730)\n",
      "(3725, 3728)\n",
      "(3727, 3728)\n",
      "(3724, 3725)\n",
      "(45, 3725)\n",
      "(3726, 3727)\n",
      "(48, 3727)\n",
      "(3722, 3724)\n",
      "(3723, 3724)\n",
      "(3719, 3722)\n",
      "(3721, 3722)\n",
      "(37, 3719)\n",
      "(3720, 3721)\n",
      "(40, 3721)\n",
      "<class 'Loss.CrossEntropy'>: 1.2240578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 108/200 [00:06<00:08, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3786, 3787)\n",
      "(3785, 3786)\n",
      "(3784, 3786)\n",
      "(3783, 3784)\n",
      "(3781, 3783)\n",
      "(3782, 3783)\n",
      "(3780, 3781)\n",
      "(3779, 3781)\n",
      "(3778, 3779)\n",
      "(3777, 3778)\n",
      "(3776, 3777)\n",
      "(3775, 3777)\n",
      "(3769, 3776)\n",
      "(3774, 3775)\n",
      "(3772, 3774)\n",
      "(3773, 3774)\n",
      "(3770, 3772)\n",
      "(3771, 3772)\n",
      "(3769, 3770)\n",
      "(3766, 3769)\n",
      "(3768, 3769)\n",
      "(3765, 3766)\n",
      "(53, 3766)\n",
      "(3767, 3768)\n",
      "(56, 3768)\n",
      "(3763, 3765)\n",
      "(3764, 3765)\n",
      "(3760, 3763)\n",
      "(3762, 3763)\n",
      "(3759, 3760)\n",
      "(45, 3760)\n",
      "(3761, 3762)\n",
      "(48, 3762)\n",
      "(3757, 3759)\n",
      "(3758, 3759)\n",
      "(3754, 3757)\n",
      "(3756, 3757)\n",
      "(37, 3754)\n",
      "(3755, 3756)\n",
      "(40, 3756)\n",
      "<class 'Loss.CrossEntropy'>: 1.049068\n",
      "(3821, 3822)\n",
      "(3820, 3821)\n",
      "(3819, 3821)\n",
      "(3818, 3819)\n",
      "(3816, 3818)\n",
      "(3817, 3818)\n",
      "(3815, 3816)\n",
      "(3814, 3816)\n",
      "(3813, 3814)\n",
      "(3812, 3813)\n",
      "(3811, 3812)\n",
      "(3810, 3812)\n",
      "(3804, 3811)\n",
      "(3809, 3810)\n",
      "(3807, 3809)\n",
      "(3808, 3809)\n",
      "(3805, 3807)\n",
      "(3806, 3807)\n",
      "(3804, 3805)\n",
      "(3801, 3804)\n",
      "(3803, 3804)\n",
      "(3800, 3801)\n",
      "(53, 3801)\n",
      "(3802, 3803)\n",
      "(56, 3803)\n",
      "(3798, 3800)\n",
      "(3799, 3800)\n",
      "(3795, 3798)\n",
      "(3797, 3798)\n",
      "(3794, 3795)\n",
      "(45, 3795)\n",
      "(3796, 3797)\n",
      "(48, 3797)\n",
      "(3792, 3794)\n",
      "(3793, 3794)\n",
      "(3789, 3792)\n",
      "(3791, 3792)\n",
      "(37, 3789)\n",
      "(3790, 3791)\n",
      "(40, 3791)\n",
      "<class 'Loss.CrossEntropy'>: 1.3635476\n",
      "(3856, 3857)\n",
      "(3855, 3856)\n",
      "(3854, 3856)\n",
      "(3853, 3854)\n",
      "(3851, 3853)\n",
      "(3852, 3853)\n",
      "(3850, 3851)\n",
      "(3849, 3851)\n",
      "(3848, 3849)\n",
      "(3847, 3848)\n",
      "(3846, 3847)\n",
      "(3845, 3847)\n",
      "(3839, 3846)\n",
      "(3844, 3845)\n",
      "(3842, 3844)\n",
      "(3843, 3844)\n",
      "(3840, 3842)\n",
      "(3841, 3842)\n",
      "(3839, 3840)\n",
      "(3836, 3839)\n",
      "(3838, 3839)\n",
      "(3835, 3836)\n",
      "(53, 3836)\n",
      "(3837, 3838)\n",
      "(56, 3838)\n",
      "(3833, 3835)\n",
      "(3834, 3835)\n",
      "(3830, 3833)\n",
      "(3832, 3833)\n",
      "(3829, 3830)\n",
      "(45, 3830)\n",
      "(3831, 3832)\n",
      "(48, 3832)\n",
      "(3827, 3829)\n",
      "(3828, 3829)\n",
      "(3824, 3827)\n",
      "(3826, 3827)\n",
      "(37, 3824)\n",
      "(3825, 3826)\n",
      "(40, 3826)\n",
      "<class 'Loss.CrossEntropy'>: 1.138973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 110/200 [00:06<00:08, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3891, 3892)\n",
      "(3890, 3891)\n",
      "(3889, 3891)\n",
      "(3888, 3889)\n",
      "(3886, 3888)\n",
      "(3887, 3888)\n",
      "(3885, 3886)\n",
      "(3884, 3886)\n",
      "(3883, 3884)\n",
      "(3882, 3883)\n",
      "(3881, 3882)\n",
      "(3880, 3882)\n",
      "(3874, 3881)\n",
      "(3879, 3880)\n",
      "(3877, 3879)\n",
      "(3878, 3879)\n",
      "(3875, 3877)\n",
      "(3876, 3877)\n",
      "(3874, 3875)\n",
      "(3871, 3874)\n",
      "(3873, 3874)\n",
      "(3870, 3871)\n",
      "(53, 3871)\n",
      "(3872, 3873)\n",
      "(56, 3873)\n",
      "(3868, 3870)\n",
      "(3869, 3870)\n",
      "(3865, 3868)\n",
      "(3867, 3868)\n",
      "(3864, 3865)\n",
      "(45, 3865)\n",
      "(3866, 3867)\n",
      "(48, 3867)\n",
      "(3862, 3864)\n",
      "(3863, 3864)\n",
      "(3859, 3862)\n",
      "(3861, 3862)\n",
      "(37, 3859)\n",
      "(3860, 3861)\n",
      "(40, 3861)\n",
      "<class 'Loss.CrossEntropy'>: 1.0060322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 112/200 [00:06<00:09,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3926, 3927)\n",
      "(3925, 3926)\n",
      "(3924, 3926)\n",
      "(3923, 3924)\n",
      "(3921, 3923)\n",
      "(3922, 3923)\n",
      "(3920, 3921)\n",
      "(3919, 3921)\n",
      "(3918, 3919)\n",
      "(3917, 3918)\n",
      "(3916, 3917)\n",
      "(3915, 3917)\n",
      "(3909, 3916)\n",
      "(3914, 3915)\n",
      "(3912, 3914)\n",
      "(3913, 3914)\n",
      "(3910, 3912)\n",
      "(3911, 3912)\n",
      "(3909, 3910)\n",
      "(3906, 3909)\n",
      "(3908, 3909)\n",
      "(3905, 3906)\n",
      "(53, 3906)\n",
      "(3907, 3908)\n",
      "(56, 3908)\n",
      "(3903, 3905)\n",
      "(3904, 3905)\n",
      "(3900, 3903)\n",
      "(3902, 3903)\n",
      "(3899, 3900)\n",
      "(45, 3900)\n",
      "(3901, 3902)\n",
      "(48, 3902)\n",
      "(3897, 3899)\n",
      "(3898, 3899)\n",
      "(3894, 3897)\n",
      "(3896, 3897)\n",
      "(37, 3894)\n",
      "(3895, 3896)\n",
      "(40, 3896)\n",
      "<class 'Loss.CrossEntropy'>: 1.2443148\n",
      "(3961, 3962)\n",
      "(3960, 3961)\n",
      "(3959, 3961)\n",
      "(3958, 3959)\n",
      "(3956, 3958)\n",
      "(3957, 3958)\n",
      "(3955, 3956)\n",
      "(3954, 3956)\n",
      "(3953, 3954)\n",
      "(3952, 3953)\n",
      "(3951, 3952)\n",
      "(3950, 3952)\n",
      "(3944, 3951)\n",
      "(3949, 3950)\n",
      "(3947, 3949)\n",
      "(3948, 3949)\n",
      "(3945, 3947)\n",
      "(3946, 3947)\n",
      "(3944, 3945)\n",
      "(3941, 3944)\n",
      "(3943, 3944)\n",
      "(3940, 3941)\n",
      "(53, 3941)\n",
      "(3942, 3943)\n",
      "(56, 3943)\n",
      "(3938, 3940)\n",
      "(3939, 3940)\n",
      "(3935, 3938)\n",
      "(3937, 3938)\n",
      "(3934, 3935)\n",
      "(45, 3935)\n",
      "(3936, 3937)\n",
      "(48, 3937)\n",
      "(3932, 3934)\n",
      "(3933, 3934)\n",
      "(3929, 3932)\n",
      "(3931, 3932)\n",
      "(37, 3929)\n",
      "(3930, 3931)\n",
      "(40, 3931)\n",
      "<class 'Loss.CrossEntropy'>: 1.1956261\n",
      "(3996, 3997)\n",
      "(3995, 3996)\n",
      "(3994, 3996)\n",
      "(3993, 3994)\n",
      "(3991, 3993)\n",
      "(3992, 3993)\n",
      "(3990, 3991)\n",
      "(3989, 3991)\n",
      "(3988, 3989)\n",
      "(3987, 3988)\n",
      "(3986, 3987)\n",
      "(3985, 3987)\n",
      "(3979, 3986)\n",
      "(3984, 3985)\n",
      "(3982, 3984)\n",
      "(3983, 3984)\n",
      "(3980, 3982)\n",
      "(3981, 3982)\n",
      "(3979, 3980)\n",
      "(3976, 3979)\n",
      "(3978, 3979)\n",
      "(3975, 3976)\n",
      "(53, 3976)\n",
      "(3977, 3978)\n",
      "(56, 3978)\n",
      "(3973, 3975)\n",
      "(3974, 3975)\n",
      "(3970, 3973)\n",
      "(3972, 3973)\n",
      "(3969, 3970)\n",
      "(45, 3970)\n",
      "(3971, 3972)\n",
      "(48, 3972)\n",
      "(3967, 3969)\n",
      "(3968, 3969)\n",
      "(3964, 3967)\n",
      "(3966, 3967)\n",
      "(37, 3964)\n",
      "(3965, 3966)\n",
      "(40, 3966)\n",
      "<class 'Loss.CrossEntropy'>: 1.0838041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 114/200 [00:06<00:08,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4031, 4032)\n",
      "(4030, 4031)\n",
      "(4029, 4031)\n",
      "(4028, 4029)\n",
      "(4026, 4028)\n",
      "(4027, 4028)\n",
      "(4025, 4026)\n",
      "(4024, 4026)\n",
      "(4023, 4024)\n",
      "(4022, 4023)\n",
      "(4021, 4022)\n",
      "(4020, 4022)\n",
      "(4014, 4021)\n",
      "(4019, 4020)\n",
      "(4017, 4019)\n",
      "(4018, 4019)\n",
      "(4015, 4017)\n",
      "(4016, 4017)\n",
      "(4014, 4015)\n",
      "(4011, 4014)\n",
      "(4013, 4014)\n",
      "(4010, 4011)\n",
      "(53, 4011)\n",
      "(4012, 4013)\n",
      "(56, 4013)\n",
      "(4008, 4010)\n",
      "(4009, 4010)\n",
      "(4005, 4008)\n",
      "(4007, 4008)\n",
      "(4004, 4005)\n",
      "(45, 4005)\n",
      "(4006, 4007)\n",
      "(48, 4007)\n",
      "(4002, 4004)\n",
      "(4003, 4004)\n",
      "(3999, 4002)\n",
      "(4001, 4002)\n",
      "(37, 3999)\n",
      "(4000, 4001)\n",
      "(40, 4001)\n",
      "<class 'Loss.CrossEntropy'>: 1.2569618\n",
      "(4066, 4067)\n",
      "(4065, 4066)\n",
      "(4064, 4066)\n",
      "(4063, 4064)\n",
      "(4061, 4063)\n",
      "(4062, 4063)\n",
      "(4060, 4061)\n",
      "(4059, 4061)\n",
      "(4058, 4059)\n",
      "(4057, 4058)\n",
      "(4056, 4057)\n",
      "(4055, 4057)\n",
      "(4049, 4056)\n",
      "(4054, 4055)\n",
      "(4052, 4054)\n",
      "(4053, 4054)\n",
      "(4050, 4052)\n",
      "(4051, 4052)\n",
      "(4049, 4050)\n",
      "(4046, 4049)\n",
      "(4048, 4049)\n",
      "(4045, 4046)\n",
      "(53, 4046)\n",
      "(4047, 4048)\n",
      "(56, 4048)\n",
      "(4043, 4045)\n",
      "(4044, 4045)\n",
      "(4040, 4043)\n",
      "(4042, 4043)\n",
      "(4039, 4040)\n",
      "(45, 4040)\n",
      "(4041, 4042)\n",
      "(48, 4042)\n",
      "(4037, 4039)\n",
      "(4038, 4039)\n",
      "(4034, 4037)\n",
      "(4036, 4037)\n",
      "(37, 4034)\n",
      "(4035, 4036)\n",
      "(40, 4036)\n",
      "<class 'Loss.CrossEntropy'>: 1.017304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 117/200 [00:07<00:10,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4101, 4102)\n",
      "(4100, 4101)\n",
      "(4099, 4101)\n",
      "(4098, 4099)\n",
      "(4096, 4098)\n",
      "(4097, 4098)\n",
      "(4095, 4096)\n",
      "(4094, 4096)\n",
      "(4093, 4094)\n",
      "(4092, 4093)\n",
      "(4091, 4092)\n",
      "(4090, 4092)\n",
      "(4084, 4091)\n",
      "(4089, 4090)\n",
      "(4087, 4089)\n",
      "(4088, 4089)\n",
      "(4085, 4087)\n",
      "(4086, 4087)\n",
      "(4084, 4085)\n",
      "(4081, 4084)\n",
      "(4083, 4084)\n",
      "(4080, 4081)\n",
      "(53, 4081)\n",
      "(4082, 4083)\n",
      "(56, 4083)\n",
      "(4078, 4080)\n",
      "(4079, 4080)\n",
      "(4075, 4078)\n",
      "(4077, 4078)\n",
      "(4074, 4075)\n",
      "(45, 4075)\n",
      "(4076, 4077)\n",
      "(48, 4077)\n",
      "(4072, 4074)\n",
      "(4073, 4074)\n",
      "(4069, 4072)\n",
      "(4071, 4072)\n",
      "(37, 4069)\n",
      "(4070, 4071)\n",
      "(40, 4071)\n",
      "<class 'Loss.CrossEntropy'>: 1.0410913\n",
      "(4136, 4137)\n",
      "(4135, 4136)\n",
      "(4134, 4136)\n",
      "(4133, 4134)\n",
      "(4131, 4133)\n",
      "(4132, 4133)\n",
      "(4130, 4131)\n",
      "(4129, 4131)\n",
      "(4128, 4129)\n",
      "(4127, 4128)\n",
      "(4126, 4127)\n",
      "(4125, 4127)\n",
      "(4119, 4126)\n",
      "(4124, 4125)\n",
      "(4122, 4124)\n",
      "(4123, 4124)\n",
      "(4120, 4122)\n",
      "(4121, 4122)\n",
      "(4119, 4120)\n",
      "(4116, 4119)\n",
      "(4118, 4119)\n",
      "(4115, 4116)\n",
      "(53, 4116)\n",
      "(4117, 4118)\n",
      "(56, 4118)\n",
      "(4113, 4115)\n",
      "(4114, 4115)\n",
      "(4110, 4113)\n",
      "(4112, 4113)\n",
      "(4109, 4110)\n",
      "(45, 4110)\n",
      "(4111, 4112)\n",
      "(48, 4112)\n",
      "(4107, 4109)\n",
      "(4108, 4109)\n",
      "(4104, 4107)\n",
      "(4106, 4107)\n",
      "(37, 4104)\n",
      "(4105, 4106)\n",
      "(40, 4106)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 118/200 [00:07<00:10,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'Loss.CrossEntropy'>: 1.3331583\n",
      "(4171, 4172)\n",
      "(4170, 4171)\n",
      "(4169, 4171)\n",
      "(4168, 4169)\n",
      "(4166, 4168)\n",
      "(4167, 4168)\n",
      "(4165, 4166)\n",
      "(4164, 4166)\n",
      "(4163, 4164)\n",
      "(4162, 4163)\n",
      "(4161, 4162)\n",
      "(4160, 4162)\n",
      "(4154, 4161)\n",
      "(4159, 4160)\n",
      "(4157, 4159)\n",
      "(4158, 4159)\n",
      "(4155, 4157)\n",
      "(4156, 4157)\n",
      "(4154, 4155)\n",
      "(4151, 4154)\n",
      "(4153, 4154)\n",
      "(4150, 4151)\n",
      "(53, 4151)\n",
      "(4152, 4153)\n",
      "(56, 4153)\n",
      "(4148, 4150)\n",
      "(4149, 4150)\n",
      "(4145, 4148)\n",
      "(4147, 4148)\n",
      "(4144, 4145)\n",
      "(45, 4145)\n",
      "(4146, 4147)\n",
      "(48, 4147)\n",
      "(4142, 4144)\n",
      "(4143, 4144)\n",
      "(4139, 4142)\n",
      "(4141, 4142)\n",
      "(37, 4139)\n",
      "(4140, 4141)\n",
      "(40, 4141)\n",
      "<class 'Loss.CrossEntropy'>: 1.1461208\n",
      "(4206, 4207)\n",
      "(4205, 4206)\n",
      "(4204, 4206)\n",
      "(4203, 4204)\n",
      "(4201, 4203)\n",
      "(4202, 4203)\n",
      "(4200, 4201)\n",
      "(4199, 4201)\n",
      "(4198, 4199)\n",
      "(4197, 4198)\n",
      "(4196, 4197)\n",
      "(4195, 4197)\n",
      "(4189, 4196)\n",
      "(4194, 4195)\n",
      "(4192, 4194)\n",
      "(4193, 4194)\n",
      "(4190, 4192)\n",
      "(4191, 4192)\n",
      "(4189, 4190)\n",
      "(4186, 4189)\n",
      "(4188, 4189)\n",
      "(4185, 4186)\n",
      "(53, 4186)\n",
      "(4187, 4188)\n",
      "(56, 4188)\n",
      "(4183, 4185)\n",
      "(4184, 4185)\n",
      "(4180, 4183)\n",
      "(4182, 4183)\n",
      "(4179, 4180)\n",
      "(45, 4180)\n",
      "(4181, 4182)\n",
      "(48, 4182)\n",
      "(4177, 4179)\n",
      "(4178, 4179)\n",
      "(4174, 4177)\n",
      "(4176, 4177)\n",
      "(37, 4174)\n",
      "(4175, 4176)\n",
      "(40, 4176)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 120/200 [00:07<00:08,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'Loss.CrossEntropy'>: 1.1575445\n",
      "(4241, 4242)\n",
      "(4240, 4241)\n",
      "(4239, 4241)\n",
      "(4238, 4239)\n",
      "(4236, 4238)\n",
      "(4237, 4238)\n",
      "(4235, 4236)\n",
      "(4234, 4236)\n",
      "(4233, 4234)\n",
      "(4232, 4233)\n",
      "(4231, 4232)\n",
      "(4230, 4232)\n",
      "(4224, 4231)\n",
      "(4229, 4230)\n",
      "(4227, 4229)\n",
      "(4228, 4229)\n",
      "(4225, 4227)\n",
      "(4226, 4227)\n",
      "(4224, 4225)\n",
      "(4221, 4224)\n",
      "(4223, 4224)\n",
      "(4220, 4221)\n",
      "(53, 4221)\n",
      "(4222, 4223)\n",
      "(56, 4223)\n",
      "(4218, 4220)\n",
      "(4219, 4220)\n",
      "(4215, 4218)\n",
      "(4217, 4218)\n",
      "(4214, 4215)\n",
      "(45, 4215)\n",
      "(4216, 4217)\n",
      "(48, 4217)\n",
      "(4212, 4214)\n",
      "(4213, 4214)\n",
      "(4209, 4212)\n",
      "(4211, 4212)\n",
      "(37, 4209)\n",
      "(4210, 4211)\n",
      "(40, 4211)\n",
      "<class 'Loss.CrossEntropy'>: 1.3594513\n",
      "(4276, 4277)\n",
      "(4275, 4276)\n",
      "(4274, 4276)\n",
      "(4273, 4274)\n",
      "(4271, 4273)\n",
      "(4272, 4273)\n",
      "(4270, 4271)\n",
      "(4269, 4271)\n",
      "(4268, 4269)\n",
      "(4267, 4268)\n",
      "(4266, 4267)\n",
      "(4265, 4267)\n",
      "(4259, 4266)\n",
      "(4264, 4265)\n",
      "(4262, 4264)\n",
      "(4263, 4264)\n",
      "(4260, 4262)\n",
      "(4261, 4262)\n",
      "(4259, 4260)\n",
      "(4256, 4259)\n",
      "(4258, 4259)\n",
      "(4255, 4256)\n",
      "(53, 4256)\n",
      "(4257, 4258)\n",
      "(56, 4258)\n",
      "(4253, 4255)\n",
      "(4254, 4255)\n",
      "(4250, 4253)\n",
      "(4252, 4253)\n",
      "(4249, 4250)\n",
      "(45, 4250)\n",
      "(4251, 4252)\n",
      "(48, 4252)\n",
      "(4247, 4249)\n",
      "(4248, 4249)\n",
      "(4244, 4247)\n",
      "(4246, 4247)\n",
      "(37, 4244)\n",
      "(4245, 4246)\n",
      "(40, 4246)\n",
      "<class 'Loss.CrossEntropy'>: 1.2752072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 124/200 [00:07<00:08,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4311, 4312)\n",
      "(4310, 4311)\n",
      "(4309, 4311)\n",
      "(4308, 4309)\n",
      "(4306, 4308)\n",
      "(4307, 4308)\n",
      "(4305, 4306)\n",
      "(4304, 4306)\n",
      "(4303, 4304)\n",
      "(4302, 4303)\n",
      "(4301, 4302)\n",
      "(4300, 4302)\n",
      "(4294, 4301)\n",
      "(4299, 4300)\n",
      "(4297, 4299)\n",
      "(4298, 4299)\n",
      "(4295, 4297)\n",
      "(4296, 4297)\n",
      "(4294, 4295)\n",
      "(4291, 4294)\n",
      "(4293, 4294)\n",
      "(4290, 4291)\n",
      "(53, 4291)\n",
      "(4292, 4293)\n",
      "(56, 4293)\n",
      "(4288, 4290)\n",
      "(4289, 4290)\n",
      "(4285, 4288)\n",
      "(4287, 4288)\n",
      "(4284, 4285)\n",
      "(45, 4285)\n",
      "(4286, 4287)\n",
      "(48, 4287)\n",
      "(4282, 4284)\n",
      "(4283, 4284)\n",
      "(4279, 4282)\n",
      "(4281, 4282)\n",
      "(37, 4279)\n",
      "(4280, 4281)\n",
      "(40, 4281)\n",
      "<class 'Loss.CrossEntropy'>: 1.2516583\n",
      "(4346, 4347)\n",
      "(4345, 4346)\n",
      "(4344, 4346)\n",
      "(4343, 4344)\n",
      "(4341, 4343)\n",
      "(4342, 4343)\n",
      "(4340, 4341)\n",
      "(4339, 4341)\n",
      "(4338, 4339)\n",
      "(4337, 4338)\n",
      "(4336, 4337)\n",
      "(4335, 4337)\n",
      "(4329, 4336)\n",
      "(4334, 4335)\n",
      "(4332, 4334)\n",
      "(4333, 4334)\n",
      "(4330, 4332)\n",
      "(4331, 4332)\n",
      "(4329, 4330)\n",
      "(4326, 4329)\n",
      "(4328, 4329)\n",
      "(4325, 4326)\n",
      "(53, 4326)\n",
      "(4327, 4328)\n",
      "(56, 4328)\n",
      "(4323, 4325)\n",
      "(4324, 4325)\n",
      "(4320, 4323)\n",
      "(4322, 4323)\n",
      "(4319, 4320)\n",
      "(45, 4320)\n",
      "(4321, 4322)\n",
      "(48, 4322)\n",
      "(4317, 4319)\n",
      "(4318, 4319)\n",
      "(4314, 4317)\n",
      "(4316, 4317)\n",
      "(37, 4314)\n",
      "(4315, 4316)\n",
      "(40, 4316)\n",
      "<class 'Loss.CrossEntropy'>: 1.1339927\n",
      "(4381, 4382)\n",
      "(4380, 4381)\n",
      "(4379, 4381)\n",
      "(4378, 4379)\n",
      "(4376, 4378)\n",
      "(4377, 4378)\n",
      "(4375, 4376)\n",
      "(4374, 4376)\n",
      "(4373, 4374)\n",
      "(4372, 4373)\n",
      "(4371, 4372)\n",
      "(4370, 4372)\n",
      "(4364, 4371)\n",
      "(4369, 4370)\n",
      "(4367, 4369)\n",
      "(4368, 4369)\n",
      "(4365, 4367)\n",
      "(4366, 4367)\n",
      "(4364, 4365)\n",
      "(4361, 4364)\n",
      "(4363, 4364)\n",
      "(4360, 4361)\n",
      "(53, 4361)\n",
      "(4362, 4363)\n",
      "(56, 4363)\n",
      "(4358, 4360)\n",
      "(4359, 4360)\n",
      "(4355, 4358)\n",
      "(4357, 4358)\n",
      "(4354, 4355)\n",
      "(45, 4355)\n",
      "(4356, 4357)\n",
      "(48, 4357)\n",
      "(4352, 4354)\n",
      "(4353, 4354)\n",
      "(4349, 4352)\n",
      "(4351, 4352)\n",
      "(37, 4349)\n",
      "(4350, 4351)\n",
      "(40, 4351)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 126/200 [00:08<00:08,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'Loss.CrossEntropy'>: 1.25606\n",
      "(4416, 4417)\n",
      "(4415, 4416)\n",
      "(4414, 4416)\n",
      "(4413, 4414)\n",
      "(4411, 4413)\n",
      "(4412, 4413)\n",
      "(4410, 4411)\n",
      "(4409, 4411)\n",
      "(4408, 4409)\n",
      "(4407, 4408)\n",
      "(4406, 4407)\n",
      "(4405, 4407)\n",
      "(4399, 4406)\n",
      "(4404, 4405)\n",
      "(4402, 4404)\n",
      "(4403, 4404)\n",
      "(4400, 4402)\n",
      "(4401, 4402)\n",
      "(4399, 4400)\n",
      "(4396, 4399)\n",
      "(4398, 4399)\n",
      "(4395, 4396)\n",
      "(53, 4396)\n",
      "(4397, 4398)\n",
      "(56, 4398)\n",
      "(4393, 4395)\n",
      "(4394, 4395)\n",
      "(4390, 4393)\n",
      "(4392, 4393)\n",
      "(4389, 4390)\n",
      "(45, 4390)\n",
      "(4391, 4392)\n",
      "(48, 4392)\n",
      "(4387, 4389)\n",
      "(4388, 4389)\n",
      "(4384, 4387)\n",
      "(4386, 4387)\n",
      "(37, 4384)\n",
      "(4385, 4386)\n",
      "(40, 4386)\n",
      "<class 'Loss.CrossEntropy'>: 1.2423934\n",
      "(4451, 4452)\n",
      "(4450, 4451)\n",
      "(4449, 4451)\n",
      "(4448, 4449)\n",
      "(4446, 4448)\n",
      "(4447, 4448)\n",
      "(4445, 4446)\n",
      "(4444, 4446)\n",
      "(4443, 4444)\n",
      "(4442, 4443)\n",
      "(4441, 4442)\n",
      "(4440, 4442)\n",
      "(4434, 4441)\n",
      "(4439, 4440)\n",
      "(4437, 4439)\n",
      "(4438, 4439)\n",
      "(4435, 4437)\n",
      "(4436, 4437)\n",
      "(4434, 4435)\n",
      "(4431, 4434)\n",
      "(4433, 4434)\n",
      "(4430, 4431)\n",
      "(53, 4431)\n",
      "(4432, 4433)\n",
      "(56, 4433)\n",
      "(4428, 4430)\n",
      "(4429, 4430)\n",
      "(4425, 4428)\n",
      "(4427, 4428)\n",
      "(4424, 4425)\n",
      "(45, 4425)\n",
      "(4426, 4427)\n",
      "(48, 4427)\n",
      "(4422, 4424)\n",
      "(4423, 4424)\n",
      "(4419, 4422)\n",
      "(4421, 4422)\n",
      "(37, 4419)\n",
      "(4420, 4421)\n",
      "(40, 4421)\n",
      "<class 'Loss.CrossEntropy'>: 1.2396286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 129/200 [00:08<00:08,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4486, 4487)\n",
      "(4485, 4486)\n",
      "(4484, 4486)\n",
      "(4483, 4484)\n",
      "(4481, 4483)\n",
      "(4482, 4483)\n",
      "(4480, 4481)\n",
      "(4479, 4481)\n",
      "(4478, 4479)\n",
      "(4477, 4478)\n",
      "(4476, 4477)\n",
      "(4475, 4477)\n",
      "(4469, 4476)\n",
      "(4474, 4475)\n",
      "(4472, 4474)\n",
      "(4473, 4474)\n",
      "(4470, 4472)\n",
      "(4471, 4472)\n",
      "(4469, 4470)\n",
      "(4466, 4469)\n",
      "(4468, 4469)\n",
      "(4465, 4466)\n",
      "(53, 4466)\n",
      "(4467, 4468)\n",
      "(56, 4468)\n",
      "(4463, 4465)\n",
      "(4464, 4465)\n",
      "(4460, 4463)\n",
      "(4462, 4463)\n",
      "(4459, 4460)\n",
      "(45, 4460)\n",
      "(4461, 4462)\n",
      "(48, 4462)\n",
      "(4457, 4459)\n",
      "(4458, 4459)\n",
      "(4454, 4457)\n",
      "(4456, 4457)\n",
      "(37, 4454)\n",
      "(4455, 4456)\n",
      "(40, 4456)\n",
      "<class 'Loss.CrossEntropy'>: 1.1844131\n",
      "(4521, 4522)\n",
      "(4520, 4521)\n",
      "(4519, 4521)\n",
      "(4518, 4519)\n",
      "(4516, 4518)\n",
      "(4517, 4518)\n",
      "(4515, 4516)\n",
      "(4514, 4516)\n",
      "(4513, 4514)\n",
      "(4512, 4513)\n",
      "(4511, 4512)\n",
      "(4510, 4512)\n",
      "(4504, 4511)\n",
      "(4509, 4510)\n",
      "(4507, 4509)\n",
      "(4508, 4509)\n",
      "(4505, 4507)\n",
      "(4506, 4507)\n",
      "(4504, 4505)\n",
      "(4501, 4504)\n",
      "(4503, 4504)\n",
      "(4500, 4501)\n",
      "(53, 4501)\n",
      "(4502, 4503)\n",
      "(56, 4503)\n",
      "(4498, 4500)\n",
      "(4499, 4500)\n",
      "(4495, 4498)\n",
      "(4497, 4498)\n",
      "(4494, 4495)\n",
      "(45, 4495)\n",
      "(4496, 4497)\n",
      "(48, 4497)\n",
      "(4492, 4494)\n",
      "(4493, 4494)\n",
      "(4489, 4492)\n",
      "(4491, 4492)\n",
      "(37, 4489)\n",
      "(4490, 4491)\n",
      "(40, 4491)\n",
      "<class 'Loss.CrossEntropy'>: 0.9702966\n",
      "(4556, 4557)\n",
      "(4555, 4556)\n",
      "(4554, 4556)\n",
      "(4553, 4554)\n",
      "(4551, 4553)\n",
      "(4552, 4553)\n",
      "(4550, 4551)\n",
      "(4549, 4551)\n",
      "(4548, 4549)\n",
      "(4547, 4548)\n",
      "(4546, 4547)\n",
      "(4545, 4547)\n",
      "(4539, 4546)\n",
      "(4544, 4545)\n",
      "(4542, 4544)\n",
      "(4543, 4544)\n",
      "(4540, 4542)\n",
      "(4541, 4542)\n",
      "(4539, 4540)\n",
      "(4536, 4539)\n",
      "(4538, 4539)\n",
      "(4535, 4536)\n",
      "(53, 4536)\n",
      "(4537, 4538)\n",
      "(56, 4538)\n",
      "(4533, 4535)\n",
      "(4534, 4535)\n",
      "(4530, 4533)\n",
      "(4532, 4533)\n",
      "(4529, 4530)\n",
      "(45, 4530)\n",
      "(4531, 4532)\n",
      "(48, 4532)\n",
      "(4527, 4529)\n",
      "(4528, 4529)\n",
      "(4524, 4527)\n",
      "(4526, 4527)\n",
      "(37, 4524)\n",
      "(4525, 4526)\n",
      "(40, 4526)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 130/200 [00:08<00:08,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'Loss.CrossEntropy'>: 1.2006435\n",
      "(4591, 4592)\n",
      "(4590, 4591)\n",
      "(4589, 4591)\n",
      "(4588, 4589)\n",
      "(4586, 4588)\n",
      "(4587, 4588)\n",
      "(4585, 4586)\n",
      "(4584, 4586)\n",
      "(4583, 4584)\n",
      "(4582, 4583)\n",
      "(4581, 4582)\n",
      "(4580, 4582)\n",
      "(4574, 4581)\n",
      "(4579, 4580)\n",
      "(4577, 4579)\n",
      "(4578, 4579)\n",
      "(4575, 4577)\n",
      "(4576, 4577)\n",
      "(4574, 4575)\n",
      "(4571, 4574)\n",
      "(4573, 4574)\n",
      "(4570, 4571)\n",
      "(53, 4571)\n",
      "(4572, 4573)\n",
      "(56, 4573)\n",
      "(4568, 4570)\n",
      "(4569, 4570)\n",
      "(4565, 4568)\n",
      "(4567, 4568)\n",
      "(4564, 4565)\n",
      "(45, 4565)\n",
      "(4566, 4567)\n",
      "(48, 4567)\n",
      "(4562, 4564)\n",
      "(4563, 4564)\n",
      "(4559, 4562)\n",
      "(4561, 4562)\n",
      "(37, 4559)\n",
      "(4560, 4561)\n",
      "(40, 4561)\n",
      "<class 'Loss.CrossEntropy'>: 0.90987504\n",
      "(4626, 4627)\n",
      "(4625, 4626)\n",
      "(4624, 4626)\n",
      "(4623, 4624)\n",
      "(4621, 4623)\n",
      "(4622, 4623)\n",
      "(4620, 4621)\n",
      "(4619, 4621)\n",
      "(4618, 4619)\n",
      "(4617, 4618)\n",
      "(4616, 4617)\n",
      "(4615, 4617)\n",
      "(4609, 4616)\n",
      "(4614, 4615)\n",
      "(4612, 4614)\n",
      "(4613, 4614)\n",
      "(4610, 4612)\n",
      "(4611, 4612)\n",
      "(4609, 4610)\n",
      "(4606, 4609)\n",
      "(4608, 4609)\n",
      "(4605, 4606)\n",
      "(53, 4606)\n",
      "(4607, 4608)\n",
      "(56, 4608)\n",
      "(4603, 4605)\n",
      "(4604, 4605)\n",
      "(4600, 4603)\n",
      "(4602, 4603)\n",
      "(4599, 4600)\n",
      "(45, 4600)\n",
      "(4601, 4602)\n",
      "(48, 4602)\n",
      "(4597, 4599)\n",
      "(4598, 4599)\n",
      "(4594, 4597)\n",
      "(4596, 4597)\n",
      "(37, 4594)\n",
      "(4595, 4596)\n",
      "(40, 4596)\n",
      "<class 'Loss.CrossEntropy'>: 1.0681747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 133/200 [00:09<00:08,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4661, 4662)\n",
      "(4660, 4661)\n",
      "(4659, 4661)\n",
      "(4658, 4659)\n",
      "(4656, 4658)\n",
      "(4657, 4658)\n",
      "(4655, 4656)\n",
      "(4654, 4656)\n",
      "(4653, 4654)\n",
      "(4652, 4653)\n",
      "(4651, 4652)\n",
      "(4650, 4652)\n",
      "(4644, 4651)\n",
      "(4649, 4650)\n",
      "(4647, 4649)\n",
      "(4648, 4649)\n",
      "(4645, 4647)\n",
      "(4646, 4647)\n",
      "(4644, 4645)\n",
      "(4641, 4644)\n",
      "(4643, 4644)\n",
      "(4640, 4641)\n",
      "(53, 4641)\n",
      "(4642, 4643)\n",
      "(56, 4643)\n",
      "(4638, 4640)\n",
      "(4639, 4640)\n",
      "(4635, 4638)\n",
      "(4637, 4638)\n",
      "(4634, 4635)\n",
      "(45, 4635)\n",
      "(4636, 4637)\n",
      "(48, 4637)\n",
      "(4632, 4634)\n",
      "(4633, 4634)\n",
      "(4629, 4632)\n",
      "(4631, 4632)\n",
      "(37, 4629)\n",
      "(4630, 4631)\n",
      "(40, 4631)\n",
      "<class 'Loss.CrossEntropy'>: 1.2955415\n",
      "(4696, 4697)\n",
      "(4695, 4696)\n",
      "(4694, 4696)\n",
      "(4693, 4694)\n",
      "(4691, 4693)\n",
      "(4692, 4693)\n",
      "(4690, 4691)\n",
      "(4689, 4691)\n",
      "(4688, 4689)\n",
      "(4687, 4688)\n",
      "(4686, 4687)\n",
      "(4685, 4687)\n",
      "(4679, 4686)\n",
      "(4684, 4685)\n",
      "(4682, 4684)\n",
      "(4683, 4684)\n",
      "(4680, 4682)\n",
      "(4681, 4682)\n",
      "(4679, 4680)\n",
      "(4676, 4679)\n",
      "(4678, 4679)\n",
      "(4675, 4676)\n",
      "(53, 4676)\n",
      "(4677, 4678)\n",
      "(56, 4678)\n",
      "(4673, 4675)\n",
      "(4674, 4675)\n",
      "(4670, 4673)\n",
      "(4672, 4673)\n",
      "(4669, 4670)\n",
      "(45, 4670)\n",
      "(4671, 4672)\n",
      "(48, 4672)\n",
      "(4667, 4669)\n",
      "(4668, 4669)\n",
      "(4664, 4667)\n",
      "(4666, 4667)\n",
      "(37, 4664)\n",
      "(4665, 4666)\n",
      "(40, 4666)\n",
      "<class 'Loss.CrossEntropy'>: 1.231329\n",
      "(4731, 4732)\n",
      "(4730, 4731)\n",
      "(4729, 4731)\n",
      "(4728, 4729)\n",
      "(4726, 4728)\n",
      "(4727, 4728)\n",
      "(4725, 4726)\n",
      "(4724, 4726)\n",
      "(4723, 4724)\n",
      "(4722, 4723)\n",
      "(4721, 4722)\n",
      "(4720, 4722)\n",
      "(4714, 4721)\n",
      "(4719, 4720)\n",
      "(4717, 4719)\n",
      "(4718, 4719)\n",
      "(4715, 4717)\n",
      "(4716, 4717)\n",
      "(4714, 4715)\n",
      "(4711, 4714)\n",
      "(4713, 4714)\n",
      "(4710, 4711)\n",
      "(53, 4711)\n",
      "(4712, 4713)\n",
      "(56, 4713)\n",
      "(4708, 4710)\n",
      "(4709, 4710)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 136/200 [00:09<00:07,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4705, 4708)\n",
      "(4707, 4708)\n",
      "(4704, 4705)\n",
      "(45, 4705)\n",
      "(4706, 4707)\n",
      "(48, 4707)\n",
      "(4702, 4704)\n",
      "(4703, 4704)\n",
      "(4699, 4702)\n",
      "(4701, 4702)\n",
      "(37, 4699)\n",
      "(4700, 4701)\n",
      "(40, 4701)\n",
      "<class 'Loss.CrossEntropy'>: 1.1604898\n",
      "(4766, 4767)\n",
      "(4765, 4766)\n",
      "(4764, 4766)\n",
      "(4763, 4764)\n",
      "(4761, 4763)\n",
      "(4762, 4763)\n",
      "(4760, 4761)\n",
      "(4759, 4761)\n",
      "(4758, 4759)\n",
      "(4757, 4758)\n",
      "(4756, 4757)\n",
      "(4755, 4757)\n",
      "(4749, 4756)\n",
      "(4754, 4755)\n",
      "(4752, 4754)\n",
      "(4753, 4754)\n",
      "(4750, 4752)\n",
      "(4751, 4752)\n",
      "(4749, 4750)\n",
      "(4746, 4749)\n",
      "(4748, 4749)\n",
      "(4745, 4746)\n",
      "(53, 4746)\n",
      "(4747, 4748)\n",
      "(56, 4748)\n",
      "(4743, 4745)\n",
      "(4744, 4745)\n",
      "(4740, 4743)\n",
      "(4742, 4743)\n",
      "(4739, 4740)\n",
      "(45, 4740)\n",
      "(4741, 4742)\n",
      "(48, 4742)\n",
      "(4737, 4739)\n",
      "(4738, 4739)\n",
      "(4734, 4737)\n",
      "(4736, 4737)\n",
      "(37, 4734)\n",
      "(4735, 4736)\n",
      "(40, 4736)\n",
      "<class 'Loss.CrossEntropy'>: 1.4355876\n",
      "(4801, 4802)\n",
      "(4800, 4801)\n",
      "(4799, 4801)\n",
      "(4798, 4799)\n",
      "(4796, 4798)\n",
      "(4797, 4798)\n",
      "(4795, 4796)\n",
      "(4794, 4796)\n",
      "(4793, 4794)\n",
      "(4792, 4793)\n",
      "(4791, 4792)\n",
      "(4790, 4792)\n",
      "(4784, 4791)\n",
      "(4789, 4790)\n",
      "(4787, 4789)\n",
      "(4788, 4789)\n",
      "(4785, 4787)\n",
      "(4786, 4787)\n",
      "(4784, 4785)\n",
      "(4781, 4784)\n",
      "(4783, 4784)\n",
      "(4780, 4781)\n",
      "(53, 4781)\n",
      "(4782, 4783)\n",
      "(56, 4783)\n",
      "(4778, 4780)\n",
      "(4779, 4780)\n",
      "(4775, 4778)\n",
      "(4777, 4778)\n",
      "(4774, 4775)\n",
      "(45, 4775)\n",
      "(4776, 4777)\n",
      "(48, 4777)\n",
      "(4772, 4774)\n",
      "(4773, 4774)\n",
      "(4769, 4772)\n",
      "(4771, 4772)\n",
      "(37, 4769)\n",
      "(4770, 4771)\n",
      "(40, 4771)\n",
      "<class 'Loss.CrossEntropy'>: 1.1971004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 138/200 [00:09<00:08,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4836, 4837)\n",
      "(4835, 4836)\n",
      "(4834, 4836)\n",
      "(4833, 4834)\n",
      "(4831, 4833)\n",
      "(4832, 4833)\n",
      "(4830, 4831)\n",
      "(4829, 4831)\n",
      "(4828, 4829)\n",
      "(4827, 4828)\n",
      "(4826, 4827)\n",
      "(4825, 4827)\n",
      "(4819, 4826)\n",
      "(4824, 4825)\n",
      "(4822, 4824)\n",
      "(4823, 4824)\n",
      "(4820, 4822)\n",
      "(4821, 4822)\n",
      "(4819, 4820)\n",
      "(4816, 4819)\n",
      "(4818, 4819)\n",
      "(4815, 4816)\n",
      "(53, 4816)\n",
      "(4817, 4818)\n",
      "(56, 4818)\n",
      "(4813, 4815)\n",
      "(4814, 4815)\n",
      "(4810, 4813)\n",
      "(4812, 4813)\n",
      "(4809, 4810)\n",
      "(45, 4810)\n",
      "(4811, 4812)\n",
      "(48, 4812)\n",
      "(4807, 4809)\n",
      "(4808, 4809)\n",
      "(4804, 4807)\n",
      "(4806, 4807)\n",
      "(37, 4804)\n",
      "(4805, 4806)\n",
      "(40, 4806)\n",
      "<class 'Loss.CrossEntropy'>: 0.97347164\n",
      "(4871, 4872)\n",
      "(4870, 4871)\n",
      "(4869, 4871)\n",
      "(4868, 4869)\n",
      "(4866, 4868)\n",
      "(4867, 4868)\n",
      "(4865, 4866)\n",
      "(4864, 4866)\n",
      "(4863, 4864)\n",
      "(4862, 4863)\n",
      "(4861, 4862)\n",
      "(4860, 4862)\n",
      "(4854, 4861)\n",
      "(4859, 4860)\n",
      "(4857, 4859)\n",
      "(4858, 4859)\n",
      "(4855, 4857)\n",
      "(4856, 4857)\n",
      "(4854, 4855)\n",
      "(4851, 4854)\n",
      "(4853, 4854)\n",
      "(4850, 4851)\n",
      "(53, 4851)\n",
      "(4852, 4853)\n",
      "(56, 4853)\n",
      "(4848, 4850)\n",
      "(4849, 4850)\n",
      "(4845, 4848)\n",
      "(4847, 4848)\n",
      "(4844, 4845)\n",
      "(45, 4845)\n",
      "(4846, 4847)\n",
      "(48, 4847)\n",
      "(4842, 4844)\n",
      "(4843, 4844)\n",
      "(4839, 4842)\n",
      "(4841, 4842)\n",
      "(37, 4839)\n",
      "(4840, 4841)\n",
      "(40, 4841)\n",
      "<class 'Loss.CrossEntropy'>: 1.034302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 140/200 [00:10<00:07,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4906, 4907)\n",
      "(4905, 4906)\n",
      "(4904, 4906)\n",
      "(4903, 4904)\n",
      "(4901, 4903)\n",
      "(4902, 4903)\n",
      "(4900, 4901)\n",
      "(4899, 4901)\n",
      "(4898, 4899)\n",
      "(4897, 4898)\n",
      "(4896, 4897)\n",
      "(4895, 4897)\n",
      "(4889, 4896)\n",
      "(4894, 4895)\n",
      "(4892, 4894)\n",
      "(4893, 4894)\n",
      "(4890, 4892)\n",
      "(4891, 4892)\n",
      "(4889, 4890)\n",
      "(4886, 4889)\n",
      "(4888, 4889)\n",
      "(4885, 4886)\n",
      "(53, 4886)\n",
      "(4887, 4888)\n",
      "(56, 4888)\n",
      "(4883, 4885)\n",
      "(4884, 4885)\n",
      "(4880, 4883)\n",
      "(4882, 4883)\n",
      "(4879, 4880)\n",
      "(45, 4880)\n",
      "(4881, 4882)\n",
      "(48, 4882)\n",
      "(4877, 4879)\n",
      "(4878, 4879)\n",
      "(4874, 4877)\n",
      "(4876, 4877)\n",
      "(37, 4874)\n",
      "(4875, 4876)\n",
      "(40, 4876)\n",
      "<class 'Loss.CrossEntropy'>: 1.2729976\n",
      "(4941, 4942)\n",
      "(4940, 4941)\n",
      "(4939, 4941)\n",
      "(4938, 4939)\n",
      "(4936, 4938)\n",
      "(4937, 4938)\n",
      "(4935, 4936)\n",
      "(4934, 4936)\n",
      "(4933, 4934)\n",
      "(4932, 4933)\n",
      "(4931, 4932)\n",
      "(4930, 4932)\n",
      "(4924, 4931)\n",
      "(4929, 4930)\n",
      "(4927, 4929)\n",
      "(4928, 4929)\n",
      "(4925, 4927)\n",
      "(4926, 4927)\n",
      "(4924, 4925)\n",
      "(4921, 4924)\n",
      "(4923, 4924)\n",
      "(4920, 4921)\n",
      "(53, 4921)\n",
      "(4922, 4923)\n",
      "(56, 4923)\n",
      "(4918, 4920)\n",
      "(4919, 4920)\n",
      "(4915, 4918)\n",
      "(4917, 4918)\n",
      "(4914, 4915)\n",
      "(45, 4915)\n",
      "(4916, 4917)\n",
      "(48, 4917)\n",
      "(4912, 4914)\n",
      "(4913, 4914)\n",
      "(4909, 4912)\n",
      "(4911, 4912)\n",
      "(37, 4909)\n",
      "(4910, 4911)\n",
      "(40, 4911)\n",
      "<class 'Loss.CrossEntropy'>: 1.2765559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 141/200 [00:10<00:07,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4976, 4977)\n",
      "(4975, 4976)\n",
      "(4974, 4976)\n",
      "(4973, 4974)\n",
      "(4971, 4973)\n",
      "(4972, 4973)\n",
      "(4970, 4971)\n",
      "(4969, 4971)\n",
      "(4968, 4969)\n",
      "(4967, 4968)\n",
      "(4966, 4967)\n",
      "(4965, 4967)\n",
      "(4959, 4966)\n",
      "(4964, 4965)\n",
      "(4962, 4964)\n",
      "(4963, 4964)\n",
      "(4960, 4962)\n",
      "(4961, 4962)\n",
      "(4959, 4960)\n",
      "(4956, 4959)\n",
      "(4958, 4959)\n",
      "(4955, 4956)\n",
      "(53, 4956)\n",
      "(4957, 4958)\n",
      "(56, 4958)\n",
      "(4953, 4955)\n",
      "(4954, 4955)\n",
      "(4950, 4953)\n",
      "(4952, 4953)\n",
      "(4949, 4950)\n",
      "(45, 4950)\n",
      "(4951, 4952)\n",
      "(48, 4952)\n",
      "(4947, 4949)\n",
      "(4948, 4949)\n",
      "(4944, 4947)\n",
      "(4946, 4947)\n",
      "(37, 4944)\n",
      "(4945, 4946)\n",
      "(40, 4946)\n",
      "<class 'Loss.CrossEntropy'>: 0.9318197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 143/200 [00:10<00:08,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5011, 5012)\n",
      "(5010, 5011)\n",
      "(5009, 5011)\n",
      "(5008, 5009)\n",
      "(5006, 5008)\n",
      "(5007, 5008)\n",
      "(5005, 5006)\n",
      "(5004, 5006)\n",
      "(5003, 5004)\n",
      "(5002, 5003)\n",
      "(5001, 5002)\n",
      "(5000, 5002)\n",
      "(4994, 5001)\n",
      "(4999, 5000)\n",
      "(4997, 4999)\n",
      "(4998, 4999)\n",
      "(4995, 4997)\n",
      "(4996, 4997)\n",
      "(4994, 4995)\n",
      "(4991, 4994)\n",
      "(4993, 4994)\n",
      "(4990, 4991)\n",
      "(53, 4991)\n",
      "(4992, 4993)\n",
      "(56, 4993)\n",
      "(4988, 4990)\n",
      "(4989, 4990)\n",
      "(4985, 4988)\n",
      "(4987, 4988)\n",
      "(4984, 4985)\n",
      "(45, 4985)\n",
      "(4986, 4987)\n",
      "(48, 4987)\n",
      "(4982, 4984)\n",
      "(4983, 4984)\n",
      "(4979, 4982)\n",
      "(4981, 4982)\n",
      "(37, 4979)\n",
      "(4980, 4981)\n",
      "(40, 4981)\n",
      "<class 'Loss.CrossEntropy'>: 1.1784931\n",
      "(5046, 5047)\n",
      "(5045, 5046)\n",
      "(5044, 5046)\n",
      "(5043, 5044)\n",
      "(5041, 5043)\n",
      "(5042, 5043)\n",
      "(5040, 5041)\n",
      "(5039, 5041)\n",
      "(5038, 5039)\n",
      "(5037, 5038)\n",
      "(5036, 5037)\n",
      "(5035, 5037)\n",
      "(5029, 5036)\n",
      "(5034, 5035)\n",
      "(5032, 5034)\n",
      "(5033, 5034)\n",
      "(5030, 5032)\n",
      "(5031, 5032)\n",
      "(5029, 5030)\n",
      "(5026, 5029)\n",
      "(5028, 5029)\n",
      "(5025, 5026)\n",
      "(53, 5026)\n",
      "(5027, 5028)\n",
      "(56, 5028)\n",
      "(5023, 5025)\n",
      "(5024, 5025)\n",
      "(5020, 5023)\n",
      "(5022, 5023)\n",
      "(5019, 5020)\n",
      "(45, 5020)\n",
      "(5021, 5022)\n",
      "(48, 5022)\n",
      "(5017, 5019)\n",
      "(5018, 5019)\n",
      "(5014, 5017)\n",
      "(5016, 5017)\n",
      "(37, 5014)\n",
      "(5015, 5016)\n",
      "(40, 5016)\n",
      "<class 'Loss.CrossEntropy'>: 1.2212963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 144/200 [00:10<00:08,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5081, 5082)\n",
      "(5080, 5081)\n",
      "(5079, 5081)\n",
      "(5078, 5079)\n",
      "(5076, 5078)\n",
      "(5077, 5078)\n",
      "(5075, 5076)\n",
      "(5074, 5076)\n",
      "(5073, 5074)\n",
      "(5072, 5073)\n",
      "(5071, 5072)\n",
      "(5070, 5072)\n",
      "(5064, 5071)\n",
      "(5069, 5070)\n",
      "(5067, 5069)\n",
      "(5068, 5069)\n",
      "(5065, 5067)\n",
      "(5066, 5067)\n",
      "(5064, 5065)\n",
      "(5061, 5064)\n",
      "(5063, 5064)\n",
      "(5060, 5061)\n",
      "(53, 5061)\n",
      "(5062, 5063)\n",
      "(56, 5063)\n",
      "(5058, 5060)\n",
      "(5059, 5060)\n",
      "(5055, 5058)\n",
      "(5057, 5058)\n",
      "(5054, 5055)\n",
      "(45, 5055)\n",
      "(5056, 5057)\n",
      "(48, 5057)\n",
      "(5052, 5054)\n",
      "(5053, 5054)\n",
      "(5049, 5052)\n",
      "(5051, 5052)\n",
      "(37, 5049)\n",
      "(5050, 5051)\n",
      "(40, 5051)\n",
      "<class 'Loss.CrossEntropy'>: 1.2490941\n",
      "(5116, 5117)\n",
      "(5115, 5116)\n",
      "(5114, 5116)\n",
      "(5113, 5114)\n",
      "(5111, 5113)\n",
      "(5112, 5113)\n",
      "(5110, 5111)\n",
      "(5109, 5111)\n",
      "(5108, 5109)\n",
      "(5107, 5108)\n",
      "(5106, 5107)\n",
      "(5105, 5107)\n",
      "(5099, 5106)\n",
      "(5104, 5105)\n",
      "(5102, 5104)\n",
      "(5103, 5104)\n",
      "(5100, 5102)\n",
      "(5101, 5102)\n",
      "(5099, 5100)\n",
      "(5096, 5099)\n",
      "(5098, 5099)\n",
      "(5095, 5096)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 146/200 [00:11<00:07,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 5096)\n",
      "(5097, 5098)\n",
      "(56, 5098)\n",
      "(5093, 5095)\n",
      "(5094, 5095)\n",
      "(5090, 5093)\n",
      "(5092, 5093)\n",
      "(5089, 5090)\n",
      "(45, 5090)\n",
      "(5091, 5092)\n",
      "(48, 5092)\n",
      "(5087, 5089)\n",
      "(5088, 5089)\n",
      "(5084, 5087)\n",
      "(5086, 5087)\n",
      "(37, 5084)\n",
      "(5085, 5086)\n",
      "(40, 5086)\n",
      "<class 'Loss.CrossEntropy'>: 0.877531\n",
      "(5151, 5152)\n",
      "(5150, 5151)\n",
      "(5149, 5151)\n",
      "(5148, 5149)\n",
      "(5146, 5148)\n",
      "(5147, 5148)\n",
      "(5145, 5146)\n",
      "(5144, 5146)\n",
      "(5143, 5144)\n",
      "(5142, 5143)\n",
      "(5141, 5142)\n",
      "(5140, 5142)\n",
      "(5134, 5141)\n",
      "(5139, 5140)\n",
      "(5137, 5139)\n",
      "(5138, 5139)\n",
      "(5135, 5137)\n",
      "(5136, 5137)\n",
      "(5134, 5135)\n",
      "(5131, 5134)\n",
      "(5133, 5134)\n",
      "(5130, 5131)\n",
      "(53, 5131)\n",
      "(5132, 5133)\n",
      "(56, 5133)\n",
      "(5128, 5130)\n",
      "(5129, 5130)\n",
      "(5125, 5128)\n",
      "(5127, 5128)\n",
      "(5124, 5125)\n",
      "(45, 5125)\n",
      "(5126, 5127)\n",
      "(48, 5127)\n",
      "(5122, 5124)\n",
      "(5123, 5124)\n",
      "(5119, 5122)\n",
      "(5121, 5122)\n",
      "(37, 5119)\n",
      "(5120, 5121)\n",
      "(40, 5121)\n",
      "<class 'Loss.CrossEntropy'>: 1.106936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 148/200 [00:11<00:08,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5186, 5187)\n",
      "(5185, 5186)\n",
      "(5184, 5186)\n",
      "(5183, 5184)\n",
      "(5181, 5183)\n",
      "(5182, 5183)\n",
      "(5180, 5181)\n",
      "(5179, 5181)\n",
      "(5178, 5179)\n",
      "(5177, 5178)\n",
      "(5176, 5177)\n",
      "(5175, 5177)\n",
      "(5169, 5176)\n",
      "(5174, 5175)\n",
      "(5172, 5174)\n",
      "(5173, 5174)\n",
      "(5170, 5172)\n",
      "(5171, 5172)\n",
      "(5169, 5170)\n",
      "(5166, 5169)\n",
      "(5168, 5169)\n",
      "(5165, 5166)\n",
      "(53, 5166)\n",
      "(5167, 5168)\n",
      "(56, 5168)\n",
      "(5163, 5165)\n",
      "(5164, 5165)\n",
      "(5160, 5163)\n",
      "(5162, 5163)\n",
      "(5159, 5160)\n",
      "(45, 5160)\n",
      "(5161, 5162)\n",
      "(48, 5162)\n",
      "(5157, 5159)\n",
      "(5158, 5159)\n",
      "(5154, 5157)\n",
      "(5156, 5157)\n",
      "(37, 5154)\n",
      "(5155, 5156)\n",
      "(40, 5156)\n",
      "<class 'Loss.CrossEntropy'>: 1.0155947\n",
      "(5221, 5222)\n",
      "(5220, 5221)\n",
      "(5219, 5221)\n",
      "(5218, 5219)\n",
      "(5216, 5218)\n",
      "(5217, 5218)\n",
      "(5215, 5216)\n",
      "(5214, 5216)\n",
      "(5213, 5214)\n",
      "(5212, 5213)\n",
      "(5211, 5212)\n",
      "(5210, 5212)\n",
      "(5204, 5211)\n",
      "(5209, 5210)\n",
      "(5207, 5209)\n",
      "(5208, 5209)\n",
      "(5205, 5207)\n",
      "(5206, 5207)\n",
      "(5204, 5205)\n",
      "(5201, 5204)\n",
      "(5203, 5204)\n",
      "(5200, 5201)\n",
      "(53, 5201)\n",
      "(5202, 5203)\n",
      "(56, 5203)\n",
      "(5198, 5200)\n",
      "(5199, 5200)\n",
      "(5195, 5198)\n",
      "(5197, 5198)\n",
      "(5194, 5195)\n",
      "(45, 5195)\n",
      "(5196, 5197)\n",
      "(48, 5197)\n",
      "(5192, 5194)\n",
      "(5193, 5194)\n",
      "(5189, 5192)\n",
      "(5191, 5192)\n",
      "(37, 5189)\n",
      "(5190, 5191)\n",
      "(40, 5191)\n",
      "<class 'Loss.CrossEntropy'>: 1.1484435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 150/200 [00:11<00:07,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5256, 5257)\n",
      "(5255, 5256)\n",
      "(5254, 5256)\n",
      "(5253, 5254)\n",
      "(5251, 5253)\n",
      "(5252, 5253)\n",
      "(5250, 5251)\n",
      "(5249, 5251)\n",
      "(5248, 5249)\n",
      "(5247, 5248)\n",
      "(5246, 5247)\n",
      "(5245, 5247)\n",
      "(5239, 5246)\n",
      "(5244, 5245)\n",
      "(5242, 5244)\n",
      "(5243, 5244)\n",
      "(5240, 5242)\n",
      "(5241, 5242)\n",
      "(5239, 5240)\n",
      "(5236, 5239)\n",
      "(5238, 5239)\n",
      "(5235, 5236)\n",
      "(53, 5236)\n",
      "(5237, 5238)\n",
      "(56, 5238)\n",
      "(5233, 5235)\n",
      "(5234, 5235)\n",
      "(5230, 5233)\n",
      "(5232, 5233)\n",
      "(5229, 5230)\n",
      "(45, 5230)\n",
      "(5231, 5232)\n",
      "(48, 5232)\n",
      "(5227, 5229)\n",
      "(5228, 5229)\n",
      "(5224, 5227)\n",
      "(5226, 5227)\n",
      "(37, 5224)\n",
      "(5225, 5226)\n",
      "(40, 5226)\n",
      "<class 'Loss.CrossEntropy'>: 1.4227817\n",
      "(5291, 5292)\n",
      "(5290, 5291)\n",
      "(5289, 5291)\n",
      "(5288, 5289)\n",
      "(5286, 5288)\n",
      "(5287, 5288)\n",
      "(5285, 5286)\n",
      "(5284, 5286)\n",
      "(5283, 5284)\n",
      "(5282, 5283)\n",
      "(5281, 5282)\n",
      "(5280, 5282)\n",
      "(5274, 5281)\n",
      "(5279, 5280)\n",
      "(5277, 5279)\n",
      "(5278, 5279)\n",
      "(5275, 5277)\n",
      "(5276, 5277)\n",
      "(5274, 5275)\n",
      "(5271, 5274)\n",
      "(5273, 5274)\n",
      "(5270, 5271)\n",
      "(53, 5271)\n",
      "(5272, 5273)\n",
      "(56, 5273)\n",
      "(5268, 5270)\n",
      "(5269, 5270)\n",
      "(5265, 5268)\n",
      "(5267, 5268)\n",
      "(5264, 5265)\n",
      "(45, 5265)\n",
      "(5266, 5267)\n",
      "(48, 5267)\n",
      "(5262, 5264)\n",
      "(5263, 5264)\n",
      "(5259, 5262)\n",
      "(5261, 5262)\n",
      "(37, 5259)\n",
      "(5260, 5261)\n",
      "(40, 5261)\n",
      "<class 'Loss.CrossEntropy'>: 1.458307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 152/200 [00:12<00:08,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5326, 5327)\n",
      "(5325, 5326)\n",
      "(5324, 5326)\n",
      "(5323, 5324)\n",
      "(5321, 5323)\n",
      "(5322, 5323)\n",
      "(5320, 5321)\n",
      "(5319, 5321)\n",
      "(5318, 5319)\n",
      "(5317, 5318)\n",
      "(5316, 5317)\n",
      "(5315, 5317)\n",
      "(5309, 5316)\n",
      "(5314, 5315)\n",
      "(5312, 5314)\n",
      "(5313, 5314)\n",
      "(5310, 5312)\n",
      "(5311, 5312)\n",
      "(5309, 5310)\n",
      "(5306, 5309)\n",
      "(5308, 5309)\n",
      "(5305, 5306)\n",
      "(53, 5306)\n",
      "(5307, 5308)\n",
      "(56, 5308)\n",
      "(5303, 5305)\n",
      "(5304, 5305)\n",
      "(5300, 5303)\n",
      "(5302, 5303)\n",
      "(5299, 5300)\n",
      "(45, 5300)\n",
      "(5301, 5302)\n",
      "(48, 5302)\n",
      "(5297, 5299)\n",
      "(5298, 5299)\n",
      "(5294, 5297)\n",
      "(5296, 5297)\n",
      "(37, 5294)\n",
      "(5295, 5296)\n",
      "(40, 5296)\n",
      "<class 'Loss.CrossEntropy'>: 1.1784875\n",
      "(5361, 5362)\n",
      "(5360, 5361)\n",
      "(5359, 5361)\n",
      "(5358, 5359)\n",
      "(5356, 5358)\n",
      "(5357, 5358)\n",
      "(5355, 5356)\n",
      "(5354, 5356)\n",
      "(5353, 5354)\n",
      "(5352, 5353)\n",
      "(5351, 5352)\n",
      "(5350, 5352)\n",
      "(5344, 5351)\n",
      "(5349, 5350)\n",
      "(5347, 5349)\n",
      "(5348, 5349)\n",
      "(5345, 5347)\n",
      "(5346, 5347)\n",
      "(5344, 5345)\n",
      "(5341, 5344)\n",
      "(5343, 5344)\n",
      "(5340, 5341)\n",
      "(53, 5341)\n",
      "(5342, 5343)\n",
      "(56, 5343)\n",
      "(5338, 5340)\n",
      "(5339, 5340)\n",
      "(5335, 5338)\n",
      "(5337, 5338)\n",
      "(5334, 5335)\n",
      "(45, 5335)\n",
      "(5336, 5337)\n",
      "(48, 5337)\n",
      "(5332, 5334)\n",
      "(5333, 5334)\n",
      "(5329, 5332)\n",
      "(5331, 5332)\n",
      "(37, 5329)\n",
      "(5330, 5331)\n",
      "(40, 5331)\n",
      "<class 'Loss.CrossEntropy'>: 1.1381953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 154/200 [00:12<00:07,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5396, 5397)\n",
      "(5395, 5396)\n",
      "(5394, 5396)\n",
      "(5393, 5394)\n",
      "(5391, 5393)\n",
      "(5392, 5393)\n",
      "(5390, 5391)\n",
      "(5389, 5391)\n",
      "(5388, 5389)\n",
      "(5387, 5388)\n",
      "(5386, 5387)\n",
      "(5385, 5387)\n",
      "(5379, 5386)\n",
      "(5384, 5385)\n",
      "(5382, 5384)\n",
      "(5383, 5384)\n",
      "(5380, 5382)\n",
      "(5381, 5382)\n",
      "(5379, 5380)\n",
      "(5376, 5379)\n",
      "(5378, 5379)\n",
      "(5375, 5376)\n",
      "(53, 5376)\n",
      "(5377, 5378)\n",
      "(56, 5378)\n",
      "(5373, 5375)\n",
      "(5374, 5375)\n",
      "(5370, 5373)\n",
      "(5372, 5373)\n",
      "(5369, 5370)\n",
      "(45, 5370)\n",
      "(5371, 5372)\n",
      "(48, 5372)\n",
      "(5367, 5369)\n",
      "(5368, 5369)\n",
      "(5364, 5367)\n",
      "(5366, 5367)\n",
      "(37, 5364)\n",
      "(5365, 5366)\n",
      "(40, 5366)\n",
      "<class 'Loss.CrossEntropy'>: 1.1729522\n",
      "(5431, 5432)\n",
      "(5430, 5431)\n",
      "(5429, 5431)\n",
      "(5428, 5429)\n",
      "(5426, 5428)\n",
      "(5427, 5428)\n",
      "(5425, 5426)\n",
      "(5424, 5426)\n",
      "(5423, 5424)\n",
      "(5422, 5423)\n",
      "(5421, 5422)\n",
      "(5420, 5422)\n",
      "(5414, 5421)\n",
      "(5419, 5420)\n",
      "(5417, 5419)\n",
      "(5418, 5419)\n",
      "(5415, 5417)\n",
      "(5416, 5417)\n",
      "(5414, 5415)\n",
      "(5411, 5414)\n",
      "(5413, 5414)\n",
      "(5410, 5411)\n",
      "(53, 5411)\n",
      "(5412, 5413)\n",
      "(56, 5413)\n",
      "(5408, 5410)\n",
      "(5409, 5410)\n",
      "(5405, 5408)\n",
      "(5407, 5408)\n",
      "(5404, 5405)\n",
      "(45, 5405)\n",
      "(5406, 5407)\n",
      "(48, 5407)\n",
      "(5402, 5404)\n",
      "(5403, 5404)\n",
      "(5399, 5402)\n",
      "(5401, 5402)\n",
      "(37, 5399)\n",
      "(5400, 5401)\n",
      "(40, 5401)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 155/200 [00:12<00:06,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'Loss.CrossEntropy'>: 1.2204038\n",
      "(5466, 5467)\n",
      "(5465, 5466)\n",
      "(5464, 5466)\n",
      "(5463, 5464)\n",
      "(5461, 5463)\n",
      "(5462, 5463)\n",
      "(5460, 5461)\n",
      "(5459, 5461)\n",
      "(5458, 5459)\n",
      "(5457, 5458)\n",
      "(5456, 5457)\n",
      "(5455, 5457)\n",
      "(5449, 5456)\n",
      "(5454, 5455)\n",
      "(5452, 5454)\n",
      "(5453, 5454)\n",
      "(5450, 5452)\n",
      "(5451, 5452)\n",
      "(5449, 5450)\n",
      "(5446, 5449)\n",
      "(5448, 5449)\n",
      "(5445, 5446)\n",
      "(53, 5446)\n",
      "(5447, 5448)\n",
      "(56, 5448)\n",
      "(5443, 5445)\n",
      "(5444, 5445)\n",
      "(5440, 5443)\n",
      "(5442, 5443)\n",
      "(5439, 5440)\n",
      "(45, 5440)\n",
      "(5441, 5442)\n",
      "(48, 5442)\n",
      "(5437, 5439)\n",
      "(5438, 5439)\n",
      "(5434, 5437)\n",
      "(5436, 5437)\n",
      "(37, 5434)\n",
      "(5435, 5436)\n",
      "(40, 5436)\n",
      "<class 'Loss.CrossEntropy'>: 1.3459426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 157/200 [00:12<00:07,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5501, 5502)\n",
      "(5500, 5501)\n",
      "(5499, 5501)\n",
      "(5498, 5499)\n",
      "(5496, 5498)\n",
      "(5497, 5498)\n",
      "(5495, 5496)\n",
      "(5494, 5496)\n",
      "(5493, 5494)\n",
      "(5492, 5493)\n",
      "(5491, 5492)\n",
      "(5490, 5492)\n",
      "(5484, 5491)\n",
      "(5489, 5490)\n",
      "(5487, 5489)\n",
      "(5488, 5489)\n",
      "(5485, 5487)\n",
      "(5486, 5487)\n",
      "(5484, 5485)\n",
      "(5481, 5484)\n",
      "(5483, 5484)\n",
      "(5480, 5481)\n",
      "(53, 5481)\n",
      "(5482, 5483)\n",
      "(56, 5483)\n",
      "(5478, 5480)\n",
      "(5479, 5480)\n",
      "(5475, 5478)\n",
      "(5477, 5478)\n",
      "(5474, 5475)\n",
      "(45, 5475)\n",
      "(5476, 5477)\n",
      "(48, 5477)\n",
      "(5472, 5474)\n",
      "(5473, 5474)\n",
      "(5469, 5472)\n",
      "(5471, 5472)\n",
      "(37, 5469)\n",
      "(5470, 5471)\n",
      "(40, 5471)\n",
      "<class 'Loss.CrossEntropy'>: 0.9575385\n",
      "(5536, 5537)\n",
      "(5535, 5536)\n",
      "(5534, 5536)\n",
      "(5533, 5534)\n",
      "(5531, 5533)\n",
      "(5532, 5533)\n",
      "(5530, 5531)\n",
      "(5529, 5531)\n",
      "(5528, 5529)\n",
      "(5527, 5528)\n",
      "(5526, 5527)\n",
      "(5525, 5527)\n",
      "(5519, 5526)\n",
      "(5524, 5525)\n",
      "(5522, 5524)\n",
      "(5523, 5524)\n",
      "(5520, 5522)\n",
      "(5521, 5522)\n",
      "(5519, 5520)\n",
      "(5516, 5519)\n",
      "(5518, 5519)\n",
      "(5515, 5516)\n",
      "(53, 5516)\n",
      "(5517, 5518)\n",
      "(56, 5518)\n",
      "(5513, 5515)\n",
      "(5514, 5515)\n",
      "(5510, 5513)\n",
      "(5512, 5513)\n",
      "(5509, 5510)\n",
      "(45, 5510)\n",
      "(5511, 5512)\n",
      "(48, 5512)\n",
      "(5507, 5509)\n",
      "(5508, 5509)\n",
      "(5504, 5507)\n",
      "(5506, 5507)\n",
      "(37, 5504)\n",
      "(5505, 5506)\n",
      "(40, 5506)\n",
      "<class 'Loss.CrossEntropy'>: 1.0503972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 159/200 [00:13<00:05,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5571, 5572)\n",
      "(5570, 5571)\n",
      "(5569, 5571)\n",
      "(5568, 5569)\n",
      "(5566, 5568)\n",
      "(5567, 5568)\n",
      "(5565, 5566)\n",
      "(5564, 5566)\n",
      "(5563, 5564)\n",
      "(5562, 5563)\n",
      "(5561, 5562)\n",
      "(5560, 5562)\n",
      "(5554, 5561)\n",
      "(5559, 5560)\n",
      "(5557, 5559)\n",
      "(5558, 5559)\n",
      "(5555, 5557)\n",
      "(5556, 5557)\n",
      "(5554, 5555)\n",
      "(5551, 5554)\n",
      "(5553, 5554)\n",
      "(5550, 5551)\n",
      "(53, 5551)\n",
      "(5552, 5553)\n",
      "(56, 5553)\n",
      "(5548, 5550)\n",
      "(5549, 5550)\n",
      "(5545, 5548)\n",
      "(5547, 5548)\n",
      "(5544, 5545)\n",
      "(45, 5545)\n",
      "(5546, 5547)\n",
      "(48, 5547)\n",
      "(5542, 5544)\n",
      "(5543, 5544)\n",
      "(5539, 5542)\n",
      "(5541, 5542)\n",
      "(37, 5539)\n",
      "(5540, 5541)\n",
      "(40, 5541)\n",
      "<class 'Loss.CrossEntropy'>: 1.2668446\n",
      "(5606, 5607)\n",
      "(5605, 5606)\n",
      "(5604, 5606)\n",
      "(5603, 5604)\n",
      "(5601, 5603)\n",
      "(5602, 5603)\n",
      "(5600, 5601)\n",
      "(5599, 5601)\n",
      "(5598, 5599)\n",
      "(5597, 5598)\n",
      "(5596, 5597)\n",
      "(5595, 5597)\n",
      "(5589, 5596)\n",
      "(5594, 5595)\n",
      "(5592, 5594)\n",
      "(5593, 5594)\n",
      "(5590, 5592)\n",
      "(5591, 5592)\n",
      "(5589, 5590)\n",
      "(5586, 5589)\n",
      "(5588, 5589)\n",
      "(5585, 5586)\n",
      "(53, 5586)\n",
      "(5587, 5588)\n",
      "(56, 5588)\n",
      "(5583, 5585)\n",
      "(5584, 5585)\n",
      "(5580, 5583)\n",
      "(5582, 5583)\n",
      "(5579, 5580)\n",
      "(45, 5580)\n",
      "(5581, 5582)\n",
      "(48, 5582)\n",
      "(5577, 5579)\n",
      "(5578, 5579)\n",
      "(5574, 5577)\n",
      "(5576, 5577)\n",
      "(37, 5574)\n",
      "(5575, 5576)\n",
      "(40, 5576)\n",
      "<class 'Loss.CrossEntropy'>: 1.1095349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 161/200 [00:13<00:06,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5641, 5642)\n",
      "(5640, 5641)\n",
      "(5639, 5641)\n",
      "(5638, 5639)\n",
      "(5636, 5638)\n",
      "(5637, 5638)\n",
      "(5635, 5636)\n",
      "(5634, 5636)\n",
      "(5633, 5634)\n",
      "(5632, 5633)\n",
      "(5631, 5632)\n",
      "(5630, 5632)\n",
      "(5624, 5631)\n",
      "(5629, 5630)\n",
      "(5627, 5629)\n",
      "(5628, 5629)\n",
      "(5625, 5627)\n",
      "(5626, 5627)\n",
      "(5624, 5625)\n",
      "(5621, 5624)\n",
      "(5623, 5624)\n",
      "(5620, 5621)\n",
      "(53, 5621)\n",
      "(5622, 5623)\n",
      "(56, 5623)\n",
      "(5618, 5620)\n",
      "(5619, 5620)\n",
      "(5615, 5618)\n",
      "(5617, 5618)\n",
      "(5614, 5615)\n",
      "(45, 5615)\n",
      "(5616, 5617)\n",
      "(48, 5617)\n",
      "(5612, 5614)\n",
      "(5613, 5614)\n",
      "(5609, 5612)\n",
      "(5611, 5612)\n",
      "(37, 5609)\n",
      "(5610, 5611)\n",
      "(40, 5611)\n",
      "<class 'Loss.CrossEntropy'>: 1.3173897\n",
      "(5676, 5677)\n",
      "(5675, 5676)\n",
      "(5674, 5676)\n",
      "(5673, 5674)\n",
      "(5671, 5673)\n",
      "(5672, 5673)\n",
      "(5670, 5671)\n",
      "(5669, 5671)\n",
      "(5668, 5669)\n",
      "(5667, 5668)\n",
      "(5666, 5667)\n",
      "(5665, 5667)\n",
      "(5659, 5666)\n",
      "(5664, 5665)\n",
      "(5662, 5664)\n",
      "(5663, 5664)\n",
      "(5660, 5662)\n",
      "(5661, 5662)\n",
      "(5659, 5660)\n",
      "(5656, 5659)\n",
      "(5658, 5659)\n",
      "(5655, 5656)\n",
      "(53, 5656)\n",
      "(5657, 5658)\n",
      "(56, 5658)\n",
      "(5653, 5655)\n",
      "(5654, 5655)\n",
      "(5650, 5653)\n",
      "(5652, 5653)\n",
      "(5649, 5650)\n",
      "(45, 5650)\n",
      "(5651, 5652)\n",
      "(48, 5652)\n",
      "(5647, 5649)\n",
      "(5648, 5649)\n",
      "(5644, 5647)\n",
      "(5646, 5647)\n",
      "(37, 5644)\n",
      "(5645, 5646)\n",
      "(40, 5646)\n",
      "<class 'Loss.CrossEntropy'>: 1.182264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 163/200 [00:13<00:05,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5711, 5712)\n",
      "(5710, 5711)\n",
      "(5709, 5711)\n",
      "(5708, 5709)\n",
      "(5706, 5708)\n",
      "(5707, 5708)\n",
      "(5705, 5706)\n",
      "(5704, 5706)\n",
      "(5703, 5704)\n",
      "(5702, 5703)\n",
      "(5701, 5702)\n",
      "(5700, 5702)\n",
      "(5694, 5701)\n",
      "(5699, 5700)\n",
      "(5697, 5699)\n",
      "(5698, 5699)\n",
      "(5695, 5697)\n",
      "(5696, 5697)\n",
      "(5694, 5695)\n",
      "(5691, 5694)\n",
      "(5693, 5694)\n",
      "(5690, 5691)\n",
      "(53, 5691)\n",
      "(5692, 5693)\n",
      "(56, 5693)\n",
      "(5688, 5690)\n",
      "(5689, 5690)\n",
      "(5685, 5688)\n",
      "(5687, 5688)\n",
      "(5684, 5685)\n",
      "(45, 5685)\n",
      "(5686, 5687)\n",
      "(48, 5687)\n",
      "(5682, 5684)\n",
      "(5683, 5684)\n",
      "(5679, 5682)\n",
      "(5681, 5682)\n",
      "(37, 5679)\n",
      "(5680, 5681)\n",
      "(40, 5681)\n",
      "<class 'Loss.CrossEntropy'>: 1.339229\n",
      "(5746, 5747)\n",
      "(5745, 5746)\n",
      "(5744, 5746)\n",
      "(5743, 5744)\n",
      "(5741, 5743)\n",
      "(5742, 5743)\n",
      "(5740, 5741)\n",
      "(5739, 5741)\n",
      "(5738, 5739)\n",
      "(5737, 5738)\n",
      "(5736, 5737)\n",
      "(5735, 5737)\n",
      "(5729, 5736)\n",
      "(5734, 5735)\n",
      "(5732, 5734)\n",
      "(5733, 5734)\n",
      "(5730, 5732)\n",
      "(5731, 5732)\n",
      "(5729, 5730)\n",
      "(5726, 5729)\n",
      "(5728, 5729)\n",
      "(5725, 5726)\n",
      "(53, 5726)\n",
      "(5727, 5728)\n",
      "(56, 5728)\n",
      "(5723, 5725)\n",
      "(5724, 5725)\n",
      "(5720, 5723)\n",
      "(5722, 5723)\n",
      "(5719, 5720)\n",
      "(45, 5720)\n",
      "(5721, 5722)\n",
      "(48, 5722)\n",
      "(5717, 5719)\n",
      "(5718, 5719)\n",
      "(5714, 5717)\n",
      "(5716, 5717)\n",
      "(37, 5714)\n",
      "(5715, 5716)\n",
      "(40, 5716)\n",
      "<class 'Loss.CrossEntropy'>: 1.2674837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 165/200 [00:14<00:05,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5781, 5782)\n",
      "(5780, 5781)\n",
      "(5779, 5781)\n",
      "(5778, 5779)\n",
      "(5776, 5778)\n",
      "(5777, 5778)\n",
      "(5775, 5776)\n",
      "(5774, 5776)\n",
      "(5773, 5774)\n",
      "(5772, 5773)\n",
      "(5771, 5772)\n",
      "(5770, 5772)\n",
      "(5764, 5771)\n",
      "(5769, 5770)\n",
      "(5767, 5769)\n",
      "(5768, 5769)\n",
      "(5765, 5767)\n",
      "(5766, 5767)\n",
      "(5764, 5765)\n",
      "(5761, 5764)\n",
      "(5763, 5764)\n",
      "(5760, 5761)\n",
      "(53, 5761)\n",
      "(5762, 5763)\n",
      "(56, 5763)\n",
      "(5758, 5760)\n",
      "(5759, 5760)\n",
      "(5755, 5758)\n",
      "(5757, 5758)\n",
      "(5754, 5755)\n",
      "(45, 5755)\n",
      "(5756, 5757)\n",
      "(48, 5757)\n",
      "(5752, 5754)\n",
      "(5753, 5754)\n",
      "(5749, 5752)\n",
      "(5751, 5752)\n",
      "(37, 5749)\n",
      "(5750, 5751)\n",
      "(40, 5751)\n",
      "<class 'Loss.CrossEntropy'>: 1.1113085\n",
      "(5816, 5817)\n",
      "(5815, 5816)\n",
      "(5814, 5816)\n",
      "(5813, 5814)\n",
      "(5811, 5813)\n",
      "(5812, 5813)\n",
      "(5810, 5811)\n",
      "(5809, 5811)\n",
      "(5808, 5809)\n",
      "(5807, 5808)\n",
      "(5806, 5807)\n",
      "(5805, 5807)\n",
      "(5799, 5806)\n",
      "(5804, 5805)\n",
      "(5802, 5804)\n",
      "(5803, 5804)\n",
      "(5800, 5802)\n",
      "(5801, 5802)\n",
      "(5799, 5800)\n",
      "(5796, 5799)\n",
      "(5798, 5799)\n",
      "(5795, 5796)\n",
      "(53, 5796)\n",
      "(5797, 5798)\n",
      "(56, 5798)\n",
      "(5793, 5795)\n",
      "(5794, 5795)\n",
      "(5790, 5793)\n",
      "(5792, 5793)\n",
      "(5789, 5790)\n",
      "(45, 5790)\n",
      "(5791, 5792)\n",
      "(48, 5792)\n",
      "(5787, 5789)\n",
      "(5788, 5789)\n",
      "(5784, 5787)\n",
      "(5786, 5787)\n",
      "(37, 5784)\n",
      "(5785, 5786)\n",
      "(40, 5786)\n",
      "<class 'Loss.CrossEntropy'>: 1.1655338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 167/200 [00:14<00:04,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5851, 5852)\n",
      "(5850, 5851)\n",
      "(5849, 5851)\n",
      "(5848, 5849)\n",
      "(5846, 5848)\n",
      "(5847, 5848)\n",
      "(5845, 5846)\n",
      "(5844, 5846)\n",
      "(5843, 5844)\n",
      "(5842, 5843)\n",
      "(5841, 5842)\n",
      "(5840, 5842)\n",
      "(5834, 5841)\n",
      "(5839, 5840)\n",
      "(5837, 5839)\n",
      "(5838, 5839)\n",
      "(5835, 5837)\n",
      "(5836, 5837)\n",
      "(5834, 5835)\n",
      "(5831, 5834)\n",
      "(5833, 5834)\n",
      "(5830, 5831)\n",
      "(53, 5831)\n",
      "(5832, 5833)\n",
      "(56, 5833)\n",
      "(5828, 5830)\n",
      "(5829, 5830)\n",
      "(5825, 5828)\n",
      "(5827, 5828)\n",
      "(5824, 5825)\n",
      "(45, 5825)\n",
      "(5826, 5827)\n",
      "(48, 5827)\n",
      "(5822, 5824)\n",
      "(5823, 5824)\n",
      "(5819, 5822)\n",
      "(5821, 5822)\n",
      "(37, 5819)\n",
      "(5820, 5821)\n",
      "(40, 5821)\n",
      "<class 'Loss.CrossEntropy'>: 1.2751055\n",
      "(5886, 5887)\n",
      "(5885, 5886)\n",
      "(5884, 5886)\n",
      "(5883, 5884)\n",
      "(5881, 5883)\n",
      "(5882, 5883)\n",
      "(5880, 5881)\n",
      "(5879, 5881)\n",
      "(5878, 5879)\n",
      "(5877, 5878)\n",
      "(5876, 5877)\n",
      "(5875, 5877)\n",
      "(5869, 5876)\n",
      "(5874, 5875)\n",
      "(5872, 5874)\n",
      "(5873, 5874)\n",
      "(5870, 5872)\n",
      "(5871, 5872)\n",
      "(5869, 5870)\n",
      "(5866, 5869)\n",
      "(5868, 5869)\n",
      "(5865, 5866)\n",
      "(53, 5866)\n",
      "(5867, 5868)\n",
      "(56, 5868)\n",
      "(5863, 5865)\n",
      "(5864, 5865)\n",
      "(5860, 5863)\n",
      "(5862, 5863)\n",
      "(5859, 5860)\n",
      "(45, 5860)\n",
      "(5861, 5862)\n",
      "(48, 5862)\n",
      "(5857, 5859)\n",
      "(5858, 5859)\n",
      "(5854, 5857)\n",
      "(5856, 5857)\n",
      "(37, 5854)\n",
      "(5855, 5856)\n",
      "(40, 5856)\n",
      "<class 'Loss.CrossEntropy'>: 1.0691723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 169/200 [00:14<00:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5921, 5922)\n",
      "(5920, 5921)\n",
      "(5919, 5921)\n",
      "(5918, 5919)\n",
      "(5916, 5918)\n",
      "(5917, 5918)\n",
      "(5915, 5916)\n",
      "(5914, 5916)\n",
      "(5913, 5914)\n",
      "(5912, 5913)\n",
      "(5911, 5912)\n",
      "(5910, 5912)\n",
      "(5904, 5911)\n",
      "(5909, 5910)\n",
      "(5907, 5909)\n",
      "(5908, 5909)\n",
      "(5905, 5907)\n",
      "(5906, 5907)\n",
      "(5904, 5905)\n",
      "(5901, 5904)\n",
      "(5903, 5904)\n",
      "(5900, 5901)\n",
      "(53, 5901)\n",
      "(5902, 5903)\n",
      "(56, 5903)\n",
      "(5898, 5900)\n",
      "(5899, 5900)\n",
      "(5895, 5898)\n",
      "(5897, 5898)\n",
      "(5894, 5895)\n",
      "(45, 5895)\n",
      "(5896, 5897)\n",
      "(48, 5897)\n",
      "(5892, 5894)\n",
      "(5893, 5894)\n",
      "(5889, 5892)\n",
      "(5891, 5892)\n",
      "(37, 5889)\n",
      "(5890, 5891)\n",
      "(40, 5891)\n",
      "<class 'Loss.CrossEntropy'>: 1.2076781\n",
      "(5956, 5957)\n",
      "(5955, 5956)\n",
      "(5954, 5956)\n",
      "(5953, 5954)\n",
      "(5951, 5953)\n",
      "(5952, 5953)\n",
      "(5950, 5951)\n",
      "(5949, 5951)\n",
      "(5948, 5949)\n",
      "(5947, 5948)\n",
      "(5946, 5947)\n",
      "(5945, 5947)\n",
      "(5939, 5946)\n",
      "(5944, 5945)\n",
      "(5942, 5944)\n",
      "(5943, 5944)\n",
      "(5940, 5942)\n",
      "(5941, 5942)\n",
      "(5939, 5940)\n",
      "(5936, 5939)\n",
      "(5938, 5939)\n",
      "(5935, 5936)\n",
      "(53, 5936)\n",
      "(5937, 5938)\n",
      "(56, 5938)\n",
      "(5933, 5935)\n",
      "(5934, 5935)\n",
      "(5930, 5933)\n",
      "(5932, 5933)\n",
      "(5929, 5930)\n",
      "(45, 5930)\n",
      "(5931, 5932)\n",
      "(48, 5932)\n",
      "(5927, 5929)\n",
      "(5928, 5929)\n",
      "(5924, 5927)\n",
      "(5926, 5927)\n",
      "(37, 5924)\n",
      "(5925, 5926)\n",
      "(40, 5926)\n",
      "<class 'Loss.CrossEntropy'>: 1.2490823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 170/200 [00:15<00:05,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5991, 5992)\n",
      "(5990, 5991)\n",
      "(5989, 5991)\n",
      "(5988, 5989)\n",
      "(5986, 5988)\n",
      "(5987, 5988)\n",
      "(5985, 5986)\n",
      "(5984, 5986)\n",
      "(5983, 5984)\n",
      "(5982, 5983)\n",
      "(5981, 5982)\n",
      "(5980, 5982)\n",
      "(5974, 5981)\n",
      "(5979, 5980)\n",
      "(5977, 5979)\n",
      "(5978, 5979)\n",
      "(5975, 5977)\n",
      "(5976, 5977)\n",
      "(5974, 5975)\n",
      "(5971, 5974)\n",
      "(5973, 5974)\n",
      "(5970, 5971)\n",
      "(53, 5971)\n",
      "(5972, 5973)\n",
      "(56, 5973)\n",
      "(5968, 5970)\n",
      "(5969, 5970)\n",
      "(5965, 5968)\n",
      "(5967, 5968)\n",
      "(5964, 5965)\n",
      "(45, 5965)\n",
      "(5966, 5967)\n",
      "(48, 5967)\n",
      "(5962, 5964)\n",
      "(5963, 5964)\n",
      "(5959, 5962)\n",
      "(5961, 5962)\n",
      "(37, 5959)\n",
      "(5960, 5961)\n",
      "(40, 5961)\n",
      "<class 'Loss.CrossEntropy'>: 1.2368785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 172/200 [00:15<00:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6026, 6027)\n",
      "(6025, 6026)\n",
      "(6024, 6026)\n",
      "(6023, 6024)\n",
      "(6021, 6023)\n",
      "(6022, 6023)\n",
      "(6020, 6021)\n",
      "(6019, 6021)\n",
      "(6018, 6019)\n",
      "(6017, 6018)\n",
      "(6016, 6017)\n",
      "(6015, 6017)\n",
      "(6009, 6016)\n",
      "(6014, 6015)\n",
      "(6012, 6014)\n",
      "(6013, 6014)\n",
      "(6010, 6012)\n",
      "(6011, 6012)\n",
      "(6009, 6010)\n",
      "(6006, 6009)\n",
      "(6008, 6009)\n",
      "(6005, 6006)\n",
      "(53, 6006)\n",
      "(6007, 6008)\n",
      "(56, 6008)\n",
      "(6003, 6005)\n",
      "(6004, 6005)\n",
      "(6000, 6003)\n",
      "(6002, 6003)\n",
      "(5999, 6000)\n",
      "(45, 6000)\n",
      "(6001, 6002)\n",
      "(48, 6002)\n",
      "(5997, 5999)\n",
      "(5998, 5999)\n",
      "(5994, 5997)\n",
      "(5996, 5997)\n",
      "(37, 5994)\n",
      "(5995, 5996)\n",
      "(40, 5996)\n",
      "<class 'Loss.CrossEntropy'>: 1.0828943\n",
      "(6061, 6062)\n",
      "(6060, 6061)\n",
      "(6059, 6061)\n",
      "(6058, 6059)\n",
      "(6056, 6058)\n",
      "(6057, 6058)\n",
      "(6055, 6056)\n",
      "(6054, 6056)\n",
      "(6053, 6054)\n",
      "(6052, 6053)\n",
      "(6051, 6052)\n",
      "(6050, 6052)\n",
      "(6044, 6051)\n",
      "(6049, 6050)\n",
      "(6047, 6049)\n",
      "(6048, 6049)\n",
      "(6045, 6047)\n",
      "(6046, 6047)\n",
      "(6044, 6045)\n",
      "(6041, 6044)\n",
      "(6043, 6044)\n",
      "(6040, 6041)\n",
      "(53, 6041)\n",
      "(6042, 6043)\n",
      "(56, 6043)\n",
      "(6038, 6040)\n",
      "(6039, 6040)\n",
      "(6035, 6038)\n",
      "(6037, 6038)\n",
      "(6034, 6035)\n",
      "(45, 6035)\n",
      "(6036, 6037)\n",
      "(48, 6037)\n",
      "(6032, 6034)\n",
      "(6033, 6034)\n",
      "(6029, 6032)\n",
      "(6031, 6032)\n",
      "(37, 6029)\n",
      "(6030, 6031)\n",
      "(40, 6031)\n",
      "<class 'Loss.CrossEntropy'>: 1.2708066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 174/200 [00:15<00:04,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6096, 6097)\n",
      "(6095, 6096)\n",
      "(6094, 6096)\n",
      "(6093, 6094)\n",
      "(6091, 6093)\n",
      "(6092, 6093)\n",
      "(6090, 6091)\n",
      "(6089, 6091)\n",
      "(6088, 6089)\n",
      "(6087, 6088)\n",
      "(6086, 6087)\n",
      "(6085, 6087)\n",
      "(6079, 6086)\n",
      "(6084, 6085)\n",
      "(6082, 6084)\n",
      "(6083, 6084)\n",
      "(6080, 6082)\n",
      "(6081, 6082)\n",
      "(6079, 6080)\n",
      "(6076, 6079)\n",
      "(6078, 6079)\n",
      "(6075, 6076)\n",
      "(53, 6076)\n",
      "(6077, 6078)\n",
      "(56, 6078)\n",
      "(6073, 6075)\n",
      "(6074, 6075)\n",
      "(6070, 6073)\n",
      "(6072, 6073)\n",
      "(6069, 6070)\n",
      "(45, 6070)\n",
      "(6071, 6072)\n",
      "(48, 6072)\n",
      "(6067, 6069)\n",
      "(6068, 6069)\n",
      "(6064, 6067)\n",
      "(6066, 6067)\n",
      "(37, 6064)\n",
      "(6065, 6066)\n",
      "(40, 6066)\n",
      "<class 'Loss.CrossEntropy'>: 1.1867287\n",
      "(6131, 6132)\n",
      "(6130, 6131)\n",
      "(6129, 6131)\n",
      "(6128, 6129)\n",
      "(6126, 6128)\n",
      "(6127, 6128)\n",
      "(6125, 6126)\n",
      "(6124, 6126)\n",
      "(6123, 6124)\n",
      "(6122, 6123)\n",
      "(6121, 6122)\n",
      "(6120, 6122)\n",
      "(6114, 6121)\n",
      "(6119, 6120)\n",
      "(6117, 6119)\n",
      "(6118, 6119)\n",
      "(6115, 6117)\n",
      "(6116, 6117)\n",
      "(6114, 6115)\n",
      "(6111, 6114)\n",
      "(6113, 6114)\n",
      "(6110, 6111)\n",
      "(53, 6111)\n",
      "(6112, 6113)\n",
      "(56, 6113)\n",
      "(6108, 6110)\n",
      "(6109, 6110)\n",
      "(6105, 6108)\n",
      "(6107, 6108)\n",
      "(6104, 6105)\n",
      "(45, 6105)\n",
      "(6106, 6107)\n",
      "(48, 6107)\n",
      "(6102, 6104)\n",
      "(6103, 6104)\n",
      "(6099, 6102)\n",
      "(6101, 6102)\n",
      "(37, 6099)\n",
      "(6100, 6101)\n",
      "(40, 6101)\n",
      "<class 'Loss.CrossEntropy'>: 1.1538974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 176/200 [00:16<00:04,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6166, 6167)\n",
      "(6165, 6166)\n",
      "(6164, 6166)\n",
      "(6163, 6164)\n",
      "(6161, 6163)\n",
      "(6162, 6163)\n",
      "(6160, 6161)\n",
      "(6159, 6161)\n",
      "(6158, 6159)\n",
      "(6157, 6158)\n",
      "(6156, 6157)\n",
      "(6155, 6157)\n",
      "(6149, 6156)\n",
      "(6154, 6155)\n",
      "(6152, 6154)\n",
      "(6153, 6154)\n",
      "(6150, 6152)\n",
      "(6151, 6152)\n",
      "(6149, 6150)\n",
      "(6146, 6149)\n",
      "(6148, 6149)\n",
      "(6145, 6146)\n",
      "(53, 6146)\n",
      "(6147, 6148)\n",
      "(56, 6148)\n",
      "(6143, 6145)\n",
      "(6144, 6145)\n",
      "(6140, 6143)\n",
      "(6142, 6143)\n",
      "(6139, 6140)\n",
      "(45, 6140)\n",
      "(6141, 6142)\n",
      "(48, 6142)\n",
      "(6137, 6139)\n",
      "(6138, 6139)\n",
      "(6134, 6137)\n",
      "(6136, 6137)\n",
      "(37, 6134)\n",
      "(6135, 6136)\n",
      "(40, 6136)\n",
      "<class 'Loss.CrossEntropy'>: 1.201652\n",
      "(6201, 6202)\n",
      "(6200, 6201)\n",
      "(6199, 6201)\n",
      "(6198, 6199)\n",
      "(6196, 6198)\n",
      "(6197, 6198)\n",
      "(6195, 6196)\n",
      "(6194, 6196)\n",
      "(6193, 6194)\n",
      "(6192, 6193)\n",
      "(6191, 6192)\n",
      "(6190, 6192)\n",
      "(6184, 6191)\n",
      "(6189, 6190)\n",
      "(6187, 6189)\n",
      "(6188, 6189)\n",
      "(6185, 6187)\n",
      "(6186, 6187)\n",
      "(6184, 6185)\n",
      "(6181, 6184)\n",
      "(6183, 6184)\n",
      "(6180, 6181)\n",
      "(53, 6181)\n",
      "(6182, 6183)\n",
      "(56, 6183)\n",
      "(6178, 6180)\n",
      "(6179, 6180)\n",
      "(6175, 6178)\n",
      "(6177, 6178)\n",
      "(6174, 6175)\n",
      "(45, 6175)\n",
      "(6176, 6177)\n",
      "(48, 6177)\n",
      "(6172, 6174)\n",
      "(6173, 6174)\n",
      "(6169, 6172)\n",
      "(6171, 6172)\n",
      "(37, 6169)\n",
      "(6170, 6171)\n",
      "(40, 6171)\n",
      "<class 'Loss.CrossEntropy'>: 1.1686807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 178/200 [00:16<00:03,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6236, 6237)\n",
      "(6235, 6236)\n",
      "(6234, 6236)\n",
      "(6233, 6234)\n",
      "(6231, 6233)\n",
      "(6232, 6233)\n",
      "(6230, 6231)\n",
      "(6229, 6231)\n",
      "(6228, 6229)\n",
      "(6227, 6228)\n",
      "(6226, 6227)\n",
      "(6225, 6227)\n",
      "(6219, 6226)\n",
      "(6224, 6225)\n",
      "(6222, 6224)\n",
      "(6223, 6224)\n",
      "(6220, 6222)\n",
      "(6221, 6222)\n",
      "(6219, 6220)\n",
      "(6216, 6219)\n",
      "(6218, 6219)\n",
      "(6215, 6216)\n",
      "(53, 6216)\n",
      "(6217, 6218)\n",
      "(56, 6218)\n",
      "(6213, 6215)\n",
      "(6214, 6215)\n",
      "(6210, 6213)\n",
      "(6212, 6213)\n",
      "(6209, 6210)\n",
      "(45, 6210)\n",
      "(6211, 6212)\n",
      "(48, 6212)\n",
      "(6207, 6209)\n",
      "(6208, 6209)\n",
      "(6204, 6207)\n",
      "(6206, 6207)\n",
      "(37, 6204)\n",
      "(6205, 6206)\n",
      "(40, 6206)\n",
      "<class 'Loss.CrossEntropy'>: 0.9606964\n",
      "(6271, 6272)\n",
      "(6270, 6271)\n",
      "(6269, 6271)\n",
      "(6268, 6269)\n",
      "(6266, 6268)\n",
      "(6267, 6268)\n",
      "(6265, 6266)\n",
      "(6264, 6266)\n",
      "(6263, 6264)\n",
      "(6262, 6263)\n",
      "(6261, 6262)\n",
      "(6260, 6262)\n",
      "(6254, 6261)\n",
      "(6259, 6260)\n",
      "(6257, 6259)\n",
      "(6258, 6259)\n",
      "(6255, 6257)\n",
      "(6256, 6257)\n",
      "(6254, 6255)\n",
      "(6251, 6254)\n",
      "(6253, 6254)\n",
      "(6250, 6251)\n",
      "(53, 6251)\n",
      "(6252, 6253)\n",
      "(56, 6253)\n",
      "(6248, 6250)\n",
      "(6249, 6250)\n",
      "(6245, 6248)\n",
      "(6247, 6248)\n",
      "(6244, 6245)\n",
      "(45, 6245)\n",
      "(6246, 6247)\n",
      "(48, 6247)\n",
      "(6242, 6244)\n",
      "(6243, 6244)\n",
      "(6239, 6242)\n",
      "(6241, 6242)\n",
      "(37, 6239)\n",
      "(6240, 6241)\n",
      "(40, 6241)\n",
      "<class 'Loss.CrossEntropy'>: 1.0987017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 180/200 [00:17<00:03,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6306, 6307)\n",
      "(6305, 6306)\n",
      "(6304, 6306)\n",
      "(6303, 6304)\n",
      "(6301, 6303)\n",
      "(6302, 6303)\n",
      "(6300, 6301)\n",
      "(6299, 6301)\n",
      "(6298, 6299)\n",
      "(6297, 6298)\n",
      "(6296, 6297)\n",
      "(6295, 6297)\n",
      "(6289, 6296)\n",
      "(6294, 6295)\n",
      "(6292, 6294)\n",
      "(6293, 6294)\n",
      "(6290, 6292)\n",
      "(6291, 6292)\n",
      "(6289, 6290)\n",
      "(6286, 6289)\n",
      "(6288, 6289)\n",
      "(6285, 6286)\n",
      "(53, 6286)\n",
      "(6287, 6288)\n",
      "(56, 6288)\n",
      "(6283, 6285)\n",
      "(6284, 6285)\n",
      "(6280, 6283)\n",
      "(6282, 6283)\n",
      "(6279, 6280)\n",
      "(45, 6280)\n",
      "(6281, 6282)\n",
      "(48, 6282)\n",
      "(6277, 6279)\n",
      "(6278, 6279)\n",
      "(6274, 6277)\n",
      "(6276, 6277)\n",
      "(37, 6274)\n",
      "(6275, 6276)\n",
      "(40, 6276)\n",
      "<class 'Loss.CrossEntropy'>: 1.1251779\n",
      "(6341, 6342)\n",
      "(6340, 6341)\n",
      "(6339, 6341)\n",
      "(6338, 6339)\n",
      "(6336, 6338)\n",
      "(6337, 6338)\n",
      "(6335, 6336)\n",
      "(6334, 6336)\n",
      "(6333, 6334)\n",
      "(6332, 6333)\n",
      "(6331, 6332)\n",
      "(6330, 6332)\n",
      "(6324, 6331)\n",
      "(6329, 6330)\n",
      "(6327, 6329)\n",
      "(6328, 6329)\n",
      "(6325, 6327)\n",
      "(6326, 6327)\n",
      "(6324, 6325)\n",
      "(6321, 6324)\n",
      "(6323, 6324)\n",
      "(6320, 6321)\n",
      "(53, 6321)\n",
      "(6322, 6323)\n",
      "(56, 6323)\n",
      "(6318, 6320)\n",
      "(6319, 6320)\n",
      "(6315, 6318)\n",
      "(6317, 6318)\n",
      "(6314, 6315)\n",
      "(45, 6315)\n",
      "(6316, 6317)\n",
      "(48, 6317)\n",
      "(6312, 6314)\n",
      "(6313, 6314)\n",
      "(6309, 6312)\n",
      "(6311, 6312)\n",
      "(37, 6309)\n",
      "(6310, 6311)\n",
      "(40, 6311)\n",
      "<class 'Loss.CrossEntropy'>: 1.0722305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 182/200 [00:17<00:02,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6376, 6377)\n",
      "(6375, 6376)\n",
      "(6374, 6376)\n",
      "(6373, 6374)\n",
      "(6371, 6373)\n",
      "(6372, 6373)\n",
      "(6370, 6371)\n",
      "(6369, 6371)\n",
      "(6368, 6369)\n",
      "(6367, 6368)\n",
      "(6366, 6367)\n",
      "(6365, 6367)\n",
      "(6359, 6366)\n",
      "(6364, 6365)\n",
      "(6362, 6364)\n",
      "(6363, 6364)\n",
      "(6360, 6362)\n",
      "(6361, 6362)\n",
      "(6359, 6360)\n",
      "(6356, 6359)\n",
      "(6358, 6359)\n",
      "(6355, 6356)\n",
      "(53, 6356)\n",
      "(6357, 6358)\n",
      "(56, 6358)\n",
      "(6353, 6355)\n",
      "(6354, 6355)\n",
      "(6350, 6353)\n",
      "(6352, 6353)\n",
      "(6349, 6350)\n",
      "(45, 6350)\n",
      "(6351, 6352)\n",
      "(48, 6352)\n",
      "(6347, 6349)\n",
      "(6348, 6349)\n",
      "(6344, 6347)\n",
      "(6346, 6347)\n",
      "(37, 6344)\n",
      "(6345, 6346)\n",
      "(40, 6346)\n",
      "<class 'Loss.CrossEntropy'>: 1.0170562\n",
      "(6411, 6412)\n",
      "(6410, 6411)\n",
      "(6409, 6411)\n",
      "(6408, 6409)\n",
      "(6406, 6408)\n",
      "(6407, 6408)\n",
      "(6405, 6406)\n",
      "(6404, 6406)\n",
      "(6403, 6404)\n",
      "(6402, 6403)\n",
      "(6401, 6402)\n",
      "(6400, 6402)\n",
      "(6394, 6401)\n",
      "(6399, 6400)\n",
      "(6397, 6399)\n",
      "(6398, 6399)\n",
      "(6395, 6397)\n",
      "(6396, 6397)\n",
      "(6394, 6395)\n",
      "(6391, 6394)\n",
      "(6393, 6394)\n",
      "(6390, 6391)\n",
      "(53, 6391)\n",
      "(6392, 6393)\n",
      "(56, 6393)\n",
      "(6388, 6390)\n",
      "(6389, 6390)\n",
      "(6385, 6388)\n",
      "(6387, 6388)\n",
      "(6384, 6385)\n",
      "(45, 6385)\n",
      "(6386, 6387)\n",
      "(48, 6387)\n",
      "(6382, 6384)\n",
      "(6383, 6384)\n",
      "(6379, 6382)\n",
      "(6381, 6382)\n",
      "(37, 6379)\n",
      "(6380, 6381)\n",
      "(40, 6381)\n",
      "<class 'Loss.CrossEntropy'>: 1.0259948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 184/200 [00:17<00:02,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6446, 6447)\n",
      "(6445, 6446)\n",
      "(6444, 6446)\n",
      "(6443, 6444)\n",
      "(6441, 6443)\n",
      "(6442, 6443)\n",
      "(6440, 6441)\n",
      "(6439, 6441)\n",
      "(6438, 6439)\n",
      "(6437, 6438)\n",
      "(6436, 6437)\n",
      "(6435, 6437)\n",
      "(6429, 6436)\n",
      "(6434, 6435)\n",
      "(6432, 6434)\n",
      "(6433, 6434)\n",
      "(6430, 6432)\n",
      "(6431, 6432)\n",
      "(6429, 6430)\n",
      "(6426, 6429)\n",
      "(6428, 6429)\n",
      "(6425, 6426)\n",
      "(53, 6426)\n",
      "(6427, 6428)\n",
      "(56, 6428)\n",
      "(6423, 6425)\n",
      "(6424, 6425)\n",
      "(6420, 6423)\n",
      "(6422, 6423)\n",
      "(6419, 6420)\n",
      "(45, 6420)\n",
      "(6421, 6422)\n",
      "(48, 6422)\n",
      "(6417, 6419)\n",
      "(6418, 6419)\n",
      "(6414, 6417)\n",
      "(6416, 6417)\n",
      "(37, 6414)\n",
      "(6415, 6416)\n",
      "(40, 6416)\n",
      "<class 'Loss.CrossEntropy'>: 1.3522344\n",
      "(6481, 6482)\n",
      "(6480, 6481)\n",
      "(6479, 6481)\n",
      "(6478, 6479)\n",
      "(6476, 6478)\n",
      "(6477, 6478)\n",
      "(6475, 6476)\n",
      "(6474, 6476)\n",
      "(6473, 6474)\n",
      "(6472, 6473)\n",
      "(6471, 6472)\n",
      "(6470, 6472)\n",
      "(6464, 6471)\n",
      "(6469, 6470)\n",
      "(6467, 6469)\n",
      "(6468, 6469)\n",
      "(6465, 6467)\n",
      "(6466, 6467)\n",
      "(6464, 6465)\n",
      "(6461, 6464)\n",
      "(6463, 6464)\n",
      "(6460, 6461)\n",
      "(53, 6461)\n",
      "(6462, 6463)\n",
      "(56, 6463)\n",
      "(6458, 6460)\n",
      "(6459, 6460)\n",
      "(6455, 6458)\n",
      "(6457, 6458)\n",
      "(6454, 6455)\n",
      "(45, 6455)\n",
      "(6456, 6457)\n",
      "(48, 6457)\n",
      "(6452, 6454)\n",
      "(6453, 6454)\n",
      "(6449, 6452)\n",
      "(6451, 6452)\n",
      "(37, 6449)\n",
      "(6450, 6451)\n",
      "(40, 6451)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 185/200 [00:17<00:02,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'Loss.CrossEntropy'>: 1.3694568\n",
      "(6516, 6517)\n",
      "(6515, 6516)\n",
      "(6514, 6516)\n",
      "(6513, 6514)\n",
      "(6511, 6513)\n",
      "(6512, 6513)\n",
      "(6510, 6511)\n",
      "(6509, 6511)\n",
      "(6508, 6509)\n",
      "(6507, 6508)\n",
      "(6506, 6507)\n",
      "(6505, 6507)\n",
      "(6499, 6506)\n",
      "(6504, 6505)\n",
      "(6502, 6504)\n",
      "(6503, 6504)\n",
      "(6500, 6502)\n",
      "(6501, 6502)\n",
      "(6499, 6500)\n",
      "(6496, 6499)\n",
      "(6498, 6499)\n",
      "(6495, 6496)\n",
      "(53, 6496)\n",
      "(6497, 6498)\n",
      "(56, 6498)\n",
      "(6493, 6495)\n",
      "(6494, 6495)\n",
      "(6490, 6493)\n",
      "(6492, 6493)\n",
      "(6489, 6490)\n",
      "(45, 6490)\n",
      "(6491, 6492)\n",
      "(48, 6492)\n",
      "(6487, 6489)\n",
      "(6488, 6489)\n",
      "(6484, 6487)\n",
      "(6486, 6487)\n",
      "(37, 6484)\n",
      "(6485, 6486)\n",
      "(40, 6486)\n",
      "<class 'Loss.CrossEntropy'>: 1.1904796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 186/200 [00:18<00:02,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6551, 6552)\n",
      "(6550, 6551)\n",
      "(6549, 6551)\n",
      "(6548, 6549)\n",
      "(6546, 6548)\n",
      "(6547, 6548)\n",
      "(6545, 6546)\n",
      "(6544, 6546)\n",
      "(6543, 6544)\n",
      "(6542, 6543)\n",
      "(6541, 6542)\n",
      "(6540, 6542)\n",
      "(6534, 6541)\n",
      "(6539, 6540)\n",
      "(6537, 6539)\n",
      "(6538, 6539)\n",
      "(6535, 6537)\n",
      "(6536, 6537)\n",
      "(6534, 6535)\n",
      "(6531, 6534)\n",
      "(6533, 6534)\n",
      "(6530, 6531)\n",
      "(53, 6531)\n",
      "(6532, 6533)\n",
      "(56, 6533)\n",
      "(6528, 6530)\n",
      "(6529, 6530)\n",
      "(6525, 6528)\n",
      "(6527, 6528)\n",
      "(6524, 6525)\n",
      "(45, 6525)\n",
      "(6526, 6527)\n",
      "(48, 6527)\n",
      "(6522, 6524)\n",
      "(6523, 6524)\n",
      "(6519, 6522)\n",
      "(6521, 6522)\n",
      "(37, 6519)\n",
      "(6520, 6521)\n",
      "(40, 6521)\n",
      "<class 'Loss.CrossEntropy'>: 1.1280956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 187/200 [00:18<00:02,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6586, 6587)\n",
      "(6585, 6586)\n",
      "(6584, 6586)\n",
      "(6583, 6584)\n",
      "(6581, 6583)\n",
      "(6582, 6583)\n",
      "(6580, 6581)\n",
      "(6579, 6581)\n",
      "(6578, 6579)\n",
      "(6577, 6578)\n",
      "(6576, 6577)\n",
      "(6575, 6577)\n",
      "(6569, 6576)\n",
      "(6574, 6575)\n",
      "(6572, 6574)\n",
      "(6573, 6574)\n",
      "(6570, 6572)\n",
      "(6571, 6572)\n",
      "(6569, 6570)\n",
      "(6566, 6569)\n",
      "(6568, 6569)\n",
      "(6565, 6566)\n",
      "(53, 6566)\n",
      "(6567, 6568)\n",
      "(56, 6568)\n",
      "(6563, 6565)\n",
      "(6564, 6565)\n",
      "(6560, 6563)\n",
      "(6562, 6563)\n",
      "(6559, 6560)\n",
      "(45, 6560)\n",
      "(6561, 6562)\n",
      "(48, 6562)\n",
      "(6557, 6559)\n",
      "(6558, 6559)\n",
      "(6554, 6557)\n",
      "(6556, 6557)\n",
      "(37, 6554)\n",
      "(6555, 6556)\n",
      "(40, 6556)\n",
      "<class 'Loss.CrossEntropy'>: 1.1550902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 188/200 [00:18<00:02,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6621, 6622)\n",
      "(6620, 6621)\n",
      "(6619, 6621)\n",
      "(6618, 6619)\n",
      "(6616, 6618)\n",
      "(6617, 6618)\n",
      "(6615, 6616)\n",
      "(6614, 6616)\n",
      "(6613, 6614)\n",
      "(6612, 6613)\n",
      "(6611, 6612)\n",
      "(6610, 6612)\n",
      "(6604, 6611)\n",
      "(6609, 6610)\n",
      "(6607, 6609)\n",
      "(6608, 6609)\n",
      "(6605, 6607)\n",
      "(6606, 6607)\n",
      "(6604, 6605)\n",
      "(6601, 6604)\n",
      "(6603, 6604)\n",
      "(6600, 6601)\n",
      "(53, 6601)\n",
      "(6602, 6603)\n",
      "(56, 6603)\n",
      "(6598, 6600)\n",
      "(6599, 6600)\n",
      "(6595, 6598)\n",
      "(6597, 6598)\n",
      "(6594, 6595)\n",
      "(45, 6595)\n",
      "(6596, 6597)\n",
      "(48, 6597)\n",
      "(6592, 6594)\n",
      "(6593, 6594)\n",
      "(6589, 6592)\n",
      "(6591, 6592)\n",
      "(37, 6589)\n",
      "(6590, 6591)\n",
      "(40, 6591)\n",
      "<class 'Loss.CrossEntropy'>: 1.2110159\n",
      "(6656, 6657)\n",
      "(6655, 6656)\n",
      "(6654, 6656)\n",
      "(6653, 6654)\n",
      "(6651, 6653)\n",
      "(6652, 6653)\n",
      "(6650, 6651)\n",
      "(6649, 6651)\n",
      "(6648, 6649)\n",
      "(6647, 6648)\n",
      "(6646, 6647)\n",
      "(6645, 6647)\n",
      "(6639, 6646)\n",
      "(6644, 6645)\n",
      "(6642, 6644)\n",
      "(6643, 6644)\n",
      "(6640, 6642)\n",
      "(6641, 6642)\n",
      "(6639, 6640)\n",
      "(6636, 6639)\n",
      "(6638, 6639)\n",
      "(6635, 6636)\n",
      "(53, 6636)\n",
      "(6637, 6638)\n",
      "(56, 6638)\n",
      "(6633, 6635)\n",
      "(6634, 6635)\n",
      "(6630, 6633)\n",
      "(6632, 6633)\n",
      "(6629, 6630)\n",
      "(45, 6630)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 189/200 [00:18<00:02,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6631, 6632)\n",
      "(48, 6632)\n",
      "(6627, 6629)\n",
      "(6628, 6629)\n",
      "(6624, 6627)\n",
      "(6626, 6627)\n",
      "(37, 6624)\n",
      "(6625, 6626)\n",
      "(40, 6626)\n",
      "<class 'Loss.CrossEntropy'>: 1.2662805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 191/200 [00:19<00:01,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6691, 6692)\n",
      "(6690, 6691)\n",
      "(6689, 6691)\n",
      "(6688, 6689)\n",
      "(6686, 6688)\n",
      "(6687, 6688)\n",
      "(6685, 6686)\n",
      "(6684, 6686)\n",
      "(6683, 6684)\n",
      "(6682, 6683)\n",
      "(6681, 6682)\n",
      "(6680, 6682)\n",
      "(6674, 6681)\n",
      "(6679, 6680)\n",
      "(6677, 6679)\n",
      "(6678, 6679)\n",
      "(6675, 6677)\n",
      "(6676, 6677)\n",
      "(6674, 6675)\n",
      "(6671, 6674)\n",
      "(6673, 6674)\n",
      "(6670, 6671)\n",
      "(53, 6671)\n",
      "(6672, 6673)\n",
      "(56, 6673)\n",
      "(6668, 6670)\n",
      "(6669, 6670)\n",
      "(6665, 6668)\n",
      "(6667, 6668)\n",
      "(6664, 6665)\n",
      "(45, 6665)\n",
      "(6666, 6667)\n",
      "(48, 6667)\n",
      "(6662, 6664)\n",
      "(6663, 6664)\n",
      "(6659, 6662)\n",
      "(6661, 6662)\n",
      "(37, 6659)\n",
      "(6660, 6661)\n",
      "(40, 6661)\n",
      "<class 'Loss.CrossEntropy'>: 1.127316\n",
      "(6726, 6727)\n",
      "(6725, 6726)\n",
      "(6724, 6726)\n",
      "(6723, 6724)\n",
      "(6721, 6723)\n",
      "(6722, 6723)\n",
      "(6720, 6721)\n",
      "(6719, 6721)\n",
      "(6718, 6719)\n",
      "(6717, 6718)\n",
      "(6716, 6717)\n",
      "(6715, 6717)\n",
      "(6709, 6716)\n",
      "(6714, 6715)\n",
      "(6712, 6714)\n",
      "(6713, 6714)\n",
      "(6710, 6712)\n",
      "(6711, 6712)\n",
      "(6709, 6710)\n",
      "(6706, 6709)\n",
      "(6708, 6709)\n",
      "(6705, 6706)\n",
      "(53, 6706)\n",
      "(6707, 6708)\n",
      "(56, 6708)\n",
      "(6703, 6705)\n",
      "(6704, 6705)\n",
      "(6700, 6703)\n",
      "(6702, 6703)\n",
      "(6699, 6700)\n",
      "(45, 6700)\n",
      "(6701, 6702)\n",
      "(48, 6702)\n",
      "(6697, 6699)\n",
      "(6698, 6699)\n",
      "(6694, 6697)\n",
      "(6696, 6697)\n",
      "(37, 6694)\n",
      "(6695, 6696)\n",
      "(40, 6696)\n",
      "<class 'Loss.CrossEntropy'>: 1.1222756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 192/200 [00:19<00:01,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6761, 6762)\n",
      "(6760, 6761)\n",
      "(6759, 6761)\n",
      "(6758, 6759)\n",
      "(6756, 6758)\n",
      "(6757, 6758)\n",
      "(6755, 6756)\n",
      "(6754, 6756)\n",
      "(6753, 6754)\n",
      "(6752, 6753)\n",
      "(6751, 6752)\n",
      "(6750, 6752)\n",
      "(6744, 6751)\n",
      "(6749, 6750)\n",
      "(6747, 6749)\n",
      "(6748, 6749)\n",
      "(6745, 6747)\n",
      "(6746, 6747)\n",
      "(6744, 6745)\n",
      "(6741, 6744)\n",
      "(6743, 6744)\n",
      "(6740, 6741)\n",
      "(53, 6741)\n",
      "(6742, 6743)\n",
      "(56, 6743)\n",
      "(6738, 6740)\n",
      "(6739, 6740)\n",
      "(6735, 6738)\n",
      "(6737, 6738)\n",
      "(6734, 6735)\n",
      "(45, 6735)\n",
      "(6736, 6737)\n",
      "(48, 6737)\n",
      "(6732, 6734)\n",
      "(6733, 6734)\n",
      "(6729, 6732)\n",
      "(6731, 6732)\n",
      "(37, 6729)\n",
      "(6730, 6731)\n",
      "(40, 6731)\n",
      "<class 'Loss.CrossEntropy'>: 1.3165975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 194/200 [00:19<00:01,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6796, 6797)\n",
      "(6795, 6796)\n",
      "(6794, 6796)\n",
      "(6793, 6794)\n",
      "(6791, 6793)\n",
      "(6792, 6793)\n",
      "(6790, 6791)\n",
      "(6789, 6791)\n",
      "(6788, 6789)\n",
      "(6787, 6788)\n",
      "(6786, 6787)\n",
      "(6785, 6787)\n",
      "(6779, 6786)\n",
      "(6784, 6785)\n",
      "(6782, 6784)\n",
      "(6783, 6784)\n",
      "(6780, 6782)\n",
      "(6781, 6782)\n",
      "(6779, 6780)\n",
      "(6776, 6779)\n",
      "(6778, 6779)\n",
      "(6775, 6776)\n",
      "(53, 6776)\n",
      "(6777, 6778)\n",
      "(56, 6778)\n",
      "(6773, 6775)\n",
      "(6774, 6775)\n",
      "(6770, 6773)\n",
      "(6772, 6773)\n",
      "(6769, 6770)\n",
      "(45, 6770)\n",
      "(6771, 6772)\n",
      "(48, 6772)\n",
      "(6767, 6769)\n",
      "(6768, 6769)\n",
      "(6764, 6767)\n",
      "(6766, 6767)\n",
      "(37, 6764)\n",
      "(6765, 6766)\n",
      "(40, 6766)\n",
      "<class 'Loss.CrossEntropy'>: 1.4409869\n",
      "(6831, 6832)\n",
      "(6830, 6831)\n",
      "(6829, 6831)\n",
      "(6828, 6829)\n",
      "(6826, 6828)\n",
      "(6827, 6828)\n",
      "(6825, 6826)\n",
      "(6824, 6826)\n",
      "(6823, 6824)\n",
      "(6822, 6823)\n",
      "(6821, 6822)\n",
      "(6820, 6822)\n",
      "(6814, 6821)\n",
      "(6819, 6820)\n",
      "(6817, 6819)\n",
      "(6818, 6819)\n",
      "(6815, 6817)\n",
      "(6816, 6817)\n",
      "(6814, 6815)\n",
      "(6811, 6814)\n",
      "(6813, 6814)\n",
      "(6810, 6811)\n",
      "(53, 6811)\n",
      "(6812, 6813)\n",
      "(56, 6813)\n",
      "(6808, 6810)\n",
      "(6809, 6810)\n",
      "(6805, 6808)\n",
      "(6807, 6808)\n",
      "(6804, 6805)\n",
      "(45, 6805)\n",
      "(6806, 6807)\n",
      "(48, 6807)\n",
      "(6802, 6804)\n",
      "(6803, 6804)\n",
      "(6799, 6802)\n",
      "(6801, 6802)\n",
      "(37, 6799)\n",
      "(6800, 6801)\n",
      "(40, 6801)\n",
      "<class 'Loss.CrossEntropy'>: 0.90905136\n",
      "(6866, 6867)\n",
      "(6865, 6866)\n",
      "(6864, 6866)\n",
      "(6863, 6864)\n",
      "(6861, 6863)\n",
      "(6862, 6863)\n",
      "(6860, 6861)\n",
      "(6859, 6861)\n",
      "(6858, 6859)\n",
      "(6857, 6858)\n",
      "(6856, 6857)\n",
      "(6855, 6857)\n",
      "(6849, 6856)\n",
      "(6854, 6855)\n",
      "(6852, 6854)\n",
      "(6853, 6854)\n",
      "(6850, 6852)\n",
      "(6851, 6852)\n",
      "(6849, 6850)\n",
      "(6846, 6849)\n",
      "(6848, 6849)\n",
      "(6845, 6846)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 196/200 [00:20<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 6846)\n",
      "(6847, 6848)\n",
      "(56, 6848)\n",
      "(6843, 6845)\n",
      "(6844, 6845)\n",
      "(6840, 6843)\n",
      "(6842, 6843)\n",
      "(6839, 6840)\n",
      "(45, 6840)\n",
      "(6841, 6842)\n",
      "(48, 6842)\n",
      "(6837, 6839)\n",
      "(6838, 6839)\n",
      "(6834, 6837)\n",
      "(6836, 6837)\n",
      "(37, 6834)\n",
      "(6835, 6836)\n",
      "(40, 6836)\n",
      "<class 'Loss.CrossEntropy'>: 1.1303368\n",
      "(6901, 6902)\n",
      "(6900, 6901)\n",
      "(6899, 6901)\n",
      "(6898, 6899)\n",
      "(6896, 6898)\n",
      "(6897, 6898)\n",
      "(6895, 6896)\n",
      "(6894, 6896)\n",
      "(6893, 6894)\n",
      "(6892, 6893)\n",
      "(6891, 6892)\n",
      "(6890, 6892)\n",
      "(6884, 6891)\n",
      "(6889, 6890)\n",
      "(6887, 6889)\n",
      "(6888, 6889)\n",
      "(6885, 6887)\n",
      "(6886, 6887)\n",
      "(6884, 6885)\n",
      "(6881, 6884)\n",
      "(6883, 6884)\n",
      "(6880, 6881)\n",
      "(53, 6881)\n",
      "(6882, 6883)\n",
      "(56, 6883)\n",
      "(6878, 6880)\n",
      "(6879, 6880)\n",
      "(6875, 6878)\n",
      "(6877, 6878)\n",
      "(6874, 6875)\n",
      "(45, 6875)\n",
      "(6876, 6877)\n",
      "(48, 6877)\n",
      "(6872, 6874)\n",
      "(6873, 6874)\n",
      "(6869, 6872)\n",
      "(6871, 6872)\n",
      "(37, 6869)\n",
      "(6870, 6871)\n",
      "(40, 6871)\n",
      "<class 'Loss.CrossEntropy'>: 1.149855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 197/200 [00:20<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6936, 6937)\n",
      "(6935, 6936)\n",
      "(6934, 6936)\n",
      "(6933, 6934)\n",
      "(6931, 6933)\n",
      "(6932, 6933)\n",
      "(6930, 6931)\n",
      "(6929, 6931)\n",
      "(6928, 6929)\n",
      "(6927, 6928)\n",
      "(6926, 6927)\n",
      "(6925, 6927)\n",
      "(6919, 6926)\n",
      "(6924, 6925)\n",
      "(6922, 6924)\n",
      "(6923, 6924)\n",
      "(6920, 6922)\n",
      "(6921, 6922)\n",
      "(6919, 6920)\n",
      "(6916, 6919)\n",
      "(6918, 6919)\n",
      "(6915, 6916)\n",
      "(53, 6916)\n",
      "(6917, 6918)\n",
      "(56, 6918)\n",
      "(6913, 6915)\n",
      "(6914, 6915)\n",
      "(6910, 6913)\n",
      "(6912, 6913)\n",
      "(6909, 6910)\n",
      "(45, 6910)\n",
      "(6911, 6912)\n",
      "(48, 6912)\n",
      "(6907, 6909)\n",
      "(6908, 6909)\n",
      "(6904, 6907)\n",
      "(6906, 6907)\n",
      "(37, 6904)\n",
      "(6905, 6906)\n",
      "(40, 6906)\n",
      "<class 'Loss.CrossEntropy'>: 1.2178568\n",
      "(6971, 6972)\n",
      "(6970, 6971)\n",
      "(6969, 6971)\n",
      "(6968, 6969)\n",
      "(6966, 6968)\n",
      "(6967, 6968)\n",
      "(6965, 6966)\n",
      "(6964, 6966)\n",
      "(6963, 6964)\n",
      "(6962, 6963)\n",
      "(6961, 6962)\n",
      "(6960, 6962)\n",
      "(6954, 6961)\n",
      "(6959, 6960)\n",
      "(6957, 6959)\n",
      "(6958, 6959)\n",
      "(6955, 6957)\n",
      "(6956, 6957)\n",
      "(6954, 6955)\n",
      "(6951, 6954)\n",
      "(6953, 6954)\n",
      "(6950, 6951)\n",
      "(53, 6951)\n",
      "(6952, 6953)\n",
      "(56, 6953)\n",
      "(6948, 6950)\n",
      "(6949, 6950)\n",
      "(6945, 6948)\n",
      "(6947, 6948)\n",
      "(6944, 6945)\n",
      "(45, 6945)\n",
      "(6946, 6947)\n",
      "(48, 6947)\n",
      "(6942, 6944)\n",
      "(6943, 6944)\n",
      "(6939, 6942)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 199/200 [00:21<00:00,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6941, 6942)\n",
      "(37, 6939)\n",
      "(6940, 6941)\n",
      "(40, 6941)\n",
      "<class 'Loss.CrossEntropy'>: 1.2365249\n",
      "(7006, 7007)\n",
      "(7005, 7006)\n",
      "(7004, 7006)\n",
      "(7003, 7004)\n",
      "(7001, 7003)\n",
      "(7002, 7003)\n",
      "(7000, 7001)\n",
      "(6999, 7001)\n",
      "(6998, 6999)\n",
      "(6997, 6998)\n",
      "(6996, 6997)\n",
      "(6995, 6997)\n",
      "(6989, 6996)\n",
      "(6994, 6995)\n",
      "(6992, 6994)\n",
      "(6993, 6994)\n",
      "(6990, 6992)\n",
      "(6991, 6992)\n",
      "(6989, 6990)\n",
      "(6986, 6989)\n",
      "(6988, 6989)\n",
      "(6985, 6986)\n",
      "(53, 6986)\n",
      "(6987, 6988)\n",
      "(56, 6988)\n",
      "(6983, 6985)\n",
      "(6984, 6985)\n",
      "(6980, 6983)\n",
      "(6982, 6983)\n",
      "(6979, 6980)\n",
      "(45, 6980)\n",
      "(6981, 6982)\n",
      "(48, 6982)\n",
      "(6977, 6979)\n",
      "(6978, 6979)\n",
      "(6974, 6977)\n",
      "(6976, 6977)\n",
      "(37, 6974)\n",
      "(6975, 6976)\n",
      "(40, 6976)\n",
      "<class 'Loss.CrossEntropy'>: 1.0183755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 200/200 [00:21<00:00,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7041, 7042)\n",
      "(7040, 7041)\n",
      "(7039, 7041)\n",
      "(7038, 7039)\n",
      "(7036, 7038)\n",
      "(7037, 7038)\n",
      "(7035, 7036)\n",
      "(7034, 7036)\n",
      "(7033, 7034)\n",
      "(7032, 7033)\n",
      "(7031, 7032)\n",
      "(7030, 7032)\n",
      "(7024, 7031)\n",
      "(7029, 7030)\n",
      "(7027, 7029)\n",
      "(7028, 7029)\n",
      "(7025, 7027)\n",
      "(7026, 7027)\n",
      "(7024, 7025)\n",
      "(7021, 7024)\n",
      "(7023, 7024)\n",
      "(7020, 7021)\n",
      "(53, 7021)\n",
      "(7022, 7023)\n",
      "(56, 7023)\n",
      "(7018, 7020)\n",
      "(7019, 7020)\n",
      "(7015, 7018)\n",
      "(7017, 7018)\n",
      "(7014, 7015)\n",
      "(45, 7015)\n",
      "(7016, 7017)\n",
      "(48, 7017)\n",
      "(7012, 7014)\n",
      "(7013, 7014)\n",
      "(7009, 7012)\n",
      "(7011, 7012)\n",
      "(37, 7009)\n",
      "(7010, 7011)\n",
      "(40, 7011)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "lr = 0.05\n",
    "decay = 0.5\n",
    "epoch = 200\n",
    "\n",
    "import MyTensor as MT\n",
    "import MyNN as MN \n",
    "import Loss\n",
    "import MyOpt\n",
    "from tqdm import tqdm\n",
    "\n",
    "relu = MN.my_relu()\n",
    "softmax = MN.my_softmax()\n",
    "layer1=MN.my_linear_layer(in_feature=4,out_feature=16)\n",
    "layer2=MN.my_linear_layer(in_feature=16,out_feature=8)\n",
    "layer3=MN.my_linear_layer(in_feature=8,out_feature=3)\n",
    "Opt =  MyOpt.BGD()\n",
    "\n",
    "L = Loss.CrossEntropy()\n",
    "\n",
    "for i in tqdm(range(epoch)):\n",
    "    X, y = dataload(X_train, y_train, batch_size)\n",
    "    inputtensor=MT.mytensor(X, with_grad=False)\n",
    "    label_true=MT.mytensor(one_hot_encoding(y,3))\n",
    "    pred=softmax(layer3(relu(layer2(relu(layer1(inputtensor))))))\n",
    "    L(pred,label_true)\n",
    "    print(L)\n",
    "    Opt.zero_grad()\n",
    "    L.backward(mode = 'force')\n",
    "    Opt.step(lr)\n",
    "    #lr = lr*decay\n",
    "    #Opt.GSlim()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MT.mytensor.computegraph._nodelist[606].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tensortype': 'tensor32',\n",
       " 'with_grad': True,\n",
       " '_cg_descend': [608],\n",
       " '_cg_ascend': [603, 605],\n",
       " '_grad_f': None,\n",
       " 'grad': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'npar_data': array([[ 0.6046766 ,  0.8363938 , -0.8299145 , ..., -1.8269135 ,\n",
       "         -1.7872964 , -0.29764798],\n",
       "        [ 1.115085  , -0.45458204, -1.0868773 , ...,  1.9348444 ,\n",
       "          1.9110682 ,  0.627694  ],\n",
       "        [-0.36552513, -0.23179615,  0.54201627, ...,  0.12682118,\n",
       "          0.13797508, -0.00481228],\n",
       "        ...,\n",
       "        [-0.9492424 ,  1.3655558 ,  0.17045236, ..., -1.1075816 ,\n",
       "         -1.6516906 , -0.2875084 ],\n",
       "        [ 1.4749874 , -1.0166832 , -1.355665  , ...,  2.504044  ,\n",
       "          2.7748299 ,  0.61983824],\n",
       "        [ 0.08081339,  1.0759332 , -0.525559  , ..., -1.7342772 ,\n",
       "         -1.8829832 , -0.33941162]], dtype=float32),\n",
       " 'shape': (128, 16)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MT.mytensor.computegraph._nodelist[606].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=MT.mytensor([1,-2,-3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=a.npar_data>=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7543"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cg._nodelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000600835002"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2658819 ,  1.52514896,  1.31053937],\n",
       "       [-0.60190575,  1.46561979,  0.19053051],\n",
       "       [-2.86871408, -0.50221672, -0.38509756]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python&Conda_Env\\Python3.9(Global)\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  \n",
    "y = iris.target  \n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_one_hot = encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IrisNN, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(4, 10)  \n",
    "        self.fc2 = nn.Linear(10, 3)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  \n",
    "        x = self.fc2(x)  \n",
    "        return x\n",
    "\n",
    "\n",
    "model = IrisNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/3000], Loss: 0.8475\n",
      "Epoch [200/3000], Loss: 0.6615\n",
      "Epoch [300/3000], Loss: 0.5583\n",
      "Epoch [400/3000], Loss: 0.4923\n",
      "Epoch [500/3000], Loss: 0.4455\n",
      "Epoch [600/3000], Loss: 0.4101\n",
      "Epoch [700/3000], Loss: 0.3818\n",
      "Epoch [800/3000], Loss: 0.3581\n",
      "Epoch [900/3000], Loss: 0.3377\n",
      "Epoch [1000/3000], Loss: 0.3196\n",
      "Epoch [1100/3000], Loss: 0.3035\n",
      "Epoch [1200/3000], Loss: 0.2887\n",
      "Epoch [1300/3000], Loss: 0.2751\n",
      "Epoch [1400/3000], Loss: 0.2623\n",
      "Epoch [1500/3000], Loss: 0.2504\n",
      "Epoch [1600/3000], Loss: 0.2390\n",
      "Epoch [1700/3000], Loss: 0.2282\n",
      "Epoch [1800/3000], Loss: 0.2179\n",
      "Epoch [1900/3000], Loss: 0.2081\n",
      "Epoch [2000/3000], Loss: 0.1988\n",
      "Epoch [2100/3000], Loss: 0.1901\n",
      "Epoch [2200/3000], Loss: 0.1818\n",
      "Epoch [2300/3000], Loss: 0.1741\n",
      "Epoch [2400/3000], Loss: 0.1668\n",
      "Epoch [2500/3000], Loss: 0.1601\n",
      "Epoch [2600/3000], Loss: 0.1538\n",
      "Epoch [2700/3000], Loss: 0.1480\n",
      "Epoch [2800/3000], Loss: 0.1427\n",
      "Epoch [2900/3000], Loss: 0.1377\n",
      "Epoch [3000/3000], Loss: 0.1330\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    outputs = model(X_train_tensor)\n",
    "    \n",
    "\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "    optimizer.zero_grad()  \n",
    "    loss.backward()  \n",
    "    optimizer.step()  \n",
    "\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: <class 'Loss.CrossEntropy'>: 0.8427157\n",
      "Epoch [200/1000], Loss: <class 'Loss.CrossEntropy'>: 0.6857039\n",
      "Epoch [300/1000], Loss: <class 'Loss.CrossEntropy'>: 0.55056727\n",
      "Epoch [400/1000], Loss: <class 'Loss.CrossEntropy'>: 0.44325456\n",
      "Epoch [500/1000], Loss: <class 'Loss.CrossEntropy'>: 0.3691366\n",
      "Epoch [600/1000], Loss: <class 'Loss.CrossEntropy'>: 0.32010415\n",
      "Epoch [700/1000], Loss: <class 'Loss.CrossEntropy'>: 0.2851685\n",
      "Epoch [800/1000], Loss: <class 'Loss.CrossEntropy'>: 0.25828034\n",
      "Epoch [900/1000], Loss: <class 'Loss.CrossEntropy'>: 0.23630683\n",
      "Epoch [1000/1000], Loss: <class 'Loss.CrossEntropy'>: 0.21806817\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "lr=0.01\n",
    "\n",
    "\n",
    "\n",
    "import MyTensor as MT\n",
    "import MyNN as MN \n",
    "import MyPara as MP\n",
    "import Loss\n",
    "import MyOpt\n",
    "from tqdm import tqdm\n",
    "\n",
    "X_train_tensor = MT.mytensor(X_train_tensor.detach().numpy())\n",
    "y_train_tensor = MT.mytensor(y_train_tensor.detach().numpy())\n",
    "\n",
    "relu = MN.my_relu()\n",
    "softmax = MN.my_softmax()\n",
    "layer1=MN.my_linear_layer(in_feature=4,out_feature=10)\n",
    "layer2=MN.my_linear_layer(in_feature=10,out_feature=3)\n",
    "L = Loss.CrossEntropy()\n",
    "params = [layer1.parameterw,layer1.parameterb,layer2.parameterw,layer2.parameterb]\n",
    "Opt =  MyOpt.BGD(params)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    outputs = softmax(layer2(relu(layer1(X_train_tensor))))\n",
    "    \n",
    "\n",
    "    L(outputs, y_train_tensor)\n",
    "    Opt.zero_grad()\n",
    "    L.backward(mode = 'force')\n",
    "    Opt.step(lr)\n",
    "\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {L}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(X_train_tensor)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#loss = criterion(outputs, y_train_tensor)\n",
    "softmax1 = torch.softmax(outputs, dim=1)\n",
    "log_probs = torch.log(softmax1)\n",
    "nll = -(y_train_tensor * log_probs).sum(dim=1)\n",
    "manual_loss = nll.mean()\n",
    "optimizer.zero_grad()  \n",
    "#manual_loss.backward()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mloss\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0192, -0.0841, -0.4568],\n",
       "        [-0.0526, -0.1028, -0.5021],\n",
       "        [ 0.1656, -0.4951,  0.3351],\n",
       "        [ 0.0141, -0.0981, -0.4163],\n",
       "        [ 0.0018, -0.0916, -0.3905],\n",
       "        [-0.1306, -0.7574,  0.6746],\n",
       "        [ 0.1966, -0.3912,  0.2908],\n",
       "        [ 0.0062, -0.1051, -0.4273],\n",
       "        [-0.0090, -0.1045, -0.4466],\n",
       "        [-0.0592, -0.0933, -0.5093],\n",
       "        [-0.1014, -0.4853,  0.5138],\n",
       "        [ 0.2384, -0.2602,  0.1695],\n",
       "        [ 0.1968, -0.5435,  0.3998],\n",
       "        [-0.0138, -0.1043, -0.4528],\n",
       "        [-0.0100, -0.1044, -0.4479],\n",
       "        [-0.3310, -0.2631,  0.1948],\n",
       "        [ 0.0832, -0.5968,  0.4824],\n",
       "        [ 0.2464, -0.5913,  0.5093],\n",
       "        [ 0.1299, -0.5119,  0.3617],\n",
       "        [ 0.4287, -0.7965,  0.7338],\n",
       "        [ 0.0057, -0.2672,  0.1766],\n",
       "        [ 0.3009, -1.1450,  0.8547],\n",
       "        [ 0.0574, -0.2442,  0.2029],\n",
       "        [ 0.0022, -0.1049, -0.4324],\n",
       "        [ 0.2315, -1.2564,  0.9075],\n",
       "        [-0.1061, -0.2992,  0.1676],\n",
       "        [ 0.0134, -0.1053, -0.4181],\n",
       "        [ 0.0084, -0.1051, -0.4245],\n",
       "        [ 0.0076, -0.0977, -0.4245],\n",
       "        [-0.6190, -0.1946,  0.2527],\n",
       "        [-0.0018, -0.6700,  0.5921],\n",
       "        [ 0.0226, -0.0936, -0.4048],\n",
       "        [-0.0160, -0.1278, -0.3294],\n",
       "        [ 0.0502, -0.1100, -0.3553],\n",
       "        [-0.1343, -0.2703,  0.2467],\n",
       "        [ 0.0143, -0.1054, -0.4170],\n",
       "        [ 0.0703, -0.2384,  0.0816],\n",
       "        [ 0.5195, -0.8282,  0.6746],\n",
       "        [ 0.0078, -0.1026, -0.3915],\n",
       "        [ 0.0526, -0.4173,  0.2943],\n",
       "        [-0.2505, -0.5228,  0.5727],\n",
       "        [-0.0591, -0.1025, -0.5103],\n",
       "        [ 0.1243, -0.4397,  0.4462],\n",
       "        [-0.1014, -0.4853,  0.5138],\n",
       "        [-0.3256, -0.5490,  0.4055],\n",
       "        [ 0.0399, -0.1920,  0.1340],\n",
       "        [ 0.2925, -0.4924,  0.5535],\n",
       "        [-0.3677, -0.3548,  0.3719],\n",
       "        [-0.0042, -0.1046, -0.4406],\n",
       "        [-0.4083, -0.1556,  0.1030],\n",
       "        [ 0.0125, -0.7439,  0.6459],\n",
       "        [ 0.0138, -0.1076, -0.4066],\n",
       "        [ 0.0096, -0.1107, -0.3957],\n",
       "        [-0.3279, -0.2799,  0.2426],\n",
       "        [ 0.1924, -0.6553,  0.5326],\n",
       "        [ 0.0051, -0.1171, -0.3656],\n",
       "        [-0.0779, -0.5311,  0.6288],\n",
       "        [ 0.0127, -0.1053, -0.4190],\n",
       "        [ 0.0454, -0.1068, -0.3763],\n",
       "        [ 0.2143, -0.3300,  0.3543],\n",
       "        [-0.2573, -0.1765,  0.0551],\n",
       "        [ 0.3046, -0.7993,  0.7046],\n",
       "        [-0.0415, -0.5211,  0.4722],\n",
       "        [-0.0649, -0.5851,  0.4685],\n",
       "        [ 0.2739, -1.1599,  0.9033],\n",
       "        [-0.2650, -0.2867,  0.2941],\n",
       "        [-0.0647, -0.0947, -0.3389],\n",
       "        [-0.0354, -0.0980, -0.3772],\n",
       "        [-0.3399, -0.6697,  0.5761],\n",
       "        [ 0.3414, -0.8260,  0.6197],\n",
       "        [ 0.0103, -0.1084, -0.3728],\n",
       "        [ 0.0124, -0.1053, -0.4195],\n",
       "        [-0.0232, -0.1014, -0.3589],\n",
       "        [-0.1014, -0.6897,  0.5604],\n",
       "        [ 0.3068, -0.5583,  0.6051],\n",
       "        [ 0.0116, -0.0909, -0.4048],\n",
       "        [ 0.2120, -0.8062,  0.6864],\n",
       "        [ 0.2899, -0.6328,  0.6572],\n",
       "        [ 0.0047, -0.1109, -0.3968],\n",
       "        [ 0.0871, -0.4465,  0.3496],\n",
       "        [ 0.0724, -0.6175,  0.4962],\n",
       "        [ 0.0397, -0.5905,  0.5429],\n",
       "        [ 0.2265, -0.5590,  0.3608],\n",
       "        [ 0.2640, -0.6162,  0.6130],\n",
       "        [-0.0208, -0.1000, -0.4611],\n",
       "        [ 0.2527, -0.7790,  0.6643],\n",
       "        [ 0.0791, -0.3215,  0.2720],\n",
       "        [ 0.1825, -0.6737,  0.6021],\n",
       "        [-0.1773, -0.2931,  0.1407],\n",
       "        [-0.1610, -0.1905,  0.1237],\n",
       "        [ 0.1155, -0.3892,  0.2958],\n",
       "        [-0.3107, -0.0549, -0.2182],\n",
       "        [ 0.1049, -0.5599,  0.3799],\n",
       "        [-0.2035, -0.2529,  0.2298],\n",
       "        [-0.0116, -0.1044, -0.4499],\n",
       "        [ 0.0651, -0.2299,  0.0805],\n",
       "        [ 0.2404, -1.0204,  0.7415],\n",
       "        [ 0.3418, -0.6607,  0.5868],\n",
       "        [ 0.0056, -0.1050, -0.4281],\n",
       "        [-0.3467, -0.1137,  0.0298],\n",
       "        [ 0.3222, -0.7356,  0.7075],\n",
       "        [ 0.2546, -0.8608,  0.6151],\n",
       "        [-0.0188, -0.0975, -0.4582],\n",
       "        [ 0.2467, -0.7961,  0.7318],\n",
       "        [-0.0197, -0.1267, -0.3392],\n",
       "        [ 0.2224, -0.6212,  0.4487],\n",
       "        [ 0.1911, -1.0925,  0.8066],\n",
       "        [ 0.1256, -0.6310,  0.5453],\n",
       "        [-0.0575, -0.2853,  0.2197],\n",
       "        [ 0.2098, -0.6654,  0.5551],\n",
       "        [-0.2123, -0.7051,  0.5524],\n",
       "        [ 0.0654, -0.4741,  0.3264],\n",
       "        [-0.0869, -0.3759,  0.4702],\n",
       "        [ 0.1079, -0.4101,  0.4273],\n",
       "        [ 0.0237, -0.1057, -0.4050],\n",
       "        [-0.0176, -0.4077,  0.3037],\n",
       "        [-0.3515, -0.1620,  0.2812],\n",
       "        [-0.0399, -0.1033, -0.4860],\n",
       "        [-0.1554, -0.3617,  0.2850],\n",
       "        [ 0.2461, -0.9315,  0.7482]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_torchloss_output=torch.autograd.grad(manual_loss, model.fc1.weight, grad_outputs=torch.ones_like(manual_loss), retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0093, -0.0043, -0.0072, -0.0136],\n",
       "         [ 0.0007,  0.0006,  0.0010,  0.0006],\n",
       "         [-0.0063, -0.0036, -0.0058, -0.0093],\n",
       "         [ 0.0030,  0.0037,  0.0032,  0.0029],\n",
       "         [ 0.0083,  0.0024,  0.0048,  0.0122],\n",
       "         [ 0.0027,  0.0028,  0.0025,  0.0022],\n",
       "         [-0.0107, -0.0054, -0.0089, -0.0156],\n",
       "         [ 0.0004,  0.0004,  0.0003,  0.0003],\n",
       "         [ 0.0068,  0.0020,  0.0036,  0.0096],\n",
       "         [ 0.0083,  0.0011,  0.0043,  0.0122]]),)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_torchloss_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw1=model.fc1.weight.detach().numpy()\n",
    "pb1=np.array([list(model.fc1.bias.detach().numpy())])\n",
    "pw2=model.fc2.weight.detach().numpy()\n",
    "pb2=np.array([list(model.fc2.bias.detach().numpy())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MyTensor as MT\n",
    "import MyNN as MN \n",
    "import MyPara as MP\n",
    "import Loss\n",
    "import MyOpt\n",
    "from tqdm import tqdm\n",
    "\n",
    "relu = MN.my_relu()\n",
    "softmax = MN.my_softmax()\n",
    "layer1=MN.my_linear_layer(in_feature=4,out_feature=10,paraw=MP.myparameter(npar_data=pw1.T),parab=MP.myparameter(npar_data=pb1))\n",
    "layer2=MN.my_linear_layer(in_feature=10,out_feature=3,paraw=MP.myparameter(npar_data=pw2.T),parab=MP.myparameter(npar_data=pb2))\n",
    "x=layer1(MT.mytensor(np.array(X_train_tensor)))\n",
    "x=relu(x)\n",
    "pred=layer2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=MT.mytensor(y_train_tensor.detach().numpy())\n",
    "L=Loss.CrossEntropy()\n",
    "L(softmax(pred),labels)\n",
    "L.backward(mode='force')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1.parameterw._myparameter__update(0.001)\n",
    "layer1.parameterb._myparameter__update(0.001)\n",
    "layer2.parameterw._myparameter__update(0.001)\n",
    "layer2.parameterb._myparameter__update(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.4623,  0.1248,  0.3628, -0.1478, -0.4270, -0.2450,  0.0288,  0.2759,\n",
       "         0.1793,  0.2262], requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'Loss.CrossEntropy'>: 0.061388623"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.31322575e-09, -2.32830644e-09,  6.51925802e-09,\n",
       "         5.58793545e-09],\n",
       "       [ 1.11758709e-08, -6.51925802e-09,  1.21071935e-08,\n",
       "         8.38190317e-09],\n",
       "       [ 2.91038305e-10,  6.46105036e-09, -2.44472176e-09,\n",
       "        -1.62981451e-09],\n",
       "       [-6.51925802e-09,  6.98491931e-10, -9.31322575e-10,\n",
       "        -3.72529030e-09],\n",
       "       [ 1.11758709e-08, -6.98491931e-09,  8.38190317e-09,\n",
       "         1.11758709e-08],\n",
       "       [ 6.98491931e-09, -4.65661287e-09,  6.51925802e-09,\n",
       "         8.38190317e-09],\n",
       "       [-7.45058060e-09, -2.32830644e-10, -6.51925802e-09,\n",
       "        -5.58793545e-09],\n",
       "       [ 8.38190317e-09, -6.98491931e-09,  7.45058060e-09,\n",
       "         9.31322575e-09],\n",
       "       [ 1.10594556e-09,  4.59840521e-09, -1.04773790e-09,\n",
       "        -9.31322575e-10],\n",
       "       [ 6.98491931e-10,  5.52972779e-09, -2.21189111e-09,\n",
       "        -1.80443749e-09]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((pred.grad.npar_data-grad_torchloss_output[0].detach().numpy())>=0.0001).astype(int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.0723e-04, -1.5369e-03, -1.1769e-03, -2.0452e-03],\n",
      "        [-1.5041e-02, -6.0474e-03, -1.2930e-02, -1.5791e-02],\n",
      "        [ 3.9860e-03,  3.8923e-03,  4.8532e-03,  4.1966e-03],\n",
      "        [ 1.7653e-03,  1.3148e-03,  2.3468e-05,  4.9364e-04],\n",
      "        [ 5.7791e-03,  4.7620e-03,  7.0304e-03,  1.0887e-02],\n",
      "        [-5.5086e-03, -3.9948e-03, -7.2203e-03, -1.1002e-02],\n",
      "        [ 3.4417e-04, -1.2825e-03, -1.9111e-03, -2.3309e-03],\n",
      "        [ 5.6064e-03,  7.1242e-03,  6.6807e-03,  6.0830e-03],\n",
      "        [ 6.6810e-03,  5.6697e-03,  8.3589e-03,  1.2717e-02],\n",
      "        [ 1.0788e-02,  5.8912e-03,  1.0286e-02,  1.6785e-02]])\n",
      "tensor([-0.0036, -0.0239, -0.0008, -0.0009,  0.0191, -0.0202, -0.0041,  0.0010,\n",
      "         0.0224,  0.0290])\n",
      "tensor([[ 0.0016, -0.0023, -0.0057,  0.0035,  0.0021, -0.0006,  0.0008, -0.0051,\n",
      "          0.0008,  0.0005],\n",
      "        [-0.0091, -0.0075,  0.0056, -0.0178, -0.0141, -0.0140, -0.0042,  0.0050,\n",
      "         -0.0085, -0.0041],\n",
      "        [ 0.0075,  0.0098,  0.0001,  0.0142,  0.0120,  0.0146,  0.0034,  0.0001,\n",
      "          0.0077,  0.0036]])\n",
      "tensor([ 0.0024, -0.0181,  0.0156])\n"
     ]
    }
   ],
   "source": [
    "for i in model.parameters():\n",
    "    print(i.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlist=[]\n",
    "for i in pred.npar_data:\n",
    "    maxlist.append(np.ones(i.shape)*np.max(i))\n",
    "XMax=MT.mytensor(np.array(maxlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor32([[9.99999046e-01 7.46828277e-07 2.69032370e-07]\n",
       " [9.99995947e-01 3.04515152e-06 9.93293952e-07]\n",
       " [1.77488534e-03 9.86826897e-01 1.13981245e-02]\n",
       " [9.99975801e-01 2.11624301e-05 3.00435158e-06]\n",
       " [9.99991059e-01 7.70362658e-06 1.18733055e-06]\n",
       " [8.36834352e-06 9.24896635e-03 9.90742624e-01]\n",
       " [8.81663244e-03 9.40907776e-01 5.02756014e-02]\n",
       " [9.99931335e-01 6.27111367e-05 5.94191124e-06]\n",
       " [9.99991894e-01 6.11697578e-06 1.99175588e-06]\n",
       " [9.99998569e-01 1.07353242e-06 3.89135977e-07]\n",
       " [7.16300056e-05 8.73720087e-03 9.91191089e-01]\n",
       " [1.03226840e-01 8.09970677e-01 8.68024528e-02]\n",
       " [2.29315343e-03 9.24229860e-01 7.34770596e-02]\n",
       " [9.99989986e-01 7.44329054e-06 2.57039028e-06]\n",
       " [9.99964833e-01 2.99012008e-05 5.25782525e-06]\n",
       " [3.73853632e-04 9.99356687e-01 2.69513548e-04]\n",
       " [6.14627730e-04 6.14726305e-01 3.84659111e-01]\n",
       " [5.10432757e-04 3.95910963e-02 9.59898412e-01]\n",
       " [1.25253003e-03 9.83066440e-01 1.56809911e-02]\n",
       " [1.23644122e-05 1.53005967e-04 9.99834657e-01]\n",
       " [7.08147744e-03 9.83270824e-01 9.64778662e-03]\n",
       " [1.64346389e-07 1.25020219e-04 9.99874830e-01]\n",
       " [2.44955327e-02 8.75047684e-01 1.00456819e-01]\n",
       " [9.99968529e-01 2.76422215e-05 3.82616645e-06]\n",
       " [4.38285639e-08 1.94713983e-04 9.99805272e-01]\n",
       " [6.04169269e-04 9.98938382e-01 4.57449147e-04]\n",
       " [9.99867678e-01 1.24903614e-04 7.34951755e-06]\n",
       " [9.99986410e-01 1.02512422e-05 3.28205715e-06]\n",
       " [9.99985099e-01 1.10816190e-05 3.86201418e-06]\n",
       " [2.43157658e-04 9.99165535e-01 5.91377378e-04]\n",
       " [1.17116775e-04 6.05321601e-02 9.39350784e-01]\n",
       " [9.99950528e-01 4.48335377e-05 4.63255583e-06]\n",
       " [9.96699989e-01 3.27561516e-03 2.43902650e-05]\n",
       " [9.99743283e-01 2.28221485e-04 2.84781418e-05]\n",
       " [2.53605912e-03 9.85175848e-01 1.22880675e-02]\n",
       " [9.99902844e-01 9.08170550e-05 6.31658440e-06]\n",
       " [1.59020070e-02 9.79371071e-01 4.72703250e-03]\n",
       " [4.09154309e-05 5.29571145e-04 9.99429524e-01]\n",
       " [9.99970555e-01 2.69071661e-05 2.54387646e-06]\n",
       " [1.19733589e-03 9.92366135e-01 6.43654820e-03]\n",
       " [1.00263169e-05 2.00259546e-03 9.97987390e-01]\n",
       " [9.99997258e-01 2.02629167e-06 7.14830662e-07]\n",
       " [2.70833145e-03 1.30048558e-01 8.67243171e-01]\n",
       " [7.16300056e-05 8.73720087e-03 9.91191089e-01]\n",
       " [1.55740108e-05 9.99330044e-01 6.54376403e-04]\n",
       " [5.72121255e-02 8.38692784e-01 1.04095086e-01]\n",
       " [4.09967091e-04 4.59856726e-03 9.94991481e-01]\n",
       " [4.14610869e-04 9.77612019e-01 2.19733678e-02]\n",
       " [9.99980927e-01 1.41297405e-05 4.93148900e-06]\n",
       " [2.34017358e-03 9.97283459e-01 3.76364886e-04]\n",
       " [1.60101754e-05 7.65082240e-03 9.92333174e-01]\n",
       " [9.99891758e-01 1.02403683e-04 5.81233508e-06]\n",
       " [9.99835014e-01 1.58805793e-04 6.22289599e-06]\n",
       " [4.67281207e-04 9.98501658e-01 1.03102939e-03]\n",
       " [8.85298708e-04 3.07190359e-01 6.91924393e-01]\n",
       " [9.99502659e-01 4.87085897e-04 1.01975602e-05]\n",
       " [4.45381556e-06 1.11656853e-04 9.99883890e-01]\n",
       " [9.99943972e-01 5.14138264e-05 4.69909992e-06]\n",
       " [9.99960423e-01 2.95442278e-05 1.00256184e-05]\n",
       " [1.83578562e-02 3.18597645e-01 6.63044453e-01]\n",
       " [2.86731757e-02 9.69729900e-01 1.59688422e-03]\n",
       " [7.39216284e-06 1.89945713e-04 9.99802649e-01]\n",
       " [3.95127456e-04 2.42788076e-01 7.56816864e-01]\n",
       " [1.27414067e-04 4.23066109e-01 5.76806486e-01]\n",
       " [1.24745966e-07 4.79229275e-05 9.99951959e-01]\n",
       " [1.33616838e-03 9.85465229e-01 1.31986570e-02]\n",
       " [9.99779642e-01 2.15406253e-04 5.05263051e-06]\n",
       " [9.99979019e-01 1.98497128e-05 1.09274447e-06]\n",
       " [1.77418788e-05 2.65121162e-01 7.34861076e-01]\n",
       " [8.30809804e-05 2.39126030e-02 9.76004362e-01]\n",
       " [9.99907374e-01 8.84025503e-05 4.19967409e-06]\n",
       " [9.99971628e-01 2.32572293e-05 5.09704614e-06]\n",
       " [9.99943495e-01 5.37605774e-05 2.76210403e-06]\n",
       " [1.06284919e-04 5.51442087e-01 4.48451579e-01]\n",
       " [9.35428106e-05 1.01628981e-03 9.98890221e-01]\n",
       " [9.99994159e-01 4.34896128e-06 1.58859086e-06]\n",
       " [1.26418454e-05 1.27924257e-03 9.98708129e-01]\n",
       " [5.86287706e-06 6.35940087e-05 9.99930501e-01]\n",
       " [9.99960065e-01 3.70072412e-05 2.95994482e-06]\n",
       " [1.90403115e-03 9.40211654e-01 5.78842498e-02]\n",
       " [6.28974871e-04 8.67628753e-01 1.31742224e-01]\n",
       " [3.99383629e-04 9.20324326e-02 9.07568157e-01]\n",
       " [1.49811909e-03 9.82817173e-01 1.56846717e-02]\n",
       " [6.07244474e-05 1.18925923e-03 9.98749971e-01]\n",
       " [9.99994159e-01 4.30828368e-06 1.58561818e-06]\n",
       " [3.26198351e-05 2.28379085e-03 9.97683525e-01]\n",
       " [1.09260157e-02 9.35456812e-01 5.36171794e-02]\n",
       " [1.00146564e-04 7.23149860e-03 9.92668331e-01]\n",
       " [1.08468253e-03 9.98489141e-01 4.26174141e-04]\n",
       " [2.60291379e-02 9.49143589e-01 2.48271804e-02]\n",
       " [3.50475684e-03 9.61207330e-01 3.52879129e-02]\n",
       " [7.93527365e-01 2.06368238e-01 1.04465973e-04]\n",
       " [4.61537478e-04 9.88763034e-01 1.07754413e-02]\n",
       " [1.22186204e-03 9.89780068e-01 8.99794884e-03]\n",
       " [9.99979138e-01 1.69273844e-05 3.91135563e-06]\n",
       " [3.73190716e-02 9.52416480e-01 1.02644451e-02]\n",
       " [2.63083507e-06 5.50580630e-03 9.94491577e-01]\n",
       " [1.05970546e-04 2.21234723e-03 9.97681618e-01]\n",
       " [9.99987721e-01 9.10430845e-06 3.19411538e-06]\n",
       " [1.28746061e-02 9.86436784e-01 6.88679807e-04]\n",
       " [6.67973882e-06 1.08023080e-04 9.99885321e-01]\n",
       " [1.06219435e-04 1.97718829e-01 8.02174926e-01]\n",
       " [9.99994755e-01 4.15457816e-06 1.11027089e-06]\n",
       " [2.91077845e-06 7.40222240e-05 9.99923110e-01]\n",
       " [9.98846769e-01 1.13945908e-03 1.37035986e-05]\n",
       " [1.36327150e-03 8.93852890e-01 1.04783855e-01]\n",
       " [8.10673214e-07 2.39444082e-03 9.97604728e-01]\n",
       " [8.87498172e-05 1.74961779e-02 9.82415020e-01]\n",
       " [3.67907248e-03 9.88259554e-01 8.06138664e-03]\n",
       " [1.93027372e-04 3.27982940e-02 9.67008710e-01]\n",
       " [3.08364288e-05 9.64007676e-01 3.59615572e-02]\n",
       " [7.72477768e-04 9.93553042e-01 5.67447767e-03]\n",
       " [1.83923446e-04 5.40290168e-03 9.94413197e-01]\n",
       " [1.47168199e-03 6.08869530e-02 9.37641323e-01]\n",
       " [9.99154329e-01 8.25133990e-04 2.04644421e-05]\n",
       " [9.83254169e-04 9.94528592e-01 4.48810449e-03]\n",
       " [3.16668209e-03 1.20449923e-01 8.76383424e-01]\n",
       " [9.99984384e-01 1.22101465e-05 3.49868924e-06]\n",
       " [6.13334938e-04 9.96724188e-01 2.66248104e-03]\n",
       " [2.57007969e-06 5.52506186e-04 9.99444902e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp=MT.add(pred,(-1)*XMax).exp()\n",
    "tempsum=MT.dot(temp,MT.ones((pred.shape[1],1)))\n",
    "tempsum_sameshape=MT.dot(tempsum, MT.ones((1, pred.shape[1])))\n",
    "MT.hadamard(temp,1/tempsum_sameshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'Loss.CrossEntropy'>: 0.06935775"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tensortype': 'tensor32',\n",
       " 'with_grad': True,\n",
       " '_cg_descend': [18],\n",
       " '_cg_ascend': [10, 13],\n",
       " '_grad_f': tensor32([[-1.66666694e-02  2.90558044e-09  3.29900857e-10]\n",
       "  [-1.66666694e-02  1.18647903e-09  6.28117058e-10]\n",
       "  [ 1.20527584e-05 -1.67772714e-02  9.85508232e-05]\n",
       "  [-1.66667886e-02  1.20071206e-07  2.07676432e-09]\n",
       "  [-1.66667365e-02  6.80816967e-08  1.51476143e-09]\n",
       "  [ 6.16279522e-07  1.80445088e-04 -1.68477297e-02]\n",
       "  [ 6.91098321e-05 -1.70220472e-02  2.86269584e-04]\n",
       "  [-1.66670494e-02  3.78761996e-07  2.62245203e-09]\n",
       "  [-1.66667104e-02  4.12893968e-08  1.09872400e-09]\n",
       "  [-1.66666694e-02  8.23885682e-10  1.48446366e-10]\n",
       "  [ 3.79145831e-06  1.26819752e-04 -1.67972781e-02]\n",
       "  [ 7.28065264e-04 -1.78450495e-02  4.50317952e-04]\n",
       "  [ 1.89086422e-05 -1.73021778e-02  6.16602832e-04]\n",
       "  [-1.66666955e-02  2.56117030e-08  1.96636818e-09]\n",
       "  [-1.66668296e-02  1.59924411e-07  1.75285830e-09]\n",
       "  [ 2.89960121e-06 -1.66734606e-02  3.89157594e-06]\n",
       "  [ 1.06924153e-05  4.47357679e-03 -2.11509336e-02]\n",
       "  [ 1.05700010e-05  3.95167794e-04 -1.70724057e-02]\n",
       "  [ 1.00621273e-05 -1.68175083e-02  1.40777847e-04]\n",
       "  [ 4.53669827e-07  2.60698744e-06 -1.66697260e-02]\n",
       "  [ 5.70649172e-05 -1.67832151e-02  5.94844423e-05]\n",
       "  [ 6.49008358e-09  1.72928833e-06 -1.66684054e-02]\n",
       "  [ 2.65710871e-04 -1.76454745e-02  7.13095244e-04]\n",
       "  [-1.66668631e-02  1.95085335e-07  1.94128980e-09]\n",
       "  [ 2.10240869e-09  2.29213629e-06 -1.66689605e-02]\n",
       "  [ 7.66267385e-06 -1.66793261e-02  4.99310090e-06]\n",
       "  [-1.66675933e-02  9.21681305e-07  3.42975426e-09]\n",
       "  [-1.66667923e-02  1.20148499e-07  2.51499443e-09]\n",
       "  [-1.66666955e-02  2.37646329e-08  3.35751671e-09]\n",
       "  [ 1.63159939e-06 -1.66765191e-02  8.21921822e-06]\n",
       "  [ 4.05245964e-06  8.45180533e-04 -1.75159015e-02]\n",
       "  [-1.66668333e-02  1.63360923e-07  2.94903368e-09]\n",
       "  [-1.66861266e-02  1.94466284e-05  1.39796095e-08]\n",
       "  [-1.66699998e-02  3.29855834e-06  3.19246709e-08]\n",
       "  [ 2.97483566e-05 -1.68131534e-02  1.16737574e-04]\n",
       "  [-1.66672543e-02  5.82891118e-07  3.20762772e-09]\n",
       "  [ 1.30937042e-04 -1.68246888e-02  2.70844794e-05]\n",
       "  [ 5.23190806e-07  5.91143589e-06 -1.66731030e-02]\n",
       "  [-1.66669004e-02  2.31608922e-07  2.45937470e-09]\n",
       "  [ 1.36913923e-05 -1.67454332e-02  6.50759248e-05]\n",
       "  [ 1.08536392e-06  4.30425825e-05 -1.67107955e-02]\n",
       "  [-1.66666694e-02  1.77365433e-09  2.72966927e-10]\n",
       "  [ 6.68386128e-05  1.74529874e-03 -1.84788071e-02]\n",
       "  [ 3.79145831e-06  1.26819752e-04 -1.67972781e-02]\n",
       "  [ 3.19720385e-07 -1.66777298e-02  1.07435872e-05]\n",
       "  [ 4.96823923e-04 -1.79310888e-02  7.67598860e-04]\n",
       "  [ 2.99837520e-05  9.58542805e-05 -1.67925023e-02]\n",
       "  [ 5.85014959e-06 -1.68787967e-02  2.06279030e-04]\n",
       "  [-1.66667104e-02  3.86117947e-08  3.13851656e-09]\n",
       "  [ 2.07262055e-05 -1.66913606e-02  3.96763653e-06]\n",
       "  [ 7.74795978e-07  1.16173651e-04 -1.67836174e-02]\n",
       "  [-1.66674815e-02  8.09537084e-07  3.49054252e-09]\n",
       "  [-1.66684519e-02  1.77770085e-06  4.06126377e-09]\n",
       "  [ 3.88608441e-06 -1.66839212e-02  1.33666417e-05]\n",
       "  [ 1.10628735e-05 -2.20853835e-02  5.40765235e-03]\n",
       "  [-1.66703947e-02  3.72134832e-06  7.05246173e-09]\n",
       "  [ 8.94211837e-07  5.37242704e-06 -1.66729353e-02]\n",
       "  [-1.66670028e-02  3.32674745e-07  2.66891598e-09]\n",
       "  [-1.66669656e-02  2.79477007e-07  1.91439025e-08]\n",
       "  [ 3.49943963e-04 -2.16243118e-02  4.60770167e-03]\n",
       "  [ 1.40896620e-04 -1.68155972e-02  8.03301373e-06]\n",
       "  [ 3.10761635e-07  4.44950911e-06 -1.66714285e-02]\n",
       "  [ 9.69426401e-06 -2.31568329e-02  6.48047309e-03]\n",
       "  [ 3.17965510e-06  2.05056998e-03 -1.87204164e-02]\n",
       "  [ 7.41620809e-09  1.47256321e-06 -1.66681483e-02]\n",
       "  [ 1.40780694e-05 -1.68042965e-02  1.23553807e-04]\n",
       "  [-1.66681539e-02  1.47899436e-06  5.40854073e-09]\n",
       "  [-1.66668613e-02  1.92435820e-07  1.23189337e-09]\n",
       "  [ 1.01038052e-06  2.16986518e-03 -1.88375413e-02]\n",
       "  [ 9.62189802e-07  1.79288603e-04 -1.68469176e-02]\n",
       "  [-1.66673642e-02  6.92013089e-07  4.06361744e-09]\n",
       "  [-1.66669041e-02  2.33272687e-07  3.39748785e-09]\n",
       "  [-1.66671649e-02  4.95032737e-07  3.27354543e-09]\n",
       "  [ 2.91602214e-06 -2.05294974e-02  3.85991507e-03]\n",
       "  [ 8.57876148e-06  2.85941169e-05 -1.67038403e-02]\n",
       "  [-1.66667067e-02  3.80873573e-08  1.99162309e-09]\n",
       "  [ 4.92684251e-07  2.66344541e-05 -1.66937914e-02]\n",
       "  [ 8.34247487e-07  2.98191912e-06 -1.66704841e-02]\n",
       "  [-1.66670382e-02  3.66233962e-07  2.62974864e-09]\n",
       "  [ 3.03757770e-05 -1.72780380e-02  5.80994878e-04]\n",
       "  [ 7.81128801e-06 -1.77804232e-02  1.10594463e-03]\n",
       "  [ 1.08592149e-05  1.22759631e-03 -1.79051235e-02]\n",
       "  [ 9.18028309e-06 -1.68342367e-02  1.58389972e-04]\n",
       "  [ 3.02378885e-06  2.21892533e-05 -1.66918803e-02]\n",
       "  [-1.66666806e-02  1.22161943e-08  7.71943676e-10]\n",
       "  [ 9.75984221e-07  4.87082470e-05 -1.67163536e-02]\n",
       "  [ 1.01543446e-04 -1.70334801e-02  2.65269220e-04]\n",
       "  [ 3.04817218e-06  1.28188694e-04 -1.67979039e-02]\n",
       "  [ 6.16451007e-06 -1.66741405e-02  1.30856301e-06]\n",
       "  [ 1.49022264e-04 -1.69682950e-02  1.52604523e-04]\n",
       "  [ 4.77570538e-05 -1.70344356e-02  3.20011168e-04]\n",
       "  [-1.82824805e-02  1.61570183e-03  1.12408721e-07]\n",
       "  [ 4.83122312e-06 -1.68085694e-02  1.37070339e-04]\n",
       "  [ 1.92127463e-05 -1.68047883e-02  1.18906653e-04]\n",
       "  [-1.66667588e-02  9.12719216e-08  1.45844026e-09]\n",
       "  [ 2.51491001e-04 -1.69808865e-02  6.27305344e-05]\n",
       "  [ 6.16505744e-08  4.23537604e-05 -1.67090818e-02]\n",
       "  [ 2.82775500e-06  3.69785266e-05 -1.67064741e-02]\n",
       "  [-1.66667141e-02  4.25070787e-08  3.09247206e-09]\n",
       "  [ 1.28649262e-04 -1.68032162e-02  7.89930800e-06]\n",
       "  [ 4.80468316e-07  2.47312687e-06 -1.66696217e-02]\n",
       "  [ 1.19872607e-06  1.21090666e-03 -1.78787727e-02]\n",
       "  [-1.66666880e-02  1.97068104e-08  5.22345611e-10]\n",
       "  [ 2.18169774e-07  2.30757882e-06 -1.66691951e-02]\n",
       "  [-1.66757256e-02  9.05032994e-06  9.21820131e-09]\n",
       "  [ 1.10031860e-05 -1.76761933e-02  9.98521922e-04]\n",
       "  [ 2.91285858e-08  2.85844417e-05 -1.66952815e-02]\n",
       "  [ 2.27747068e-06  1.53439905e-04 -1.68223847e-02]\n",
       "  [ 3.39215730e-05 -1.67605523e-02  5.99624182e-05]\n",
       "  [ 3.78214963e-06  3.04993358e-04 -1.69754438e-02]\n",
       "  [ 8.30357578e-07 -1.70148723e-02  3.47375171e-04]\n",
       "  [ 7.57671660e-06 -1.67337824e-02  5.95387392e-05]\n",
       "  [ 1.31019979e-05  1.59298550e-04 -1.68390684e-02]\n",
       "  [ 4.54428300e-05  7.57557747e-04 -1.74696669e-02]\n",
       "  [-1.66705232e-02  3.84859595e-06  7.03280367e-09]\n",
       "  [ 9.90282206e-06 -1.67134497e-02  3.68790897e-05]\n",
       "  [ 8.48843847e-05  1.50828494e-03 -1.82598401e-02]\n",
       "  [-1.66667253e-02  5.65059892e-08  8.10698619e-10]\n",
       "  [ 6.52258495e-06 -1.67034771e-02  3.02872104e-05]\n",
       "  [ 1.00522328e-07  9.94386119e-06 -1.66767128e-02]]),\n",
       " 'grad': tensor32([[-1.66666694e-02  2.90558044e-09  3.29900857e-10]\n",
       "  [-1.66666694e-02  1.18647903e-09  6.28117058e-10]\n",
       "  [ 1.20527584e-05 -1.67772714e-02  9.85508232e-05]\n",
       "  [-1.66667886e-02  1.20071206e-07  2.07676432e-09]\n",
       "  [-1.66667365e-02  6.80816967e-08  1.51476143e-09]\n",
       "  [ 6.16279522e-07  1.80445088e-04 -1.68477297e-02]\n",
       "  [ 6.91098321e-05 -1.70220472e-02  2.86269584e-04]\n",
       "  [-1.66670494e-02  3.78761996e-07  2.62245203e-09]\n",
       "  [-1.66667104e-02  4.12893968e-08  1.09872400e-09]\n",
       "  [-1.66666694e-02  8.23885682e-10  1.48446366e-10]\n",
       "  [ 3.79145831e-06  1.26819752e-04 -1.67972781e-02]\n",
       "  [ 7.28065264e-04 -1.78450495e-02  4.50317952e-04]\n",
       "  [ 1.89086422e-05 -1.73021778e-02  6.16602832e-04]\n",
       "  [-1.66666955e-02  2.56117030e-08  1.96636818e-09]\n",
       "  [-1.66668296e-02  1.59924411e-07  1.75285830e-09]\n",
       "  [ 2.89960121e-06 -1.66734606e-02  3.89157594e-06]\n",
       "  [ 1.06924153e-05  4.47357679e-03 -2.11509336e-02]\n",
       "  [ 1.05700010e-05  3.95167794e-04 -1.70724057e-02]\n",
       "  [ 1.00621273e-05 -1.68175083e-02  1.40777847e-04]\n",
       "  [ 4.53669827e-07  2.60698744e-06 -1.66697260e-02]\n",
       "  [ 5.70649172e-05 -1.67832151e-02  5.94844423e-05]\n",
       "  [ 6.49008358e-09  1.72928833e-06 -1.66684054e-02]\n",
       "  [ 2.65710871e-04 -1.76454745e-02  7.13095244e-04]\n",
       "  [-1.66668631e-02  1.95085335e-07  1.94128980e-09]\n",
       "  [ 2.10240869e-09  2.29213629e-06 -1.66689605e-02]\n",
       "  [ 7.66267385e-06 -1.66793261e-02  4.99310090e-06]\n",
       "  [-1.66675933e-02  9.21681305e-07  3.42975426e-09]\n",
       "  [-1.66667923e-02  1.20148499e-07  2.51499443e-09]\n",
       "  [-1.66666955e-02  2.37646329e-08  3.35751671e-09]\n",
       "  [ 1.63159939e-06 -1.66765191e-02  8.21921822e-06]\n",
       "  [ 4.05245964e-06  8.45180533e-04 -1.75159015e-02]\n",
       "  [-1.66668333e-02  1.63360923e-07  2.94903368e-09]\n",
       "  [-1.66861266e-02  1.94466284e-05  1.39796095e-08]\n",
       "  [-1.66699998e-02  3.29855834e-06  3.19246709e-08]\n",
       "  [ 2.97483566e-05 -1.68131534e-02  1.16737574e-04]\n",
       "  [-1.66672543e-02  5.82891118e-07  3.20762772e-09]\n",
       "  [ 1.30937042e-04 -1.68246888e-02  2.70844794e-05]\n",
       "  [ 5.23190806e-07  5.91143589e-06 -1.66731030e-02]\n",
       "  [-1.66669004e-02  2.31608922e-07  2.45937470e-09]\n",
       "  [ 1.36913923e-05 -1.67454332e-02  6.50759248e-05]\n",
       "  [ 1.08536392e-06  4.30425825e-05 -1.67107955e-02]\n",
       "  [-1.66666694e-02  1.77365433e-09  2.72966927e-10]\n",
       "  [ 6.68386128e-05  1.74529874e-03 -1.84788071e-02]\n",
       "  [ 3.79145831e-06  1.26819752e-04 -1.67972781e-02]\n",
       "  [ 3.19720385e-07 -1.66777298e-02  1.07435872e-05]\n",
       "  [ 4.96823923e-04 -1.79310888e-02  7.67598860e-04]\n",
       "  [ 2.99837520e-05  9.58542805e-05 -1.67925023e-02]\n",
       "  [ 5.85014959e-06 -1.68787967e-02  2.06279030e-04]\n",
       "  [-1.66667104e-02  3.86117947e-08  3.13851656e-09]\n",
       "  [ 2.07262055e-05 -1.66913606e-02  3.96763653e-06]\n",
       "  [ 7.74795978e-07  1.16173651e-04 -1.67836174e-02]\n",
       "  [-1.66674815e-02  8.09537084e-07  3.49054252e-09]\n",
       "  [-1.66684519e-02  1.77770085e-06  4.06126377e-09]\n",
       "  [ 3.88608441e-06 -1.66839212e-02  1.33666417e-05]\n",
       "  [ 1.10628735e-05 -2.20853835e-02  5.40765235e-03]\n",
       "  [-1.66703947e-02  3.72134832e-06  7.05246173e-09]\n",
       "  [ 8.94211837e-07  5.37242704e-06 -1.66729353e-02]\n",
       "  [-1.66670028e-02  3.32674745e-07  2.66891598e-09]\n",
       "  [-1.66669656e-02  2.79477007e-07  1.91439025e-08]\n",
       "  [ 3.49943963e-04 -2.16243118e-02  4.60770167e-03]\n",
       "  [ 1.40896620e-04 -1.68155972e-02  8.03301373e-06]\n",
       "  [ 3.10761635e-07  4.44950911e-06 -1.66714285e-02]\n",
       "  [ 9.69426401e-06 -2.31568329e-02  6.48047309e-03]\n",
       "  [ 3.17965510e-06  2.05056998e-03 -1.87204164e-02]\n",
       "  [ 7.41620809e-09  1.47256321e-06 -1.66681483e-02]\n",
       "  [ 1.40780694e-05 -1.68042965e-02  1.23553807e-04]\n",
       "  [-1.66681539e-02  1.47899436e-06  5.40854073e-09]\n",
       "  [-1.66668613e-02  1.92435820e-07  1.23189337e-09]\n",
       "  [ 1.01038052e-06  2.16986518e-03 -1.88375413e-02]\n",
       "  [ 9.62189802e-07  1.79288603e-04 -1.68469176e-02]\n",
       "  [-1.66673642e-02  6.92013089e-07  4.06361744e-09]\n",
       "  [-1.66669041e-02  2.33272687e-07  3.39748785e-09]\n",
       "  [-1.66671649e-02  4.95032737e-07  3.27354543e-09]\n",
       "  [ 2.91602214e-06 -2.05294974e-02  3.85991507e-03]\n",
       "  [ 8.57876148e-06  2.85941169e-05 -1.67038403e-02]\n",
       "  [-1.66667067e-02  3.80873573e-08  1.99162309e-09]\n",
       "  [ 4.92684251e-07  2.66344541e-05 -1.66937914e-02]\n",
       "  [ 8.34247487e-07  2.98191912e-06 -1.66704841e-02]\n",
       "  [-1.66670382e-02  3.66233962e-07  2.62974864e-09]\n",
       "  [ 3.03757770e-05 -1.72780380e-02  5.80994878e-04]\n",
       "  [ 7.81128801e-06 -1.77804232e-02  1.10594463e-03]\n",
       "  [ 1.08592149e-05  1.22759631e-03 -1.79051235e-02]\n",
       "  [ 9.18028309e-06 -1.68342367e-02  1.58389972e-04]\n",
       "  [ 3.02378885e-06  2.21892533e-05 -1.66918803e-02]\n",
       "  [-1.66666806e-02  1.22161943e-08  7.71943676e-10]\n",
       "  [ 9.75984221e-07  4.87082470e-05 -1.67163536e-02]\n",
       "  [ 1.01543446e-04 -1.70334801e-02  2.65269220e-04]\n",
       "  [ 3.04817218e-06  1.28188694e-04 -1.67979039e-02]\n",
       "  [ 6.16451007e-06 -1.66741405e-02  1.30856301e-06]\n",
       "  [ 1.49022264e-04 -1.69682950e-02  1.52604523e-04]\n",
       "  [ 4.77570538e-05 -1.70344356e-02  3.20011168e-04]\n",
       "  [-1.82824805e-02  1.61570183e-03  1.12408721e-07]\n",
       "  [ 4.83122312e-06 -1.68085694e-02  1.37070339e-04]\n",
       "  [ 1.92127463e-05 -1.68047883e-02  1.18906653e-04]\n",
       "  [-1.66667588e-02  9.12719216e-08  1.45844026e-09]\n",
       "  [ 2.51491001e-04 -1.69808865e-02  6.27305344e-05]\n",
       "  [ 6.16505744e-08  4.23537604e-05 -1.67090818e-02]\n",
       "  [ 2.82775500e-06  3.69785266e-05 -1.67064741e-02]\n",
       "  [-1.66667141e-02  4.25070787e-08  3.09247206e-09]\n",
       "  [ 1.28649262e-04 -1.68032162e-02  7.89930800e-06]\n",
       "  [ 4.80468316e-07  2.47312687e-06 -1.66696217e-02]\n",
       "  [ 1.19872607e-06  1.21090666e-03 -1.78787727e-02]\n",
       "  [-1.66666880e-02  1.97068104e-08  5.22345611e-10]\n",
       "  [ 2.18169774e-07  2.30757882e-06 -1.66691951e-02]\n",
       "  [-1.66757256e-02  9.05032994e-06  9.21820131e-09]\n",
       "  [ 1.10031860e-05 -1.76761933e-02  9.98521922e-04]\n",
       "  [ 2.91285858e-08  2.85844417e-05 -1.66952815e-02]\n",
       "  [ 2.27747068e-06  1.53439905e-04 -1.68223847e-02]\n",
       "  [ 3.39215730e-05 -1.67605523e-02  5.99624182e-05]\n",
       "  [ 3.78214963e-06  3.04993358e-04 -1.69754438e-02]\n",
       "  [ 8.30357578e-07 -1.70148723e-02  3.47375171e-04]\n",
       "  [ 7.57671660e-06 -1.67337824e-02  5.95387392e-05]\n",
       "  [ 1.31019979e-05  1.59298550e-04 -1.68390684e-02]\n",
       "  [ 4.54428300e-05  7.57557747e-04 -1.74696669e-02]\n",
       "  [-1.66705232e-02  3.84859595e-06  7.03280367e-09]\n",
       "  [ 9.90282206e-06 -1.67134497e-02  3.68790897e-05]\n",
       "  [ 8.48843847e-05  1.50828494e-03 -1.82598401e-02]\n",
       "  [-1.66667253e-02  5.65059892e-08  8.10698619e-10]\n",
       "  [ 6.52258495e-06 -1.67034771e-02  3.02872104e-05]\n",
       "  [ 1.00522328e-07  9.94386119e-06 -1.66767128e-02]]),\n",
       " 'npar_data': array([[  7.311186  ,  -7.5579543 ,  -9.733551  ],\n",
       "        [  7.6014934 ,  -8.163291  ,  -8.799309  ],\n",
       "        [ -4.3533506 ,   2.1720135 ,  -2.2520716 ],\n",
       "        [  5.8057957 ,  -5.3418794 ,  -9.399153  ],\n",
       "        [  6.0027337 ,  -5.712323  ,  -9.517775  ],\n",
       "        [ -7.520256  ,  -1.8407747 ,   1.9698507 ],\n",
       "        [ -3.3024385 ,   1.4463016 ,  -1.8812017 ],\n",
       "        [  5.4265842 ,  -4.572236  ,  -9.545034  ],\n",
       "        [  6.2805552 ,  -5.934608  ,  -9.561065  ],\n",
       "        [  7.928524  ,  -8.200973  ,  -9.914782  ],\n",
       "        [ -5.6126704 ,  -2.1026545 ,   2.0668    ],\n",
       "        [ -1.4268023 ,   0.8583669 ,  -1.907239  ],\n",
       "        [ -4.767377  ,   1.2416968 ,  -1.2827709 ],\n",
       "        [  6.368424  ,  -6.3242974 ,  -8.891158  ],\n",
       "        [  5.7970886 ,  -5.0639644 ,  -9.577418  ],\n",
       "        [ -4.207637  ,   3.7549932 ,  -3.9133964 ],\n",
       "        [ -5.903369  ,   0.13304001,  -0.01731813],\n",
       "        [ -5.2002044 ,  -1.5789138 ,   1.4198807 ],\n",
       "        [ -4.6684513 ,   2.032522  ,  -2.0300472 ],\n",
       "        [ -5.8053026 ,  -4.056721  ,   4.012735  ],\n",
       "        [ -2.8011272 ,   2.1686172 ,  -2.759602  ],\n",
       "        [ -9.669473  ,  -4.084283  ,   4.3958178 ],\n",
       "        [ -2.526648  ,   0.7940145 ,  -1.5394418 ],\n",
       "        [  5.684242  ,  -4.978072  ,  -9.588156  ],\n",
       "        [-10.892749  ,  -3.898593  ,   4.299666  ],\n",
       "        [ -3.5748498 ,   3.4152882 ,  -4.0031533 ],\n",
       "        [  5.0879283 ,  -4.0215354 ,  -9.615247  ],\n",
       "        [  5.7846565 ,  -5.3623743 ,  -9.228832  ],\n",
       "        [  6.2814693 ,  -6.4861035 ,  -8.4431    ],\n",
       "        [ -5.031634  ,   3.5056415 ,  -3.4147196 ],\n",
       "        [ -6.3782506 ,  -1.0380244 ,   1.1429615 ],\n",
       "        [  5.6494145 ,  -5.1903777 ,  -9.204862  ],\n",
       "        [  3.831602  ,  -2.226405  ,  -9.464234  ],\n",
       "        [  4.2745657 ,  -3.559568  ,  -8.19743   ],\n",
       "        [ -3.6656592 ,   1.951851  ,  -2.2985048 ],\n",
       "        [  5.2413316 ,  -4.326371  ,  -9.528841  ],\n",
       "        [ -1.9300398 ,   2.204118  ,  -3.5057955 ],\n",
       "        [ -6.10633   ,  -3.6816323 ,   3.5687256 ],\n",
       "        [  5.539545  ,  -4.951151  ,  -9.496294  ],\n",
       "        [ -4.0790415 ,   2.3227127 ,  -2.5202544 ],\n",
       "        [ -6.3295455 ,  -2.649271  ,   2.6112485 ],\n",
       "        [  7.597601  ,  -7.765131  ,  -9.636578  ],\n",
       "        [ -4.0685186 ,  -0.80611867,   0.5120133 ],\n",
       "        [ -5.6126704 ,  -2.1026545 ,   2.0668    ],\n",
       "        [ -6.692671  ,   3.474328  ,  -3.1780534 ],\n",
       "        [ -2.031348  ,   0.623878  ,  -1.5963166 ],\n",
       "        [ -3.685744  ,  -2.5235708 ,   1.9264034 ],\n",
       "        [ -5.353861  ,   1.8819056 ,  -1.7910984 ],\n",
       "        [  6.1599154 ,  -6.1222963 ,  -8.632103  ],\n",
       "        [ -2.8082218 ,   3.1854305 ,  -4.46145   ],\n",
       "        [ -7.0833254 ,  -2.0730834 ,   2.1857162 ],\n",
       "        [  5.1082063 ,  -4.131007  ,  -9.577413  ],\n",
       "        [  4.821677  ,  -3.6308072 ,  -9.712389  ],\n",
       "        [ -4.4640827 ,   3.2044616 ,  -3.2287226 ],\n",
       "        [ -5.803652  ,  -0.22975281,   0.38832355],\n",
       "        [  4.4800434 ,  -3.2334418 ,  -9.501906  ],\n",
       "        [ -5.5544076 ,  -3.7613153 ,   3.5846715 ],\n",
       "        [  5.4468617 ,  -4.681707  ,  -9.507199  ],\n",
       "        [  5.156547  ,  -5.146271  ,  -7.827207  ],\n",
       "        [ -2.7735822 ,  -0.5070007 ,  -0.19587082],\n",
       "        [ -1.7207114 ,   2.341248  ,  -4.585178  ],\n",
       "        [ -6.4062915 ,  -3.744769  ,   3.7898846 ],\n",
       "        [ -5.839129  ,  -0.5914235 ,   0.66588545],\n",
       "        [ -6.945503  ,  -0.4764031 ,   0.64278305],\n",
       "        [ -9.466345  ,  -4.1752524 ,   4.4655843 ],\n",
       "        [ -4.3176794 ,   2.0490675 ,  -2.1456208 ],\n",
       "        [  4.7782574 ,  -3.8582215 ,  -9.469359  ],\n",
       "        [  5.688195  ,  -4.987793  , -10.039003  ],\n",
       "        [ -8.092388  ,  -0.42029512,   0.6235157 ],\n",
       "        [ -7.0231485 ,  -1.7956083 ,   2.0215464 ],\n",
       "        [  5.0966353 ,  -4.2994504 ,  -9.436981  ],\n",
       "        [  5.526999  ,  -4.956538  ,  -9.185711  ],\n",
       "        [  5.2211676 ,  -4.5099225 ,  -9.528673  ],\n",
       "        [ -7.1565747 ,   0.17846091,   0.03160512],\n",
       "        [ -4.2809744 ,  -3.077063  ,   2.5932841 ],\n",
       "        [  6.163869  ,  -6.1320176 ,  -9.082951  ],\n",
       "        [ -6.8084903 ,  -2.8183973 ,   2.9241552 ],\n",
       "        [ -5.386907  ,  -4.1131144 ,   3.8218794 ],\n",
       "        [  5.386142  ,  -4.646315  ,  -9.5827    ],\n",
       "        [ -4.364991  ,   1.1731871 ,  -1.4138949 ],\n",
       "        [ -5.795631  ,   1.0333508 ,  -0.8427458 ],\n",
       "        [ -5.576095  ,  -0.848296  ,   0.9060191 ],\n",
       "        [ -4.8256817 ,   1.9649659 ,  -1.9776794 ],\n",
       "        [ -5.001832  ,  -3.0087345 ,   2.916646  ],\n",
       "        [  6.752337  ,  -6.6806726 ,  -9.44228   ],\n",
       "        [ -6.4245443 ,  -2.5143874 ,   2.6218033 ],\n",
       "        [ -2.9108763 ,   1.4516401 ,  -1.9506177 ],\n",
       "        [ -5.7932196 ,  -2.0542586 ,   2.1043835 ],\n",
       "        [ -3.1473618 ,   4.060951  ,  -4.6972404 ],\n",
       "        [ -2.4189863 ,   1.5680704 ,  -2.3952322 ],\n",
       "        [ -3.7093039 ,   1.4074528 ,  -1.8070745 ],\n",
       "        [  1.7908878 ,   0.36593828,  -9.2072    ],\n",
       "        [ -5.335136  ,   2.100608  ,  -1.9897414 ],\n",
       "        [ -4.098012  ,   1.9577199 ,  -2.275247  ],\n",
       "        [  6.0026193 ,  -5.4193006 ,  -9.555777  ],\n",
       "        [ -1.7401727 ,   1.7220032 ,  -3.1287313 ],\n",
       "        [ -9.011406  ,  -2.4790754 ,   2.7977834 ],\n",
       "        [ -5.33353   ,  -2.7626755 ,   2.6502175 ],\n",
       "        [  6.0991945 ,  -6.086904  ,  -8.707603  ],\n",
       "        [ -1.8546854 ,   2.299722  ,  -4.6450005 ],\n",
       "        [ -5.741374  ,  -4.1028967 ,   4.0192847 ],\n",
       "        [ -7.6493635 ,  -0.7314979 ,   1.040213  ],\n",
       "        [  6.6433287 ,  -6.311479  ,  -9.941868  ],\n",
       "        [ -6.458369  ,  -4.0996876 ,   4.091829  ],\n",
       "        [  4.1413875 ,  -2.6827424 ,  -9.572119  ],\n",
       "        [ -5.448552  ,   1.0521489 ,  -0.94046086],\n",
       "        [ -9.553439  ,  -2.664541  ,   3.0071754 ],\n",
       "        [ -6.1642675 ,  -1.9540241 ,   2.021823  ],\n",
       "        [ -3.2443032 ,   2.2483342 ,  -2.6746364 ],\n",
       "        [ -5.983968  ,  -1.5939704 ,   1.6760014 ],\n",
       "        [ -7.4587507 ,   1.7124845 ,  -1.4224464 ],\n",
       "        [ -4.547705  ,   2.4471474 ,  -2.486158  ],\n",
       "        [ -4.56686   ,  -2.068845  ,   1.8674887 ],\n",
       "        [ -4.152954  ,  -1.3393096 ,   0.9572853 ],\n",
       "        [  4.5204854 ,  -3.1593623 ,  -9.46424   ],\n",
       "        [ -4.0753746 ,   2.6541946 ,  -2.76055   ],\n",
       "        [ -3.8240027 ,  -0.94656456,   0.5505465 ],\n",
       "        [  6.3036976 ,  -5.597723  ,  -9.841929  ],\n",
       "        [ -4.375984  ,   2.7723367 ,  -2.84053   ],\n",
       "        [ -7.8678565 ,  -3.273525  ,   3.4563322 ]], dtype=float32),\n",
       " 'shape': (120, 3)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((cg._nodelist[25]._grad.npar_data-grad_torchloss_output[0].detach().numpy())>0.0001).astype(int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00833337,  0.        ,  0.        ],\n",
       "       [-0.00833335,  0.        ,  0.        ],\n",
       "       [ 0.        , -0.0083657 ,  0.        ],\n",
       "       [-0.00833375,  0.        ,  0.        ],\n",
       "       [-0.0083336 ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00836317],\n",
       "       [ 0.        , -0.0085101 ,  0.        ],\n",
       "       [-0.00833382,  0.        ,  0.        ],\n",
       "       [-0.00833349,  0.        ,  0.        ],\n",
       "       [-0.00833336,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00836614],\n",
       "       [ 0.        , -0.01030229,  0.        ],\n",
       "       [ 0.        , -0.00859346,  0.        ],\n",
       "       [-0.00833342,  0.        ,  0.        ],\n",
       "       [-0.00833358,  0.        ,  0.        ],\n",
       "       [ 0.        , -0.00833622,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.02246874],\n",
       "       [ 0.        ,  0.        , -0.00858401],\n",
       "       [ 0.        , -0.00837364,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00833354],\n",
       "       [ 0.        , -0.00845372,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.0083335 ],\n",
       "       [ 0.        , -0.008935  ,  0.        ],\n",
       "       [-0.00833363,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00833354],\n",
       "       [ 0.        , -0.00834175,  0.        ],\n",
       "       [-0.00833418,  0.        ,  0.        ],\n",
       "       [-0.00833356,  0.        ,  0.        ],\n",
       "       [-0.0083336 ,  0.        ,  0.        ],\n",
       "       [ 0.        , -0.00833546,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00869609],\n",
       "       [-0.00833411,  0.        ,  0.        ],\n",
       "       [-0.00835139,  0.        ,  0.        ],\n",
       "       [-0.00833569,  0.        ,  0.        ],\n",
       "       [ 0.        , -0.00837923,  0.        ],\n",
       "       [-0.00833408,  0.        ,  0.        ],\n",
       "       [ 0.        , -0.00861808,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00833492],\n",
       "       [-0.00833388,  0.        ,  0.        ],\n",
       "       [ 0.        , -0.00835762,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00833836],\n",
       "       [-0.00833336,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00976679],\n",
       "       [ 0.        ,  0.        , -0.00836614],\n",
       "       [ 0.        , -0.00833548,  0.        ],\n",
       "       [ 0.        , -0.00927598,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00834879],\n",
       "       [ 0.        , -0.00843924,  0.        ],\n",
       "       [-0.00833353,  0.        ,  0.        ],\n",
       "       [ 0.        , -0.00834682,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00835902],\n",
       "       [-0.00833428,  0.        ,  0.        ],\n",
       "       [-0.00833472,  0.        ,  0.        ],\n",
       "       [ 0.        , -0.00833747,  0.        ],\n",
       "       [ 0.        , -0.02375772,  0.        ],\n",
       "       [-0.00833746,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00833348],\n",
       "       [-0.00833387,  0.        ,  0.        ],\n",
       "       [-0.00833399,  0.        ,  0.        ],\n",
       "       [ 0.        , -0.01886284,  0.        ],\n",
       "       [ 0.        , -0.00848419,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00833374],\n",
       "       [ 0.        , -0.04352109,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.01172468],\n",
       "       [ 0.        ,  0.        , -0.00833341],\n",
       "       [ 0.        , -0.00838004,  0.        ],\n",
       "       [-0.00833629,  0.        ,  0.        ],\n",
       "       [-0.00833385,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00966123],\n",
       "       [ 0.        ,  0.        , -0.00845428],\n",
       "       [-0.0083348 ,  0.        ,  0.        ],\n",
       "       [-0.00833368,  0.        ,  0.        ],\n",
       "       [-0.00833441,  0.        ,  0.        ],\n",
       "       [ 0.        , -0.01673573,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00833572],\n",
       "       [-0.00833355,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00833767],\n",
       "       [ 0.        ,  0.        , -0.00833343],\n",
       "       [-0.00833395,  0.        ,  0.        ],\n",
       "       [ 0.        , -0.00859086,  0.        ],\n",
       "       [ 0.        , -0.00905756,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00905583],\n",
       "       [ 0.        , -0.00837133,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00833608],\n",
       "       [-0.00833344,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00834345],\n",
       "       [ 0.        , -0.0085545 ,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00837031],\n",
       "       [ 0.        , -0.00834269,  0.        ],\n",
       "       [ 0.        , -0.00860387,  0.        ],\n",
       "       [ 0.        , -0.00845936,  0.        ],\n",
       "       [-0.01011715,  0.        ,  0.        ],\n",
       "       [ 0.        , -0.00836599,  0.        ],\n",
       "       [ 0.        , -0.00837011,  0.        ],\n",
       "       [-0.00833354,  0.        ,  0.        ],\n",
       "       [ 0.        , -0.00890007,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00834647],\n",
       "       [ 0.        ,  0.        , -0.00834186],\n",
       "       [-0.00833352,  0.        ,  0.        ],\n",
       "       [ 0.        , -0.00839396,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00833347],\n",
       "       [ 0.        ,  0.        , -0.00982455],\n",
       "       [-0.00833344,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00833342],\n",
       "       [-0.00834096,  0.        ,  0.        ],\n",
       "       [ 0.        , -0.0087756 ,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00833842],\n",
       "       [ 0.        ,  0.        , -0.00840414],\n",
       "       [ 0.        , -0.00838712,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00851139],\n",
       "       [ 0.        , -0.00856981,  0.        ],\n",
       "       [ 0.        , -0.00834878,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.0083597 ],\n",
       "       [ 0.        ,  0.        , -0.00879892],\n",
       "       [-0.00833649,  0.        ,  0.        ],\n",
       "       [ 0.        , -0.00835085,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00924144],\n",
       "       [-0.0083334 ,  0.        ,  0.        ],\n",
       "       [ 0.        , -0.00834208,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.00833467]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._nodelist[25]._grad.npar_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_linear_layer(\n",
       "w:myparameter([[-0.5465865  -1.1365149   0.8851863 ]\n",
       " [ 0.47745004 -0.7450613  -0.4789138 ]\n",
       " [ 0.25911197  0.17714854 -0.08043776]\n",
       " [-0.7711505   0.37853917  0.37466738]\n",
       " [ 0.8685523  -0.82236767 -0.59599406]\n",
       " [-0.6842407  -0.68042135  0.6325501 ]\n",
       " [-0.14750935  0.9744143  -1.1336955 ]\n",
       " [ 0.7068196  -0.97089523 -0.5774444 ]\n",
       " [-0.7227318   1.2226455  -1.0053382 ]\n",
       " [-0.3615517   0.56247324 -0.82798433]], tensor32),\n",
       "b:myparameter([[-0.6898719   0.09342609 -0.8802652 ]], tensor32)\n",
       "in_feature:10, out_feature:3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_linear_layer(\n",
       "w:myparameter([[-0.20691593 -0.20642148 -0.5253173  -0.05031373  0.13919987 -0.79240215\n",
       "   0.34794363  0.27541992  0.07065982  0.04959585]\n",
       " [ 0.5583495   0.6173304   0.6260519  -0.3361071  -0.08923443  0.4273993\n",
       "  -0.71896756 -0.31411874 -0.33092985 -0.53446054]\n",
       " [-0.73223215 -0.68009067 -0.22099966  0.5886065  -0.413971   -0.8216021\n",
       "   1.069108    0.97245     0.5466745   0.48937905]\n",
       " [-1.0044916  -0.24838638 -0.8262004  -0.35492924 -1.014545   -0.88128996\n",
       "   0.8814471   1.0404075   1.138127   -0.54916054]], tensor32),\n",
       "b:myparameter([[ 0.2997948   1.0142444   0.2496798   0.69192505  1.3261359   0.5410491\n",
       "   0.27374572  0.34851605 -0.53641826  0.6922423 ]], tensor32)\n",
       "in_feature:4, out_feature:10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_linear_layer(\n",
       "w:myparameter([[-0.0563 -0.0549  0.1685]\n",
       " [ 0.2046 -0.257  -0.2691]\n",
       " [-0.1037 -0.3128  0.308 ]\n",
       " [-0.0737  0.0578  0.1142]\n",
       " [-0.1956 -0.2316  0.0627]\n",
       " [-0.0927 -0.1932 -0.1426]\n",
       " [-0.0953 -0.0461 -0.0726]\n",
       " [-0.0411 -0.2202  0.1837]\n",
       " [-0.0397  0.079   0.0402]\n",
       " [-0.0228  0.3161  0.0071]], tensor32),\n",
       "b:myparameter([[0.0525 0.09   0.1575]], tensor32)\n",
       "in_feature:10, out_feature:3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor32([[-2.71855682e-01 -7.61168838e-01  5.19651890e-01]\n",
       " [ 9.49691236e-03 -2.60993540e-01  2.44601816e-02]\n",
       " [ 5.97541779e-02  1.67577639e-02  1.79710969e-01]\n",
       " [-2.66628027e-01 -7.34584093e-01  5.57383657e-01]\n",
       " [-3.77820224e-01 -9.44918036e-01  7.75303364e-01]\n",
       " [-1.90145671e-01 -2.14561850e-01  5.29756725e-01]\n",
       " [ 4.79216576e-02  3.26436423e-02  1.94376886e-01]\n",
       " [-1.83396742e-01 -6.34305477e-01  4.03407574e-01]\n",
       " [-2.01967135e-01 -6.50328040e-01  4.15840000e-01]\n",
       " [-9.99015719e-02 -4.75028008e-01  1.71764717e-01]\n",
       " [-1.88922703e-01 -2.25691319e-01  5.24638712e-01]\n",
       " [ 3.72859910e-02  1.13430731e-01  1.95637524e-01]\n",
       " [ 3.87379639e-02  4.19836566e-02  2.08069310e-01]\n",
       " [-6.35643154e-02 -4.33607906e-01  1.47575319e-01]\n",
       " [-1.17725417e-01 -5.33396006e-01  2.65427470e-01]\n",
       " [-3.60737234e-01 -7.35887289e-01  8.05676818e-01]\n",
       " [-9.81004089e-02 -8.18742365e-02  3.94138128e-01]\n",
       " [-4.36813347e-02  1.33637205e-01  2.92488575e-01]\n",
       " [ 4.27028909e-02  5.93245775e-03  2.16645673e-01]\n",
       " [-3.10009979e-02  3.42735112e-01  2.70076692e-01]\n",
       " [-1.43445596e-01 -3.01163882e-01  4.86137599e-01]\n",
       " [-8.53776783e-02  2.18894064e-01  3.40655804e-01]\n",
       " [-1.22768298e-01 -2.05206275e-01  4.48939890e-01]\n",
       " [-2.00868890e-01 -6.62015676e-01  4.29360569e-01]\n",
       " [-1.18332848e-01  1.53000072e-01  3.47326458e-01]\n",
       " [-2.11327657e-01 -4.44213361e-01  5.81961751e-01]\n",
       " [-2.00286731e-01 -6.76468492e-01  4.45187926e-01]\n",
       " [-2.06623986e-01 -6.62576318e-01  4.39424545e-01]\n",
       " [-1.27302721e-01 -4.72869486e-01  2.82725513e-01]\n",
       " [-5.89869559e-01 -1.11352479e+00  1.13066125e+00]\n",
       " [-1.20219588e-01 -1.27894506e-01  4.30796921e-01]\n",
       " [-2.65112460e-01 -7.09604025e-01  5.62729001e-01]\n",
       " [-3.11037749e-01 -8.89147758e-01  7.13909030e-01]\n",
       " [-2.02682003e-01 -6.53852940e-01  4.99685436e-01]\n",
       " [-2.30361328e-01 -4.35595125e-01  6.12531543e-01]\n",
       " [-2.16232374e-01 -6.84760094e-01  4.72397655e-01]\n",
       " [-1.18339613e-01 -2.65922576e-01  4.41558182e-01]\n",
       " [-2.24547945e-02  4.27923143e-01  2.38362432e-01]\n",
       " [-3.40173453e-01 -8.88920426e-01  7.22478271e-01]\n",
       " [-4.45773713e-02 -1.47591785e-01  3.64274800e-01]\n",
       " [-2.55615413e-01 -3.56322050e-01  6.35774672e-01]\n",
       " [-2.79362984e-02 -3.72849882e-01  4.76400182e-02]\n",
       " [-6.14538677e-02 -4.54193652e-02  3.45339626e-01]\n",
       " [-1.88922703e-01 -2.25691319e-01  5.24638712e-01]\n",
       " [-3.34179729e-01 -6.64648294e-01  7.87019849e-01]\n",
       " [-1.63629040e-01 -2.61555135e-01  4.98115212e-01]\n",
       " [-2.81513296e-02  2.19187275e-01  3.01059425e-01]\n",
       " [-3.78101826e-01 -6.99878812e-01  8.39499354e-01]\n",
       " [-6.15435354e-02 -4.00301129e-01  1.54702380e-01]\n",
       " [-4.84274864e-01 -9.78145242e-01  9.76510525e-01]\n",
       " [-1.30829602e-01 -6.69705123e-02  4.11422580e-01]\n",
       " [-2.53224790e-01 -7.63105392e-01  5.55926919e-01]\n",
       " [-2.74364769e-01 -8.33658576e-01  6.12663150e-01]\n",
       " [-3.55430812e-01 -7.06202269e-01  7.99969316e-01]\n",
       " [-2.69081444e-04  5.48585914e-02  2.71127880e-01]\n",
       " [-3.06978792e-01 -8.66065621e-01  6.92781925e-01]\n",
       " [-1.47624344e-01 -1.56100705e-01  4.38726097e-01]\n",
       " [-2.33199343e-01 -7.04143643e-01  5.00132382e-01]\n",
       " [-1.72865719e-01 -5.71729779e-01  4.10102338e-01]\n",
       " [-1.78661607e-02  7.05581754e-02  2.76518762e-01]\n",
       " [-3.80566806e-01 -8.61548424e-01  8.41776967e-01]\n",
       " [-4.64979596e-02  1.72398448e-01  3.34090948e-01]\n",
       " [-1.72433615e-01 -1.88139468e-01  5.08442163e-01]\n",
       " [-2.13912740e-01 -1.96832985e-01  5.45991659e-01]\n",
       " [-6.64228797e-02  1.12272687e-01  3.36813629e-01]\n",
       " [-3.11534047e-01 -5.93786001e-01  7.37609506e-01]\n",
       " [-4.58015501e-01 -1.12684953e+00  9.01461244e-01]\n",
       " [-4.60488439e-01 -1.13321114e+00  8.99534702e-01]\n",
       " [-3.23612183e-01 -4.58727449e-01  7.62287736e-01]\n",
       " [-2.10029669e-02  2.15348542e-01  2.58596063e-01]\n",
       " [-3.64676267e-01 -9.38757777e-01  7.66222119e-01]\n",
       " [-1.89151838e-01 -6.34866118e-01  4.13471609e-01]\n",
       " [-4.31129068e-01 -1.07204425e+00  8.61384392e-01]\n",
       " [-1.80968687e-01 -2.51463890e-01  5.42053699e-01]\n",
       " [-3.59656103e-02  2.39330858e-01  3.11601639e-01]\n",
       " [-2.92245597e-01 -7.75661349e-01  6.04084313e-01]\n",
       " [-5.08059151e-02  7.29384273e-02  3.36923778e-01]\n",
       " [-6.47500008e-02  2.45510072e-01  3.36380690e-01]\n",
       " [-3.24274421e-01 -8.80878329e-01  6.95476890e-01]\n",
       " [-6.98836148e-02 -1.12559810e-01  3.85574520e-01]\n",
       " [-4.04139124e-02 -8.14786404e-02  3.40995699e-01]\n",
       " [-9.66673642e-02 -1.05896205e-01  4.01215583e-01]\n",
       " [ 5.94458170e-02  4.20691893e-02  1.47103876e-01]\n",
       " [-4.09099869e-02  1.27051488e-01  3.35890830e-01]\n",
       " [-1.52252406e-01 -5.52148819e-01  3.09158176e-01]\n",
       " [-2.57622711e-02  8.88137221e-02  3.13214898e-01]\n",
       " [-5.31100146e-02 -1.55830398e-01  3.73453438e-01]\n",
       " [-4.61278148e-02  4.33117598e-02  3.19564760e-01]\n",
       " [-2.47730598e-01 -5.96877217e-01  6.53462648e-01]\n",
       " [-2.94960737e-01 -5.66783309e-01  7.02208757e-01]\n",
       " [-3.23517881e-02 -6.97634518e-02  3.33530366e-01]\n",
       " [-5.91737926e-01 -1.47031379e+00  1.13641167e+00]\n",
       " [ 6.76787645e-03 -2.39750817e-02  2.75102288e-01]\n",
       " [-2.97913998e-01 -5.11025548e-01  6.95662022e-01]\n",
       " [-1.34692386e-01 -5.52779675e-01  2.93162197e-01]\n",
       " [-1.27638176e-01 -2.88335800e-01  4.59038854e-01]\n",
       " [-7.68821836e-02  1.45922005e-01  3.14106047e-01]\n",
       " [-3.35665606e-02  2.24885747e-01  2.96342492e-01]\n",
       " [-1.45192221e-01 -5.37247539e-01  3.16853762e-01]\n",
       " [-4.71338928e-01 -9.53437328e-01  9.50069785e-01]\n",
       " [-4.69337367e-02  2.00850874e-01  3.37007463e-01]\n",
       " [-2.51625739e-02  1.27231136e-01  2.57771462e-01]\n",
       " [-2.30651096e-01 -6.96861148e-01  4.59463716e-01]\n",
       " [-6.06417693e-02  1.16486110e-01  3.61047685e-01]\n",
       " [-3.30704927e-01 -9.32767034e-01  7.42933393e-01]\n",
       " [ 3.43900919e-02  5.71078360e-02  2.03725561e-01]\n",
       " [-8.63604993e-02  1.05684742e-01  3.28110665e-01]\n",
       " [-9.25342441e-02  2.50408873e-02  3.33365381e-01]\n",
       " [-1.73858017e-01 -3.66090119e-01  5.36424458e-01]\n",
       " [-5.26792891e-02  8.39613751e-02  3.01199675e-01]\n",
       " [-2.26804242e-01 -4.25651878e-01  6.46098018e-01]\n",
       " [-3.88149172e-03 -9.09148902e-02  3.15266490e-01]\n",
       " [-1.70996442e-01 -2.29605556e-01  5.08161664e-01]\n",
       " [-8.91784877e-02 -3.85255218e-02  3.66705596e-01]\n",
       " [-1.64321154e-01 -6.09956264e-01  3.92756939e-01]\n",
       " [-8.95947516e-02 -2.64616132e-01  4.37749863e-01]\n",
       " [-3.91287684e-01 -6.63318515e-01  8.30923080e-01]\n",
       " [-7.44085014e-03 -3.91210943e-01  3.63722816e-02]\n",
       " [-2.25384280e-01 -4.73529369e-01  6.19517684e-01]\n",
       " [-5.63310273e-02  1.29366264e-01  3.43957216e-01]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2(relu(layer1(MT.mytensor(np.array(X_train_tensor)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7181e-01, -7.6111e-01,  5.1969e-01],\n",
       "        [ 9.5367e-03, -2.6091e-01,  2.4433e-02],\n",
       "        [ 5.9741e-02,  1.6805e-02,  1.7962e-01],\n",
       "        [-2.6659e-01, -7.3454e-01,  5.5743e-01],\n",
       "        [-3.7779e-01, -9.4494e-01,  7.7540e-01],\n",
       "        [-1.9015e-01, -2.1464e-01,  5.2961e-01],\n",
       "        [ 4.7917e-02,  3.2693e-02,  1.9429e-01],\n",
       "        [-1.8336e-01, -6.3424e-01,  4.0343e-01],\n",
       "        [-2.0193e-01, -6.5026e-01,  4.1586e-01],\n",
       "        [-9.9853e-02, -4.7492e-01,  1.7174e-01],\n",
       "        [-1.8890e-01, -2.2577e-01,  5.2450e-01],\n",
       "        [ 3.7285e-02,  1.1348e-01,  1.9557e-01],\n",
       "        [ 3.8727e-02,  4.2026e-02,  2.0797e-01],\n",
       "        [-6.3522e-02, -4.3350e-01,  1.4755e-01],\n",
       "        [-1.1769e-01, -5.3331e-01,  2.6543e-01],\n",
       "        [-3.6075e-01, -7.3604e-01,  8.0567e-01],\n",
       "        [-9.8097e-02, -8.1897e-02,  3.9402e-01],\n",
       "        [-4.3681e-02,  1.3367e-01,  2.9238e-01],\n",
       "        [ 4.2686e-02,  5.9622e-03,  2.1656e-01],\n",
       "        [-3.1006e-02,  3.4278e-01,  2.6996e-01],\n",
       "        [-1.4344e-01, -3.0120e-01,  4.8609e-01],\n",
       "        [-8.5397e-02,  2.1891e-01,  3.4049e-01],\n",
       "        [-1.2275e-01, -2.0522e-01,  4.4887e-01],\n",
       "        [-2.0083e-01, -6.6196e-01,  4.2939e-01],\n",
       "        [-1.1834e-01,  1.5300e-01,  3.4716e-01],\n",
       "        [-2.1134e-01, -4.4429e-01,  5.8194e-01],\n",
       "        [-2.0026e-01, -6.7644e-01,  4.4524e-01],\n",
       "        [-2.0659e-01, -6.6252e-01,  4.3945e-01],\n",
       "        [-1.2726e-01, -4.7279e-01,  2.8271e-01],\n",
       "        [-5.8988e-01, -1.1138e+00,  1.1307e+00],\n",
       "        [-1.2022e-01, -1.2793e-01,  4.3067e-01],\n",
       "        [-2.6508e-01, -7.0957e-01,  5.6277e-01],\n",
       "        [-3.1103e-01, -8.8917e-01,  7.1400e-01],\n",
       "        [-2.0266e-01, -6.5383e-01,  4.9973e-01],\n",
       "        [-2.3036e-01, -4.3568e-01,  6.1249e-01],\n",
       "        [-2.1620e-01, -6.8471e-01,  4.7243e-01],\n",
       "        [-1.1833e-01, -2.6593e-01,  4.4152e-01],\n",
       "        [-2.2491e-02,  4.2793e-01,  2.3831e-01],\n",
       "        [-3.4015e-01, -8.8893e-01,  7.2256e-01],\n",
       "        [-4.4592e-02, -1.4761e-01,  3.6420e-01],\n",
       "        [-2.5559e-01, -3.5645e-01,  6.3564e-01],\n",
       "        [-2.7887e-02, -3.7272e-01,  4.7591e-02],\n",
       "        [-6.1442e-02, -4.5409e-02,  3.4522e-01],\n",
       "        [-1.8890e-01, -2.2577e-01,  5.2450e-01],\n",
       "        [-3.3422e-01, -6.6483e-01,  7.8699e-01],\n",
       "        [-1.6361e-01, -2.6158e-01,  4.9806e-01],\n",
       "        [-2.8148e-02,  2.1922e-01,  3.0095e-01],\n",
       "        [-3.7811e-01, -7.0006e-01,  8.3946e-01],\n",
       "        [-6.1504e-02, -4.0020e-01,  1.5468e-01],\n",
       "        [-4.8427e-01, -9.7833e-01,  9.7653e-01],\n",
       "        [-1.3083e-01, -6.7008e-02,  4.1127e-01],\n",
       "        [-2.5320e-01, -7.6309e-01,  5.5599e-01],\n",
       "        [-2.7434e-01, -8.3366e-01,  6.1274e-01],\n",
       "        [-3.5544e-01, -7.0635e-01,  7.9995e-01],\n",
       "        [-2.7870e-04,  5.4893e-02,  2.7102e-01],\n",
       "        [-3.0696e-01, -8.6608e-01,  6.9287e-01],\n",
       "        [-1.4759e-01, -1.5615e-01,  4.3855e-01],\n",
       "        [-2.3317e-01, -7.0410e-01,  5.0017e-01],\n",
       "        [-1.7284e-01, -5.7168e-01,  4.1013e-01],\n",
       "        [-1.7859e-02,  7.0600e-02,  2.7643e-01],\n",
       "        [-3.8056e-01, -8.6168e-01,  8.4180e-01],\n",
       "        [-4.6512e-02,  1.7244e-01,  3.3396e-01],\n",
       "        [-1.7242e-01, -1.8820e-01,  5.0833e-01],\n",
       "        [-2.1389e-01, -1.9693e-01,  5.4587e-01],\n",
       "        [-6.6442e-02,  1.1230e-01,  3.3665e-01],\n",
       "        [-3.1154e-01, -5.9392e-01,  7.3757e-01],\n",
       "        [-4.5800e-01, -1.1269e+00,  9.0157e-01],\n",
       "        [-4.6046e-01, -1.1333e+00,  8.9965e-01],\n",
       "        [-3.2361e-01, -4.5889e-01,  7.6219e-01],\n",
       "        [-2.1019e-02,  2.1538e-01,  2.5847e-01],\n",
       "        [-3.6465e-01, -9.3879e-01,  7.6632e-01],\n",
       "        [-1.8912e-01, -6.3480e-01,  4.1350e-01],\n",
       "        [-4.3111e-01, -1.0721e+00,  8.6149e-01],\n",
       "        [-1.8097e-01, -2.5155e-01,  5.4194e-01],\n",
       "        [-3.5964e-02,  2.3936e-01,  3.1149e-01],\n",
       "        [-2.9221e-01, -7.7565e-01,  6.0415e-01],\n",
       "        [-5.0812e-02,  7.2961e-02,  3.3678e-01],\n",
       "        [-6.4741e-02,  2.4554e-01,  3.3626e-01],\n",
       "        [-3.2425e-01, -8.8089e-01,  6.9556e-01],\n",
       "        [-6.9878e-02, -1.1257e-01,  3.8549e-01],\n",
       "        [-4.0422e-02, -8.1484e-02,  3.4089e-01],\n",
       "        [-9.6665e-02, -1.0592e-01,  4.0109e-01],\n",
       "        [ 5.9433e-02,  4.2121e-02,  1.4702e-01],\n",
       "        [-4.0903e-02,  1.2708e-01,  3.3576e-01],\n",
       "        [-1.5221e-01, -5.5207e-01,  3.0916e-01],\n",
       "        [-2.5774e-02,  8.8851e-02,  3.1308e-01],\n",
       "        [-5.3110e-02, -1.5583e-01,  3.7338e-01],\n",
       "        [-4.6131e-02,  4.3332e-02,  3.1944e-01],\n",
       "        [-2.4774e-01, -5.9697e-01,  6.5345e-01],\n",
       "        [-2.9495e-01, -5.6688e-01,  7.0218e-01],\n",
       "        [-3.2345e-02, -6.9749e-02,  3.3344e-01],\n",
       "        [-5.9174e-01, -1.4705e+00,  1.1366e+00],\n",
       "        [ 6.7591e-03, -2.3956e-02,  2.7500e-01],\n",
       "        [-2.9791e-01, -5.1114e-01,  6.9562e-01],\n",
       "        [-1.3465e-01, -5.5270e-01,  2.9317e-01],\n",
       "        [-1.2763e-01, -2.8835e-01,  4.5899e-01],\n",
       "        [-7.6890e-02,  1.4594e-01,  3.1396e-01],\n",
       "        [-3.3567e-02,  2.2491e-01,  2.9622e-01],\n",
       "        [-1.4515e-01, -5.3717e-01,  3.1686e-01],\n",
       "        [-4.7133e-01, -9.5361e-01,  9.5010e-01],\n",
       "        [-4.6934e-02,  2.0088e-01,  3.3687e-01],\n",
       "        [-2.5177e-02,  1.2725e-01,  2.5764e-01],\n",
       "        [-2.3061e-01, -6.9680e-01,  4.5949e-01],\n",
       "        [-6.0637e-02,  1.1651e-01,  3.6090e-01],\n",
       "        [-3.3069e-01, -9.3280e-01,  7.4303e-01],\n",
       "        [ 3.4375e-02,  5.7148e-02,  2.0362e-01],\n",
       "        [-8.6373e-02,  1.0569e-01,  3.2796e-01],\n",
       "        [-9.2511e-02,  2.5031e-02,  3.3320e-01],\n",
       "        [-1.7386e-01, -3.6614e-01,  5.3638e-01],\n",
       "        [-5.2679e-02,  8.3985e-02,  3.0108e-01],\n",
       "        [-2.2684e-01, -4.2580e-01,  6.4602e-01],\n",
       "        [-3.9035e-03, -9.0920e-02,  3.1519e-01],\n",
       "        [-1.7097e-01, -2.2967e-01,  5.0803e-01],\n",
       "        [-8.9152e-02, -3.8530e-02,  3.6658e-01],\n",
       "        [-1.6429e-01, -6.0990e-01,  3.9279e-01],\n",
       "        [-8.9611e-02, -2.6465e-01,  4.3769e-01],\n",
       "        [-3.9126e-01, -6.6349e-01,  8.3086e-01],\n",
       "        [-7.3981e-03, -3.9109e-01,  3.6336e-02],\n",
       "        [-2.2540e-01, -4.7362e-01,  6.1948e-01],\n",
       "        [-5.6342e-02,  1.2940e-01,  3.4381e-01]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc2(torch.relu(model.fc1(X_train_tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFsubs=(res1torch.detach().numpy()-res1my.npar_data)<0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([120, 120, 120, 120, 120, 120, 120, 120, 120, 120])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyTensor\n",
      "Lf1 tensor32(31.0)\n",
      "x_grad tensor32([13.])\n",
      "y_grad tensor32([12.])\n",
      "f = 31.0\n",
      "Gradient of x (df/dx) = 13.0\n",
      "Gradient of y (df/dy) = 12.0\n",
      "Expected df/dx = 13.0\n",
      "Expected df/dy = 12.0\n",
      "Gradients match expected values!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import MyTensor as MT\n",
    "import Loss\n",
    "import numpy as np\n",
    "\n",
    "def test_gradient():\n",
    "\n",
    "    x = torch.tensor(2.0, requires_grad=True)\n",
    "    y = torch.tensor(3.0, requires_grad=True)\n",
    "    \n",
    "    mtx = MT.mytensor(np.array([2.0]))\n",
    "    mty = MT.mytensor(np.array([3.0]))\n",
    "\n",
    "    #print(mtx,mty)\n",
    "\n",
    "    class Lf(Loss.loss):\n",
    "        def __init__(self,comment=None):\n",
    "            super().__init__(comment)\n",
    "        def _loss(self, pred=None, label=None):\n",
    "            temp1 = MT.dot(mtx,mtx)\n",
    "            temp2 = MT.dot(mtx,mty)\n",
    "            temp3 = MT.dot(mty,mty)\n",
    "            return MT.add(temp1,MT.add(3*temp2,temp3))\n",
    "\n",
    "\n",
    "    f = x**2 + 3 * x * y + y**2\n",
    "\n",
    "\n",
    "    Lf1 = Lf()\n",
    "    Lf1(None,None)\n",
    "    Lf1.backward(mode='force')\n",
    "\n",
    "    f.backward()\n",
    "\n",
    "    print(\"MyTensor\")\n",
    "    print(\"Lf1\", Lf1._tensorloss)\n",
    "    print(\"x_grad\", mtx._grad)\n",
    "    print(\"y_grad\", mty._grad)\n",
    "\n",
    "    print(\"f =\", f.item())\n",
    "    print(\"Gradient of x (df/dx) =\", x.grad.item())\n",
    "    print(\"Gradient of y (df/dy) =\", y.grad.item())\n",
    "\n",
    "\n",
    "    expected_grad_x = 2 * x.item() + 3 * y.item()\n",
    "    expected_grad_y = 3 * x.item() + 2 * y.item()\n",
    "    print(\"Expected df/dx =\", expected_grad_x)\n",
    "    print(\"Expected df/dy =\", expected_grad_y)\n",
    "\n",
    "\n",
    "    assert torch.isclose(x.grad, torch.tensor(expected_grad_x)), \"x gradient mismatch\"\n",
    "    assert torch.isclose(y.grad, torch.tensor(expected_grad_y)), \"y gradient mismatch\"\n",
    "    print(\"Gradients match expected values!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_gradient()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "cg = MT.mytensor.computegraph\n",
    "simple_DiG=nx.DiGraph()\n",
    "for i in cg._edgelist:\n",
    "    simple_DiG.add_edge(i['from'],i['to'])\n",
    "nx.draw_networkx(simple_DiG,pos=nx.spring_layout(simple_DiG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [2], '_cg_ascend': [], '_grad_f': tensor32([[ 0.12471187 -0.084971    0.06914134  0.04172961]\n",
      " [ 0.12471198 -0.08497108  0.0691414   0.04172962]\n",
      " [-0.01829926 -0.01804726  0.13736257  0.2221632 ]\n",
      " [ 0.12471411 -0.08497252  0.06914227  0.04172983]\n",
      " [ 0.12471245 -0.0849714   0.06914158  0.04172967]\n",
      " [ 0.02468698  0.02740471 -0.14751449 -0.23312378]\n",
      " [-0.01861994 -0.01821938  0.13893643  0.2247088 ]\n",
      " [ 0.12472337 -0.08497889  0.06914608  0.04173072]\n",
      " [ 0.12471302 -0.08497179  0.06914182  0.04172972]\n",
      " [ 0.12471189 -0.08497101  0.06914136  0.04172962]\n",
      " [ 0.0246447   0.02737424 -0.1472813  -0.23274854]\n",
      " [-0.10133414  0.09645997  0.0006414   0.08341423]\n",
      " [-0.0187145  -0.01845911  0.1400246   0.22642255]\n",
      " [ 0.12471309 -0.08497185  0.06914186  0.04172973]\n",
      " [ 0.12471963 -0.08497632  0.06914455  0.04173036]\n",
      " [-0.06017826 -0.01218989  0.08374501  0.17520781]\n",
      " [ 0.02828715  0.03126367 -0.17154604 -0.27152124]\n",
      " [ 0.02481441  0.02758269 -0.14850177 -0.2346938 ]\n",
      " [-0.01832114 -0.01807507  0.137523    0.22241874]\n",
      " [-0.05230846  0.09037028 -0.09707578 -0.15916526]\n",
      " [-0.0643567   0.04444235  0.08283781  0.15408024]\n",
      " [ 0.02456665  0.02727527 -0.14670976 -0.23183808]\n",
      " [-0.0580909   0.01718766  0.13606781  0.1902437 ]\n",
      " [ 0.12471715 -0.08497462  0.06914353  0.04173011]\n",
      " [ 0.02456759  0.02727623 -0.14671588 -0.23184785]\n",
      " [-0.06800601  0.01489565  0.03583812  0.14727491]\n",
      " [ 0.12473556 -0.08498724  0.06915111  0.04173188]\n",
      " [ 0.12471445 -0.08497276  0.06914241  0.04172986]\n",
      " [ 0.12471272 -0.08497159  0.06914172  0.04172971]\n",
      " [-0.06019228 -0.01218665  0.08375923  0.17523721]\n",
      " [ 0.02515117  0.02790883 -0.15063469 -0.23810804]\n",
      " [ 0.12471513 -0.08497324  0.06914269  0.04172993]\n",
      " [ 0.12495591 -0.08513825  0.06924186  0.04175288]\n",
      " [ 0.12476331 -0.08500625  0.06916258  0.04173459]\n",
      " [-0.01833892 -0.01803443  0.13744456  0.22230414]\n",
      " [ 0.12472589 -0.08498061  0.06914712  0.04173095]\n",
      " [-0.11662726  0.11447581  0.02613377  0.0939967 ]\n",
      " [-0.00526169  0.05934844 -0.10767801 -0.20679145]\n",
      " [ 0.12471445 -0.08497276  0.0691424   0.04172985]\n",
      " [-0.01827038 -0.01801191  0.13715526  0.22183272]\n",
      " [ 0.02458997  0.02730385 -0.14687721 -0.23210499]\n",
      " [ 0.12471201 -0.08497109  0.06914141  0.04172963]\n",
      " [ 0.02544133  0.02839347 -0.15314488 -0.24208754]\n",
      " [ 0.0246447   0.02737424 -0.1472813  -0.23274854]\n",
      " [-0.01820343 -0.0179807   0.13684231  0.2213254 ]\n",
      " [-0.05912239  0.01775319  0.13735788  0.19225918]\n",
      " [-0.0789627   0.09269889 -0.08759614 -0.10009214]\n",
      " [-0.01832524 -0.01809181  0.13759115  0.2225254 ]\n",
      " [ 0.12471394 -0.08497242  0.06914221  0.04172983]\n",
      " [-0.14168666  0.07511578 -0.01018813  0.06111959]\n",
      " [ 0.02464808  0.02736469 -0.14726035 -0.23271742]\n",
      " [ 0.12472691 -0.08498131  0.06914754  0.04173106]\n",
      " [ 0.12473913 -0.08498969  0.06915257  0.04173221]\n",
      " [-0.06018843 -0.01219428  0.08378095  0.17526828]\n",
      " [-0.0221558  -0.02211862  0.1628994   0.26297697]\n",
      " [ 0.12476027 -0.08500417  0.06916128  0.04173423]\n",
      " [-0.07877323  0.09249275 -0.08738767 -0.09985968]\n",
      " [ 0.12471917 -0.084976    0.06914435  0.04173031]\n",
      " [ 0.12471652 -0.08497418  0.0691433   0.04173012]\n",
      " [ 0.07129125 -0.09560342  0.1184978   0.17957175]\n",
      " [-0.1946366   0.1455582  -0.06699102  0.00124979]\n",
      " [-0.00526026  0.05933844 -0.10765734 -0.206753  ]\n",
      " [-0.02269457 -0.02268131  0.16644686  0.26864776]\n",
      " [ 0.02695839  0.02983126 -0.16264957 -0.257308  ]\n",
      " [ 0.024566    0.02727457 -0.14670537 -0.23183107]\n",
      " [-0.06030598 -0.01225831  0.08424719  0.1760447 ]\n",
      " [ 0.12472084 -0.08497715  0.06914505  0.04173046]\n",
      " [ 0.12471312 -0.08497185  0.06914186  0.04172972]\n",
      " [ 0.02672717  0.02956645 -0.1610501  -0.2547554 ]\n",
      " [ 0.02472866  0.02745294 -0.14780445 -0.23358643]\n",
      " [ 0.12471874 -0.0849757   0.06914418  0.04173028]\n",
      " [ 0.1247175  -0.08497487  0.06914368  0.04173015]\n",
      " [ 0.12471524 -0.08497331  0.06914272  0.04172994]\n",
      " [-0.02054266 -0.02044451  0.15231304  0.24605228]\n",
      " [-0.07882658  0.09255089 -0.08744638 -0.09992519]\n",
      " [ 0.12471233 -0.08497132  0.06914154  0.04172967]\n",
      " [ 0.02457994  0.02729106 -0.14680356 -0.23198768]\n",
      " [-0.07877047  0.09248982 -0.08738463 -0.09985633]\n",
      " [ 0.12471624 -0.08497399  0.06914315  0.04173003]\n",
      " [-0.01868095 -0.01838257  0.13966668  0.22585797]\n",
      " [-0.01892877 -0.01872126  0.14156213  0.22887337]\n",
      " [ 0.02536783  0.0281625  -0.15215167 -0.24052802]\n",
      " [-0.01833271 -0.01808948  0.13760689  0.2225524 ]\n",
      " [-0.07879138  0.09251254 -0.08740764 -0.09988197]\n",
      " [ 0.12471236 -0.08497134  0.06914155  0.04172966]\n",
      " [ 0.02459049  0.0273037  -0.14687839 -0.23210701]\n",
      " [-0.01865932 -0.01817301  0.1389068   0.22467738]\n",
      " [ 0.02463567  0.02735911 -0.14720303 -0.23262444]\n",
      " [-0.06801369  0.01490436  0.0358218   0.14725648]\n",
      " [-0.09933291  0.02339168  0.0782631   0.13702275]\n",
      " [-0.01855789 -0.01820545  0.1386959   0.224315  ]\n",
      " [ 0.14172083 -0.12078328  0.08572654  0.06425004]\n",
      " [-0.01828663 -0.01805362  0.13734399  0.22212991]\n",
      " [-0.01830713 -0.01802899  0.13732696  0.22211108]\n",
      " [ 0.12471589 -0.08497376  0.069143    0.04172999]\n",
      " [-0.15931232  0.12071674 -0.02719996  0.04792336]\n",
      " [ 0.02461224  0.02732394 -0.14701341 -0.23232329]\n",
      " [-0.00526758  0.05938758 -0.10775823 -0.20694044]\n",
      " [ 0.12471309 -0.08497184  0.06914186  0.04172974]\n",
      " [-0.19468449  0.1455958  -0.06701114  0.00124325]\n",
      " [-0.07876433  0.09248315 -0.08737789 -0.09984881]\n",
      " [ 0.02583136  0.0286213  -0.15512016 -0.24527791]\n",
      " [ 0.12471241 -0.08497137  0.06914156  0.04172966]\n",
      " [-0.03171453  0.06144673 -0.0979511  -0.14742206]\n",
      " [ 0.12481131 -0.08503915  0.06918231  0.04173909]\n",
      " [-0.01889685 -0.01867524  0.1413101   0.22847274]\n",
      " [ 0.02459219  0.02730242 -0.14687946 -0.23210928]\n",
      " [ 0.02469238  0.02742216 -0.14758903 -0.23324078]\n",
      " [-0.01830436 -0.01799206  0.13719624  0.22190836]\n",
      " [ 0.02480212  0.02754468 -0.14833769 -0.23443612]\n",
      " [-0.01837113 -0.01815656  0.13794887  0.22309415]\n",
      " [-0.01825264 -0.01801099  0.13709661  0.22173578]\n",
      " [-0.02258263  0.05848918 -0.13651636 -0.18477122]\n",
      " [ 0.02492931  0.02780362 -0.14959162 -0.23641756]\n",
      " [ 0.12483838 -0.08505771  0.06919346  0.04174169]\n",
      " [-0.01824234 -0.01799481  0.13701092  0.22159979]\n",
      " [ 0.02538712  0.02843303 -0.15310556 -0.24200714]\n",
      " [ 0.1247175  -0.08497487  0.06914367  0.04173015]\n",
      " [-0.01822822 -0.01798872  0.1369465   0.22149518]\n",
      " [ 0.02457168  0.02728099 -0.14674443 -0.23189342]]), 'grad': tensor32([[ 0.12471187 -0.084971    0.06914134  0.04172961]\n",
      " [ 0.12471198 -0.08497108  0.0691414   0.04172962]\n",
      " [-0.01829926 -0.01804726  0.13736257  0.2221632 ]\n",
      " [ 0.12471411 -0.08497252  0.06914227  0.04172983]\n",
      " [ 0.12471245 -0.0849714   0.06914158  0.04172967]\n",
      " [ 0.02468698  0.02740471 -0.14751449 -0.23312378]\n",
      " [-0.01861994 -0.01821938  0.13893643  0.2247088 ]\n",
      " [ 0.12472337 -0.08497889  0.06914608  0.04173072]\n",
      " [ 0.12471302 -0.08497179  0.06914182  0.04172972]\n",
      " [ 0.12471189 -0.08497101  0.06914136  0.04172962]\n",
      " [ 0.0246447   0.02737424 -0.1472813  -0.23274854]\n",
      " [-0.10133414  0.09645997  0.0006414   0.08341423]\n",
      " [-0.0187145  -0.01845911  0.1400246   0.22642255]\n",
      " [ 0.12471309 -0.08497185  0.06914186  0.04172973]\n",
      " [ 0.12471963 -0.08497632  0.06914455  0.04173036]\n",
      " [-0.06017826 -0.01218989  0.08374501  0.17520781]\n",
      " [ 0.02828715  0.03126367 -0.17154604 -0.27152124]\n",
      " [ 0.02481441  0.02758269 -0.14850177 -0.2346938 ]\n",
      " [-0.01832114 -0.01807507  0.137523    0.22241874]\n",
      " [-0.05230846  0.09037028 -0.09707578 -0.15916526]\n",
      " [-0.0643567   0.04444235  0.08283781  0.15408024]\n",
      " [ 0.02456665  0.02727527 -0.14670976 -0.23183808]\n",
      " [-0.0580909   0.01718766  0.13606781  0.1902437 ]\n",
      " [ 0.12471715 -0.08497462  0.06914353  0.04173011]\n",
      " [ 0.02456759  0.02727623 -0.14671588 -0.23184785]\n",
      " [-0.06800601  0.01489565  0.03583812  0.14727491]\n",
      " [ 0.12473556 -0.08498724  0.06915111  0.04173188]\n",
      " [ 0.12471445 -0.08497276  0.06914241  0.04172986]\n",
      " [ 0.12471272 -0.08497159  0.06914172  0.04172971]\n",
      " [-0.06019228 -0.01218665  0.08375923  0.17523721]\n",
      " [ 0.02515117  0.02790883 -0.15063469 -0.23810804]\n",
      " [ 0.12471513 -0.08497324  0.06914269  0.04172993]\n",
      " [ 0.12495591 -0.08513825  0.06924186  0.04175288]\n",
      " [ 0.12476331 -0.08500625  0.06916258  0.04173459]\n",
      " [-0.01833892 -0.01803443  0.13744456  0.22230414]\n",
      " [ 0.12472589 -0.08498061  0.06914712  0.04173095]\n",
      " [-0.11662726  0.11447581  0.02613377  0.0939967 ]\n",
      " [-0.00526169  0.05934844 -0.10767801 -0.20679145]\n",
      " [ 0.12471445 -0.08497276  0.0691424   0.04172985]\n",
      " [-0.01827038 -0.01801191  0.13715526  0.22183272]\n",
      " [ 0.02458997  0.02730385 -0.14687721 -0.23210499]\n",
      " [ 0.12471201 -0.08497109  0.06914141  0.04172963]\n",
      " [ 0.02544133  0.02839347 -0.15314488 -0.24208754]\n",
      " [ 0.0246447   0.02737424 -0.1472813  -0.23274854]\n",
      " [-0.01820343 -0.0179807   0.13684231  0.2213254 ]\n",
      " [-0.05912239  0.01775319  0.13735788  0.19225918]\n",
      " [-0.0789627   0.09269889 -0.08759614 -0.10009214]\n",
      " [-0.01832524 -0.01809181  0.13759115  0.2225254 ]\n",
      " [ 0.12471394 -0.08497242  0.06914221  0.04172983]\n",
      " [-0.14168666  0.07511578 -0.01018813  0.06111959]\n",
      " [ 0.02464808  0.02736469 -0.14726035 -0.23271742]\n",
      " [ 0.12472691 -0.08498131  0.06914754  0.04173106]\n",
      " [ 0.12473913 -0.08498969  0.06915257  0.04173221]\n",
      " [-0.06018843 -0.01219428  0.08378095  0.17526828]\n",
      " [-0.0221558  -0.02211862  0.1628994   0.26297697]\n",
      " [ 0.12476027 -0.08500417  0.06916128  0.04173423]\n",
      " [-0.07877323  0.09249275 -0.08738767 -0.09985968]\n",
      " [ 0.12471917 -0.084976    0.06914435  0.04173031]\n",
      " [ 0.12471652 -0.08497418  0.0691433   0.04173012]\n",
      " [ 0.07129125 -0.09560342  0.1184978   0.17957175]\n",
      " [-0.1946366   0.1455582  -0.06699102  0.00124979]\n",
      " [-0.00526026  0.05933844 -0.10765734 -0.206753  ]\n",
      " [-0.02269457 -0.02268131  0.16644686  0.26864776]\n",
      " [ 0.02695839  0.02983126 -0.16264957 -0.257308  ]\n",
      " [ 0.024566    0.02727457 -0.14670537 -0.23183107]\n",
      " [-0.06030598 -0.01225831  0.08424719  0.1760447 ]\n",
      " [ 0.12472084 -0.08497715  0.06914505  0.04173046]\n",
      " [ 0.12471312 -0.08497185  0.06914186  0.04172972]\n",
      " [ 0.02672717  0.02956645 -0.1610501  -0.2547554 ]\n",
      " [ 0.02472866  0.02745294 -0.14780445 -0.23358643]\n",
      " [ 0.12471874 -0.0849757   0.06914418  0.04173028]\n",
      " [ 0.1247175  -0.08497487  0.06914368  0.04173015]\n",
      " [ 0.12471524 -0.08497331  0.06914272  0.04172994]\n",
      " [-0.02054266 -0.02044451  0.15231304  0.24605228]\n",
      " [-0.07882658  0.09255089 -0.08744638 -0.09992519]\n",
      " [ 0.12471233 -0.08497132  0.06914154  0.04172967]\n",
      " [ 0.02457994  0.02729106 -0.14680356 -0.23198768]\n",
      " [-0.07877047  0.09248982 -0.08738463 -0.09985633]\n",
      " [ 0.12471624 -0.08497399  0.06914315  0.04173003]\n",
      " [-0.01868095 -0.01838257  0.13966668  0.22585797]\n",
      " [-0.01892877 -0.01872126  0.14156213  0.22887337]\n",
      " [ 0.02536783  0.0281625  -0.15215167 -0.24052802]\n",
      " [-0.01833271 -0.01808948  0.13760689  0.2225524 ]\n",
      " [-0.07879138  0.09251254 -0.08740764 -0.09988197]\n",
      " [ 0.12471236 -0.08497134  0.06914155  0.04172966]\n",
      " [ 0.02459049  0.0273037  -0.14687839 -0.23210701]\n",
      " [-0.01865932 -0.01817301  0.1389068   0.22467738]\n",
      " [ 0.02463567  0.02735911 -0.14720303 -0.23262444]\n",
      " [-0.06801369  0.01490436  0.0358218   0.14725648]\n",
      " [-0.09933291  0.02339168  0.0782631   0.13702275]\n",
      " [-0.01855789 -0.01820545  0.1386959   0.224315  ]\n",
      " [ 0.14172083 -0.12078328  0.08572654  0.06425004]\n",
      " [-0.01828663 -0.01805362  0.13734399  0.22212991]\n",
      " [-0.01830713 -0.01802899  0.13732696  0.22211108]\n",
      " [ 0.12471589 -0.08497376  0.069143    0.04172999]\n",
      " [-0.15931232  0.12071674 -0.02719996  0.04792336]\n",
      " [ 0.02461224  0.02732394 -0.14701341 -0.23232329]\n",
      " [-0.00526758  0.05938758 -0.10775823 -0.20694044]\n",
      " [ 0.12471309 -0.08497184  0.06914186  0.04172974]\n",
      " [-0.19468449  0.1455958  -0.06701114  0.00124325]\n",
      " [-0.07876433  0.09248315 -0.08737789 -0.09984881]\n",
      " [ 0.02583136  0.0286213  -0.15512016 -0.24527791]\n",
      " [ 0.12471241 -0.08497137  0.06914156  0.04172966]\n",
      " [-0.03171453  0.06144673 -0.0979511  -0.14742206]\n",
      " [ 0.12481131 -0.08503915  0.06918231  0.04173909]\n",
      " [-0.01889685 -0.01867524  0.1413101   0.22847274]\n",
      " [ 0.02459219  0.02730242 -0.14687946 -0.23210928]\n",
      " [ 0.02469238  0.02742216 -0.14758903 -0.23324078]\n",
      " [-0.01830436 -0.01799206  0.13719624  0.22190836]\n",
      " [ 0.02480212  0.02754468 -0.14833769 -0.23443612]\n",
      " [-0.01837113 -0.01815656  0.13794887  0.22309415]\n",
      " [-0.01825264 -0.01801099  0.13709661  0.22173578]\n",
      " [-0.02258263  0.05848918 -0.13651636 -0.18477122]\n",
      " [ 0.02492931  0.02780362 -0.14959162 -0.23641756]\n",
      " [ 0.12483838 -0.08505771  0.06919346  0.04174169]\n",
      " [-0.01824234 -0.01799481  0.13701092  0.22159979]\n",
      " [ 0.02538712  0.02843303 -0.15310556 -0.24200714]\n",
      " [ 0.1247175  -0.08497487  0.06914367  0.04173015]\n",
      " [-0.01822822 -0.01798872  0.1369465   0.22149518]\n",
      " [ 0.02457168  0.02728099 -0.14674443 -0.23189342]]), 'npar_data': array([[-1.5065205e+00,  1.2492011e+00, -1.5675763e+00, -1.3154444e+00],\n",
      "       [-1.7367394e-01,  3.0907753e+00, -1.2833891e+00, -1.0521799e+00],\n",
      "       [ 1.0380048e+00,  9.8217286e-02,  3.6489627e-01,  2.6414192e-01],\n",
      "       [-1.2641848e+00,  7.8880757e-01, -1.2265517e+00, -1.3154444e+00],\n",
      "       [-1.7488563e+00,  3.2841405e-01, -1.3970640e+00, -1.3154444e+00],\n",
      "       [ 5.5333328e-01, -1.2829633e+00,  7.0592082e-01,  9.2230284e-01],\n",
      "       [ 6.7450112e-01,  3.2841405e-01,  4.2173371e-01,  3.9577410e-01],\n",
      "       [-7.7951330e-01,  1.0190043e+00, -1.2833891e+00, -1.3154444e+00],\n",
      "       [-1.0218490e+00,  1.2492011e+00, -1.3402265e+00, -1.3154444e+00],\n",
      "       [-7.7951330e-01,  2.4001849e+00, -1.2833891e+00, -1.4470764e+00],\n",
      "       [-5.2506078e-02, -8.2256979e-01,  7.6275826e-01,  9.2230284e-01],\n",
      "       [ 1.8982966e-01,  7.8880757e-01,  4.2173371e-01,  5.2740628e-01],\n",
      "       [ 1.0380048e+00,  9.8217286e-02,  5.3540856e-01,  3.9577410e-01],\n",
      "       [-5.3717756e-01,  1.9397914e+00, -1.3970640e+00, -1.0521799e+00],\n",
      "       [-5.3717756e-01,  1.4793979e+00, -1.2833891e+00, -1.3154444e+00],\n",
      "       [-4.1600969e-01, -1.5131601e+00, -3.2965709e-02, -2.6238683e-01],\n",
      "       [ 5.5333328e-01, -5.9237301e-01,  7.6275826e-01,  3.9577410e-01],\n",
      "       [ 6.7450112e-01,  9.8217286e-02,  9.9010795e-01,  7.9067063e-01],\n",
      "       [ 9.1683686e-01, -1.3197948e-01,  3.6489627e-01,  2.6414192e-01],\n",
      "       [ 1.6438441e+00,  1.2492011e+00,  1.3311325e+00,  1.7120960e+00],\n",
      "       [-1.7367394e-01, -3.6217624e-01,  2.5122142e-01,  1.3250974e-01],\n",
      "       [ 2.1285155e+00, -1.3197948e-01,  1.6153197e+00,  1.1855673e+00],\n",
      "       [-2.9484183e-01, -1.3197948e-01,  4.2173371e-01,  3.9577410e-01],\n",
      "       [-9.0068120e-01,  1.0190043e+00, -1.3402265e+00, -1.3154444e+00],\n",
      "       [ 2.2496834e+00, -5.9237301e-01,  1.6721570e+00,  1.0539351e+00],\n",
      "       [-5.2506078e-02, -8.2256979e-01,  1.9438399e-01, -2.6238683e-01],\n",
      "       [-7.7951330e-01,  7.8880757e-01, -1.3402265e+00, -1.3154444e+00],\n",
      "       [-1.0218490e+00,  1.0190043e+00, -1.3970640e+00, -1.1838121e+00],\n",
      "       [-9.0068120e-01,  1.7095946e+00, -1.0560393e+00, -1.0521799e+00],\n",
      "       [-1.0218490e+00, -2.4339471e+00, -1.4664055e-01, -2.6238683e-01],\n",
      "       [ 5.5333328e-01, -8.2256979e-01,  6.4908344e-01,  7.9067063e-01],\n",
      "       [-1.2641848e+00,  7.8880757e-01, -1.0560393e+00, -1.3154444e+00],\n",
      "       [-1.0218490e+00, -1.3197948e-01, -1.2265517e+00, -1.3154444e+00],\n",
      "       [-9.0068120e-01,  5.5861080e-01, -1.1697142e+00, -9.2054772e-01],\n",
      "       [-2.9484183e-01, -8.2256979e-01,  2.5122142e-01,  1.3250974e-01],\n",
      "       [-9.0068120e-01,  7.8880757e-01, -1.2833891e+00, -1.3154444e+00],\n",
      "       [-1.7367394e-01, -1.3197948e-01,  2.5122142e-01,  8.7754789e-04],\n",
      "       [ 2.2496834e+00,  1.7095946e+00,  1.6721570e+00,  1.3171993e+00],\n",
      "       [-1.5065205e+00,  3.2841405e-01, -1.3402265e+00, -1.3154444e+00],\n",
      "       [ 4.3216541e-01, -3.6217624e-01,  3.0805886e-01,  1.3250974e-01],\n",
      "       [-1.7367394e-01, -1.2829633e+00,  7.0592082e-01,  1.0539351e+00],\n",
      "       [-4.1600969e-01,  2.6303818e+00, -1.3402265e+00, -1.3154444e+00],\n",
      "       [ 1.8982966e-01, -1.3197948e-01,  5.9224600e-01,  7.9067063e-01],\n",
      "       [-5.2506078e-02, -8.2256979e-01,  7.6275826e-01,  9.2230284e-01],\n",
      "       [ 1.8982966e-01, -1.9735537e+00,  1.3754657e-01, -2.6238683e-01],\n",
      "       [-5.3717756e-01, -1.3197948e-01,  4.2173371e-01,  3.9577410e-01],\n",
      "       [ 4.3216541e-01,  7.8880757e-01,  9.3327057e-01,  1.4488316e+00],\n",
      "       [-4.1600969e-01, -1.7433568e+00,  1.3754657e-01,  1.3250974e-01],\n",
      "       [-5.3717756e-01,  1.9397914e+00, -1.1697142e+00, -1.0521799e+00],\n",
      "       [-1.0218490e+00, -1.7433568e+00, -2.6031542e-01, -2.6238683e-01],\n",
      "       [ 6.7450112e-01, -8.2256979e-01,  8.7643313e-01,  9.2230284e-01],\n",
      "       [-1.0218490e+00,  5.5861080e-01, -1.3402265e+00, -1.3154444e+00],\n",
      "       [-1.0218490e+00,  3.2841405e-01, -1.4539014e+00, -1.3154444e+00],\n",
      "       [-4.1600969e-01, -1.5131601e+00,  2.3871720e-02, -1.3075463e-01],\n",
      "       [ 1.0380048e+00, -1.3197948e-01,  7.0592082e-01,  6.5903848e-01],\n",
      "       [-1.1430169e+00,  9.8217286e-02, -1.2833891e+00, -1.3154444e+00],\n",
      "       [-5.2506078e-02, -5.9237301e-01,  7.6275826e-01,  1.5804638e+00],\n",
      "       [-1.0218490e+00,  7.8880757e-01, -1.2833891e+00, -1.3154444e+00],\n",
      "       [-1.0218490e+00,  1.0190043e+00, -1.2265517e+00, -7.8891557e-01],\n",
      "       [ 6.8661794e-02,  3.2841405e-01,  5.9224600e-01,  7.9067063e-01],\n",
      "       [-9.0068120e-01, -1.2829633e+00, -4.3082771e-01, -1.3075463e-01],\n",
      "       [ 1.2803406e+00,  3.2841405e-01,  1.1037828e+00,  1.4488316e+00],\n",
      "       [ 1.8982966e-01, -8.2256979e-01,  7.6275826e-01,  5.2740628e-01],\n",
      "       [ 3.1099755e-01, -1.0527666e+00,  1.0469455e+00,  2.6414192e-01],\n",
      "       [ 2.2496834e+00, -1.3197948e-01,  1.3311325e+00,  1.4488316e+00],\n",
      "       [-4.1600969e-01, -1.2829633e+00,  1.3754657e-01,  1.3250974e-01],\n",
      "       [-1.7488563e+00, -3.6217624e-01, -1.3402265e+00, -1.3154444e+00],\n",
      "       [-1.8700241e+00, -1.3197948e-01, -1.5107388e+00, -1.4470764e+00],\n",
      "       [ 1.8982966e-01, -1.9735537e+00,  7.0592082e-01,  3.9577410e-01],\n",
      "       [ 1.6438441e+00,  3.2841405e-01,  1.2742951e+00,  7.9067063e-01],\n",
      "       [-1.5065205e+00,  9.8217286e-02, -1.2833891e+00, -1.3154444e+00],\n",
      "       [-9.0068120e-01,  1.0190043e+00, -1.3402265e+00, -1.1838121e+00],\n",
      "       [-1.7488563e+00, -1.3197948e-01, -1.3970640e+00, -1.3154444e+00],\n",
      "       [ 5.5333328e-01, -1.2829633e+00,  6.4908344e-01,  3.9577410e-01],\n",
      "       [ 5.5333328e-01,  7.8880757e-01,  1.0469455e+00,  1.5804638e+00],\n",
      "       [-1.5065205e+00,  7.8880757e-01, -1.3402265e+00, -1.1838121e+00],\n",
      "       [ 1.1591727e+00, -1.3197948e-01,  9.9010795e-01,  1.1855673e+00],\n",
      "       [ 5.5333328e-01,  5.5861080e-01,  1.2742951e+00,  1.7120960e+00],\n",
      "       [-1.3853526e+00,  3.2841405e-01, -1.3970640e+00, -1.3154444e+00],\n",
      "       [ 3.1099755e-01, -3.6217624e-01,  5.3540856e-01,  2.6414192e-01],\n",
      "       [ 7.9566902e-01, -5.9237301e-01,  4.7857115e-01,  3.9577410e-01],\n",
      "       [ 4.3216541e-01, -5.9237301e-01,  5.9224600e-01,  7.9067063e-01],\n",
      "       [ 1.4015083e+00,  3.2841405e-01,  5.3540856e-01,  2.6414192e-01],\n",
      "       [ 6.7450112e-01,  3.2841405e-01,  8.7643313e-01,  1.4488316e+00],\n",
      "       [-9.0068120e-01,  1.7095946e+00, -1.2265517e+00, -1.3154444e+00],\n",
      "       [ 1.2803406e+00,  9.8217286e-02,  9.3327057e-01,  1.1855673e+00],\n",
      "       [ 6.8661794e-02, -1.3197948e-01,  2.5122142e-01,  3.9577410e-01],\n",
      "       [ 7.9566902e-01, -1.3197948e-01,  8.1959569e-01,  1.0539351e+00],\n",
      "       [-1.7367394e-01, -1.0527666e+00, -1.4664055e-01, -2.6238683e-01],\n",
      "       [-7.7951330e-01, -8.2256979e-01,  8.0709144e-02,  2.6414192e-01],\n",
      "       [ 3.1099755e-01, -1.3197948e-01,  4.7857115e-01,  2.6414192e-01],\n",
      "       [-1.6276884e+00, -1.7433568e+00, -1.3970640e+00, -1.1838121e+00],\n",
      "       [ 9.1683686e-01, -3.6217624e-01,  4.7857115e-01,  1.3250974e-01],\n",
      "       [-4.1600969e-01, -1.0527666e+00,  3.6489627e-01,  8.7754789e-04],\n",
      "       [-6.5834540e-01,  1.4793979e+00, -1.2833891e+00, -1.3154444e+00],\n",
      "       [-2.9484183e-01, -1.3197948e-01,  1.9438399e-01,  1.3250974e-01],\n",
      "       [ 1.7650120e+00, -3.6217624e-01,  1.4448074e+00,  7.9067063e-01],\n",
      "       [ 1.0380048e+00,  5.5861080e-01,  1.1037828e+00,  1.1855673e+00],\n",
      "       [-9.0068120e-01,  1.4793979e+00, -1.2833891e+00, -1.0521799e+00],\n",
      "       [-1.1430169e+00, -1.5131601e+00, -2.6031542e-01, -2.6238683e-01],\n",
      "       [ 1.0380048e+00,  5.5861080e-01,  1.1037828e+00,  1.7120960e+00],\n",
      "       [ 1.6438441e+00, -1.3197948e-01,  1.1606202e+00,  5.2740628e-01],\n",
      "       [-1.1430169e+00,  1.2492011e+00, -1.3402265e+00, -1.4470764e+00],\n",
      "       [ 1.0380048e+00,  9.8217286e-02,  1.0469455e+00,  1.5804638e+00],\n",
      "       [-1.1430169e+00, -1.3197948e-01, -1.3402265e+00, -1.3154444e+00],\n",
      "       [ 1.2803406e+00,  9.8217286e-02,  6.4908344e-01,  3.9577410e-01],\n",
      "       [ 1.8861798e+00, -5.9237301e-01,  1.3311325e+00,  9.2230284e-01],\n",
      "       [ 5.5333328e-01, -3.6217624e-01,  1.0469455e+00,  7.9067063e-01],\n",
      "       [-1.7367394e-01, -5.9237301e-01,  1.9438399e-01,  1.3250974e-01],\n",
      "       [ 7.9566902e-01, -1.3197948e-01,  9.9010795e-01,  7.9067063e-01],\n",
      "       [ 5.5333328e-01, -1.7433568e+00,  3.6489627e-01,  1.3250974e-01],\n",
      "       [ 6.7450112e-01, -3.6217624e-01,  3.0805886e-01,  1.3250974e-01],\n",
      "       [-2.9484183e-01, -5.9237301e-01,  6.4908344e-01,  1.0539351e+00],\n",
      "       [ 6.8661794e-02, -1.3197948e-01,  7.6275826e-01,  7.9067063e-01],\n",
      "       [-5.3717756e-01,  7.8880757e-01, -1.1697142e+00, -1.3154444e+00],\n",
      "       [ 3.1099755e-01, -5.9237301e-01,  1.3754657e-01,  1.3250974e-01],\n",
      "       [-1.1430169e+00, -1.2829633e+00,  4.2173371e-01,  6.5903848e-01],\n",
      "       [-5.2506078e-02,  2.1699882e+00, -1.4539014e+00, -1.3154444e+00],\n",
      "       [-5.2506078e-02, -1.0527666e+00,  1.3754657e-01,  8.7754789e-04],\n",
      "       [ 1.5226762e+00, -1.3197948e-01,  1.2174577e+00,  1.1855673e+00]],\n",
      "      dtype=float32), 'shape': (120, 4)}\n",
      "==================================\n",
      "1\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [2], '_cg_ascend': [], '_grad_f': tensor32([[-1.2731211   0.9299848   0.         -0.870614    1.7791085  -0.9271074\n",
      "   1.2971213   1.4957967  -0.37150478  0.07777094]\n",
      " [-1.2100147  -1.2488086   0.          0.695135   -2.519009   -0.58342934\n",
      "   1.1278945  -1.8509722   2.8138888   0.983989  ]\n",
      " [-1.2789072   1.5120082   0.         -1.1683072   2.6301575  -0.95403147\n",
      "   1.0185858   2.1791482  -1.1515125  -0.14696647]\n",
      " [-1.6910678   1.4544145   0.         -1.1004534   2.48558    -1.2205572\n",
      "   1.1629702   2.0532196  -0.8485754  -0.0583169 ]]), 'grad': tensor32([[-1.2731211   0.9299848   0.         -0.870614    1.7791085  -0.9271074\n",
      "   1.2971213   1.4957967  -0.37150478  0.07777094]\n",
      " [-1.2100147  -1.2488086   0.          0.695135   -2.519009   -0.58342934\n",
      "   1.1278945  -1.8509722   2.8138888   0.983989  ]\n",
      " [-1.2789072   1.5120082   0.         -1.1683072   2.6301575  -0.95403147\n",
      "   1.0185858   2.1791482  -1.1515125  -0.14696647]\n",
      " [-1.6910678   1.4544145   0.         -1.1004534   2.48558    -1.2205572\n",
      "   1.1629702   2.0532196  -0.8485754  -0.0583169 ]]), 'npar_data': array([[ 0.784984  , -0.8764669 , -0.13726951,  0.24448678, -0.8746909 ,\n",
      "         0.8911599 ,  0.40001345, -0.13819207,  0.8022238 ,  0.6174983 ],\n",
      "       [-1.0514857 ,  0.8102416 ,  0.03325998, -0.69030243,  0.12049541,\n",
      "        -0.6259413 , -0.03193145,  0.47818777, -0.52917415, -0.6637637 ],\n",
      "       [ 0.8504453 , -0.14801179, -0.06607606,  0.30801174, -1.1065223 ,\n",
      "         0.9953512 , -0.1466548 , -0.84581524, -0.18031809, -0.808585  ],\n",
      "       [ 0.90028536, -0.9183311 ,  0.31801304,  0.47559074, -0.9610271 ,\n",
      "         1.1643059 , -0.8969186 , -0.4932232 , -0.8112155 , -0.51948196]],\n",
      "      dtype=float32), 'shape': (4, 10), '_is_para': True}\n",
      "==================================\n",
      "2\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [6], '_cg_ascend': [0, 1], '_grad_f': tensor32([[ 0.         -0.02387252  0.         ... -0.035341    0.03613661\n",
      "   0.01807759]\n",
      " [ 0.         -0.02387254  0.         ... -0.03534104  0.03613665\n",
      "   0.01807761]\n",
      " [ 0.05705399  0.          0.         ...  0.         -0.06139434\n",
      "  -0.02828485]\n",
      " ...\n",
      " [ 0.         -0.0238738   0.         ... -0.03534276  0.03613866\n",
      "   0.01807857]\n",
      " [ 0.05688089  0.          0.         ...  0.         -0.06119867\n",
      "  -0.02816384]\n",
      " [-0.04427791  0.          0.         ...  0.          0.05028728\n",
      "   0.04141196]]), 'grad': tensor32([[ 0.         -0.02387252  0.         ... -0.035341    0.03613661\n",
      "   0.01807759]\n",
      " [ 0.         -0.02387254  0.         ... -0.03534104  0.03613665\n",
      "   0.01807761]\n",
      " [ 0.05705399  0.          0.         ...  0.         -0.06139434\n",
      "  -0.02828485]\n",
      " ...\n",
      " [ 0.         -0.0238738   0.         ... -0.03534276  0.03613866\n",
      "   0.01807857]\n",
      " [ 0.05688089  0.          0.         ...  0.         -0.06119867\n",
      "  -0.02816384]\n",
      " [-0.04427791  0.          0.         ...  0.          0.05028728\n",
      "   0.04141196]]), 'npar_data': array([[-5.0135245 ,  3.772603  , -0.06640144, ...,  2.7802296 ,\n",
      "        -0.51984036,  0.19142011],\n",
      "       [-5.4249516 ,  3.8127003 , -0.12316636, ...,  3.1064408 ,\n",
      "        -0.6899208 , -0.5744701 ],\n",
      "       [ 1.2596705 , -1.1267757 , -0.07933004, ..., -0.5353935 ,\n",
      "         0.50066465,  0.14350653],\n",
      "       ...,\n",
      "       [-4.7436666 ,  3.2274425 , -0.24287912, ...,  2.9234574 ,\n",
      "         0.13885033,  0.3861707 ],\n",
      "       [ 1.1835183 , -0.8281398 , -0.03661698, ..., -0.612936  ,\n",
      "         0.4894612 ,  0.55469185],\n",
      "       [ 3.4367812 , -2.7104518 ,  0.08317439, ..., -1.8880262 ,\n",
      "         0.11008698, -0.57244563]], dtype=float32), 'shape': (120, 10)}\n",
      "==================================\n",
      "3\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [5], '_cg_ascend': [], '_grad_f': tensor32([[ 0.03049011]\n",
      " [ 0.03049016]\n",
      " [-0.20202255]\n",
      " [ 0.0304911 ]\n",
      " [ 0.03049037]\n",
      " [ 0.16860752]\n",
      " [-0.20419604]\n",
      " [ 0.03049523]\n",
      " [ 0.03049062]\n",
      " [ 0.03049012]\n",
      " [ 0.16829342]\n",
      " [-0.11390397]\n",
      " [-0.2055064 ]\n",
      " [ 0.03049066]\n",
      " [ 0.03049356]\n",
      " [-0.1957068 ]\n",
      " [ 0.19983359]\n",
      " [ 0.1698594 ]\n",
      " [-0.20222774]\n",
      " [ 0.07172512]\n",
      " [-0.15974542]\n",
      " [ 0.16756223]\n",
      " [-0.19273008]\n",
      " [ 0.03049245]\n",
      " [ 0.16757019]\n",
      " [-0.17003433]\n",
      " [ 0.03050065]\n",
      " [ 0.03049125]\n",
      " [ 0.03049047]\n",
      " [-0.19574183]\n",
      " [ 0.17265694]\n",
      " [ 0.03049156]\n",
      " [ 0.03059874]\n",
      " [ 0.03051294]\n",
      " [-0.20217049]\n",
      " [ 0.03049634]\n",
      " [-0.13771723]\n",
      " [ 0.12154335]\n",
      " [ 0.03049125]\n",
      " [-0.20175645]\n",
      " [ 0.16777714]\n",
      " [ 0.03049017]\n",
      " [ 0.17578867]\n",
      " [ 0.16829342]\n",
      " [-0.20131946]\n",
      " [-0.19513631]\n",
      " [-0.00359903]\n",
      " [-0.20230708]\n",
      " [ 0.03049102]\n",
      " [-0.15268528]\n",
      " [ 0.16827603]\n",
      " [ 0.0304968 ]\n",
      " [ 0.03050225]\n",
      " [-0.19575997]\n",
      " [-0.23525123]\n",
      " [ 0.03051165]\n",
      " [-0.00363443]\n",
      " [ 0.03049335]\n",
      " [ 0.03049212]\n",
      " [-0.1294911 ]\n",
      " [-0.13133565]\n",
      " [ 0.12151705]\n",
      " [-0.2398718 ]\n",
      " [ 0.1882798 ]\n",
      " [ 0.16755652]\n",
      " [-0.1964296 ]\n",
      " [ 0.0304941 ]\n",
      " [ 0.03049067]\n",
      " [ 0.18621418]\n",
      " [ 0.16898164]\n",
      " [ 0.03049316]\n",
      " [ 0.03049262]\n",
      " [ 0.03049161]\n",
      " [-0.22145438]\n",
      " [-0.00362478]\n",
      " [ 0.03049032]\n",
      " [ 0.16768296]\n",
      " [-0.00363522]\n",
      " [ 0.03049205]\n",
      " [-0.2050717 ]\n",
      " [-0.20747995]\n",
      " [ 0.17461202]\n",
      " [-0.20233524]\n",
      " [-0.00363119]\n",
      " [ 0.03049033]\n",
      " [ 0.16777919]\n",
      " [-0.20422381]\n",
      " [ 0.16819578]\n",
      " [-0.1700283 ]\n",
      " [-0.18132317]\n",
      " [-0.20384413]\n",
      " [ 0.07869286]\n",
      " [-0.20198353]\n",
      " [-0.20199624]\n",
      " [ 0.0304919 ]\n",
      " [-0.13262843]\n",
      " [ 0.16795692]\n",
      " [ 0.12164481]\n",
      " [ 0.03049065]\n",
      " [-0.13136707]\n",
      " [-0.00363638]\n",
      " [ 0.17849769]\n",
      " [ 0.03049035]\n",
      " [ 0.04614635]\n",
      " [ 0.03053437]\n",
      " [-0.20716125]\n",
      " [ 0.1677829 ]\n",
      " [ 0.16869566]\n",
      " [-0.20185186]\n",
      " [ 0.16966479]\n",
      " [-0.20276022]\n",
      " [-0.20166671]\n",
      " [ 0.11813691]\n",
      " [ 0.17120236]\n",
      " [ 0.03054642]\n",
      " [-0.2015592 ]\n",
      " [ 0.17566447]\n",
      " [ 0.03049263]\n",
      " [-0.20146872]\n",
      " [ 0.16760702]]), 'grad': tensor32([[ 0.03049011]\n",
      " [ 0.03049016]\n",
      " [-0.20202255]\n",
      " [ 0.0304911 ]\n",
      " [ 0.03049037]\n",
      " [ 0.16860752]\n",
      " [-0.20419604]\n",
      " [ 0.03049523]\n",
      " [ 0.03049062]\n",
      " [ 0.03049012]\n",
      " [ 0.16829342]\n",
      " [-0.11390397]\n",
      " [-0.2055064 ]\n",
      " [ 0.03049066]\n",
      " [ 0.03049356]\n",
      " [-0.1957068 ]\n",
      " [ 0.19983359]\n",
      " [ 0.1698594 ]\n",
      " [-0.20222774]\n",
      " [ 0.07172512]\n",
      " [-0.15974542]\n",
      " [ 0.16756223]\n",
      " [-0.19273008]\n",
      " [ 0.03049245]\n",
      " [ 0.16757019]\n",
      " [-0.17003433]\n",
      " [ 0.03050065]\n",
      " [ 0.03049125]\n",
      " [ 0.03049047]\n",
      " [-0.19574183]\n",
      " [ 0.17265694]\n",
      " [ 0.03049156]\n",
      " [ 0.03059874]\n",
      " [ 0.03051294]\n",
      " [-0.20217049]\n",
      " [ 0.03049634]\n",
      " [-0.13771723]\n",
      " [ 0.12154335]\n",
      " [ 0.03049125]\n",
      " [-0.20175645]\n",
      " [ 0.16777714]\n",
      " [ 0.03049017]\n",
      " [ 0.17578867]\n",
      " [ 0.16829342]\n",
      " [-0.20131946]\n",
      " [-0.19513631]\n",
      " [-0.00359903]\n",
      " [-0.20230708]\n",
      " [ 0.03049102]\n",
      " [-0.15268528]\n",
      " [ 0.16827603]\n",
      " [ 0.0304968 ]\n",
      " [ 0.03050225]\n",
      " [-0.19575997]\n",
      " [-0.23525123]\n",
      " [ 0.03051165]\n",
      " [-0.00363443]\n",
      " [ 0.03049335]\n",
      " [ 0.03049212]\n",
      " [-0.1294911 ]\n",
      " [-0.13133565]\n",
      " [ 0.12151705]\n",
      " [-0.2398718 ]\n",
      " [ 0.1882798 ]\n",
      " [ 0.16755652]\n",
      " [-0.1964296 ]\n",
      " [ 0.0304941 ]\n",
      " [ 0.03049067]\n",
      " [ 0.18621418]\n",
      " [ 0.16898164]\n",
      " [ 0.03049316]\n",
      " [ 0.03049262]\n",
      " [ 0.03049161]\n",
      " [-0.22145438]\n",
      " [-0.00362478]\n",
      " [ 0.03049032]\n",
      " [ 0.16768296]\n",
      " [-0.00363522]\n",
      " [ 0.03049205]\n",
      " [-0.2050717 ]\n",
      " [-0.20747995]\n",
      " [ 0.17461202]\n",
      " [-0.20233524]\n",
      " [-0.00363119]\n",
      " [ 0.03049033]\n",
      " [ 0.16777919]\n",
      " [-0.20422381]\n",
      " [ 0.16819578]\n",
      " [-0.1700283 ]\n",
      " [-0.18132317]\n",
      " [-0.20384413]\n",
      " [ 0.07869286]\n",
      " [-0.20198353]\n",
      " [-0.20199624]\n",
      " [ 0.0304919 ]\n",
      " [-0.13262843]\n",
      " [ 0.16795692]\n",
      " [ 0.12164481]\n",
      " [ 0.03049065]\n",
      " [-0.13136707]\n",
      " [-0.00363638]\n",
      " [ 0.17849769]\n",
      " [ 0.03049035]\n",
      " [ 0.04614635]\n",
      " [ 0.03053437]\n",
      " [-0.20716125]\n",
      " [ 0.1677829 ]\n",
      " [ 0.16869566]\n",
      " [-0.20185186]\n",
      " [ 0.16966479]\n",
      " [-0.20276022]\n",
      " [-0.20166671]\n",
      " [ 0.11813691]\n",
      " [ 0.17120236]\n",
      " [ 0.03054642]\n",
      " [-0.2015592 ]\n",
      " [ 0.17566447]\n",
      " [ 0.03049263]\n",
      " [-0.20146872]\n",
      " [ 0.16760702]]), 'npar_data': array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]], dtype=float32), 'shape': (120, 1)}\n",
      "==================================\n",
      "4\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [5], '_cg_ascend': [], '_grad_f': tensor32([[ 0.39227873 -0.67682976  0.         -1.7151966  -1.4994833   0.08313452\n",
      "   0.10508615 -1.1382366   0.6379584   0.91118085]]), 'grad': tensor32([[ 0.39227873 -0.67682976  0.         -1.7151966  -1.4994833   0.08313452\n",
      "   0.10508615 -1.1382366   0.6379584   0.91118085]]), 'npar_data': array([[-0.33027405,  0.38017938, -0.4435005 ,  0.9881284 ,  0.1170668 ,\n",
      "        -0.024523  ,  1.1395146 ,  0.45329037,  0.8488572 ,  0.9533681 ]],\n",
      "      dtype=float32), 'shape': (1, 10), '_is_para': True}\n",
      "==================================\n",
      "5\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [6], '_cg_ascend': [3, 4], '_grad_f': tensor32([[ 0.         -0.02387252  0.         ... -0.035341    0.03613661\n",
      "   0.01807759]\n",
      " [ 0.         -0.02387254  0.         ... -0.03534104  0.03613665\n",
      "   0.01807761]\n",
      " [ 0.05705399  0.          0.         ...  0.         -0.06139434\n",
      "  -0.02828485]\n",
      " ...\n",
      " [ 0.         -0.0238738   0.         ... -0.03534276  0.03613866\n",
      "   0.01807857]\n",
      " [ 0.05688089  0.          0.         ...  0.         -0.06119867\n",
      "  -0.02816384]\n",
      " [-0.04427791  0.          0.         ...  0.          0.05028728\n",
      "   0.04141196]]), 'grad': tensor32([[ 0.         -0.02387252  0.         ... -0.035341    0.03613661\n",
      "   0.01807759]\n",
      " [ 0.         -0.02387254  0.         ... -0.03534104  0.03613665\n",
      "   0.01807761]\n",
      " [ 0.05705399  0.          0.         ...  0.         -0.06139434\n",
      "  -0.02828485]\n",
      " ...\n",
      " [ 0.         -0.0238738   0.         ... -0.03534276  0.03613866\n",
      "   0.01807857]\n",
      " [ 0.05688089  0.          0.         ...  0.         -0.06119867\n",
      "  -0.02816384]\n",
      " [-0.04427791  0.          0.         ...  0.          0.05028728\n",
      "   0.04141196]]), 'npar_data': array([[-0.33027405,  0.38017938, -0.4435005 , ...,  0.45329037,\n",
      "         0.8488572 ,  0.9533681 ],\n",
      "       [-0.33027405,  0.38017938, -0.4435005 , ...,  0.45329037,\n",
      "         0.8488572 ,  0.9533681 ],\n",
      "       [-0.33027405,  0.38017938, -0.4435005 , ...,  0.45329037,\n",
      "         0.8488572 ,  0.9533681 ],\n",
      "       ...,\n",
      "       [-0.33027405,  0.38017938, -0.4435005 , ...,  0.45329037,\n",
      "         0.8488572 ,  0.9533681 ],\n",
      "       [-0.33027405,  0.38017938, -0.4435005 , ...,  0.45329037,\n",
      "         0.8488572 ,  0.9533681 ],\n",
      "       [-0.33027405,  0.38017938, -0.4435005 , ...,  0.45329037,\n",
      "         0.8488572 ,  0.9533681 ]], dtype=float32), 'shape': (120, 10)}\n",
      "==================================\n",
      "6\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [8], '_cg_ascend': [2, 5], '_grad_f': tensor32([[ 0.         -0.01989377  0.         ... -0.02945083  0.03011385\n",
      "   0.01506466]\n",
      " [ 0.         -0.01989379  0.         ... -0.02945087  0.03011389\n",
      "   0.01506468]\n",
      " [ 0.04758303  0.          0.         ...  0.         -0.05120562\n",
      "  -0.02359758]\n",
      " ...\n",
      " [ 0.         -0.01989505  0.         ... -0.0294526   0.03011589\n",
      "   0.01506564]\n",
      " [ 0.04740993  0.          0.         ...  0.         -0.05100996\n",
      "  -0.02347656]\n",
      " [-0.03690136  0.          0.         ...  0.          0.04190946\n",
      "   0.03451209]]), 'grad': tensor32([[ 0.         -0.01989377  0.         ... -0.02945083  0.03011385\n",
      "   0.01506466]\n",
      " [ 0.         -0.01989379  0.         ... -0.02945087  0.03011389\n",
      "   0.01506468]\n",
      " [ 0.04758303  0.          0.         ...  0.         -0.05120562\n",
      "  -0.02359758]\n",
      " ...\n",
      " [ 0.         -0.01989505  0.         ... -0.0294526   0.03011589\n",
      "   0.01506564]\n",
      " [ 0.04740993  0.          0.         ...  0.         -0.05100996\n",
      "  -0.02347656]\n",
      " [-0.03690136  0.          0.         ...  0.          0.04190946\n",
      "   0.03451209]]), 'npar_data': array([[-5.3437986 ,  4.1527824 , -0.50990194, ...,  3.23352   ,\n",
      "         0.32901686,  1.1447883 ],\n",
      "       [-5.7552257 ,  4.1928797 , -0.56666684, ...,  3.5597312 ,\n",
      "         0.15893644,  0.37889802],\n",
      "       [ 0.92939645, -0.74659634, -0.52283055, ..., -0.0821031 ,\n",
      "         1.3495219 ,  1.0968747 ],\n",
      "       ...,\n",
      "       [-5.0739408 ,  3.607622  , -0.6863796 , ...,  3.3767478 ,\n",
      "         0.98770756,  1.3395388 ],\n",
      "       [ 0.85324425, -0.4479604 , -0.48011747, ..., -0.15964565,\n",
      "         1.3383185 ,  1.50806   ],\n",
      "       [ 3.106507  , -2.3302724 , -0.3603261 , ..., -1.4347359 ,\n",
      "         0.9589442 ,  0.3809225 ]], dtype=float32), 'shape': (120, 10)}\n",
      "==================================\n",
      "7\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [8], '_cg_ascend': [], '_grad_f': tensor32([[-0.12170199 -0.08261447  0.00550507 ... -0.09522986  0.00990796\n",
      "   0.01724585]\n",
      " [-0.13107194 -0.08341227  0.00611793 ... -0.10483719  0.00478619\n",
      "   0.00570798]\n",
      " [ 0.0442235  -0.02320689  0.00387365 ... -0.00332609 -0.06910311\n",
      "  -0.02588358]\n",
      " ...\n",
      " [-0.11555299 -0.07177382  0.00741044 ... -0.099454    0.02974569\n",
      "   0.020181  ]\n",
      " [ 0.04045225 -0.01391206  0.00354688 ... -0.0064611  -0.06826757\n",
      "  -0.03540406]\n",
      " [-0.11463435 -0.04649455 -0.00120852 ... -0.03451504  0.04018883\n",
      "   0.01314643]]), 'grad': tensor32([[-0.12170199 -0.08261447  0.00550507 ... -0.09522986  0.00990796\n",
      "   0.01724585]\n",
      " [-0.13107194 -0.08341227  0.00611793 ... -0.10483719  0.00478619\n",
      "   0.00570798]\n",
      " [ 0.0442235  -0.02320689  0.00387365 ... -0.00332609 -0.06910311\n",
      "  -0.02588358]\n",
      " ...\n",
      " [-0.11555299 -0.07177382  0.00741044 ... -0.099454    0.02974569\n",
      "   0.020181  ]\n",
      " [ 0.04045225 -0.01391206  0.00354688 ... -0.0064611  -0.06826757\n",
      "  -0.03540406]\n",
      " [-0.11463435 -0.04649455 -0.00120852 ... -0.03451504  0.04018883\n",
      "   0.01314643]]), 'npar_data': array([[0., 1., 0., ..., 1., 1., 1.],\n",
      "       [0., 1., 0., ..., 1., 1., 1.],\n",
      "       [1., 0., 0., ..., 0., 1., 1.],\n",
      "       ...,\n",
      "       [0., 1., 0., ..., 1., 1., 1.],\n",
      "       [1., 0., 0., ..., 0., 1., 1.],\n",
      "       [1., 0., 0., ..., 0., 1., 1.]], dtype=float32), 'shape': (120, 10)}\n",
      "==================================\n",
      "8\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [10], '_cg_ascend': [6, 7], '_grad_f': tensor32([[ 0.01821955 -0.01591501 -0.00863707 ... -0.02356067  0.02409108\n",
      "   0.01205173]\n",
      " [ 0.01821953 -0.01591504 -0.00863707 ... -0.02356071  0.02409112\n",
      "   0.01205175]\n",
      " [ 0.03811207  0.02487473 -0.00593275 ...  0.0324203  -0.04101691\n",
      "  -0.0189103 ]\n",
      " ...\n",
      " [ 0.01821893 -0.0159163  -0.00863715 ... -0.02356244  0.02409313\n",
      "   0.0120527 ]\n",
      " [ 0.03793897  0.02484761 -0.00591129 ...  0.0323807  -0.04082125\n",
      "  -0.01878928]\n",
      " [-0.02952481  0.01596146  0.00268364 ...  0.01924469  0.03353164\n",
      "   0.02761222]]), 'grad': tensor32([[ 0.01821955 -0.01591501 -0.00863707 ... -0.02356067  0.02409108\n",
      "   0.01205173]\n",
      " [ 0.01821953 -0.01591504 -0.00863707 ... -0.02356071  0.02409112\n",
      "   0.01205175]\n",
      " [ 0.03811207  0.02487473 -0.00593275 ...  0.0324203  -0.04101691\n",
      "  -0.0189103 ]\n",
      " ...\n",
      " [ 0.01821893 -0.0159163  -0.00863715 ... -0.02356244  0.02409313\n",
      "   0.0120527 ]\n",
      " [ 0.03793897  0.02484761 -0.00591129 ...  0.0323807  -0.04082125\n",
      "  -0.01878928]\n",
      " [-0.02952481  0.01596146  0.00268364 ...  0.01924469  0.03353164\n",
      "   0.02761222]]), 'npar_data': array([[-0.        ,  4.1527824 , -0.        , ...,  3.23352   ,\n",
      "         0.32901686,  1.1447883 ],\n",
      "       [-0.        ,  4.1928797 , -0.        , ...,  3.5597312 ,\n",
      "         0.15893644,  0.37889802],\n",
      "       [ 0.92939645, -0.        , -0.        , ..., -0.        ,\n",
      "         1.3495219 ,  1.0968747 ],\n",
      "       ...,\n",
      "       [-0.        ,  3.607622  , -0.        , ...,  3.3767478 ,\n",
      "         0.98770756,  1.3395388 ],\n",
      "       [ 0.85324425, -0.        , -0.        , ..., -0.        ,\n",
      "         1.3383185 ,  1.50806   ],\n",
      "       [ 3.106507  , -0.        , -0.        , ..., -0.        ,\n",
      "         0.9589442 ,  0.3809225 ]], dtype=float32), 'shape': (120, 10)}\n",
      "==================================\n",
      "9\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [10], '_cg_ascend': [], '_grad_f': tensor32([[ 9.1169728e-04 -1.1360691e+00 -3.0518661e+00]\n",
      " [-4.4964757e+00 -8.6688280e-02  1.0618910e-03]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [-2.3427835e-02 -2.2370305e+00 -2.7808251e+00]\n",
      " [-5.0572352e+00 -2.4149776e-01  1.3138502e-04]\n",
      " [ 2.0810221e-03 -1.3383240e+00 -3.9914927e+00]\n",
      " [-2.6879416e+00 -1.3914210e+00 -5.4269803e-01]\n",
      " [-3.6821153e+00 -5.2465007e-02  2.9251209e-04]\n",
      " [-1.0587807e+00 -1.4944949e+00 -8.5563594e-01]\n",
      " [-1.9008181e+00 -1.5687493e+00 -5.1889408e-01]]), 'grad': tensor32([[ 9.1169728e-04 -1.1360691e+00 -3.0518661e+00]\n",
      " [-4.4964757e+00 -8.6688280e-02  1.0618910e-03]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [-2.3427835e-02 -2.2370305e+00 -2.7808251e+00]\n",
      " [-5.0572352e+00 -2.4149776e-01  1.3138502e-04]\n",
      " [ 2.0810221e-03 -1.3383240e+00 -3.9914927e+00]\n",
      " [-2.6879416e+00 -1.3914210e+00 -5.4269803e-01]\n",
      " [-3.6821153e+00 -5.2465007e-02  2.9251209e-04]\n",
      " [-1.0587807e+00 -1.4944949e+00 -8.5563594e-01]\n",
      " [-1.9008181e+00 -1.5687493e+00 -5.1889408e-01]]), 'npar_data': array([[-0.5465865 , -1.1365149 ,  0.8851863 ],\n",
      "       [ 0.47745004, -0.7450613 , -0.4789138 ],\n",
      "       [ 0.25911197,  0.17714854, -0.08043776],\n",
      "       [-0.7711505 ,  0.37853917,  0.37466738],\n",
      "       [ 0.8685523 , -0.82236767, -0.59599406],\n",
      "       [-0.6842407 , -0.68042135,  0.6325501 ],\n",
      "       [-0.14750935,  0.9744143 , -1.1336955 ],\n",
      "       [ 0.7068196 , -0.97089523, -0.5774444 ],\n",
      "       [-0.7227318 ,  1.2226455 , -1.0053382 ],\n",
      "       [-0.3615517 ,  0.56247324, -0.82798433]], dtype=float32), 'shape': (10, 3), '_is_para': True}\n",
      "==================================\n",
      "10\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [14], '_cg_ascend': [8, 9], '_grad_f': tensor32([[-2.50000097e-02  1.00053770e-08  2.01935538e-10]\n",
      " [-2.50000320e-02  3.13242481e-08  1.44465628e-09]\n",
      " [ 8.13020870e-06 -2.51186527e-02  1.10522240e-04]\n",
      " [-2.50004269e-02  4.23158752e-07  1.48871004e-09]\n",
      " [-2.50001177e-02  1.17240155e-07  6.95568214e-10]\n",
      " [ 4.90446723e-07  1.67289181e-04 -2.51677819e-02]\n",
      " [ 4.61717063e-05 -2.54695117e-02  4.23338643e-04]\n",
      " [-2.50021555e-02  2.15380373e-06  1.87444416e-09]\n",
      " [-2.50002258e-02  2.22337590e-07  8.61081206e-10]\n",
      " [-2.50000134e-02  1.25783775e-08  2.42020015e-10]\n",
      " [ 3.73807325e-06  1.17005722e-04 -2.51207463e-02]\n",
      " [ 8.36097868e-04 -2.72237100e-02  1.38761499e-03]\n",
      " [ 1.43897214e-05 -2.56708153e-02  6.56427292e-04]\n",
      " [-2.50002407e-02  2.38435831e-07  2.03747641e-09]\n",
      " [-2.50014588e-02  1.45470085e-06  1.59965585e-09]\n",
      " [ 4.23463644e-06 -2.50073746e-02  3.13937267e-06]\n",
      " [ 1.17421378e-05  5.10381535e-03 -3.01155616e-02]\n",
      " [ 1.03044931e-05  3.63450352e-04 -2.53737569e-02]\n",
      " [ 7.06932769e-06 -2.51509063e-02  1.43836631e-04]\n",
      " [ 2.66708184e-07  1.16418050e-06 -2.50014327e-02]\n",
      " [ 4.17765659e-05 -2.51237750e-02  8.19995621e-05]\n",
      " [ 9.30147603e-09  2.05983201e-06 -2.50020698e-02]\n",
      " [ 2.04299722e-04 -2.63319798e-02  1.12767785e-03]\n",
      " [-2.50009932e-02  9.92131845e-07  1.30458599e-09]\n",
      " [ 3.46401929e-09  3.32134960e-06 -2.50033252e-02]\n",
      " [ 4.06466097e-06 -2.50079222e-02  3.85483190e-06]\n",
      " [-2.50044279e-02  4.42574992e-06  1.97588812e-09]\n",
      " [-2.50004902e-02  4.88762169e-07  1.59382918e-09]\n",
      " [-2.50001736e-02  1.68013628e-07  5.06048581e-09]\n",
      " [ 7.03756359e-06 -2.50135437e-02  6.50468564e-06]\n",
      " [ 3.43651004e-06  8.07185424e-04 -2.58106217e-02]\n",
      " [-2.50006206e-02  6.16654063e-07  2.66772071e-09]\n",
      " [-2.50455216e-02  4.55168265e-05  5.57571012e-09]\n",
      " [-2.50096172e-02  9.59615227e-06  2.07244941e-08]\n",
      " [ 2.05966135e-05 -2.51443796e-02  1.23781807e-04]\n",
      " [-2.50026248e-02  2.62069580e-06  2.02903605e-09]\n",
      " [ 8.95269259e-05 -2.51255929e-02  3.60672602e-05]\n",
      " [ 6.25832058e-07  8.10587790e-06 -2.50087343e-02]\n",
      " [-2.50004902e-02  4.87456987e-07  1.18248433e-09]\n",
      " [ 9.21803985e-06 -2.50767693e-02  6.75511619e-05]\n",
      " [ 8.99985196e-07  3.58816251e-05 -2.50367820e-02]\n",
      " [-2.50000358e-02  3.57630583e-08  4.52265503e-10]\n",
      " [ 4.38463612e-05  1.29494176e-03 -2.63387896e-02]\n",
      " [ 3.73807325e-06  1.17005722e-04 -2.51207463e-02]\n",
      " [ 1.98228605e-07 -2.50059702e-02  5.77177479e-06]\n",
      " [ 4.43784375e-04 -2.67781951e-02  1.33441156e-03]\n",
      " [ 1.06203215e-05  6.38174752e-05 -2.50744410e-02]\n",
      " [ 4.24837526e-06 -2.51629241e-02  1.58676237e-04]\n",
      " [-2.50004008e-02  3.93938365e-07  4.43478987e-09]\n",
      " [ 4.37926356e-05 -2.50480361e-02  4.24315976e-06]\n",
      " [ 7.51037135e-07  1.14816008e-04 -2.51155682e-02]\n",
      " [-2.50028148e-02  2.81270604e-06  1.80831228e-09]\n",
      " [-2.50050984e-02  5.09786469e-06  1.56933411e-09]\n",
      " [ 4.96626171e-06 -2.50159763e-02  1.10100300e-05]\n",
      " [ 1.02715221e-05 -3.03744115e-02  5.36413817e-03]\n",
      " [-2.50090398e-02  9.03579257e-06  3.04292991e-09]\n",
      " [ 5.26360850e-07  4.51733331e-06 -2.50050426e-02]\n",
      " [-2.50013731e-02  1.36867504e-06  1.71530457e-09]\n",
      " [-2.50008889e-02  8.71410975e-07  1.54515547e-08]\n",
      " [ 1.71941734e-04 -3.14768404e-02  6.30489783e-03]\n",
      " [ 1.98003050e-04 -2.52049640e-02  6.95944664e-06]\n",
      " [ 2.29267002e-07  2.90030630e-06 -2.50031315e-02]\n",
      " [ 1.19533233e-05 -3.11054997e-02  6.09354768e-03]\n",
      " [ 5.73998341e-06  3.27762705e-03 -2.82833651e-02]\n",
      " [ 5.84898086e-09  1.15937360e-06 -2.50011645e-02]\n",
      " [ 1.08505255e-05 -2.51235962e-02  1.12745009e-04]\n",
      " [-2.50016861e-02  1.68173801e-06  1.77447368e-09]\n",
      " [-2.50002407e-02  2.41818128e-07  3.72334441e-10]\n",
      " [ 1.15886201e-06  2.95178709e-03 -2.79529467e-02]\n",
      " [ 1.42968508e-06  2.26285323e-04 -2.52277143e-02]\n",
      " [-2.50012912e-02  1.28773581e-06  1.83930970e-09]\n",
      " [-2.50010639e-02  1.06112145e-06  2.29019648e-09]\n",
      " [-2.50006393e-02  6.36620598e-07  1.14083409e-09]\n",
      " [ 2.80184918e-06 -2.81909443e-02  3.18814162e-03]\n",
      " [ 3.61730667e-06  2.09817372e-05 -2.50246003e-02]\n",
      " [-2.50000991e-02  9.60117319e-08  1.26563737e-09]\n",
      " [ 4.05234317e-07  2.10804355e-05 -2.50214860e-02]\n",
      " [ 5.89525825e-07  3.45525632e-06 -2.50040442e-02]\n",
      " [-2.50008255e-02  8.23348387e-07  1.15171150e-09]\n",
      " [ 2.37269251e-05 -2.56038122e-02  5.80083404e-04]\n",
      " [ 6.33803666e-06 -2.59814449e-02  9.75104398e-04]\n",
      " [ 8.98668986e-06  1.11536530e-03 -2.61243507e-02]\n",
      " [ 6.57523697e-06 -2.51678154e-02  1.61239892e-04]\n",
      " [ 1.60436764e-06  1.00923926e-05 -2.50116996e-02]\n",
      " [-2.50001028e-02  1.00786288e-07  9.16321907e-10]\n",
      " [ 7.36713446e-07  3.62383980e-05 -2.50369757e-02]\n",
      " [ 6.62006496e-05 -2.54776478e-02  4.11447283e-04]\n",
      " [ 2.46897866e-06  1.01802150e-04 -2.51042731e-02]\n",
      " [ 6.58383624e-06 -2.50077322e-02  1.14934028e-06]\n",
      " [ 1.63320990e-04 -2.53972039e-02  2.33882689e-04]\n",
      " [ 3.44014079e-05 -2.54116543e-02  3.77253251e-04]\n",
      " [-2.60651633e-02  1.06513395e-03  2.92220577e-08]\n",
      " [ 3.64305856e-06 -2.51116417e-02  1.07993656e-04]\n",
      " [ 1.41806040e-05 -2.51156203e-02  1.01439204e-04]\n",
      " [-2.50007622e-02  7.59676823e-07  1.35222666e-09]\n",
      " [ 1.68252256e-04 -2.52544880e-02  8.62348679e-05]\n",
      " [ 1.07529218e-07  6.44646425e-05 -2.50645727e-02]\n",
      " [ 2.34968024e-06  2.81542962e-05 -2.50305086e-02]\n",
      " [-2.50002407e-02  2.36969129e-07  2.97753000e-09]\n",
      " [ 2.06102341e-04 -2.52136048e-02  7.49763558e-06]\n",
      " [ 2.76337005e-07  1.52219775e-06 -2.50017978e-02]\n",
      " [ 1.78110020e-06  1.73125300e-03 -2.67330371e-02]\n",
      " [-2.50001103e-02  1.08551937e-07  4.14603962e-10]\n",
      " [ 1.26064009e-07  1.03098046e-06 -2.50011571e-02]\n",
      " [-2.50185542e-02  1.85510635e-05  3.20481686e-09]\n",
      " [ 9.11394181e-06 -2.59315558e-02  9.22441308e-04]\n",
      " [ 3.82608540e-08  3.69566515e-05 -2.50369944e-02]\n",
      " [ 3.16175556e-06  1.80730916e-04 -2.51838937e-02]\n",
      " [ 2.19154390e-05 -2.50942297e-02  7.23118210e-05]\n",
      " [ 4.61561649e-06  3.33732809e-04 -2.53383517e-02]\n",
      " [ 5.65380446e-07 -2.52339058e-02  2.33339058e-04]\n",
      " [ 5.16046111e-06 -2.50618197e-02  5.66583367e-05]\n",
      " [ 8.29806777e-06  8.14430387e-05 -2.50897408e-02]\n",
      " [ 3.29079667e-05  5.71627170e-04 -2.56045349e-02]\n",
      " [-2.50236057e-02  2.35992065e-05  4.94458208e-09]\n",
      " [ 6.35553442e-06 -2.50450373e-02  3.86824686e-05]\n",
      " [ 6.58949357e-05  1.27118058e-03 -2.63370760e-02]\n",
      " [-2.50010639e-02  1.06102129e-06  8.32523717e-10]\n",
      " [ 4.34735784e-06 -2.50303522e-02  2.60059696e-05]\n",
      " [ 1.00911507e-07  9.12783526e-06 -2.50092298e-02]]), 'grad': tensor32([[-2.50000097e-02  1.00053770e-08  2.01935538e-10]\n",
      " [-2.50000320e-02  3.13242481e-08  1.44465628e-09]\n",
      " [ 8.13020870e-06 -2.51186527e-02  1.10522240e-04]\n",
      " [-2.50004269e-02  4.23158752e-07  1.48871004e-09]\n",
      " [-2.50001177e-02  1.17240155e-07  6.95568214e-10]\n",
      " [ 4.90446723e-07  1.67289181e-04 -2.51677819e-02]\n",
      " [ 4.61717063e-05 -2.54695117e-02  4.23338643e-04]\n",
      " [-2.50021555e-02  2.15380373e-06  1.87444416e-09]\n",
      " [-2.50002258e-02  2.22337590e-07  8.61081206e-10]\n",
      " [-2.50000134e-02  1.25783775e-08  2.42020015e-10]\n",
      " [ 3.73807325e-06  1.17005722e-04 -2.51207463e-02]\n",
      " [ 8.36097868e-04 -2.72237100e-02  1.38761499e-03]\n",
      " [ 1.43897214e-05 -2.56708153e-02  6.56427292e-04]\n",
      " [-2.50002407e-02  2.38435831e-07  2.03747641e-09]\n",
      " [-2.50014588e-02  1.45470085e-06  1.59965585e-09]\n",
      " [ 4.23463644e-06 -2.50073746e-02  3.13937267e-06]\n",
      " [ 1.17421378e-05  5.10381535e-03 -3.01155616e-02]\n",
      " [ 1.03044931e-05  3.63450352e-04 -2.53737569e-02]\n",
      " [ 7.06932769e-06 -2.51509063e-02  1.43836631e-04]\n",
      " [ 2.66708184e-07  1.16418050e-06 -2.50014327e-02]\n",
      " [ 4.17765659e-05 -2.51237750e-02  8.19995621e-05]\n",
      " [ 9.30147603e-09  2.05983201e-06 -2.50020698e-02]\n",
      " [ 2.04299722e-04 -2.63319798e-02  1.12767785e-03]\n",
      " [-2.50009932e-02  9.92131845e-07  1.30458599e-09]\n",
      " [ 3.46401929e-09  3.32134960e-06 -2.50033252e-02]\n",
      " [ 4.06466097e-06 -2.50079222e-02  3.85483190e-06]\n",
      " [-2.50044279e-02  4.42574992e-06  1.97588812e-09]\n",
      " [-2.50004902e-02  4.88762169e-07  1.59382918e-09]\n",
      " [-2.50001736e-02  1.68013628e-07  5.06048581e-09]\n",
      " [ 7.03756359e-06 -2.50135437e-02  6.50468564e-06]\n",
      " [ 3.43651004e-06  8.07185424e-04 -2.58106217e-02]\n",
      " [-2.50006206e-02  6.16654063e-07  2.66772071e-09]\n",
      " [-2.50455216e-02  4.55168265e-05  5.57571012e-09]\n",
      " [-2.50096172e-02  9.59615227e-06  2.07244941e-08]\n",
      " [ 2.05966135e-05 -2.51443796e-02  1.23781807e-04]\n",
      " [-2.50026248e-02  2.62069580e-06  2.02903605e-09]\n",
      " [ 8.95269259e-05 -2.51255929e-02  3.60672602e-05]\n",
      " [ 6.25832058e-07  8.10587790e-06 -2.50087343e-02]\n",
      " [-2.50004902e-02  4.87456987e-07  1.18248433e-09]\n",
      " [ 9.21803985e-06 -2.50767693e-02  6.75511619e-05]\n",
      " [ 8.99985196e-07  3.58816251e-05 -2.50367820e-02]\n",
      " [-2.50000358e-02  3.57630583e-08  4.52265503e-10]\n",
      " [ 4.38463612e-05  1.29494176e-03 -2.63387896e-02]\n",
      " [ 3.73807325e-06  1.17005722e-04 -2.51207463e-02]\n",
      " [ 1.98228605e-07 -2.50059702e-02  5.77177479e-06]\n",
      " [ 4.43784375e-04 -2.67781951e-02  1.33441156e-03]\n",
      " [ 1.06203215e-05  6.38174752e-05 -2.50744410e-02]\n",
      " [ 4.24837526e-06 -2.51629241e-02  1.58676237e-04]\n",
      " [-2.50004008e-02  3.93938365e-07  4.43478987e-09]\n",
      " [ 4.37926356e-05 -2.50480361e-02  4.24315976e-06]\n",
      " [ 7.51037135e-07  1.14816008e-04 -2.51155682e-02]\n",
      " [-2.50028148e-02  2.81270604e-06  1.80831228e-09]\n",
      " [-2.50050984e-02  5.09786469e-06  1.56933411e-09]\n",
      " [ 4.96626171e-06 -2.50159763e-02  1.10100300e-05]\n",
      " [ 1.02715221e-05 -3.03744115e-02  5.36413817e-03]\n",
      " [-2.50090398e-02  9.03579257e-06  3.04292991e-09]\n",
      " [ 5.26360850e-07  4.51733331e-06 -2.50050426e-02]\n",
      " [-2.50013731e-02  1.36867504e-06  1.71530457e-09]\n",
      " [-2.50008889e-02  8.71410975e-07  1.54515547e-08]\n",
      " [ 1.71941734e-04 -3.14768404e-02  6.30489783e-03]\n",
      " [ 1.98003050e-04 -2.52049640e-02  6.95944664e-06]\n",
      " [ 2.29267002e-07  2.90030630e-06 -2.50031315e-02]\n",
      " [ 1.19533233e-05 -3.11054997e-02  6.09354768e-03]\n",
      " [ 5.73998341e-06  3.27762705e-03 -2.82833651e-02]\n",
      " [ 5.84898086e-09  1.15937360e-06 -2.50011645e-02]\n",
      " [ 1.08505255e-05 -2.51235962e-02  1.12745009e-04]\n",
      " [-2.50016861e-02  1.68173801e-06  1.77447368e-09]\n",
      " [-2.50002407e-02  2.41818128e-07  3.72334441e-10]\n",
      " [ 1.15886201e-06  2.95178709e-03 -2.79529467e-02]\n",
      " [ 1.42968508e-06  2.26285323e-04 -2.52277143e-02]\n",
      " [-2.50012912e-02  1.28773581e-06  1.83930970e-09]\n",
      " [-2.50010639e-02  1.06112145e-06  2.29019648e-09]\n",
      " [-2.50006393e-02  6.36620598e-07  1.14083409e-09]\n",
      " [ 2.80184918e-06 -2.81909443e-02  3.18814162e-03]\n",
      " [ 3.61730667e-06  2.09817372e-05 -2.50246003e-02]\n",
      " [-2.50000991e-02  9.60117319e-08  1.26563737e-09]\n",
      " [ 4.05234317e-07  2.10804355e-05 -2.50214860e-02]\n",
      " [ 5.89525825e-07  3.45525632e-06 -2.50040442e-02]\n",
      " [-2.50008255e-02  8.23348387e-07  1.15171150e-09]\n",
      " [ 2.37269251e-05 -2.56038122e-02  5.80083404e-04]\n",
      " [ 6.33803666e-06 -2.59814449e-02  9.75104398e-04]\n",
      " [ 8.98668986e-06  1.11536530e-03 -2.61243507e-02]\n",
      " [ 6.57523697e-06 -2.51678154e-02  1.61239892e-04]\n",
      " [ 1.60436764e-06  1.00923926e-05 -2.50116996e-02]\n",
      " [-2.50001028e-02  1.00786288e-07  9.16321907e-10]\n",
      " [ 7.36713446e-07  3.62383980e-05 -2.50369757e-02]\n",
      " [ 6.62006496e-05 -2.54776478e-02  4.11447283e-04]\n",
      " [ 2.46897866e-06  1.01802150e-04 -2.51042731e-02]\n",
      " [ 6.58383624e-06 -2.50077322e-02  1.14934028e-06]\n",
      " [ 1.63320990e-04 -2.53972039e-02  2.33882689e-04]\n",
      " [ 3.44014079e-05 -2.54116543e-02  3.77253251e-04]\n",
      " [-2.60651633e-02  1.06513395e-03  2.92220577e-08]\n",
      " [ 3.64305856e-06 -2.51116417e-02  1.07993656e-04]\n",
      " [ 1.41806040e-05 -2.51156203e-02  1.01439204e-04]\n",
      " [-2.50007622e-02  7.59676823e-07  1.35222666e-09]\n",
      " [ 1.68252256e-04 -2.52544880e-02  8.62348679e-05]\n",
      " [ 1.07529218e-07  6.44646425e-05 -2.50645727e-02]\n",
      " [ 2.34968024e-06  2.81542962e-05 -2.50305086e-02]\n",
      " [-2.50002407e-02  2.36969129e-07  2.97753000e-09]\n",
      " [ 2.06102341e-04 -2.52136048e-02  7.49763558e-06]\n",
      " [ 2.76337005e-07  1.52219775e-06 -2.50017978e-02]\n",
      " [ 1.78110020e-06  1.73125300e-03 -2.67330371e-02]\n",
      " [-2.50001103e-02  1.08551937e-07  4.14603962e-10]\n",
      " [ 1.26064009e-07  1.03098046e-06 -2.50011571e-02]\n",
      " [-2.50185542e-02  1.85510635e-05  3.20481686e-09]\n",
      " [ 9.11394181e-06 -2.59315558e-02  9.22441308e-04]\n",
      " [ 3.82608540e-08  3.69566515e-05 -2.50369944e-02]\n",
      " [ 3.16175556e-06  1.80730916e-04 -2.51838937e-02]\n",
      " [ 2.19154390e-05 -2.50942297e-02  7.23118210e-05]\n",
      " [ 4.61561649e-06  3.33732809e-04 -2.53383517e-02]\n",
      " [ 5.65380446e-07 -2.52339058e-02  2.33339058e-04]\n",
      " [ 5.16046111e-06 -2.50618197e-02  5.66583367e-05]\n",
      " [ 8.29806777e-06  8.14430387e-05 -2.50897408e-02]\n",
      " [ 3.29079667e-05  5.71627170e-04 -2.56045349e-02]\n",
      " [-2.50236057e-02  2.35992065e-05  4.94458208e-09]\n",
      " [ 6.35553442e-06 -2.50450373e-02  3.86824686e-05]\n",
      " [ 6.58949357e-05  1.27118058e-03 -2.63370760e-02]\n",
      " [-2.50010639e-02  1.06102129e-06  8.32523717e-10]\n",
      " [ 4.34735784e-06 -2.50303522e-02  2.60059696e-05]\n",
      " [ 1.00911507e-07  9.12783526e-06 -2.50092298e-02]]), 'npar_data': array([[  7.316809  ,  -7.099139  , -10.028377  ],\n",
      "       [  6.6246433 ,  -6.6500325 ,  -8.752862  ],\n",
      "       [ -4.1879535 ,   1.9468404 ,  -1.38793   ],\n",
      "       [  5.7238765 ,  -4.9473977 ,  -9.623544  ],\n",
      "       [  6.291539  ,  -5.663295  ,  -9.816854  ],\n",
      "       [ -6.975352  ,  -1.9264868 ,   2.9351604 ],\n",
      "       [ -3.0826228 ,   1.2717398 ,  -0.6764245 ],\n",
      "       [  5.0903726 ,  -3.9534495 , -10.026437  ],\n",
      "       [  6.011149  ,  -5.3036995 ,  -9.883771  ],\n",
      "       [  7.1964273 ,  -6.990664  ,  -9.967686  ],\n",
      "       [ -4.767276  ,  -2.106921  ,   3.117971  ],\n",
      "       [ -1.0157287 ,   0.18984765,  -0.31873932],\n",
      "       [ -4.4466896 ,   1.0475942 ,  -0.43599847],\n",
      "       [  5.859946  ,  -5.384997  ,  -9.173694  ],\n",
      "       [  5.242909  ,  -4.193433  , -10.032508  ],\n",
      "       [ -3.3563802 ,   3.4441578 ,  -3.4652617 ],\n",
      "       [ -5.1409154 ,   0.15034626,   0.6627402 ],\n",
      "       [ -4.410009  ,  -1.6302439 ,   2.4299362 ],\n",
      "       [ -4.432582  ,   1.8380989 ,  -1.2292758 ],\n",
      "       [ -5.344118  ,  -4.6537976 ,   5.195723  ],\n",
      "       [ -2.389693  ,   2.1077275 ,  -1.524922  ],\n",
      "       [ -8.828821  ,  -4.211913  ,   5.0669246 ],\n",
      "       [ -2.0023463 ,   0.74862653,  -0.10362565],\n",
      "       [  5.4167876 ,  -4.40231   , -10.062589  ],\n",
      "       [-10.032365  ,  -3.9499662 ,   4.8509736 ],\n",
      "       [ -3.235624  ,   3.605816  ,  -3.0982335 ],\n",
      "       [  4.822426  ,  -3.5009193 , -10.2414055 ],\n",
      "       [  5.6490374 ,  -4.8781004 ,  -9.630145  ],\n",
      "       [  5.897561  ,  -5.6974454 ,  -8.2263365 ],\n",
      "       [ -3.5018208 ,   2.790012  ,  -3.3901665 ],\n",
      "       [ -5.827771  ,  -1.151972  ,   2.0538478 ],\n",
      "       [  5.521772  ,  -4.7729177 ,  -9.24231   ],\n",
      "       [  3.8645232 ,  -2.1232343 , -10.1569605 ],\n",
      "       [  4.261558  ,  -3.287242  ,  -8.451352  ],\n",
      "       [ -3.188914  ,   2.013203  ,  -1.205127  ],\n",
      "       [  5.014104  ,  -3.8334587 , -10.023401  ],\n",
      "       [ -1.5848063 ,   2.1501894 ,  -2.303567  ],\n",
      "       [ -5.551147  ,  -3.7731817 ,   4.1348906 ],\n",
      "       [  5.7060766 ,  -4.823735  ,  -9.871628  ],\n",
      "       [ -3.765717  ,   2.2485871 ,  -1.5836005 ],\n",
      "       [ -5.554931  ,  -2.6526268 ,   3.7644343 ],\n",
      "       [  6.7278047 ,  -6.414348  ,  -9.811058  ],\n",
      "       [ -3.5214832 ,  -0.9192523 ,   1.7411039 ],\n",
      "       [ -4.767276  ,  -2.106921  ,   3.117971  ],\n",
      "       [ -6.2880282 ,   3.5743108 ,  -2.7263205 ],\n",
      "       [ -1.3945949 ,   0.51477253,  -0.10329486],\n",
      "       [ -3.5736752 ,  -2.5637152 ,   3.2729952 ],\n",
      "       [ -4.8201866 ,   1.958253  ,  -1.0094641 ],\n",
      "       [  5.590472  ,  -5.1523576 ,  -8.6653805 ],\n",
      "       [ -1.853451  ,   2.606023  ,  -3.9972155 ],\n",
      "       [ -6.3930554 ,  -2.1467223 ,   3.0976918 ],\n",
      "       [  5.005204  ,  -3.7716274 , -10.147445  ],\n",
      "       [  4.804626  ,  -3.3772566 , -10.4894905 ],\n",
      "       [ -3.6728604 ,   2.9672742 ,  -2.6863277 ],\n",
      "       [ -5.3018293 ,  -0.4219218 ,   1.1466798 ],\n",
      "       [  4.5262527 ,  -3.082785  , -10.105222  ],\n",
      "       [ -5.081427  ,  -3.7150352 ,   4.7781477 ],\n",
      "       [  5.273151  ,  -4.2241583 ,  -9.932475  ],\n",
      "       [  5.1644373 ,  -4.7844143 ,  -7.8431277 ],\n",
      "       [ -2.3261926 ,  -0.73020184,   1.4661268 ],\n",
      "       [ -0.986594  ,   1.9449414 ,  -4.1443834 ],\n",
      "       [ -5.820919  ,  -4.066532  ,   4.869986  ],\n",
      "       [ -4.9778056 ,  -0.5333283 ,   1.4465641 ],\n",
      "       [ -5.7984557 ,  -0.2343352 ,   1.1716182 ],\n",
      "       [ -9.012313  ,  -4.506243  ,   5.347447  ],\n",
      "       [ -3.7839289 ,   2.0616362 ,  -1.25262   ],\n",
      "       [  5.2182255 ,  -4.073061  ,  -9.953449  ],\n",
      "       [  6.1088567 ,  -5.1220007 , -10.624458  ],\n",
      "       [ -7.3148217 ,  -0.25539207,   1.3186487 ],\n",
      "       [ -6.204463  ,  -1.9234179 ,   2.6287894 ],\n",
      "       [  5.303393  ,  -4.254884  ,  -9.832442  ],\n",
      "       [  5.3226223 ,  -4.429241  ,  -9.593993  ],\n",
      "       [  5.6209087 ,  -4.641913  ,  -9.992636  ],\n",
      "       [ -6.5275583 ,   0.20413749,   0.69974893],\n",
      "       [ -4.0975704 ,  -3.1229458 ,   3.8321557 ],\n",
      "       [  6.2825413 ,  -5.8720484 ,  -9.227252  ],\n",
      "       [ -6.216304  ,  -3.0479662 ,   3.9028165 ],\n",
      "       [ -4.9834414 ,  -3.998406  ,   4.7629223 ],\n",
      "       [  5.5143986 ,  -4.4911957 , -10.089634  ],\n",
      "       [ -3.8246603 ,   1.178234  ,  -0.4377054 ],\n",
      "       [ -5.3803687 ,   0.892477  ,  -0.15400001],\n",
      "       [ -5.0234237 ,  -0.98552865,   1.8543082 ],\n",
      "       [ -4.6097984 ,   1.7312686 ,  -1.2198225 ],\n",
      "       [ -4.4993443 ,  -3.4435906 ,   4.244933  ],\n",
      "       [  6.287996  ,  -5.8180623 ,  -9.54476   ],\n",
      "       [ -5.918297  ,  -2.8059192 ,   3.6012244 ],\n",
      "       [ -2.652236  ,   1.3407682 ,  -0.6348522 ],\n",
      "       [ -5.1980543 ,  -2.2621248 ,   3.1039622 ],\n",
      "       [ -2.626369  ,   3.732806  ,  -4.181405  ],\n",
      "       [ -1.7369614 ,   1.3632044 ,  -1.1874657 ],\n",
      "       [ -3.2734835 ,   1.3824792 ,  -0.6882712 ],\n",
      "       [  2.3033397 ,  -0.40036216,  -9.930358  ],\n",
      "       [ -4.938533  ,   1.9998776 ,  -1.3588909 ],\n",
      "       [ -3.441694  ,   2.13718   ,  -1.283716  ],\n",
      "       [  5.501955  ,  -4.584132  ,  -9.941582  ],\n",
      "       [ -1.3791265 ,   1.7091156 ,  -1.8571229 ],\n",
      "       [ -8.111164  ,  -2.4983525 ,   3.329462  ],\n",
      "       [ -4.679471  ,  -2.9793477 ,   3.6809952 ],\n",
      "       [  5.8317184 ,  -5.4193945 ,  -8.822539  ],\n",
      "       [ -0.9808302 ,   1.9095517 ,  -4.104222  ],\n",
      "       [ -5.342419  ,  -4.419428  ,   5.1619115 ],\n",
      "       [ -6.8960986 ,  -0.8000271 ,   1.5119337 ],\n",
      "       [  6.3643613 ,  -5.667469  , -10.261438  ],\n",
      "       [ -5.867445  ,  -4.549268  ,   5.421794  ],\n",
      "       [  4.2583065 ,  -2.630254  , -10.32019   ],\n",
      "       [ -5.0597863 ,   0.8565863 ,  -0.25217432],\n",
      "       [ -8.853984  ,  -2.7642086 ,   3.6233068 ],\n",
      "       [ -5.205815  ,  -1.9432307 ,   2.839156  ],\n",
      "       [ -2.890908  ,   2.25525   ,  -1.5067188 ],\n",
      "       [ -5.1609793 ,  -1.6633818 ,   2.4865384 ],\n",
      "       [ -7.0590625 ,   1.7274446 ,  -0.8459202 ],\n",
      "       [ -4.272059  ,   2.3241906 ,  -1.6856521 ],\n",
      "       [ -3.7883844 ,  -2.2878008 ,   3.303178  ],\n",
      "       [ -3.4284449 ,  -1.3569703 ,   2.2209427 ],\n",
      "       [  4.102227  ,  -2.54504   , -10.042025  ],\n",
      "       [ -3.8502133 ,   2.5397623 ,  -1.8537596 ],\n",
      "       [ -2.9668655 ,  -0.7905237 ,   1.8885969 ],\n",
      "       [  5.414771  ,  -4.3371863 , -10.513776  ],\n",
      "       [ -3.9876962 ,   2.7838075 ,  -2.0085447 ],\n",
      "       [ -7.1893253 ,  -3.4677832 ,   4.3214903 ]], dtype=float32), 'shape': (120, 3)}\n",
      "==================================\n",
      "11\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [13], '_cg_ascend': [], '_grad_f': tensor32([[ 0.02299574]\n",
      " [ 0.02299576]\n",
      " [-0.00322819]\n",
      " [ 0.02299606]\n",
      " [ 0.02299582]\n",
      " [ 0.02950516]\n",
      " [-0.00356257]\n",
      " [ 0.02299742]\n",
      " [ 0.02299591]\n",
      " [ 0.02299574]\n",
      " [ 0.02945681]\n",
      " [-0.00512022]\n",
      " [-0.00376463]\n",
      " [ 0.02299592]\n",
      " [ 0.02299687]\n",
      " [-0.00312058]\n",
      " [ 0.03431395]\n",
      " [ 0.02969803]\n",
      " [-0.00325979]\n",
      " [ 0.02934336]\n",
      " [-0.00322677]\n",
      " [ 0.02934418]\n",
      " [-0.00437224]\n",
      " [ 0.02299651]\n",
      " [ 0.02934541]\n",
      " [-0.00312114]\n",
      " [ 0.0229992 ]\n",
      " [ 0.02299611]\n",
      " [ 0.02299586]\n",
      " [-0.00312605]\n",
      " [ 0.03012878]\n",
      " [ 0.02299622]\n",
      " [ 0.02303138]\n",
      " [ 0.02300324]\n",
      " [-0.00325086]\n",
      " [ 0.02299778]\n",
      " [-0.00321945]\n",
      " [ 0.02935019]\n",
      " [ 0.02299611]\n",
      " [-0.0031872 ]\n",
      " [ 0.02937728]\n",
      " [ 0.02299576]\n",
      " [ 0.0306114 ]\n",
      " [ 0.02945681]\n",
      " [-0.00311998]\n",
      " [-0.00476112]\n",
      " [ 0.02940634]\n",
      " [-0.00327203]\n",
      " [ 0.02299604]\n",
      " [-0.00315264]\n",
      " [ 0.02945411]\n",
      " [ 0.02299793]\n",
      " [ 0.02299972]\n",
      " [-0.00312881]\n",
      " [-0.00834526]\n",
      " [ 0.02300281]\n",
      " [ 0.02934667]\n",
      " [ 0.02299681]\n",
      " [ 0.02299641]\n",
      " [-0.00938791]\n",
      " [-0.00327608]\n",
      " [ 0.02934504]\n",
      " [-0.0090568 ]\n",
      " [ 0.03253466]\n",
      " [ 0.0293433 ]\n",
      " [-0.00323248]\n",
      " [ 0.02299705]\n",
      " [ 0.02299592]\n",
      " [ 0.03221653]\n",
      " [ 0.02956278]\n",
      " [ 0.02299674]\n",
      " [ 0.02299656]\n",
      " [ 0.02299623]\n",
      " [-0.00622066]\n",
      " [ 0.02936329]\n",
      " [ 0.02299581]\n",
      " [ 0.02936278]\n",
      " [ 0.02934565]\n",
      " [ 0.02299638]\n",
      " [-0.00369761]\n",
      " [-0.00406862]\n",
      " [ 0.0304299 ]\n",
      " [-0.00327635]\n",
      " [ 0.02935231]\n",
      " [ 0.02299581]\n",
      " [ 0.0293776 ]\n",
      " [-0.00356668]\n",
      " [ 0.02944177]\n",
      " [-0.00312048]\n",
      " [-0.00346986]\n",
      " [-0.00350848]\n",
      " [ 0.02383004]\n",
      " [-0.00322221]\n",
      " [-0.00322408]\n",
      " [ 0.02299633]\n",
      " [-0.00332996]\n",
      " [ 0.02940496]\n",
      " [ 0.02937004]\n",
      " [ 0.02299592]\n",
      " [-0.00328294]\n",
      " [ 0.02934371]\n",
      " [ 0.03102822]\n",
      " [ 0.02299582]\n",
      " [ 0.0293432 ]\n",
      " [ 0.02301026]\n",
      " [-0.00401951]\n",
      " [ 0.02937816]\n",
      " [ 0.02951875]\n",
      " [-0.00320178]\n",
      " [ 0.02966801]\n",
      " [-0.00334185]\n",
      " [-0.00317341]\n",
      " [ 0.02942305]\n",
      " [ 0.02990503]\n",
      " [ 0.02301422]\n",
      " [-0.00315685]\n",
      " [ 0.03059246]\n",
      " [ 0.02299656]\n",
      " [-0.00314293]\n",
      " [ 0.02935108]]), 'grad': tensor32([[ 0.02299574]\n",
      " [ 0.02299576]\n",
      " [-0.00322819]\n",
      " [ 0.02299606]\n",
      " [ 0.02299582]\n",
      " [ 0.02950516]\n",
      " [-0.00356257]\n",
      " [ 0.02299742]\n",
      " [ 0.02299591]\n",
      " [ 0.02299574]\n",
      " [ 0.02945681]\n",
      " [-0.00512022]\n",
      " [-0.00376463]\n",
      " [ 0.02299592]\n",
      " [ 0.02299687]\n",
      " [-0.00312058]\n",
      " [ 0.03431395]\n",
      " [ 0.02969803]\n",
      " [-0.00325979]\n",
      " [ 0.02934336]\n",
      " [-0.00322677]\n",
      " [ 0.02934418]\n",
      " [-0.00437224]\n",
      " [ 0.02299651]\n",
      " [ 0.02934541]\n",
      " [-0.00312114]\n",
      " [ 0.0229992 ]\n",
      " [ 0.02299611]\n",
      " [ 0.02299586]\n",
      " [-0.00312605]\n",
      " [ 0.03012878]\n",
      " [ 0.02299622]\n",
      " [ 0.02303138]\n",
      " [ 0.02300324]\n",
      " [-0.00325086]\n",
      " [ 0.02299778]\n",
      " [-0.00321945]\n",
      " [ 0.02935019]\n",
      " [ 0.02299611]\n",
      " [-0.0031872 ]\n",
      " [ 0.02937728]\n",
      " [ 0.02299576]\n",
      " [ 0.0306114 ]\n",
      " [ 0.02945681]\n",
      " [-0.00311998]\n",
      " [-0.00476112]\n",
      " [ 0.02940634]\n",
      " [-0.00327203]\n",
      " [ 0.02299604]\n",
      " [-0.00315264]\n",
      " [ 0.02945411]\n",
      " [ 0.02299793]\n",
      " [ 0.02299972]\n",
      " [-0.00312881]\n",
      " [-0.00834526]\n",
      " [ 0.02300281]\n",
      " [ 0.02934667]\n",
      " [ 0.02299681]\n",
      " [ 0.02299641]\n",
      " [-0.00938791]\n",
      " [-0.00327608]\n",
      " [ 0.02934504]\n",
      " [-0.0090568 ]\n",
      " [ 0.03253466]\n",
      " [ 0.0293433 ]\n",
      " [-0.00323248]\n",
      " [ 0.02299705]\n",
      " [ 0.02299592]\n",
      " [ 0.03221653]\n",
      " [ 0.02956278]\n",
      " [ 0.02299674]\n",
      " [ 0.02299656]\n",
      " [ 0.02299623]\n",
      " [-0.00622066]\n",
      " [ 0.02936329]\n",
      " [ 0.02299581]\n",
      " [ 0.02936278]\n",
      " [ 0.02934565]\n",
      " [ 0.02299638]\n",
      " [-0.00369761]\n",
      " [-0.00406862]\n",
      " [ 0.0304299 ]\n",
      " [-0.00327635]\n",
      " [ 0.02935231]\n",
      " [ 0.02299581]\n",
      " [ 0.0293776 ]\n",
      " [-0.00356668]\n",
      " [ 0.02944177]\n",
      " [-0.00312048]\n",
      " [-0.00346986]\n",
      " [-0.00350848]\n",
      " [ 0.02383004]\n",
      " [-0.00322221]\n",
      " [-0.00322408]\n",
      " [ 0.02299633]\n",
      " [-0.00332996]\n",
      " [ 0.02940496]\n",
      " [ 0.02937004]\n",
      " [ 0.02299592]\n",
      " [-0.00328294]\n",
      " [ 0.02934371]\n",
      " [ 0.03102822]\n",
      " [ 0.02299582]\n",
      " [ 0.0293432 ]\n",
      " [ 0.02301026]\n",
      " [-0.00401951]\n",
      " [ 0.02937816]\n",
      " [ 0.02951875]\n",
      " [-0.00320178]\n",
      " [ 0.02966801]\n",
      " [-0.00334185]\n",
      " [-0.00317341]\n",
      " [ 0.02942305]\n",
      " [ 0.02990503]\n",
      " [ 0.02301422]\n",
      " [-0.00315685]\n",
      " [ 0.03059246]\n",
      " [ 0.02299656]\n",
      " [-0.00314293]\n",
      " [ 0.02935108]]), 'npar_data': array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]], dtype=float32), 'shape': (120, 1)}\n",
      "==================================\n",
      "12\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [13], '_cg_ascend': [], '_grad_f': tensor32([[-1.3313582 -1.3792696 -1.2893724]]), 'grad': tensor32([[-1.3313582 -1.3792696 -1.2893724]]), 'npar_data': array([[-0.6898719 ,  0.09342609, -0.8802652 ]], dtype=float32), 'shape': (1, 3), '_is_para': True}\n",
      "==================================\n",
      "13\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [14], '_cg_ascend': [11, 12], '_grad_f': tensor32([[-2.50000097e-02  1.00053770e-08  2.01935538e-10]\n",
      " [-2.50000320e-02  3.13242481e-08  1.44465628e-09]\n",
      " [ 8.13020870e-06 -2.51186527e-02  1.10522240e-04]\n",
      " [-2.50004269e-02  4.23158752e-07  1.48871004e-09]\n",
      " [-2.50001177e-02  1.17240155e-07  6.95568214e-10]\n",
      " [ 4.90446723e-07  1.67289181e-04 -2.51677819e-02]\n",
      " [ 4.61717063e-05 -2.54695117e-02  4.23338643e-04]\n",
      " [-2.50021555e-02  2.15380373e-06  1.87444416e-09]\n",
      " [-2.50002258e-02  2.22337590e-07  8.61081206e-10]\n",
      " [-2.50000134e-02  1.25783775e-08  2.42020015e-10]\n",
      " [ 3.73807325e-06  1.17005722e-04 -2.51207463e-02]\n",
      " [ 8.36097868e-04 -2.72237100e-02  1.38761499e-03]\n",
      " [ 1.43897214e-05 -2.56708153e-02  6.56427292e-04]\n",
      " [-2.50002407e-02  2.38435831e-07  2.03747641e-09]\n",
      " [-2.50014588e-02  1.45470085e-06  1.59965585e-09]\n",
      " [ 4.23463644e-06 -2.50073746e-02  3.13937267e-06]\n",
      " [ 1.17421378e-05  5.10381535e-03 -3.01155616e-02]\n",
      " [ 1.03044931e-05  3.63450352e-04 -2.53737569e-02]\n",
      " [ 7.06932769e-06 -2.51509063e-02  1.43836631e-04]\n",
      " [ 2.66708184e-07  1.16418050e-06 -2.50014327e-02]\n",
      " [ 4.17765659e-05 -2.51237750e-02  8.19995621e-05]\n",
      " [ 9.30147603e-09  2.05983201e-06 -2.50020698e-02]\n",
      " [ 2.04299722e-04 -2.63319798e-02  1.12767785e-03]\n",
      " [-2.50009932e-02  9.92131845e-07  1.30458599e-09]\n",
      " [ 3.46401929e-09  3.32134960e-06 -2.50033252e-02]\n",
      " [ 4.06466097e-06 -2.50079222e-02  3.85483190e-06]\n",
      " [-2.50044279e-02  4.42574992e-06  1.97588812e-09]\n",
      " [-2.50004902e-02  4.88762169e-07  1.59382918e-09]\n",
      " [-2.50001736e-02  1.68013628e-07  5.06048581e-09]\n",
      " [ 7.03756359e-06 -2.50135437e-02  6.50468564e-06]\n",
      " [ 3.43651004e-06  8.07185424e-04 -2.58106217e-02]\n",
      " [-2.50006206e-02  6.16654063e-07  2.66772071e-09]\n",
      " [-2.50455216e-02  4.55168265e-05  5.57571012e-09]\n",
      " [-2.50096172e-02  9.59615227e-06  2.07244941e-08]\n",
      " [ 2.05966135e-05 -2.51443796e-02  1.23781807e-04]\n",
      " [-2.50026248e-02  2.62069580e-06  2.02903605e-09]\n",
      " [ 8.95269259e-05 -2.51255929e-02  3.60672602e-05]\n",
      " [ 6.25832058e-07  8.10587790e-06 -2.50087343e-02]\n",
      " [-2.50004902e-02  4.87456987e-07  1.18248433e-09]\n",
      " [ 9.21803985e-06 -2.50767693e-02  6.75511619e-05]\n",
      " [ 8.99985196e-07  3.58816251e-05 -2.50367820e-02]\n",
      " [-2.50000358e-02  3.57630583e-08  4.52265503e-10]\n",
      " [ 4.38463612e-05  1.29494176e-03 -2.63387896e-02]\n",
      " [ 3.73807325e-06  1.17005722e-04 -2.51207463e-02]\n",
      " [ 1.98228605e-07 -2.50059702e-02  5.77177479e-06]\n",
      " [ 4.43784375e-04 -2.67781951e-02  1.33441156e-03]\n",
      " [ 1.06203215e-05  6.38174752e-05 -2.50744410e-02]\n",
      " [ 4.24837526e-06 -2.51629241e-02  1.58676237e-04]\n",
      " [-2.50004008e-02  3.93938365e-07  4.43478987e-09]\n",
      " [ 4.37926356e-05 -2.50480361e-02  4.24315976e-06]\n",
      " [ 7.51037135e-07  1.14816008e-04 -2.51155682e-02]\n",
      " [-2.50028148e-02  2.81270604e-06  1.80831228e-09]\n",
      " [-2.50050984e-02  5.09786469e-06  1.56933411e-09]\n",
      " [ 4.96626171e-06 -2.50159763e-02  1.10100300e-05]\n",
      " [ 1.02715221e-05 -3.03744115e-02  5.36413817e-03]\n",
      " [-2.50090398e-02  9.03579257e-06  3.04292991e-09]\n",
      " [ 5.26360850e-07  4.51733331e-06 -2.50050426e-02]\n",
      " [-2.50013731e-02  1.36867504e-06  1.71530457e-09]\n",
      " [-2.50008889e-02  8.71410975e-07  1.54515547e-08]\n",
      " [ 1.71941734e-04 -3.14768404e-02  6.30489783e-03]\n",
      " [ 1.98003050e-04 -2.52049640e-02  6.95944664e-06]\n",
      " [ 2.29267002e-07  2.90030630e-06 -2.50031315e-02]\n",
      " [ 1.19533233e-05 -3.11054997e-02  6.09354768e-03]\n",
      " [ 5.73998341e-06  3.27762705e-03 -2.82833651e-02]\n",
      " [ 5.84898086e-09  1.15937360e-06 -2.50011645e-02]\n",
      " [ 1.08505255e-05 -2.51235962e-02  1.12745009e-04]\n",
      " [-2.50016861e-02  1.68173801e-06  1.77447368e-09]\n",
      " [-2.50002407e-02  2.41818128e-07  3.72334441e-10]\n",
      " [ 1.15886201e-06  2.95178709e-03 -2.79529467e-02]\n",
      " [ 1.42968508e-06  2.26285323e-04 -2.52277143e-02]\n",
      " [-2.50012912e-02  1.28773581e-06  1.83930970e-09]\n",
      " [-2.50010639e-02  1.06112145e-06  2.29019648e-09]\n",
      " [-2.50006393e-02  6.36620598e-07  1.14083409e-09]\n",
      " [ 2.80184918e-06 -2.81909443e-02  3.18814162e-03]\n",
      " [ 3.61730667e-06  2.09817372e-05 -2.50246003e-02]\n",
      " [-2.50000991e-02  9.60117319e-08  1.26563737e-09]\n",
      " [ 4.05234317e-07  2.10804355e-05 -2.50214860e-02]\n",
      " [ 5.89525825e-07  3.45525632e-06 -2.50040442e-02]\n",
      " [-2.50008255e-02  8.23348387e-07  1.15171150e-09]\n",
      " [ 2.37269251e-05 -2.56038122e-02  5.80083404e-04]\n",
      " [ 6.33803666e-06 -2.59814449e-02  9.75104398e-04]\n",
      " [ 8.98668986e-06  1.11536530e-03 -2.61243507e-02]\n",
      " [ 6.57523697e-06 -2.51678154e-02  1.61239892e-04]\n",
      " [ 1.60436764e-06  1.00923926e-05 -2.50116996e-02]\n",
      " [-2.50001028e-02  1.00786288e-07  9.16321907e-10]\n",
      " [ 7.36713446e-07  3.62383980e-05 -2.50369757e-02]\n",
      " [ 6.62006496e-05 -2.54776478e-02  4.11447283e-04]\n",
      " [ 2.46897866e-06  1.01802150e-04 -2.51042731e-02]\n",
      " [ 6.58383624e-06 -2.50077322e-02  1.14934028e-06]\n",
      " [ 1.63320990e-04 -2.53972039e-02  2.33882689e-04]\n",
      " [ 3.44014079e-05 -2.54116543e-02  3.77253251e-04]\n",
      " [-2.60651633e-02  1.06513395e-03  2.92220577e-08]\n",
      " [ 3.64305856e-06 -2.51116417e-02  1.07993656e-04]\n",
      " [ 1.41806040e-05 -2.51156203e-02  1.01439204e-04]\n",
      " [-2.50007622e-02  7.59676823e-07  1.35222666e-09]\n",
      " [ 1.68252256e-04 -2.52544880e-02  8.62348679e-05]\n",
      " [ 1.07529218e-07  6.44646425e-05 -2.50645727e-02]\n",
      " [ 2.34968024e-06  2.81542962e-05 -2.50305086e-02]\n",
      " [-2.50002407e-02  2.36969129e-07  2.97753000e-09]\n",
      " [ 2.06102341e-04 -2.52136048e-02  7.49763558e-06]\n",
      " [ 2.76337005e-07  1.52219775e-06 -2.50017978e-02]\n",
      " [ 1.78110020e-06  1.73125300e-03 -2.67330371e-02]\n",
      " [-2.50001103e-02  1.08551937e-07  4.14603962e-10]\n",
      " [ 1.26064009e-07  1.03098046e-06 -2.50011571e-02]\n",
      " [-2.50185542e-02  1.85510635e-05  3.20481686e-09]\n",
      " [ 9.11394181e-06 -2.59315558e-02  9.22441308e-04]\n",
      " [ 3.82608540e-08  3.69566515e-05 -2.50369944e-02]\n",
      " [ 3.16175556e-06  1.80730916e-04 -2.51838937e-02]\n",
      " [ 2.19154390e-05 -2.50942297e-02  7.23118210e-05]\n",
      " [ 4.61561649e-06  3.33732809e-04 -2.53383517e-02]\n",
      " [ 5.65380446e-07 -2.52339058e-02  2.33339058e-04]\n",
      " [ 5.16046111e-06 -2.50618197e-02  5.66583367e-05]\n",
      " [ 8.29806777e-06  8.14430387e-05 -2.50897408e-02]\n",
      " [ 3.29079667e-05  5.71627170e-04 -2.56045349e-02]\n",
      " [-2.50236057e-02  2.35992065e-05  4.94458208e-09]\n",
      " [ 6.35553442e-06 -2.50450373e-02  3.86824686e-05]\n",
      " [ 6.58949357e-05  1.27118058e-03 -2.63370760e-02]\n",
      " [-2.50010639e-02  1.06102129e-06  8.32523717e-10]\n",
      " [ 4.34735784e-06 -2.50303522e-02  2.60059696e-05]\n",
      " [ 1.00911507e-07  9.12783526e-06 -2.50092298e-02]]), 'grad': tensor32([[-2.50000097e-02  1.00053770e-08  2.01935538e-10]\n",
      " [-2.50000320e-02  3.13242481e-08  1.44465628e-09]\n",
      " [ 8.13020870e-06 -2.51186527e-02  1.10522240e-04]\n",
      " [-2.50004269e-02  4.23158752e-07  1.48871004e-09]\n",
      " [-2.50001177e-02  1.17240155e-07  6.95568214e-10]\n",
      " [ 4.90446723e-07  1.67289181e-04 -2.51677819e-02]\n",
      " [ 4.61717063e-05 -2.54695117e-02  4.23338643e-04]\n",
      " [-2.50021555e-02  2.15380373e-06  1.87444416e-09]\n",
      " [-2.50002258e-02  2.22337590e-07  8.61081206e-10]\n",
      " [-2.50000134e-02  1.25783775e-08  2.42020015e-10]\n",
      " [ 3.73807325e-06  1.17005722e-04 -2.51207463e-02]\n",
      " [ 8.36097868e-04 -2.72237100e-02  1.38761499e-03]\n",
      " [ 1.43897214e-05 -2.56708153e-02  6.56427292e-04]\n",
      " [-2.50002407e-02  2.38435831e-07  2.03747641e-09]\n",
      " [-2.50014588e-02  1.45470085e-06  1.59965585e-09]\n",
      " [ 4.23463644e-06 -2.50073746e-02  3.13937267e-06]\n",
      " [ 1.17421378e-05  5.10381535e-03 -3.01155616e-02]\n",
      " [ 1.03044931e-05  3.63450352e-04 -2.53737569e-02]\n",
      " [ 7.06932769e-06 -2.51509063e-02  1.43836631e-04]\n",
      " [ 2.66708184e-07  1.16418050e-06 -2.50014327e-02]\n",
      " [ 4.17765659e-05 -2.51237750e-02  8.19995621e-05]\n",
      " [ 9.30147603e-09  2.05983201e-06 -2.50020698e-02]\n",
      " [ 2.04299722e-04 -2.63319798e-02  1.12767785e-03]\n",
      " [-2.50009932e-02  9.92131845e-07  1.30458599e-09]\n",
      " [ 3.46401929e-09  3.32134960e-06 -2.50033252e-02]\n",
      " [ 4.06466097e-06 -2.50079222e-02  3.85483190e-06]\n",
      " [-2.50044279e-02  4.42574992e-06  1.97588812e-09]\n",
      " [-2.50004902e-02  4.88762169e-07  1.59382918e-09]\n",
      " [-2.50001736e-02  1.68013628e-07  5.06048581e-09]\n",
      " [ 7.03756359e-06 -2.50135437e-02  6.50468564e-06]\n",
      " [ 3.43651004e-06  8.07185424e-04 -2.58106217e-02]\n",
      " [-2.50006206e-02  6.16654063e-07  2.66772071e-09]\n",
      " [-2.50455216e-02  4.55168265e-05  5.57571012e-09]\n",
      " [-2.50096172e-02  9.59615227e-06  2.07244941e-08]\n",
      " [ 2.05966135e-05 -2.51443796e-02  1.23781807e-04]\n",
      " [-2.50026248e-02  2.62069580e-06  2.02903605e-09]\n",
      " [ 8.95269259e-05 -2.51255929e-02  3.60672602e-05]\n",
      " [ 6.25832058e-07  8.10587790e-06 -2.50087343e-02]\n",
      " [-2.50004902e-02  4.87456987e-07  1.18248433e-09]\n",
      " [ 9.21803985e-06 -2.50767693e-02  6.75511619e-05]\n",
      " [ 8.99985196e-07  3.58816251e-05 -2.50367820e-02]\n",
      " [-2.50000358e-02  3.57630583e-08  4.52265503e-10]\n",
      " [ 4.38463612e-05  1.29494176e-03 -2.63387896e-02]\n",
      " [ 3.73807325e-06  1.17005722e-04 -2.51207463e-02]\n",
      " [ 1.98228605e-07 -2.50059702e-02  5.77177479e-06]\n",
      " [ 4.43784375e-04 -2.67781951e-02  1.33441156e-03]\n",
      " [ 1.06203215e-05  6.38174752e-05 -2.50744410e-02]\n",
      " [ 4.24837526e-06 -2.51629241e-02  1.58676237e-04]\n",
      " [-2.50004008e-02  3.93938365e-07  4.43478987e-09]\n",
      " [ 4.37926356e-05 -2.50480361e-02  4.24315976e-06]\n",
      " [ 7.51037135e-07  1.14816008e-04 -2.51155682e-02]\n",
      " [-2.50028148e-02  2.81270604e-06  1.80831228e-09]\n",
      " [-2.50050984e-02  5.09786469e-06  1.56933411e-09]\n",
      " [ 4.96626171e-06 -2.50159763e-02  1.10100300e-05]\n",
      " [ 1.02715221e-05 -3.03744115e-02  5.36413817e-03]\n",
      " [-2.50090398e-02  9.03579257e-06  3.04292991e-09]\n",
      " [ 5.26360850e-07  4.51733331e-06 -2.50050426e-02]\n",
      " [-2.50013731e-02  1.36867504e-06  1.71530457e-09]\n",
      " [-2.50008889e-02  8.71410975e-07  1.54515547e-08]\n",
      " [ 1.71941734e-04 -3.14768404e-02  6.30489783e-03]\n",
      " [ 1.98003050e-04 -2.52049640e-02  6.95944664e-06]\n",
      " [ 2.29267002e-07  2.90030630e-06 -2.50031315e-02]\n",
      " [ 1.19533233e-05 -3.11054997e-02  6.09354768e-03]\n",
      " [ 5.73998341e-06  3.27762705e-03 -2.82833651e-02]\n",
      " [ 5.84898086e-09  1.15937360e-06 -2.50011645e-02]\n",
      " [ 1.08505255e-05 -2.51235962e-02  1.12745009e-04]\n",
      " [-2.50016861e-02  1.68173801e-06  1.77447368e-09]\n",
      " [-2.50002407e-02  2.41818128e-07  3.72334441e-10]\n",
      " [ 1.15886201e-06  2.95178709e-03 -2.79529467e-02]\n",
      " [ 1.42968508e-06  2.26285323e-04 -2.52277143e-02]\n",
      " [-2.50012912e-02  1.28773581e-06  1.83930970e-09]\n",
      " [-2.50010639e-02  1.06112145e-06  2.29019648e-09]\n",
      " [-2.50006393e-02  6.36620598e-07  1.14083409e-09]\n",
      " [ 2.80184918e-06 -2.81909443e-02  3.18814162e-03]\n",
      " [ 3.61730667e-06  2.09817372e-05 -2.50246003e-02]\n",
      " [-2.50000991e-02  9.60117319e-08  1.26563737e-09]\n",
      " [ 4.05234317e-07  2.10804355e-05 -2.50214860e-02]\n",
      " [ 5.89525825e-07  3.45525632e-06 -2.50040442e-02]\n",
      " [-2.50008255e-02  8.23348387e-07  1.15171150e-09]\n",
      " [ 2.37269251e-05 -2.56038122e-02  5.80083404e-04]\n",
      " [ 6.33803666e-06 -2.59814449e-02  9.75104398e-04]\n",
      " [ 8.98668986e-06  1.11536530e-03 -2.61243507e-02]\n",
      " [ 6.57523697e-06 -2.51678154e-02  1.61239892e-04]\n",
      " [ 1.60436764e-06  1.00923926e-05 -2.50116996e-02]\n",
      " [-2.50001028e-02  1.00786288e-07  9.16321907e-10]\n",
      " [ 7.36713446e-07  3.62383980e-05 -2.50369757e-02]\n",
      " [ 6.62006496e-05 -2.54776478e-02  4.11447283e-04]\n",
      " [ 2.46897866e-06  1.01802150e-04 -2.51042731e-02]\n",
      " [ 6.58383624e-06 -2.50077322e-02  1.14934028e-06]\n",
      " [ 1.63320990e-04 -2.53972039e-02  2.33882689e-04]\n",
      " [ 3.44014079e-05 -2.54116543e-02  3.77253251e-04]\n",
      " [-2.60651633e-02  1.06513395e-03  2.92220577e-08]\n",
      " [ 3.64305856e-06 -2.51116417e-02  1.07993656e-04]\n",
      " [ 1.41806040e-05 -2.51156203e-02  1.01439204e-04]\n",
      " [-2.50007622e-02  7.59676823e-07  1.35222666e-09]\n",
      " [ 1.68252256e-04 -2.52544880e-02  8.62348679e-05]\n",
      " [ 1.07529218e-07  6.44646425e-05 -2.50645727e-02]\n",
      " [ 2.34968024e-06  2.81542962e-05 -2.50305086e-02]\n",
      " [-2.50002407e-02  2.36969129e-07  2.97753000e-09]\n",
      " [ 2.06102341e-04 -2.52136048e-02  7.49763558e-06]\n",
      " [ 2.76337005e-07  1.52219775e-06 -2.50017978e-02]\n",
      " [ 1.78110020e-06  1.73125300e-03 -2.67330371e-02]\n",
      " [-2.50001103e-02  1.08551937e-07  4.14603962e-10]\n",
      " [ 1.26064009e-07  1.03098046e-06 -2.50011571e-02]\n",
      " [-2.50185542e-02  1.85510635e-05  3.20481686e-09]\n",
      " [ 9.11394181e-06 -2.59315558e-02  9.22441308e-04]\n",
      " [ 3.82608540e-08  3.69566515e-05 -2.50369944e-02]\n",
      " [ 3.16175556e-06  1.80730916e-04 -2.51838937e-02]\n",
      " [ 2.19154390e-05 -2.50942297e-02  7.23118210e-05]\n",
      " [ 4.61561649e-06  3.33732809e-04 -2.53383517e-02]\n",
      " [ 5.65380446e-07 -2.52339058e-02  2.33339058e-04]\n",
      " [ 5.16046111e-06 -2.50618197e-02  5.66583367e-05]\n",
      " [ 8.29806777e-06  8.14430387e-05 -2.50897408e-02]\n",
      " [ 3.29079667e-05  5.71627170e-04 -2.56045349e-02]\n",
      " [-2.50236057e-02  2.35992065e-05  4.94458208e-09]\n",
      " [ 6.35553442e-06 -2.50450373e-02  3.86824686e-05]\n",
      " [ 6.58949357e-05  1.27118058e-03 -2.63370760e-02]\n",
      " [-2.50010639e-02  1.06102129e-06  8.32523717e-10]\n",
      " [ 4.34735784e-06 -2.50303522e-02  2.60059696e-05]\n",
      " [ 1.00911507e-07  9.12783526e-06 -2.50092298e-02]]), 'npar_data': array([[-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ],\n",
      "       [-0.6898719 ,  0.09342609, -0.8802652 ]], dtype=float32), 'shape': (120, 3)}\n",
      "==================================\n",
      "14\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [18], '_cg_ascend': [10, 13], '_grad_f': tensor32([[-1.66666768e-02  1.00053770e-08  2.01935538e-10]\n",
      " [-1.66666992e-02  3.13242481e-08  1.44465628e-09]\n",
      " [ 8.13020870e-06 -1.67853199e-02  1.10522240e-04]\n",
      " [-1.66670922e-02  4.23158752e-07  1.48871004e-09]\n",
      " [-1.66667849e-02  1.17240155e-07  6.95568214e-10]\n",
      " [ 4.90446723e-07  1.67289181e-04 -1.68344472e-02]\n",
      " [ 4.61717063e-05 -1.71361789e-02  4.23338643e-04]\n",
      " [-1.66688226e-02  2.15380373e-06  1.87444416e-09]\n",
      " [-1.66668911e-02  2.22337590e-07  8.61081206e-10]\n",
      " [-1.66666806e-02  1.25783775e-08  2.42020015e-10]\n",
      " [ 3.73807325e-06  1.17005722e-04 -1.67874116e-02]\n",
      " [ 8.36097868e-04 -1.88903771e-02  1.38761499e-03]\n",
      " [ 1.43897214e-05 -1.73374824e-02  6.56427292e-04]\n",
      " [-1.66669078e-02  2.38435831e-07  2.03747641e-09]\n",
      " [-1.66681241e-02  1.45470085e-06  1.59965585e-09]\n",
      " [ 4.23463644e-06 -1.66740417e-02  3.13937267e-06]\n",
      " [ 1.17421378e-05  5.10381535e-03 -2.17822269e-02]\n",
      " [ 1.03044931e-05  3.63450352e-04 -1.70404222e-02]\n",
      " [ 7.06932769e-06 -1.68175735e-02  1.43836631e-04]\n",
      " [ 2.66708184e-07  1.16418050e-06 -1.66680999e-02]\n",
      " [ 4.17765659e-05 -1.67904422e-02  8.19995621e-05]\n",
      " [ 9.30147603e-09  2.05983201e-06 -1.66687369e-02]\n",
      " [ 2.04299722e-04 -1.79986451e-02  1.12767785e-03]\n",
      " [-1.66676603e-02  9.92131845e-07  1.30458599e-09]\n",
      " [ 3.46401929e-09  3.32134960e-06 -1.66699924e-02]\n",
      " [ 4.06466097e-06 -1.66745875e-02  3.85483190e-06]\n",
      " [-1.66710950e-02  4.42574992e-06  1.97588812e-09]\n",
      " [-1.66671574e-02  4.88762169e-07  1.59382918e-09]\n",
      " [-1.66668408e-02  1.68013628e-07  5.06048581e-09]\n",
      " [ 7.03756359e-06 -1.66802108e-02  6.50468564e-06]\n",
      " [ 3.43651004e-06  8.07185424e-04 -1.74772888e-02]\n",
      " [-1.66672878e-02  6.16654063e-07  2.66772071e-09]\n",
      " [-1.67121887e-02  4.55168265e-05  5.57571012e-09]\n",
      " [-1.66762844e-02  9.59615227e-06  2.07244941e-08]\n",
      " [ 2.05966135e-05 -1.68110467e-02  1.23781807e-04]\n",
      " [-1.66692901e-02  2.62069580e-06  2.02903605e-09]\n",
      " [ 8.95269259e-05 -1.67922601e-02  3.60672602e-05]\n",
      " [ 6.25832058e-07  8.10587790e-06 -1.66753996e-02]\n",
      " [-1.66671574e-02  4.87456987e-07  1.18248433e-09]\n",
      " [ 9.21803985e-06 -1.67434365e-02  6.75511619e-05]\n",
      " [ 8.99985196e-07  3.58816251e-05 -1.67034492e-02]\n",
      " [-1.66667029e-02  3.57630583e-08  4.52265503e-10]\n",
      " [ 4.38463612e-05  1.29494176e-03 -1.80054568e-02]\n",
      " [ 3.73807325e-06  1.17005722e-04 -1.67874116e-02]\n",
      " [ 1.98228605e-07 -1.66726373e-02  5.77177479e-06]\n",
      " [ 4.43784375e-04 -1.84448622e-02  1.33441156e-03]\n",
      " [ 1.06203215e-05  6.38174752e-05 -1.67411063e-02]\n",
      " [ 4.24837526e-06 -1.68295912e-02  1.58676237e-04]\n",
      " [-1.66670661e-02  3.93938365e-07  4.43478987e-09]\n",
      " [ 4.37926356e-05 -1.67147033e-02  4.24315976e-06]\n",
      " [ 7.51037135e-07  1.14816008e-04 -1.67822354e-02]\n",
      " [-1.66694820e-02  2.81270604e-06  1.80831228e-09]\n",
      " [-1.66717656e-02  5.09786469e-06  1.56933411e-09]\n",
      " [ 4.96626171e-06 -1.66826434e-02  1.10100300e-05]\n",
      " [ 1.02715221e-05 -2.20410787e-02  5.36413817e-03]\n",
      " [-1.66757070e-02  9.03579257e-06  3.04292991e-09]\n",
      " [ 5.26360850e-07  4.51733331e-06 -1.66717097e-02]\n",
      " [-1.66680384e-02  1.36867504e-06  1.71530457e-09]\n",
      " [-1.66675542e-02  8.71410975e-07  1.54515547e-08]\n",
      " [ 1.71941734e-04 -2.31435057e-02  6.30489783e-03]\n",
      " [ 1.98003050e-04 -1.68716293e-02  6.95944664e-06]\n",
      " [ 2.29267002e-07  2.90030630e-06 -1.66697986e-02]\n",
      " [ 1.19533233e-05 -2.27721669e-02  6.09354768e-03]\n",
      " [ 5.73998341e-06  3.27762705e-03 -1.99500322e-02]\n",
      " [ 5.84898086e-09  1.15937360e-06 -1.66678317e-02]\n",
      " [ 1.08505255e-05 -1.67902634e-02  1.12745009e-04]\n",
      " [-1.66683514e-02  1.68173801e-06  1.77447368e-09]\n",
      " [-1.66669078e-02  2.41818128e-07  3.72334441e-10]\n",
      " [ 1.15886201e-06  2.95178709e-03 -1.96196139e-02]\n",
      " [ 1.42968508e-06  2.26285323e-04 -1.68943815e-02]\n",
      " [-1.66679565e-02  1.28773581e-06  1.83930970e-09]\n",
      " [-1.66677311e-02  1.06112145e-06  2.29019648e-09]\n",
      " [-1.66673064e-02  6.36620598e-07  1.14083409e-09]\n",
      " [ 2.80184918e-06 -1.98576115e-02  3.18814162e-03]\n",
      " [ 3.61730667e-06  2.09817372e-05 -1.66912675e-02]\n",
      " [-1.66667644e-02  9.60117319e-08  1.26563737e-09]\n",
      " [ 4.05234317e-07  2.10804355e-05 -1.66881531e-02]\n",
      " [ 5.89525825e-07  3.45525632e-06 -1.66707113e-02]\n",
      " [-1.66674927e-02  8.23348387e-07  1.15171150e-09]\n",
      " [ 2.37269251e-05 -1.72704794e-02  5.80083404e-04]\n",
      " [ 6.33803666e-06 -1.76481120e-02  9.75104398e-04]\n",
      " [ 8.98668986e-06  1.11536530e-03 -1.77910179e-02]\n",
      " [ 6.57523697e-06 -1.68344826e-02  1.61239892e-04]\n",
      " [ 1.60436764e-06  1.00923926e-05 -1.66783649e-02]\n",
      " [-1.66667700e-02  1.00786288e-07  9.16321907e-10]\n",
      " [ 7.36713446e-07  3.62383980e-05 -1.67036429e-02]\n",
      " [ 6.62006496e-05 -1.71443149e-02  4.11447283e-04]\n",
      " [ 2.46897866e-06  1.01802150e-04 -1.67709403e-02]\n",
      " [ 6.58383624e-06 -1.66743994e-02  1.14934028e-06]\n",
      " [ 1.63320990e-04 -1.70638710e-02  2.33882689e-04]\n",
      " [ 3.44014079e-05 -1.70783214e-02  3.77253251e-04]\n",
      " [-1.77318305e-02  1.06513395e-03  2.92220577e-08]\n",
      " [ 3.64305856e-06 -1.67783070e-02  1.07993656e-04]\n",
      " [ 1.41806040e-05 -1.67822875e-02  1.01439204e-04]\n",
      " [-1.66674294e-02  7.59676823e-07  1.35222666e-09]\n",
      " [ 1.68252256e-04 -1.69211552e-02  8.62348679e-05]\n",
      " [ 1.07529218e-07  6.44646425e-05 -1.67312399e-02]\n",
      " [ 2.34968024e-06  2.81542962e-05 -1.66971739e-02]\n",
      " [-1.66669078e-02  2.36969129e-07  2.97753000e-09]\n",
      " [ 2.06102341e-04 -1.68802701e-02  7.49763558e-06]\n",
      " [ 2.76337005e-07  1.52219775e-06 -1.66684650e-02]\n",
      " [ 1.78110020e-06  1.73125300e-03 -1.83997024e-02]\n",
      " [-1.66667774e-02  1.08551937e-07  4.14603962e-10]\n",
      " [ 1.26064009e-07  1.03098046e-06 -1.66678242e-02]\n",
      " [-1.66852213e-02  1.85510635e-05  3.20481686e-09]\n",
      " [ 9.11394181e-06 -1.75982229e-02  9.22441308e-04]\n",
      " [ 3.82608540e-08  3.69566515e-05 -1.67036615e-02]\n",
      " [ 3.16175556e-06  1.80730916e-04 -1.68505609e-02]\n",
      " [ 2.19154390e-05 -1.67608950e-02  7.23118210e-05]\n",
      " [ 4.61561649e-06  3.33732809e-04 -1.70050170e-02]\n",
      " [ 5.65380446e-07 -1.69005729e-02  2.33339058e-04]\n",
      " [ 5.16046111e-06 -1.67284869e-02  5.66583367e-05]\n",
      " [ 8.29806777e-06  8.14430387e-05 -1.67564079e-02]\n",
      " [ 3.29079667e-05  5.71627170e-04 -1.72712021e-02]\n",
      " [-1.66902710e-02  2.35992065e-05  4.94458208e-09]\n",
      " [ 6.35553442e-06 -1.67117044e-02  3.86824686e-05]\n",
      " [ 6.58949357e-05  1.27118058e-03 -1.80037431e-02]\n",
      " [-1.66677292e-02  1.06102129e-06  8.32523717e-10]\n",
      " [ 4.34735784e-06 -1.66970193e-02  2.60059696e-05]\n",
      " [ 1.00911507e-07  9.12783526e-06 -1.66758969e-02]]), 'grad': tensor32([[-1.66666768e-02  1.00053770e-08  2.01935538e-10]\n",
      " [-1.66666992e-02  3.13242481e-08  1.44465628e-09]\n",
      " [ 8.13020870e-06 -1.67853199e-02  1.10522240e-04]\n",
      " [-1.66670922e-02  4.23158752e-07  1.48871004e-09]\n",
      " [-1.66667849e-02  1.17240155e-07  6.95568214e-10]\n",
      " [ 4.90446723e-07  1.67289181e-04 -1.68344472e-02]\n",
      " [ 4.61717063e-05 -1.71361789e-02  4.23338643e-04]\n",
      " [-1.66688226e-02  2.15380373e-06  1.87444416e-09]\n",
      " [-1.66668911e-02  2.22337590e-07  8.61081206e-10]\n",
      " [-1.66666806e-02  1.25783775e-08  2.42020015e-10]\n",
      " [ 3.73807325e-06  1.17005722e-04 -1.67874116e-02]\n",
      " [ 8.36097868e-04 -1.88903771e-02  1.38761499e-03]\n",
      " [ 1.43897214e-05 -1.73374824e-02  6.56427292e-04]\n",
      " [-1.66669078e-02  2.38435831e-07  2.03747641e-09]\n",
      " [-1.66681241e-02  1.45470085e-06  1.59965585e-09]\n",
      " [ 4.23463644e-06 -1.66740417e-02  3.13937267e-06]\n",
      " [ 1.17421378e-05  5.10381535e-03 -2.17822269e-02]\n",
      " [ 1.03044931e-05  3.63450352e-04 -1.70404222e-02]\n",
      " [ 7.06932769e-06 -1.68175735e-02  1.43836631e-04]\n",
      " [ 2.66708184e-07  1.16418050e-06 -1.66680999e-02]\n",
      " [ 4.17765659e-05 -1.67904422e-02  8.19995621e-05]\n",
      " [ 9.30147603e-09  2.05983201e-06 -1.66687369e-02]\n",
      " [ 2.04299722e-04 -1.79986451e-02  1.12767785e-03]\n",
      " [-1.66676603e-02  9.92131845e-07  1.30458599e-09]\n",
      " [ 3.46401929e-09  3.32134960e-06 -1.66699924e-02]\n",
      " [ 4.06466097e-06 -1.66745875e-02  3.85483190e-06]\n",
      " [-1.66710950e-02  4.42574992e-06  1.97588812e-09]\n",
      " [-1.66671574e-02  4.88762169e-07  1.59382918e-09]\n",
      " [-1.66668408e-02  1.68013628e-07  5.06048581e-09]\n",
      " [ 7.03756359e-06 -1.66802108e-02  6.50468564e-06]\n",
      " [ 3.43651004e-06  8.07185424e-04 -1.74772888e-02]\n",
      " [-1.66672878e-02  6.16654063e-07  2.66772071e-09]\n",
      " [-1.67121887e-02  4.55168265e-05  5.57571012e-09]\n",
      " [-1.66762844e-02  9.59615227e-06  2.07244941e-08]\n",
      " [ 2.05966135e-05 -1.68110467e-02  1.23781807e-04]\n",
      " [-1.66692901e-02  2.62069580e-06  2.02903605e-09]\n",
      " [ 8.95269259e-05 -1.67922601e-02  3.60672602e-05]\n",
      " [ 6.25832058e-07  8.10587790e-06 -1.66753996e-02]\n",
      " [-1.66671574e-02  4.87456987e-07  1.18248433e-09]\n",
      " [ 9.21803985e-06 -1.67434365e-02  6.75511619e-05]\n",
      " [ 8.99985196e-07  3.58816251e-05 -1.67034492e-02]\n",
      " [-1.66667029e-02  3.57630583e-08  4.52265503e-10]\n",
      " [ 4.38463612e-05  1.29494176e-03 -1.80054568e-02]\n",
      " [ 3.73807325e-06  1.17005722e-04 -1.67874116e-02]\n",
      " [ 1.98228605e-07 -1.66726373e-02  5.77177479e-06]\n",
      " [ 4.43784375e-04 -1.84448622e-02  1.33441156e-03]\n",
      " [ 1.06203215e-05  6.38174752e-05 -1.67411063e-02]\n",
      " [ 4.24837526e-06 -1.68295912e-02  1.58676237e-04]\n",
      " [-1.66670661e-02  3.93938365e-07  4.43478987e-09]\n",
      " [ 4.37926356e-05 -1.67147033e-02  4.24315976e-06]\n",
      " [ 7.51037135e-07  1.14816008e-04 -1.67822354e-02]\n",
      " [-1.66694820e-02  2.81270604e-06  1.80831228e-09]\n",
      " [-1.66717656e-02  5.09786469e-06  1.56933411e-09]\n",
      " [ 4.96626171e-06 -1.66826434e-02  1.10100300e-05]\n",
      " [ 1.02715221e-05 -2.20410787e-02  5.36413817e-03]\n",
      " [-1.66757070e-02  9.03579257e-06  3.04292991e-09]\n",
      " [ 5.26360850e-07  4.51733331e-06 -1.66717097e-02]\n",
      " [-1.66680384e-02  1.36867504e-06  1.71530457e-09]\n",
      " [-1.66675542e-02  8.71410975e-07  1.54515547e-08]\n",
      " [ 1.71941734e-04 -2.31435057e-02  6.30489783e-03]\n",
      " [ 1.98003050e-04 -1.68716293e-02  6.95944664e-06]\n",
      " [ 2.29267002e-07  2.90030630e-06 -1.66697986e-02]\n",
      " [ 1.19533233e-05 -2.27721669e-02  6.09354768e-03]\n",
      " [ 5.73998341e-06  3.27762705e-03 -1.99500322e-02]\n",
      " [ 5.84898086e-09  1.15937360e-06 -1.66678317e-02]\n",
      " [ 1.08505255e-05 -1.67902634e-02  1.12745009e-04]\n",
      " [-1.66683514e-02  1.68173801e-06  1.77447368e-09]\n",
      " [-1.66669078e-02  2.41818128e-07  3.72334441e-10]\n",
      " [ 1.15886201e-06  2.95178709e-03 -1.96196139e-02]\n",
      " [ 1.42968508e-06  2.26285323e-04 -1.68943815e-02]\n",
      " [-1.66679565e-02  1.28773581e-06  1.83930970e-09]\n",
      " [-1.66677311e-02  1.06112145e-06  2.29019648e-09]\n",
      " [-1.66673064e-02  6.36620598e-07  1.14083409e-09]\n",
      " [ 2.80184918e-06 -1.98576115e-02  3.18814162e-03]\n",
      " [ 3.61730667e-06  2.09817372e-05 -1.66912675e-02]\n",
      " [-1.66667644e-02  9.60117319e-08  1.26563737e-09]\n",
      " [ 4.05234317e-07  2.10804355e-05 -1.66881531e-02]\n",
      " [ 5.89525825e-07  3.45525632e-06 -1.66707113e-02]\n",
      " [-1.66674927e-02  8.23348387e-07  1.15171150e-09]\n",
      " [ 2.37269251e-05 -1.72704794e-02  5.80083404e-04]\n",
      " [ 6.33803666e-06 -1.76481120e-02  9.75104398e-04]\n",
      " [ 8.98668986e-06  1.11536530e-03 -1.77910179e-02]\n",
      " [ 6.57523697e-06 -1.68344826e-02  1.61239892e-04]\n",
      " [ 1.60436764e-06  1.00923926e-05 -1.66783649e-02]\n",
      " [-1.66667700e-02  1.00786288e-07  9.16321907e-10]\n",
      " [ 7.36713446e-07  3.62383980e-05 -1.67036429e-02]\n",
      " [ 6.62006496e-05 -1.71443149e-02  4.11447283e-04]\n",
      " [ 2.46897866e-06  1.01802150e-04 -1.67709403e-02]\n",
      " [ 6.58383624e-06 -1.66743994e-02  1.14934028e-06]\n",
      " [ 1.63320990e-04 -1.70638710e-02  2.33882689e-04]\n",
      " [ 3.44014079e-05 -1.70783214e-02  3.77253251e-04]\n",
      " [-1.77318305e-02  1.06513395e-03  2.92220577e-08]\n",
      " [ 3.64305856e-06 -1.67783070e-02  1.07993656e-04]\n",
      " [ 1.41806040e-05 -1.67822875e-02  1.01439204e-04]\n",
      " [-1.66674294e-02  7.59676823e-07  1.35222666e-09]\n",
      " [ 1.68252256e-04 -1.69211552e-02  8.62348679e-05]\n",
      " [ 1.07529218e-07  6.44646425e-05 -1.67312399e-02]\n",
      " [ 2.34968024e-06  2.81542962e-05 -1.66971739e-02]\n",
      " [-1.66669078e-02  2.36969129e-07  2.97753000e-09]\n",
      " [ 2.06102341e-04 -1.68802701e-02  7.49763558e-06]\n",
      " [ 2.76337005e-07  1.52219775e-06 -1.66684650e-02]\n",
      " [ 1.78110020e-06  1.73125300e-03 -1.83997024e-02]\n",
      " [-1.66667774e-02  1.08551937e-07  4.14603962e-10]\n",
      " [ 1.26064009e-07  1.03098046e-06 -1.66678242e-02]\n",
      " [-1.66852213e-02  1.85510635e-05  3.20481686e-09]\n",
      " [ 9.11394181e-06 -1.75982229e-02  9.22441308e-04]\n",
      " [ 3.82608540e-08  3.69566515e-05 -1.67036615e-02]\n",
      " [ 3.16175556e-06  1.80730916e-04 -1.68505609e-02]\n",
      " [ 2.19154390e-05 -1.67608950e-02  7.23118210e-05]\n",
      " [ 4.61561649e-06  3.33732809e-04 -1.70050170e-02]\n",
      " [ 5.65380446e-07 -1.69005729e-02  2.33339058e-04]\n",
      " [ 5.16046111e-06 -1.67284869e-02  5.66583367e-05]\n",
      " [ 8.29806777e-06  8.14430387e-05 -1.67564079e-02]\n",
      " [ 3.29079667e-05  5.71627170e-04 -1.72712021e-02]\n",
      " [-1.66902710e-02  2.35992065e-05  4.94458208e-09]\n",
      " [ 6.35553442e-06 -1.67117044e-02  3.86824686e-05]\n",
      " [ 6.58949357e-05  1.27118058e-03 -1.80037431e-02]\n",
      " [-1.66677292e-02  1.06102129e-06  8.32523717e-10]\n",
      " [ 4.34735784e-06 -1.66970193e-02  2.60059696e-05]\n",
      " [ 1.00911507e-07  9.12783526e-06 -1.66758969e-02]]), 'npar_data': array([[  6.6269374 ,  -7.005713  , -10.908642  ],\n",
      "       [  5.9347715 ,  -6.5566063 ,  -9.633127  ],\n",
      "       [ -4.8778253 ,   2.0402665 ,  -2.2681952 ],\n",
      "       [  5.0340047 ,  -4.8539715 , -10.503809  ],\n",
      "       [  5.6016674 ,  -5.5698686 , -10.697119  ],\n",
      "       [ -7.6652236 ,  -1.8330607 ,   2.0548952 ],\n",
      "       [ -3.7724948 ,   1.365166  ,  -1.5566897 ],\n",
      "       [  4.400501  ,  -3.8600235 , -10.906702  ],\n",
      "       [  5.321277  ,  -5.2102733 , -10.764036  ],\n",
      "       [  6.5065556 ,  -6.897238  , -10.847951  ],\n",
      "       [ -5.4571476 ,  -2.013495  ,   2.2377057 ],\n",
      "       [ -1.7056006 ,   0.28327373,  -1.1990045 ],\n",
      "       [ -5.1365614 ,   1.1410203 ,  -1.3162637 ],\n",
      "       [  5.170074  ,  -5.2915707 , -10.053959  ],\n",
      "       [  4.553037  ,  -4.1000066 , -10.912773  ],\n",
      "       [ -4.0462523 ,   3.5375838 ,  -4.3455267 ],\n",
      "       [ -5.830787  ,   0.24377236,  -0.217525  ],\n",
      "       [ -5.0998807 ,  -1.5368178 ,   1.5496709 ],\n",
      "       [ -5.1224537 ,   1.931525  ,  -2.109541  ],\n",
      "       [ -6.03399   ,  -4.5603714 ,   4.315458  ],\n",
      "       [ -3.079565  ,   2.2011535 ,  -2.4051871 ],\n",
      "       [ -9.518693  ,  -4.118487  ,   4.1866593 ],\n",
      "       [ -2.6922183 ,   0.84205264,  -0.98389083],\n",
      "       [  4.726916  ,  -4.3088837 , -10.942854  ],\n",
      "       [-10.722237  ,  -3.8565402 ,   3.9707084 ],\n",
      "       [ -3.925496  ,   3.6992419 ,  -3.9784987 ],\n",
      "       [  4.132554  ,  -3.4074934 , -11.121671  ],\n",
      "       [  4.9591656 ,  -4.784674  , -10.51041   ],\n",
      "       [  5.2076893 ,  -5.604019  ,  -9.106602  ],\n",
      "       [ -4.191693  ,   2.8834379 ,  -4.2704315 ],\n",
      "       [ -6.517643  ,  -1.058546  ,   1.1735826 ],\n",
      "       [  4.8319    ,  -4.6794915 , -10.122575  ],\n",
      "       [  3.1746511 ,  -2.0298083 , -11.037226  ],\n",
      "       [  3.5716863 ,  -3.193816  ,  -9.331617  ],\n",
      "       [ -3.878786  ,   2.106629  ,  -2.0853922 ],\n",
      "       [  4.324232  ,  -3.7400327 , -10.9036665 ],\n",
      "       [ -2.2746782 ,   2.2436154 ,  -3.1838322 ],\n",
      "       [ -6.241019  ,  -3.6797557 ,   3.2546253 ],\n",
      "       [  5.016205  ,  -4.730309  , -10.751893  ],\n",
      "       [ -4.455589  ,   2.3420131 ,  -2.4638658 ],\n",
      "       [ -6.244803  ,  -2.5592008 ,   2.884169  ],\n",
      "       [  6.037933  ,  -6.320922  , -10.691323  ],\n",
      "       [ -4.211355  ,  -0.82582617,   0.8608387 ],\n",
      "       [ -5.4571476 ,  -2.013495  ,   2.2377057 ],\n",
      "       [ -6.9779    ,   3.6677368 ,  -3.6065857 ],\n",
      "       [ -2.084467  ,   0.60819864,  -0.98356   ],\n",
      "       [ -4.263547  ,  -2.4702892 ,   2.39273   ],\n",
      "       [ -5.5100584 ,   2.0516791 ,  -1.8897293 ],\n",
      "       [  4.9006004 ,  -5.0589314 ,  -9.545646  ],\n",
      "       [ -2.543323  ,   2.699449  ,  -4.8774805 ],\n",
      "       [ -7.082927  ,  -2.0532963 ,   2.2174265 ],\n",
      "       [  4.3153324 ,  -3.6782014 , -11.02771   ],\n",
      "       [  4.114754  ,  -3.2838306 , -11.369756  ],\n",
      "       [ -4.3627324 ,   3.0607002 ,  -3.566593  ],\n",
      "       [ -5.991701  ,  -0.3284957 ,   0.26641458],\n",
      "       [  3.836381  ,  -2.989359  , -10.985487  ],\n",
      "       [ -5.771299  ,  -3.6216092 ,   3.8978825 ],\n",
      "       [  4.583279  ,  -4.130732  , -10.81274   ],\n",
      "       [  4.4745655 ,  -4.690988  ,  -8.7233925 ],\n",
      "       [ -3.0160646 ,  -0.63677573,   0.5858616 ],\n",
      "       [ -1.676466  ,   2.0383675 ,  -5.0246487 ],\n",
      "       [ -6.510791  ,  -3.9731061 ,   3.9897208 ],\n",
      "       [ -5.6676774 ,  -0.43990222,   0.5662989 ],\n",
      "       [ -6.4883275 ,  -0.1409091 ,   0.29135305],\n",
      "       [ -9.702185  ,  -4.412817  ,   4.4671817 ],\n",
      "       [ -4.4738007 ,   2.1550622 ,  -2.1328852 ],\n",
      "       [  4.5283537 ,  -3.979635  , -10.8337145 ],\n",
      "       [  5.418985  ,  -5.0285745 , -11.504724  ],\n",
      "       [ -8.004694  ,  -0.161966  ,   0.43838352],\n",
      "       [ -6.894335  ,  -1.8299918 ,   1.7485242 ],\n",
      "       [  4.613521  ,  -4.1614575 , -10.7127075 ],\n",
      "       [  4.6327505 ,  -4.335815  , -10.474258  ],\n",
      "       [  4.931037  ,  -4.5484867 , -10.872901  ],\n",
      "       [ -7.21743   ,   0.29756358,  -0.18051624],\n",
      "       [ -4.787442  ,  -3.0295198 ,   2.9518905 ],\n",
      "       [  5.5926695 ,  -5.778622  , -10.107517  ],\n",
      "       [ -6.9061756 ,  -2.9545403 ,   3.0225513 ],\n",
      "       [ -5.673313  ,  -3.90498   ,   3.882657  ],\n",
      "       [  4.824527  ,  -4.3977695 , -10.969899  ],\n",
      "       [ -4.514532  ,   1.2716601 ,  -1.3179705 ],\n",
      "       [ -6.0702405 ,   0.9859031 ,  -1.0342652 ],\n",
      "       [ -5.7132955 ,  -0.89210254,   0.9740431 ],\n",
      "       [ -5.29967   ,   1.8246948 ,  -2.1000876 ],\n",
      "       [ -5.189216  ,  -3.3501647 ,   3.364668  ],\n",
      "       [  5.598124  ,  -5.724636  , -10.425025  ],\n",
      "       [ -6.6081686 ,  -2.7124932 ,   2.7209592 ],\n",
      "       [ -3.3421078 ,   1.4341943 ,  -1.5151174 ],\n",
      "       [ -5.887926  ,  -2.1686988 ,   2.223697  ],\n",
      "       [ -3.3162408 ,   3.826232  ,  -5.0616703 ],\n",
      "       [ -2.4268332 ,   1.4566305 ,  -2.067731  ],\n",
      "       [ -3.9633555 ,   1.4759053 ,  -1.5685364 ],\n",
      "       [  1.6134678 ,  -0.3069361 , -10.810623  ],\n",
      "       [ -5.6284046 ,   2.0933037 ,  -2.239156  ],\n",
      "       [ -4.131566  ,   2.230606  ,  -2.1639812 ],\n",
      "       [  4.8120832 ,  -4.490706  , -10.821847  ],\n",
      "       [ -2.0689983 ,   1.8025417 ,  -2.7373881 ],\n",
      "       [ -8.801036  ,  -2.4049265 ,   2.4491968 ],\n",
      "       [ -5.369343  ,  -2.8859217 ,   2.80073   ],\n",
      "       [  5.1418467 ,  -5.3259683 ,  -9.702805  ],\n",
      "       [ -1.6707021 ,   2.0029778 ,  -4.984487  ],\n",
      "       [ -6.032291  ,  -4.3260016 ,   4.2816463 ],\n",
      "       [ -7.5859704 ,  -0.70660096,   0.6316685 ],\n",
      "       [  5.6744895 ,  -5.574043  , -11.141704  ],\n",
      "       [ -6.557317  ,  -4.4558415 ,   4.5415287 ],\n",
      "       [  3.5684347 ,  -2.536828  , -11.200456  ],\n",
      "       [ -5.749658  ,   0.9500124 ,  -1.1324395 ],\n",
      "       [ -9.543856  ,  -2.6707826 ,   2.7430415 ],\n",
      "       [ -5.8956866 ,  -1.8498046 ,   1.9588907 ],\n",
      "       [ -3.58078   ,   2.348676  ,  -2.3869839 ],\n",
      "       [ -5.850851  ,  -1.5699557 ,   1.6062732 ],\n",
      "       [ -7.7489343 ,   1.8208708 ,  -1.7261853 ],\n",
      "       [ -4.9619308 ,   2.4176166 ,  -2.5659173 ],\n",
      "       [ -4.478256  ,  -2.1943748 ,   2.4229128 ],\n",
      "       [ -4.1183167 ,  -1.2635442 ,   1.3406775 ],\n",
      "       [  3.4123554 ,  -2.451614  , -10.92229   ],\n",
      "       [ -4.5400853 ,   2.6331882 ,  -2.7340248 ],\n",
      "       [ -3.6567373 ,  -0.6970976 ,   1.0083318 ],\n",
      "       [  4.7248993 ,  -4.24376   , -11.394041  ],\n",
      "       [ -4.677568  ,   2.8772335 ,  -2.88881   ],\n",
      "       [ -7.879197  ,  -3.3743572 ,   3.441225  ]], dtype=float32), 'shape': (120, 3)}\n",
      "==================================\n",
      "15\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [17], '_cg_ascend': [], '_grad_f': tensor32([[ 2.50000097e-02 -1.00053770e-08 -2.01935538e-10]\n",
      " [ 2.50000320e-02 -3.13242481e-08 -1.44465628e-09]\n",
      " [-8.13020870e-06  2.51186527e-02 -1.10522240e-04]\n",
      " [ 2.50004269e-02 -4.23158752e-07 -1.48871004e-09]\n",
      " [ 2.50001177e-02 -1.17240155e-07 -6.95568214e-10]\n",
      " [-4.90446723e-07 -1.67289181e-04  2.51677819e-02]\n",
      " [-4.61717063e-05  2.54695117e-02 -4.23338643e-04]\n",
      " [ 2.50021555e-02 -2.15380373e-06 -1.87444416e-09]\n",
      " [ 2.50002258e-02 -2.22337590e-07 -8.61081206e-10]\n",
      " [ 2.50000134e-02 -1.25783775e-08 -2.42020015e-10]\n",
      " [-3.73807325e-06 -1.17005722e-04  2.51207463e-02]\n",
      " [-8.36097868e-04  2.72237100e-02 -1.38761499e-03]\n",
      " [-1.43897214e-05  2.56708153e-02 -6.56427292e-04]\n",
      " [ 2.50002407e-02 -2.38435831e-07 -2.03747641e-09]\n",
      " [ 2.50014588e-02 -1.45470085e-06 -1.59965585e-09]\n",
      " [-4.23463644e-06  2.50073746e-02 -3.13937267e-06]\n",
      " [-1.17421378e-05 -5.10381535e-03  3.01155616e-02]\n",
      " [-1.03044931e-05 -3.63450352e-04  2.53737569e-02]\n",
      " [-7.06932769e-06  2.51509063e-02 -1.43836631e-04]\n",
      " [-2.66708184e-07 -1.16418050e-06  2.50014327e-02]\n",
      " [-4.17765659e-05  2.51237750e-02 -8.19995621e-05]\n",
      " [-9.30147603e-09 -2.05983201e-06  2.50020698e-02]\n",
      " [-2.04299722e-04  2.63319798e-02 -1.12767785e-03]\n",
      " [ 2.50009932e-02 -9.92131845e-07 -1.30458599e-09]\n",
      " [-3.46401929e-09 -3.32134960e-06  2.50033252e-02]\n",
      " [-4.06466097e-06  2.50079222e-02 -3.85483190e-06]\n",
      " [ 2.50044279e-02 -4.42574992e-06 -1.97588812e-09]\n",
      " [ 2.50004902e-02 -4.88762169e-07 -1.59382918e-09]\n",
      " [ 2.50001736e-02 -1.68013628e-07 -5.06048581e-09]\n",
      " [-7.03756359e-06  2.50135437e-02 -6.50468564e-06]\n",
      " [-3.43651004e-06 -8.07185424e-04  2.58106217e-02]\n",
      " [ 2.50006206e-02 -6.16654063e-07 -2.66772071e-09]\n",
      " [ 2.50455216e-02 -4.55168265e-05 -5.57571012e-09]\n",
      " [ 2.50096172e-02 -9.59615227e-06 -2.07244941e-08]\n",
      " [-2.05966135e-05  2.51443796e-02 -1.23781807e-04]\n",
      " [ 2.50026248e-02 -2.62069580e-06 -2.02903605e-09]\n",
      " [-8.95269259e-05  2.51255929e-02 -3.60672602e-05]\n",
      " [-6.25832058e-07 -8.10587790e-06  2.50087343e-02]\n",
      " [ 2.50004902e-02 -4.87456987e-07 -1.18248433e-09]\n",
      " [-9.21803985e-06  2.50767693e-02 -6.75511619e-05]\n",
      " [-8.99985196e-07 -3.58816251e-05  2.50367820e-02]\n",
      " [ 2.50000358e-02 -3.57630583e-08 -4.52265503e-10]\n",
      " [-4.38463612e-05 -1.29494176e-03  2.63387896e-02]\n",
      " [-3.73807325e-06 -1.17005722e-04  2.51207463e-02]\n",
      " [-1.98228605e-07  2.50059702e-02 -5.77177479e-06]\n",
      " [-4.43784375e-04  2.67781951e-02 -1.33441156e-03]\n",
      " [-1.06203215e-05 -6.38174752e-05  2.50744410e-02]\n",
      " [-4.24837526e-06  2.51629241e-02 -1.58676237e-04]\n",
      " [ 2.50004008e-02 -3.93938365e-07 -4.43478987e-09]\n",
      " [-4.37926356e-05  2.50480361e-02 -4.24315976e-06]\n",
      " [-7.51037135e-07 -1.14816008e-04  2.51155682e-02]\n",
      " [ 2.50028148e-02 -2.81270604e-06 -1.80831228e-09]\n",
      " [ 2.50050984e-02 -5.09786469e-06 -1.56933411e-09]\n",
      " [-4.96626171e-06  2.50159763e-02 -1.10100300e-05]\n",
      " [-1.02715221e-05  3.03744115e-02 -5.36413817e-03]\n",
      " [ 2.50090398e-02 -9.03579257e-06 -3.04292991e-09]\n",
      " [-5.26360850e-07 -4.51733331e-06  2.50050426e-02]\n",
      " [ 2.50013731e-02 -1.36867504e-06 -1.71530457e-09]\n",
      " [ 2.50008889e-02 -8.71410975e-07 -1.54515547e-08]\n",
      " [-1.71941734e-04  3.14768404e-02 -6.30489783e-03]\n",
      " [-1.98003050e-04  2.52049640e-02 -6.95944664e-06]\n",
      " [-2.29267002e-07 -2.90030630e-06  2.50031315e-02]\n",
      " [-1.19533233e-05  3.11054997e-02 -6.09354768e-03]\n",
      " [-5.73998341e-06 -3.27762705e-03  2.82833651e-02]\n",
      " [-5.84898086e-09 -1.15937360e-06  2.50011645e-02]\n",
      " [-1.08505255e-05  2.51235962e-02 -1.12745009e-04]\n",
      " [ 2.50016861e-02 -1.68173801e-06 -1.77447368e-09]\n",
      " [ 2.50002407e-02 -2.41818128e-07 -3.72334441e-10]\n",
      " [-1.15886201e-06 -2.95178709e-03  2.79529467e-02]\n",
      " [-1.42968508e-06 -2.26285323e-04  2.52277143e-02]\n",
      " [ 2.50012912e-02 -1.28773581e-06 -1.83930970e-09]\n",
      " [ 2.50010639e-02 -1.06112145e-06 -2.29019648e-09]\n",
      " [ 2.50006393e-02 -6.36620598e-07 -1.14083409e-09]\n",
      " [-2.80184918e-06  2.81909443e-02 -3.18814162e-03]\n",
      " [-3.61730667e-06 -2.09817372e-05  2.50246003e-02]\n",
      " [ 2.50000991e-02 -9.60117319e-08 -1.26563737e-09]\n",
      " [-4.05234317e-07 -2.10804355e-05  2.50214860e-02]\n",
      " [-5.89525825e-07 -3.45525632e-06  2.50040442e-02]\n",
      " [ 2.50008255e-02 -8.23348387e-07 -1.15171150e-09]\n",
      " [-2.37269251e-05  2.56038122e-02 -5.80083404e-04]\n",
      " [-6.33803666e-06  2.59814449e-02 -9.75104398e-04]\n",
      " [-8.98668986e-06 -1.11536530e-03  2.61243507e-02]\n",
      " [-6.57523697e-06  2.51678154e-02 -1.61239892e-04]\n",
      " [-1.60436764e-06 -1.00923926e-05  2.50116996e-02]\n",
      " [ 2.50001028e-02 -1.00786288e-07 -9.16321907e-10]\n",
      " [-7.36713446e-07 -3.62383980e-05  2.50369757e-02]\n",
      " [-6.62006496e-05  2.54776478e-02 -4.11447283e-04]\n",
      " [-2.46897866e-06 -1.01802150e-04  2.51042731e-02]\n",
      " [-6.58383624e-06  2.50077322e-02 -1.14934028e-06]\n",
      " [-1.63320990e-04  2.53972039e-02 -2.33882689e-04]\n",
      " [-3.44014079e-05  2.54116543e-02 -3.77253251e-04]\n",
      " [ 2.60651633e-02 -1.06513395e-03 -2.92220577e-08]\n",
      " [-3.64305856e-06  2.51116417e-02 -1.07993656e-04]\n",
      " [-1.41806040e-05  2.51156203e-02 -1.01439204e-04]\n",
      " [ 2.50007622e-02 -7.59676823e-07 -1.35222666e-09]\n",
      " [-1.68252256e-04  2.52544880e-02 -8.62348679e-05]\n",
      " [-1.07529218e-07 -6.44646425e-05  2.50645727e-02]\n",
      " [-2.34968024e-06 -2.81542962e-05  2.50305086e-02]\n",
      " [ 2.50002407e-02 -2.36969129e-07 -2.97753000e-09]\n",
      " [-2.06102341e-04  2.52136048e-02 -7.49763558e-06]\n",
      " [-2.76337005e-07 -1.52219775e-06  2.50017978e-02]\n",
      " [-1.78110020e-06 -1.73125300e-03  2.67330371e-02]\n",
      " [ 2.50001103e-02 -1.08551937e-07 -4.14603962e-10]\n",
      " [-1.26064009e-07 -1.03098046e-06  2.50011571e-02]\n",
      " [ 2.50185542e-02 -1.85510635e-05 -3.20481686e-09]\n",
      " [-9.11394181e-06  2.59315558e-02 -9.22441308e-04]\n",
      " [-3.82608540e-08 -3.69566515e-05  2.50369944e-02]\n",
      " [-3.16175556e-06 -1.80730916e-04  2.51838937e-02]\n",
      " [-2.19154390e-05  2.50942297e-02 -7.23118210e-05]\n",
      " [-4.61561649e-06 -3.33732809e-04  2.53383517e-02]\n",
      " [-5.65380446e-07  2.52339058e-02 -2.33339058e-04]\n",
      " [-5.16046111e-06  2.50618197e-02 -5.66583367e-05]\n",
      " [-8.29806777e-06 -8.14430387e-05  2.50897408e-02]\n",
      " [-3.29079667e-05 -5.71627170e-04  2.56045349e-02]\n",
      " [ 2.50236057e-02 -2.35992065e-05 -4.94458208e-09]\n",
      " [-6.35553442e-06  2.50450373e-02 -3.86824686e-05]\n",
      " [-6.58949357e-05 -1.27118058e-03  2.63370760e-02]\n",
      " [ 2.50010639e-02 -1.06102129e-06 -8.32523717e-10]\n",
      " [-4.34735784e-06  2.50303522e-02 -2.60059696e-05]\n",
      " [-1.00911507e-07 -9.12783526e-06  2.50092298e-02]]), 'grad': tensor32([[ 2.50000097e-02 -1.00053770e-08 -2.01935538e-10]\n",
      " [ 2.50000320e-02 -3.13242481e-08 -1.44465628e-09]\n",
      " [-8.13020870e-06  2.51186527e-02 -1.10522240e-04]\n",
      " [ 2.50004269e-02 -4.23158752e-07 -1.48871004e-09]\n",
      " [ 2.50001177e-02 -1.17240155e-07 -6.95568214e-10]\n",
      " [-4.90446723e-07 -1.67289181e-04  2.51677819e-02]\n",
      " [-4.61717063e-05  2.54695117e-02 -4.23338643e-04]\n",
      " [ 2.50021555e-02 -2.15380373e-06 -1.87444416e-09]\n",
      " [ 2.50002258e-02 -2.22337590e-07 -8.61081206e-10]\n",
      " [ 2.50000134e-02 -1.25783775e-08 -2.42020015e-10]\n",
      " [-3.73807325e-06 -1.17005722e-04  2.51207463e-02]\n",
      " [-8.36097868e-04  2.72237100e-02 -1.38761499e-03]\n",
      " [-1.43897214e-05  2.56708153e-02 -6.56427292e-04]\n",
      " [ 2.50002407e-02 -2.38435831e-07 -2.03747641e-09]\n",
      " [ 2.50014588e-02 -1.45470085e-06 -1.59965585e-09]\n",
      " [-4.23463644e-06  2.50073746e-02 -3.13937267e-06]\n",
      " [-1.17421378e-05 -5.10381535e-03  3.01155616e-02]\n",
      " [-1.03044931e-05 -3.63450352e-04  2.53737569e-02]\n",
      " [-7.06932769e-06  2.51509063e-02 -1.43836631e-04]\n",
      " [-2.66708184e-07 -1.16418050e-06  2.50014327e-02]\n",
      " [-4.17765659e-05  2.51237750e-02 -8.19995621e-05]\n",
      " [-9.30147603e-09 -2.05983201e-06  2.50020698e-02]\n",
      " [-2.04299722e-04  2.63319798e-02 -1.12767785e-03]\n",
      " [ 2.50009932e-02 -9.92131845e-07 -1.30458599e-09]\n",
      " [-3.46401929e-09 -3.32134960e-06  2.50033252e-02]\n",
      " [-4.06466097e-06  2.50079222e-02 -3.85483190e-06]\n",
      " [ 2.50044279e-02 -4.42574992e-06 -1.97588812e-09]\n",
      " [ 2.50004902e-02 -4.88762169e-07 -1.59382918e-09]\n",
      " [ 2.50001736e-02 -1.68013628e-07 -5.06048581e-09]\n",
      " [-7.03756359e-06  2.50135437e-02 -6.50468564e-06]\n",
      " [-3.43651004e-06 -8.07185424e-04  2.58106217e-02]\n",
      " [ 2.50006206e-02 -6.16654063e-07 -2.66772071e-09]\n",
      " [ 2.50455216e-02 -4.55168265e-05 -5.57571012e-09]\n",
      " [ 2.50096172e-02 -9.59615227e-06 -2.07244941e-08]\n",
      " [-2.05966135e-05  2.51443796e-02 -1.23781807e-04]\n",
      " [ 2.50026248e-02 -2.62069580e-06 -2.02903605e-09]\n",
      " [-8.95269259e-05  2.51255929e-02 -3.60672602e-05]\n",
      " [-6.25832058e-07 -8.10587790e-06  2.50087343e-02]\n",
      " [ 2.50004902e-02 -4.87456987e-07 -1.18248433e-09]\n",
      " [-9.21803985e-06  2.50767693e-02 -6.75511619e-05]\n",
      " [-8.99985196e-07 -3.58816251e-05  2.50367820e-02]\n",
      " [ 2.50000358e-02 -3.57630583e-08 -4.52265503e-10]\n",
      " [-4.38463612e-05 -1.29494176e-03  2.63387896e-02]\n",
      " [-3.73807325e-06 -1.17005722e-04  2.51207463e-02]\n",
      " [-1.98228605e-07  2.50059702e-02 -5.77177479e-06]\n",
      " [-4.43784375e-04  2.67781951e-02 -1.33441156e-03]\n",
      " [-1.06203215e-05 -6.38174752e-05  2.50744410e-02]\n",
      " [-4.24837526e-06  2.51629241e-02 -1.58676237e-04]\n",
      " [ 2.50004008e-02 -3.93938365e-07 -4.43478987e-09]\n",
      " [-4.37926356e-05  2.50480361e-02 -4.24315976e-06]\n",
      " [-7.51037135e-07 -1.14816008e-04  2.51155682e-02]\n",
      " [ 2.50028148e-02 -2.81270604e-06 -1.80831228e-09]\n",
      " [ 2.50050984e-02 -5.09786469e-06 -1.56933411e-09]\n",
      " [-4.96626171e-06  2.50159763e-02 -1.10100300e-05]\n",
      " [-1.02715221e-05  3.03744115e-02 -5.36413817e-03]\n",
      " [ 2.50090398e-02 -9.03579257e-06 -3.04292991e-09]\n",
      " [-5.26360850e-07 -4.51733331e-06  2.50050426e-02]\n",
      " [ 2.50013731e-02 -1.36867504e-06 -1.71530457e-09]\n",
      " [ 2.50008889e-02 -8.71410975e-07 -1.54515547e-08]\n",
      " [-1.71941734e-04  3.14768404e-02 -6.30489783e-03]\n",
      " [-1.98003050e-04  2.52049640e-02 -6.95944664e-06]\n",
      " [-2.29267002e-07 -2.90030630e-06  2.50031315e-02]\n",
      " [-1.19533233e-05  3.11054997e-02 -6.09354768e-03]\n",
      " [-5.73998341e-06 -3.27762705e-03  2.82833651e-02]\n",
      " [-5.84898086e-09 -1.15937360e-06  2.50011645e-02]\n",
      " [-1.08505255e-05  2.51235962e-02 -1.12745009e-04]\n",
      " [ 2.50016861e-02 -1.68173801e-06 -1.77447368e-09]\n",
      " [ 2.50002407e-02 -2.41818128e-07 -3.72334441e-10]\n",
      " [-1.15886201e-06 -2.95178709e-03  2.79529467e-02]\n",
      " [-1.42968508e-06 -2.26285323e-04  2.52277143e-02]\n",
      " [ 2.50012912e-02 -1.28773581e-06 -1.83930970e-09]\n",
      " [ 2.50010639e-02 -1.06112145e-06 -2.29019648e-09]\n",
      " [ 2.50006393e-02 -6.36620598e-07 -1.14083409e-09]\n",
      " [-2.80184918e-06  2.81909443e-02 -3.18814162e-03]\n",
      " [-3.61730667e-06 -2.09817372e-05  2.50246003e-02]\n",
      " [ 2.50000991e-02 -9.60117319e-08 -1.26563737e-09]\n",
      " [-4.05234317e-07 -2.10804355e-05  2.50214860e-02]\n",
      " [-5.89525825e-07 -3.45525632e-06  2.50040442e-02]\n",
      " [ 2.50008255e-02 -8.23348387e-07 -1.15171150e-09]\n",
      " [-2.37269251e-05  2.56038122e-02 -5.80083404e-04]\n",
      " [-6.33803666e-06  2.59814449e-02 -9.75104398e-04]\n",
      " [-8.98668986e-06 -1.11536530e-03  2.61243507e-02]\n",
      " [-6.57523697e-06  2.51678154e-02 -1.61239892e-04]\n",
      " [-1.60436764e-06 -1.00923926e-05  2.50116996e-02]\n",
      " [ 2.50001028e-02 -1.00786288e-07 -9.16321907e-10]\n",
      " [-7.36713446e-07 -3.62383980e-05  2.50369757e-02]\n",
      " [-6.62006496e-05  2.54776478e-02 -4.11447283e-04]\n",
      " [-2.46897866e-06 -1.01802150e-04  2.51042731e-02]\n",
      " [-6.58383624e-06  2.50077322e-02 -1.14934028e-06]\n",
      " [-1.63320990e-04  2.53972039e-02 -2.33882689e-04]\n",
      " [-3.44014079e-05  2.54116543e-02 -3.77253251e-04]\n",
      " [ 2.60651633e-02 -1.06513395e-03 -2.92220577e-08]\n",
      " [-3.64305856e-06  2.51116417e-02 -1.07993656e-04]\n",
      " [-1.41806040e-05  2.51156203e-02 -1.01439204e-04]\n",
      " [ 2.50007622e-02 -7.59676823e-07 -1.35222666e-09]\n",
      " [-1.68252256e-04  2.52544880e-02 -8.62348679e-05]\n",
      " [-1.07529218e-07 -6.44646425e-05  2.50645727e-02]\n",
      " [-2.34968024e-06 -2.81542962e-05  2.50305086e-02]\n",
      " [ 2.50002407e-02 -2.36969129e-07 -2.97753000e-09]\n",
      " [-2.06102341e-04  2.52136048e-02 -7.49763558e-06]\n",
      " [-2.76337005e-07 -1.52219775e-06  2.50017978e-02]\n",
      " [-1.78110020e-06 -1.73125300e-03  2.67330371e-02]\n",
      " [ 2.50001103e-02 -1.08551937e-07 -4.14603962e-10]\n",
      " [-1.26064009e-07 -1.03098046e-06  2.50011571e-02]\n",
      " [ 2.50185542e-02 -1.85510635e-05 -3.20481686e-09]\n",
      " [-9.11394181e-06  2.59315558e-02 -9.22441308e-04]\n",
      " [-3.82608540e-08 -3.69566515e-05  2.50369944e-02]\n",
      " [-3.16175556e-06 -1.80730916e-04  2.51838937e-02]\n",
      " [-2.19154390e-05  2.50942297e-02 -7.23118210e-05]\n",
      " [-4.61561649e-06 -3.33732809e-04  2.53383517e-02]\n",
      " [-5.65380446e-07  2.52339058e-02 -2.33339058e-04]\n",
      " [-5.16046111e-06  2.50618197e-02 -5.66583367e-05]\n",
      " [-8.29806777e-06 -8.14430387e-05  2.50897408e-02]\n",
      " [-3.29079667e-05 -5.71627170e-04  2.56045349e-02]\n",
      " [ 2.50236057e-02 -2.35992065e-05 -4.94458208e-09]\n",
      " [-6.35553442e-06  2.50450373e-02 -3.86824686e-05]\n",
      " [-6.58949357e-05 -1.27118058e-03  2.63370760e-02]\n",
      " [ 2.50010639e-02 -1.06102129e-06 -8.32523717e-10]\n",
      " [-4.34735784e-06  2.50303522e-02 -2.60059696e-05]\n",
      " [-1.00911507e-07 -9.12783526e-06  2.50092298e-02]]), 'npar_data': array([[6.6269374 ],\n",
      "       [5.9347715 ],\n",
      "       [2.0402665 ],\n",
      "       [5.0340047 ],\n",
      "       [5.6016674 ],\n",
      "       [2.0548952 ],\n",
      "       [1.365166  ],\n",
      "       [4.400501  ],\n",
      "       [5.321277  ],\n",
      "       [6.5065556 ],\n",
      "       [2.2377057 ],\n",
      "       [0.28327373],\n",
      "       [1.1410203 ],\n",
      "       [5.170074  ],\n",
      "       [4.553037  ],\n",
      "       [3.5375838 ],\n",
      "       [0.24377236],\n",
      "       [1.5496709 ],\n",
      "       [1.931525  ],\n",
      "       [4.315458  ],\n",
      "       [2.2011535 ],\n",
      "       [4.1866593 ],\n",
      "       [0.84205264],\n",
      "       [4.726916  ],\n",
      "       [3.9707084 ],\n",
      "       [3.6992419 ],\n",
      "       [4.132554  ],\n",
      "       [4.9591656 ],\n",
      "       [5.2076893 ],\n",
      "       [2.8834379 ],\n",
      "       [1.1735826 ],\n",
      "       [4.8319    ],\n",
      "       [3.1746511 ],\n",
      "       [3.5716863 ],\n",
      "       [2.106629  ],\n",
      "       [4.324232  ],\n",
      "       [2.2436154 ],\n",
      "       [3.2546253 ],\n",
      "       [5.016205  ],\n",
      "       [2.3420131 ],\n",
      "       [2.884169  ],\n",
      "       [6.037933  ],\n",
      "       [0.8608387 ],\n",
      "       [2.2377057 ],\n",
      "       [3.6677368 ],\n",
      "       [0.60819864],\n",
      "       [2.39273   ],\n",
      "       [2.0516791 ],\n",
      "       [4.9006004 ],\n",
      "       [2.699449  ],\n",
      "       [2.2174265 ],\n",
      "       [4.3153324 ],\n",
      "       [4.114754  ],\n",
      "       [3.0607002 ],\n",
      "       [0.26641458],\n",
      "       [3.836381  ],\n",
      "       [3.8978825 ],\n",
      "       [4.583279  ],\n",
      "       [4.4745655 ],\n",
      "       [0.5858616 ],\n",
      "       [2.0383675 ],\n",
      "       [3.9897208 ],\n",
      "       [0.5662989 ],\n",
      "       [0.29135305],\n",
      "       [4.4671817 ],\n",
      "       [2.1550622 ],\n",
      "       [4.5283537 ],\n",
      "       [5.418985  ],\n",
      "       [0.43838352],\n",
      "       [1.7485242 ],\n",
      "       [4.613521  ],\n",
      "       [4.6327505 ],\n",
      "       [4.931037  ],\n",
      "       [0.29756358],\n",
      "       [2.9518905 ],\n",
      "       [5.5926695 ],\n",
      "       [3.0225513 ],\n",
      "       [3.882657  ],\n",
      "       [4.824527  ],\n",
      "       [1.2716601 ],\n",
      "       [0.9859031 ],\n",
      "       [0.9740431 ],\n",
      "       [1.8246948 ],\n",
      "       [3.364668  ],\n",
      "       [5.598124  ],\n",
      "       [2.7209592 ],\n",
      "       [1.4341943 ],\n",
      "       [2.223697  ],\n",
      "       [3.826232  ],\n",
      "       [1.4566305 ],\n",
      "       [1.4759053 ],\n",
      "       [1.6134678 ],\n",
      "       [2.0933037 ],\n",
      "       [2.230606  ],\n",
      "       [4.8120832 ],\n",
      "       [1.8025417 ],\n",
      "       [2.4491968 ],\n",
      "       [2.80073   ],\n",
      "       [5.1418467 ],\n",
      "       [2.0029778 ],\n",
      "       [4.2816463 ],\n",
      "       [0.6316685 ],\n",
      "       [5.6744895 ],\n",
      "       [4.5415287 ],\n",
      "       [3.5684347 ],\n",
      "       [0.9500124 ],\n",
      "       [2.7430415 ],\n",
      "       [1.9588907 ],\n",
      "       [2.348676  ],\n",
      "       [1.6062732 ],\n",
      "       [1.8208708 ],\n",
      "       [2.4176166 ],\n",
      "       [2.4229128 ],\n",
      "       [1.3406775 ],\n",
      "       [3.4123554 ],\n",
      "       [2.6331882 ],\n",
      "       [1.0083318 ],\n",
      "       [4.7248993 ],\n",
      "       [2.8772335 ],\n",
      "       [3.441225  ]], dtype=float32), 'shape': (120, 1)}\n",
      "==================================\n",
      "16\n",
      "-1\n",
      "==================================\n",
      "17\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [18], '_cg_ascend': [15], '_grad_f': tensor32([[-1.66666768e-02  1.00053770e-08  2.01935538e-10]\n",
      " [-1.66666992e-02  3.13242481e-08  1.44465628e-09]\n",
      " [ 8.13020870e-06 -1.67853199e-02  1.10522240e-04]\n",
      " [-1.66670922e-02  4.23158752e-07  1.48871004e-09]\n",
      " [-1.66667849e-02  1.17240155e-07  6.95568214e-10]\n",
      " [ 4.90446723e-07  1.67289181e-04 -1.68344472e-02]\n",
      " [ 4.61717063e-05 -1.71361789e-02  4.23338643e-04]\n",
      " [-1.66688226e-02  2.15380373e-06  1.87444416e-09]\n",
      " [-1.66668911e-02  2.22337590e-07  8.61081206e-10]\n",
      " [-1.66666806e-02  1.25783775e-08  2.42020015e-10]\n",
      " [ 3.73807325e-06  1.17005722e-04 -1.67874116e-02]\n",
      " [ 8.36097868e-04 -1.88903771e-02  1.38761499e-03]\n",
      " [ 1.43897214e-05 -1.73374824e-02  6.56427292e-04]\n",
      " [-1.66669078e-02  2.38435831e-07  2.03747641e-09]\n",
      " [-1.66681241e-02  1.45470085e-06  1.59965585e-09]\n",
      " [ 4.23463644e-06 -1.66740417e-02  3.13937267e-06]\n",
      " [ 1.17421378e-05  5.10381535e-03 -2.17822269e-02]\n",
      " [ 1.03044931e-05  3.63450352e-04 -1.70404222e-02]\n",
      " [ 7.06932769e-06 -1.68175735e-02  1.43836631e-04]\n",
      " [ 2.66708184e-07  1.16418050e-06 -1.66680999e-02]\n",
      " [ 4.17765659e-05 -1.67904422e-02  8.19995621e-05]\n",
      " [ 9.30147603e-09  2.05983201e-06 -1.66687369e-02]\n",
      " [ 2.04299722e-04 -1.79986451e-02  1.12767785e-03]\n",
      " [-1.66676603e-02  9.92131845e-07  1.30458599e-09]\n",
      " [ 3.46401929e-09  3.32134960e-06 -1.66699924e-02]\n",
      " [ 4.06466097e-06 -1.66745875e-02  3.85483190e-06]\n",
      " [-1.66710950e-02  4.42574992e-06  1.97588812e-09]\n",
      " [-1.66671574e-02  4.88762169e-07  1.59382918e-09]\n",
      " [-1.66668408e-02  1.68013628e-07  5.06048581e-09]\n",
      " [ 7.03756359e-06 -1.66802108e-02  6.50468564e-06]\n",
      " [ 3.43651004e-06  8.07185424e-04 -1.74772888e-02]\n",
      " [-1.66672878e-02  6.16654063e-07  2.66772071e-09]\n",
      " [-1.67121887e-02  4.55168265e-05  5.57571012e-09]\n",
      " [-1.66762844e-02  9.59615227e-06  2.07244941e-08]\n",
      " [ 2.05966135e-05 -1.68110467e-02  1.23781807e-04]\n",
      " [-1.66692901e-02  2.62069580e-06  2.02903605e-09]\n",
      " [ 8.95269259e-05 -1.67922601e-02  3.60672602e-05]\n",
      " [ 6.25832058e-07  8.10587790e-06 -1.66753996e-02]\n",
      " [-1.66671574e-02  4.87456987e-07  1.18248433e-09]\n",
      " [ 9.21803985e-06 -1.67434365e-02  6.75511619e-05]\n",
      " [ 8.99985196e-07  3.58816251e-05 -1.67034492e-02]\n",
      " [-1.66667029e-02  3.57630583e-08  4.52265503e-10]\n",
      " [ 4.38463612e-05  1.29494176e-03 -1.80054568e-02]\n",
      " [ 3.73807325e-06  1.17005722e-04 -1.67874116e-02]\n",
      " [ 1.98228605e-07 -1.66726373e-02  5.77177479e-06]\n",
      " [ 4.43784375e-04 -1.84448622e-02  1.33441156e-03]\n",
      " [ 1.06203215e-05  6.38174752e-05 -1.67411063e-02]\n",
      " [ 4.24837526e-06 -1.68295912e-02  1.58676237e-04]\n",
      " [-1.66670661e-02  3.93938365e-07  4.43478987e-09]\n",
      " [ 4.37926356e-05 -1.67147033e-02  4.24315976e-06]\n",
      " [ 7.51037135e-07  1.14816008e-04 -1.67822354e-02]\n",
      " [-1.66694820e-02  2.81270604e-06  1.80831228e-09]\n",
      " [-1.66717656e-02  5.09786469e-06  1.56933411e-09]\n",
      " [ 4.96626171e-06 -1.66826434e-02  1.10100300e-05]\n",
      " [ 1.02715221e-05 -2.20410787e-02  5.36413817e-03]\n",
      " [-1.66757070e-02  9.03579257e-06  3.04292991e-09]\n",
      " [ 5.26360850e-07  4.51733331e-06 -1.66717097e-02]\n",
      " [-1.66680384e-02  1.36867504e-06  1.71530457e-09]\n",
      " [-1.66675542e-02  8.71410975e-07  1.54515547e-08]\n",
      " [ 1.71941734e-04 -2.31435057e-02  6.30489783e-03]\n",
      " [ 1.98003050e-04 -1.68716293e-02  6.95944664e-06]\n",
      " [ 2.29267002e-07  2.90030630e-06 -1.66697986e-02]\n",
      " [ 1.19533233e-05 -2.27721669e-02  6.09354768e-03]\n",
      " [ 5.73998341e-06  3.27762705e-03 -1.99500322e-02]\n",
      " [ 5.84898086e-09  1.15937360e-06 -1.66678317e-02]\n",
      " [ 1.08505255e-05 -1.67902634e-02  1.12745009e-04]\n",
      " [-1.66683514e-02  1.68173801e-06  1.77447368e-09]\n",
      " [-1.66669078e-02  2.41818128e-07  3.72334441e-10]\n",
      " [ 1.15886201e-06  2.95178709e-03 -1.96196139e-02]\n",
      " [ 1.42968508e-06  2.26285323e-04 -1.68943815e-02]\n",
      " [-1.66679565e-02  1.28773581e-06  1.83930970e-09]\n",
      " [-1.66677311e-02  1.06112145e-06  2.29019648e-09]\n",
      " [-1.66673064e-02  6.36620598e-07  1.14083409e-09]\n",
      " [ 2.80184918e-06 -1.98576115e-02  3.18814162e-03]\n",
      " [ 3.61730667e-06  2.09817372e-05 -1.66912675e-02]\n",
      " [-1.66667644e-02  9.60117319e-08  1.26563737e-09]\n",
      " [ 4.05234317e-07  2.10804355e-05 -1.66881531e-02]\n",
      " [ 5.89525825e-07  3.45525632e-06 -1.66707113e-02]\n",
      " [-1.66674927e-02  8.23348387e-07  1.15171150e-09]\n",
      " [ 2.37269251e-05 -1.72704794e-02  5.80083404e-04]\n",
      " [ 6.33803666e-06 -1.76481120e-02  9.75104398e-04]\n",
      " [ 8.98668986e-06  1.11536530e-03 -1.77910179e-02]\n",
      " [ 6.57523697e-06 -1.68344826e-02  1.61239892e-04]\n",
      " [ 1.60436764e-06  1.00923926e-05 -1.66783649e-02]\n",
      " [-1.66667700e-02  1.00786288e-07  9.16321907e-10]\n",
      " [ 7.36713446e-07  3.62383980e-05 -1.67036429e-02]\n",
      " [ 6.62006496e-05 -1.71443149e-02  4.11447283e-04]\n",
      " [ 2.46897866e-06  1.01802150e-04 -1.67709403e-02]\n",
      " [ 6.58383624e-06 -1.66743994e-02  1.14934028e-06]\n",
      " [ 1.63320990e-04 -1.70638710e-02  2.33882689e-04]\n",
      " [ 3.44014079e-05 -1.70783214e-02  3.77253251e-04]\n",
      " [-1.77318305e-02  1.06513395e-03  2.92220577e-08]\n",
      " [ 3.64305856e-06 -1.67783070e-02  1.07993656e-04]\n",
      " [ 1.41806040e-05 -1.67822875e-02  1.01439204e-04]\n",
      " [-1.66674294e-02  7.59676823e-07  1.35222666e-09]\n",
      " [ 1.68252256e-04 -1.69211552e-02  8.62348679e-05]\n",
      " [ 1.07529218e-07  6.44646425e-05 -1.67312399e-02]\n",
      " [ 2.34968024e-06  2.81542962e-05 -1.66971739e-02]\n",
      " [-1.66669078e-02  2.36969129e-07  2.97753000e-09]\n",
      " [ 2.06102341e-04 -1.68802701e-02  7.49763558e-06]\n",
      " [ 2.76337005e-07  1.52219775e-06 -1.66684650e-02]\n",
      " [ 1.78110020e-06  1.73125300e-03 -1.83997024e-02]\n",
      " [-1.66667774e-02  1.08551937e-07  4.14603962e-10]\n",
      " [ 1.26064009e-07  1.03098046e-06 -1.66678242e-02]\n",
      " [-1.66852213e-02  1.85510635e-05  3.20481686e-09]\n",
      " [ 9.11394181e-06 -1.75982229e-02  9.22441308e-04]\n",
      " [ 3.82608540e-08  3.69566515e-05 -1.67036615e-02]\n",
      " [ 3.16175556e-06  1.80730916e-04 -1.68505609e-02]\n",
      " [ 2.19154390e-05 -1.67608950e-02  7.23118210e-05]\n",
      " [ 4.61561649e-06  3.33732809e-04 -1.70050170e-02]\n",
      " [ 5.65380446e-07 -1.69005729e-02  2.33339058e-04]\n",
      " [ 5.16046111e-06 -1.67284869e-02  5.66583367e-05]\n",
      " [ 8.29806777e-06  8.14430387e-05 -1.67564079e-02]\n",
      " [ 3.29079667e-05  5.71627170e-04 -1.72712021e-02]\n",
      " [-1.66902710e-02  2.35992065e-05  4.94458208e-09]\n",
      " [ 6.35553442e-06 -1.67117044e-02  3.86824686e-05]\n",
      " [ 6.58949357e-05  1.27118058e-03 -1.80037431e-02]\n",
      " [-1.66677292e-02  1.06102129e-06  8.32523717e-10]\n",
      " [ 4.34735784e-06 -1.66970193e-02  2.60059696e-05]\n",
      " [ 1.00911507e-07  9.12783526e-06 -1.66758969e-02]]), 'grad': tensor32([[-1.66666768e-02  1.00053770e-08  2.01935538e-10]\n",
      " [-1.66666992e-02  3.13242481e-08  1.44465628e-09]\n",
      " [ 8.13020870e-06 -1.67853199e-02  1.10522240e-04]\n",
      " [-1.66670922e-02  4.23158752e-07  1.48871004e-09]\n",
      " [-1.66667849e-02  1.17240155e-07  6.95568214e-10]\n",
      " [ 4.90446723e-07  1.67289181e-04 -1.68344472e-02]\n",
      " [ 4.61717063e-05 -1.71361789e-02  4.23338643e-04]\n",
      " [-1.66688226e-02  2.15380373e-06  1.87444416e-09]\n",
      " [-1.66668911e-02  2.22337590e-07  8.61081206e-10]\n",
      " [-1.66666806e-02  1.25783775e-08  2.42020015e-10]\n",
      " [ 3.73807325e-06  1.17005722e-04 -1.67874116e-02]\n",
      " [ 8.36097868e-04 -1.88903771e-02  1.38761499e-03]\n",
      " [ 1.43897214e-05 -1.73374824e-02  6.56427292e-04]\n",
      " [-1.66669078e-02  2.38435831e-07  2.03747641e-09]\n",
      " [-1.66681241e-02  1.45470085e-06  1.59965585e-09]\n",
      " [ 4.23463644e-06 -1.66740417e-02  3.13937267e-06]\n",
      " [ 1.17421378e-05  5.10381535e-03 -2.17822269e-02]\n",
      " [ 1.03044931e-05  3.63450352e-04 -1.70404222e-02]\n",
      " [ 7.06932769e-06 -1.68175735e-02  1.43836631e-04]\n",
      " [ 2.66708184e-07  1.16418050e-06 -1.66680999e-02]\n",
      " [ 4.17765659e-05 -1.67904422e-02  8.19995621e-05]\n",
      " [ 9.30147603e-09  2.05983201e-06 -1.66687369e-02]\n",
      " [ 2.04299722e-04 -1.79986451e-02  1.12767785e-03]\n",
      " [-1.66676603e-02  9.92131845e-07  1.30458599e-09]\n",
      " [ 3.46401929e-09  3.32134960e-06 -1.66699924e-02]\n",
      " [ 4.06466097e-06 -1.66745875e-02  3.85483190e-06]\n",
      " [-1.66710950e-02  4.42574992e-06  1.97588812e-09]\n",
      " [-1.66671574e-02  4.88762169e-07  1.59382918e-09]\n",
      " [-1.66668408e-02  1.68013628e-07  5.06048581e-09]\n",
      " [ 7.03756359e-06 -1.66802108e-02  6.50468564e-06]\n",
      " [ 3.43651004e-06  8.07185424e-04 -1.74772888e-02]\n",
      " [-1.66672878e-02  6.16654063e-07  2.66772071e-09]\n",
      " [-1.67121887e-02  4.55168265e-05  5.57571012e-09]\n",
      " [-1.66762844e-02  9.59615227e-06  2.07244941e-08]\n",
      " [ 2.05966135e-05 -1.68110467e-02  1.23781807e-04]\n",
      " [-1.66692901e-02  2.62069580e-06  2.02903605e-09]\n",
      " [ 8.95269259e-05 -1.67922601e-02  3.60672602e-05]\n",
      " [ 6.25832058e-07  8.10587790e-06 -1.66753996e-02]\n",
      " [-1.66671574e-02  4.87456987e-07  1.18248433e-09]\n",
      " [ 9.21803985e-06 -1.67434365e-02  6.75511619e-05]\n",
      " [ 8.99985196e-07  3.58816251e-05 -1.67034492e-02]\n",
      " [-1.66667029e-02  3.57630583e-08  4.52265503e-10]\n",
      " [ 4.38463612e-05  1.29494176e-03 -1.80054568e-02]\n",
      " [ 3.73807325e-06  1.17005722e-04 -1.67874116e-02]\n",
      " [ 1.98228605e-07 -1.66726373e-02  5.77177479e-06]\n",
      " [ 4.43784375e-04 -1.84448622e-02  1.33441156e-03]\n",
      " [ 1.06203215e-05  6.38174752e-05 -1.67411063e-02]\n",
      " [ 4.24837526e-06 -1.68295912e-02  1.58676237e-04]\n",
      " [-1.66670661e-02  3.93938365e-07  4.43478987e-09]\n",
      " [ 4.37926356e-05 -1.67147033e-02  4.24315976e-06]\n",
      " [ 7.51037135e-07  1.14816008e-04 -1.67822354e-02]\n",
      " [-1.66694820e-02  2.81270604e-06  1.80831228e-09]\n",
      " [-1.66717656e-02  5.09786469e-06  1.56933411e-09]\n",
      " [ 4.96626171e-06 -1.66826434e-02  1.10100300e-05]\n",
      " [ 1.02715221e-05 -2.20410787e-02  5.36413817e-03]\n",
      " [-1.66757070e-02  9.03579257e-06  3.04292991e-09]\n",
      " [ 5.26360850e-07  4.51733331e-06 -1.66717097e-02]\n",
      " [-1.66680384e-02  1.36867504e-06  1.71530457e-09]\n",
      " [-1.66675542e-02  8.71410975e-07  1.54515547e-08]\n",
      " [ 1.71941734e-04 -2.31435057e-02  6.30489783e-03]\n",
      " [ 1.98003050e-04 -1.68716293e-02  6.95944664e-06]\n",
      " [ 2.29267002e-07  2.90030630e-06 -1.66697986e-02]\n",
      " [ 1.19533233e-05 -2.27721669e-02  6.09354768e-03]\n",
      " [ 5.73998341e-06  3.27762705e-03 -1.99500322e-02]\n",
      " [ 5.84898086e-09  1.15937360e-06 -1.66678317e-02]\n",
      " [ 1.08505255e-05 -1.67902634e-02  1.12745009e-04]\n",
      " [-1.66683514e-02  1.68173801e-06  1.77447368e-09]\n",
      " [-1.66669078e-02  2.41818128e-07  3.72334441e-10]\n",
      " [ 1.15886201e-06  2.95178709e-03 -1.96196139e-02]\n",
      " [ 1.42968508e-06  2.26285323e-04 -1.68943815e-02]\n",
      " [-1.66679565e-02  1.28773581e-06  1.83930970e-09]\n",
      " [-1.66677311e-02  1.06112145e-06  2.29019648e-09]\n",
      " [-1.66673064e-02  6.36620598e-07  1.14083409e-09]\n",
      " [ 2.80184918e-06 -1.98576115e-02  3.18814162e-03]\n",
      " [ 3.61730667e-06  2.09817372e-05 -1.66912675e-02]\n",
      " [-1.66667644e-02  9.60117319e-08  1.26563737e-09]\n",
      " [ 4.05234317e-07  2.10804355e-05 -1.66881531e-02]\n",
      " [ 5.89525825e-07  3.45525632e-06 -1.66707113e-02]\n",
      " [-1.66674927e-02  8.23348387e-07  1.15171150e-09]\n",
      " [ 2.37269251e-05 -1.72704794e-02  5.80083404e-04]\n",
      " [ 6.33803666e-06 -1.76481120e-02  9.75104398e-04]\n",
      " [ 8.98668986e-06  1.11536530e-03 -1.77910179e-02]\n",
      " [ 6.57523697e-06 -1.68344826e-02  1.61239892e-04]\n",
      " [ 1.60436764e-06  1.00923926e-05 -1.66783649e-02]\n",
      " [-1.66667700e-02  1.00786288e-07  9.16321907e-10]\n",
      " [ 7.36713446e-07  3.62383980e-05 -1.67036429e-02]\n",
      " [ 6.62006496e-05 -1.71443149e-02  4.11447283e-04]\n",
      " [ 2.46897866e-06  1.01802150e-04 -1.67709403e-02]\n",
      " [ 6.58383624e-06 -1.66743994e-02  1.14934028e-06]\n",
      " [ 1.63320990e-04 -1.70638710e-02  2.33882689e-04]\n",
      " [ 3.44014079e-05 -1.70783214e-02  3.77253251e-04]\n",
      " [-1.77318305e-02  1.06513395e-03  2.92220577e-08]\n",
      " [ 3.64305856e-06 -1.67783070e-02  1.07993656e-04]\n",
      " [ 1.41806040e-05 -1.67822875e-02  1.01439204e-04]\n",
      " [-1.66674294e-02  7.59676823e-07  1.35222666e-09]\n",
      " [ 1.68252256e-04 -1.69211552e-02  8.62348679e-05]\n",
      " [ 1.07529218e-07  6.44646425e-05 -1.67312399e-02]\n",
      " [ 2.34968024e-06  2.81542962e-05 -1.66971739e-02]\n",
      " [-1.66669078e-02  2.36969129e-07  2.97753000e-09]\n",
      " [ 2.06102341e-04 -1.68802701e-02  7.49763558e-06]\n",
      " [ 2.76337005e-07  1.52219775e-06 -1.66684650e-02]\n",
      " [ 1.78110020e-06  1.73125300e-03 -1.83997024e-02]\n",
      " [-1.66667774e-02  1.08551937e-07  4.14603962e-10]\n",
      " [ 1.26064009e-07  1.03098046e-06 -1.66678242e-02]\n",
      " [-1.66852213e-02  1.85510635e-05  3.20481686e-09]\n",
      " [ 9.11394181e-06 -1.75982229e-02  9.22441308e-04]\n",
      " [ 3.82608540e-08  3.69566515e-05 -1.67036615e-02]\n",
      " [ 3.16175556e-06  1.80730916e-04 -1.68505609e-02]\n",
      " [ 2.19154390e-05 -1.67608950e-02  7.23118210e-05]\n",
      " [ 4.61561649e-06  3.33732809e-04 -1.70050170e-02]\n",
      " [ 5.65380446e-07 -1.69005729e-02  2.33339058e-04]\n",
      " [ 5.16046111e-06 -1.67284869e-02  5.66583367e-05]\n",
      " [ 8.29806777e-06  8.14430387e-05 -1.67564079e-02]\n",
      " [ 3.29079667e-05  5.71627170e-04 -1.72712021e-02]\n",
      " [-1.66902710e-02  2.35992065e-05  4.94458208e-09]\n",
      " [ 6.35553442e-06 -1.67117044e-02  3.86824686e-05]\n",
      " [ 6.58949357e-05  1.27118058e-03 -1.80037431e-02]\n",
      " [-1.66677292e-02  1.06102129e-06  8.32523717e-10]\n",
      " [ 4.34735784e-06 -1.66970193e-02  2.60059696e-05]\n",
      " [ 1.00911507e-07  9.12783526e-06 -1.66758969e-02]]), 'npar_data': array([[-6.6269374 ],\n",
      "       [-5.9347715 ],\n",
      "       [-2.0402665 ],\n",
      "       [-5.0340047 ],\n",
      "       [-5.6016674 ],\n",
      "       [-2.0548952 ],\n",
      "       [-1.365166  ],\n",
      "       [-4.400501  ],\n",
      "       [-5.321277  ],\n",
      "       [-6.5065556 ],\n",
      "       [-2.2377057 ],\n",
      "       [-0.28327373],\n",
      "       [-1.1410203 ],\n",
      "       [-5.170074  ],\n",
      "       [-4.553037  ],\n",
      "       [-3.5375838 ],\n",
      "       [-0.24377236],\n",
      "       [-1.5496709 ],\n",
      "       [-1.931525  ],\n",
      "       [-4.315458  ],\n",
      "       [-2.2011535 ],\n",
      "       [-4.1866593 ],\n",
      "       [-0.84205264],\n",
      "       [-4.726916  ],\n",
      "       [-3.9707084 ],\n",
      "       [-3.6992419 ],\n",
      "       [-4.132554  ],\n",
      "       [-4.9591656 ],\n",
      "       [-5.2076893 ],\n",
      "       [-2.8834379 ],\n",
      "       [-1.1735826 ],\n",
      "       [-4.8319    ],\n",
      "       [-3.1746511 ],\n",
      "       [-3.5716863 ],\n",
      "       [-2.106629  ],\n",
      "       [-4.324232  ],\n",
      "       [-2.2436154 ],\n",
      "       [-3.2546253 ],\n",
      "       [-5.016205  ],\n",
      "       [-2.3420131 ],\n",
      "       [-2.884169  ],\n",
      "       [-6.037933  ],\n",
      "       [-0.8608387 ],\n",
      "       [-2.2377057 ],\n",
      "       [-3.6677368 ],\n",
      "       [-0.60819864],\n",
      "       [-2.39273   ],\n",
      "       [-2.0516791 ],\n",
      "       [-4.9006004 ],\n",
      "       [-2.699449  ],\n",
      "       [-2.2174265 ],\n",
      "       [-4.3153324 ],\n",
      "       [-4.114754  ],\n",
      "       [-3.0607002 ],\n",
      "       [-0.26641458],\n",
      "       [-3.836381  ],\n",
      "       [-3.8978825 ],\n",
      "       [-4.583279  ],\n",
      "       [-4.4745655 ],\n",
      "       [-0.5858616 ],\n",
      "       [-2.0383675 ],\n",
      "       [-3.9897208 ],\n",
      "       [-0.5662989 ],\n",
      "       [-0.29135305],\n",
      "       [-4.4671817 ],\n",
      "       [-2.1550622 ],\n",
      "       [-4.5283537 ],\n",
      "       [-5.418985  ],\n",
      "       [-0.43838352],\n",
      "       [-1.7485242 ],\n",
      "       [-4.613521  ],\n",
      "       [-4.6327505 ],\n",
      "       [-4.931037  ],\n",
      "       [-0.29756358],\n",
      "       [-2.9518905 ],\n",
      "       [-5.5926695 ],\n",
      "       [-3.0225513 ],\n",
      "       [-3.882657  ],\n",
      "       [-4.824527  ],\n",
      "       [-1.2716601 ],\n",
      "       [-0.9859031 ],\n",
      "       [-0.9740431 ],\n",
      "       [-1.8246948 ],\n",
      "       [-3.364668  ],\n",
      "       [-5.598124  ],\n",
      "       [-2.7209592 ],\n",
      "       [-1.4341943 ],\n",
      "       [-2.223697  ],\n",
      "       [-3.826232  ],\n",
      "       [-1.4566305 ],\n",
      "       [-1.4759053 ],\n",
      "       [-1.6134678 ],\n",
      "       [-2.0933037 ],\n",
      "       [-2.230606  ],\n",
      "       [-4.8120832 ],\n",
      "       [-1.8025417 ],\n",
      "       [-2.4491968 ],\n",
      "       [-2.80073   ],\n",
      "       [-5.1418467 ],\n",
      "       [-2.0029778 ],\n",
      "       [-4.2816463 ],\n",
      "       [-0.6316685 ],\n",
      "       [-5.6744895 ],\n",
      "       [-4.5415287 ],\n",
      "       [-3.5684347 ],\n",
      "       [-0.9500124 ],\n",
      "       [-2.7430415 ],\n",
      "       [-1.9588907 ],\n",
      "       [-2.348676  ],\n",
      "       [-1.6062732 ],\n",
      "       [-1.8208708 ],\n",
      "       [-2.4176166 ],\n",
      "       [-2.4229128 ],\n",
      "       [-1.3406775 ],\n",
      "       [-3.4123554 ],\n",
      "       [-2.6331882 ],\n",
      "       [-1.0083318 ],\n",
      "       [-4.7248993 ],\n",
      "       [-2.8772335 ],\n",
      "       [-3.441225  ]], dtype=float32), 'shape': (120, 1)}\n",
      "==================================\n",
      "18\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [19], '_cg_ascend': [14, 17], '_grad_f': tensor32([[-8.33334308e-03  1.00053770e-08  2.01935538e-10]\n",
      " [-8.33336636e-03  3.13242481e-08  1.44465628e-09]\n",
      " [ 8.13020870e-06 -8.45198520e-03  1.10522240e-04]\n",
      " [-8.33375845e-03  4.23158752e-07  1.48871004e-09]\n",
      " [-8.33345205e-03  1.17240155e-07  6.95568214e-10]\n",
      " [ 4.90446723e-07  1.67289181e-04 -8.50111339e-03]\n",
      " [ 4.61717063e-05 -8.80284421e-03  4.23338643e-04]\n",
      " [-8.33548978e-03  2.15380373e-06  1.87444416e-09]\n",
      " [-8.33355729e-03  2.22337590e-07  8.61081206e-10]\n",
      " [-8.33334681e-03  1.25783775e-08  2.42020015e-10]\n",
      " [ 3.73807325e-06  1.17005722e-04 -8.45407788e-03]\n",
      " [ 8.36097868e-04 -1.05570443e-02  1.38761499e-03]\n",
      " [ 1.43897214e-05 -9.00414959e-03  6.56427292e-04]\n",
      " [-8.33357405e-03  2.38435831e-07  2.03747641e-09]\n",
      " [-8.33479036e-03  1.45470085e-06  1.59965585e-09]\n",
      " [ 4.23463644e-06 -8.34070798e-03  3.13937267e-06]\n",
      " [ 1.17421378e-05  5.10381535e-03 -1.34488922e-02]\n",
      " [ 1.03044931e-05  3.63450352e-04 -8.70708842e-03]\n",
      " [ 7.06932769e-06 -8.48423876e-03  1.43836631e-04]\n",
      " [ 2.66708184e-07  1.16418050e-06 -8.33476521e-03]\n",
      " [ 4.17765659e-05 -8.45710933e-03  8.19995621e-05]\n",
      " [ 9.30147603e-09  2.05983201e-06 -8.33540224e-03]\n",
      " [ 2.04299722e-04 -9.66531131e-03  1.12767785e-03]\n",
      " [-8.33432656e-03  9.92131845e-07  1.30458599e-09]\n",
      " [ 3.46401929e-09  3.32134960e-06 -8.33665859e-03]\n",
      " [ 4.06466097e-06 -8.34125374e-03  3.85483190e-06]\n",
      " [-8.33776128e-03  4.42574992e-06  1.97588812e-09]\n",
      " [-8.33382457e-03  4.88762169e-07  1.59382918e-09]\n",
      " [-8.33350606e-03  1.68013628e-07  5.06048581e-09]\n",
      " [ 7.03756359e-06 -8.34687613e-03  6.50468564e-06]\n",
      " [ 3.43651004e-06  8.07185424e-04 -9.14395601e-03]\n",
      " [-8.33395310e-03  6.16654063e-07  2.66772071e-09]\n",
      " [-8.37885588e-03  4.55168265e-05  5.57571012e-09]\n",
      " [-8.34295060e-03  9.59615227e-06  2.07244941e-08]\n",
      " [ 2.05966135e-05 -8.47771205e-03  1.23781807e-04]\n",
      " [-8.33595637e-03  2.62069580e-06  2.02903605e-09]\n",
      " [ 8.95269259e-05 -8.45892634e-03  3.60672602e-05]\n",
      " [ 6.25832058e-07  8.10587790e-06 -8.34206585e-03]\n",
      " [-8.33382271e-03  4.87456987e-07  1.18248433e-09]\n",
      " [ 9.21803985e-06 -8.41010176e-03  6.75511619e-05]\n",
      " [ 8.99985196e-07  3.58816251e-05 -8.37011635e-03]\n",
      " [-8.33337009e-03  3.57630583e-08  4.52265503e-10]\n",
      " [ 4.38463612e-05  1.29494176e-03 -9.67212208e-03]\n",
      " [ 3.73807325e-06  1.17005722e-04 -8.45407788e-03]\n",
      " [ 1.98228605e-07 -8.33930355e-03  5.77177479e-06]\n",
      " [ 4.43784375e-04 -1.01115294e-02  1.33441156e-03]\n",
      " [ 1.06203215e-05  6.38174752e-05 -8.40777252e-03]\n",
      " [ 4.24837526e-06 -8.49625841e-03  1.58676237e-04]\n",
      " [-8.33373237e-03  3.93938365e-07  4.43478987e-09]\n",
      " [ 4.37926356e-05 -8.38137046e-03  4.24315976e-06]\n",
      " [ 7.51037135e-07  1.14816008e-04 -8.44890065e-03]\n",
      " [-8.33614822e-03  2.81270604e-06  1.80831228e-09]\n",
      " [-8.33843276e-03  5.09786469e-06  1.56933411e-09]\n",
      " [ 4.96626171e-06 -8.34931061e-03  1.10100300e-05]\n",
      " [ 1.02715221e-05 -1.37077440e-02  5.36413817e-03]\n",
      " [-8.34237318e-03  9.03579257e-06  3.04292991e-09]\n",
      " [ 5.26360850e-07  4.51733331e-06 -8.33837688e-03]\n",
      " [-8.33470467e-03  1.36867504e-06  1.71530457e-09]\n",
      " [-8.33422039e-03  8.71410975e-07  1.54515547e-08]\n",
      " [ 1.71941734e-04 -1.48101728e-02  6.30489783e-03]\n",
      " [ 1.98003050e-04 -8.53829551e-03  6.95944664e-06]\n",
      " [ 2.29267002e-07  2.90030630e-06 -8.33646394e-03]\n",
      " [ 1.19533233e-05 -1.44388340e-02  6.09354768e-03]\n",
      " [ 5.73998341e-06  3.27762705e-03 -1.16166994e-02]\n",
      " [ 5.84898086e-09  1.15937360e-06 -8.33449885e-03]\n",
      " [ 1.08505255e-05 -8.45692866e-03  1.12745009e-04]\n",
      " [-8.33501760e-03  1.68173801e-06  1.77447368e-09]\n",
      " [-8.33357498e-03  2.41818128e-07  3.72334441e-10]\n",
      " [ 1.15886201e-06  2.95178709e-03 -1.12862810e-02]\n",
      " [ 1.42968508e-06  2.26285323e-04 -8.56104866e-03]\n",
      " [-8.33462272e-03  1.28773581e-06  1.83930970e-09]\n",
      " [-8.33439641e-03  1.06112145e-06  2.29019648e-09]\n",
      " [-8.33397172e-03  6.36620598e-07  1.14083409e-09]\n",
      " [ 2.80184918e-06 -1.15242768e-02  3.18814162e-03]\n",
      " [ 3.61730667e-06  2.09817372e-05 -8.35793372e-03]\n",
      " [-8.33343063e-03  9.60117319e-08  1.26563737e-09]\n",
      " [ 4.05234317e-07  2.10804355e-05 -8.35481938e-03]\n",
      " [ 5.89525825e-07  3.45525632e-06 -8.33737850e-03]\n",
      " [-8.33415892e-03  8.23348387e-07  1.15171150e-09]\n",
      " [ 2.37269251e-05 -8.93714465e-03  5.80083404e-04]\n",
      " [ 6.33803666e-06 -9.31477733e-03  9.75104398e-04]\n",
      " [ 8.98668986e-06  1.11536530e-03 -9.45768505e-03]\n",
      " [ 6.57523697e-06 -8.50114878e-03  1.61239892e-04]\n",
      " [ 1.60436764e-06  1.00923926e-05 -8.34503118e-03]\n",
      " [-8.33343528e-03  1.00786288e-07  9.16321907e-10]\n",
      " [ 7.36713446e-07  3.62383980e-05 -8.37030914e-03]\n",
      " [ 6.62006496e-05 -8.81098118e-03  4.11447283e-04]\n",
      " [ 2.46897866e-06  1.01802150e-04 -8.43760557e-03]\n",
      " [ 6.58383624e-06 -8.34106561e-03  1.14934028e-06]\n",
      " [ 1.63320990e-04 -8.73053726e-03  2.33882689e-04]\n",
      " [ 3.44014079e-05 -8.74498859e-03  3.77253251e-04]\n",
      " [-9.39849764e-03  1.06513395e-03  2.92220577e-08]\n",
      " [ 3.64305856e-06 -8.44497234e-03  1.07993656e-04]\n",
      " [ 1.41806040e-05 -8.44895467e-03  1.01439204e-04]\n",
      " [-8.33409466e-03  7.59676823e-07  1.35222666e-09]\n",
      " [ 1.68252256e-04 -8.58782046e-03  8.62348679e-05]\n",
      " [ 1.07529218e-07  6.44646425e-05 -8.39790609e-03]\n",
      " [ 2.34968024e-06  2.81542962e-05 -8.36383924e-03]\n",
      " [-8.33357405e-03  2.36969129e-07  2.97753000e-09]\n",
      " [ 2.06102341e-04 -8.54693539e-03  7.49763558e-06]\n",
      " [ 2.76337005e-07  1.52219775e-06 -8.33513215e-03]\n",
      " [ 1.78110020e-06  1.73125300e-03 -1.00663686e-02]\n",
      " [-8.33344273e-03  1.08551937e-07  4.14603962e-10]\n",
      " [ 1.26064009e-07  1.03098046e-06 -8.33449047e-03]\n",
      " [-8.35188758e-03  1.85510635e-05  3.20481686e-09]\n",
      " [ 9.11394181e-06 -9.26488824e-03  9.22441308e-04]\n",
      " [ 3.82608540e-08  3.69566515e-05 -8.37032776e-03]\n",
      " [ 3.16175556e-06  1.80730916e-04 -8.51722714e-03]\n",
      " [ 2.19154390e-05 -8.42756126e-03  7.23118210e-05]\n",
      " [ 4.61561649e-06  3.33732809e-04 -8.67168326e-03]\n",
      " [ 5.65380446e-07 -8.56723916e-03  2.33339058e-04]\n",
      " [ 5.16046111e-06 -8.39515217e-03  5.66583367e-05]\n",
      " [ 8.29806777e-06  8.14430387e-05 -8.42307508e-03]\n",
      " [ 3.29079667e-05  5.71627170e-04 -8.93786922e-03]\n",
      " [-8.35693721e-03  2.35992065e-05  4.94458208e-09]\n",
      " [ 6.35553442e-06 -8.37837160e-03  3.86824686e-05]\n",
      " [ 6.58949357e-05  1.27118058e-03 -9.67041031e-03]\n",
      " [-8.33439548e-03  1.06102129e-06  8.32523717e-10]\n",
      " [ 4.34735784e-06 -8.36368557e-03  2.60059696e-05]\n",
      " [ 1.00911507e-07  9.12783526e-06 -8.34256224e-03]]), 'grad': tensor32([[-8.33334308e-03  1.00053770e-08  2.01935538e-10]\n",
      " [-8.33336636e-03  3.13242481e-08  1.44465628e-09]\n",
      " [ 8.13020870e-06 -8.45198520e-03  1.10522240e-04]\n",
      " [-8.33375845e-03  4.23158752e-07  1.48871004e-09]\n",
      " [-8.33345205e-03  1.17240155e-07  6.95568214e-10]\n",
      " [ 4.90446723e-07  1.67289181e-04 -8.50111339e-03]\n",
      " [ 4.61717063e-05 -8.80284421e-03  4.23338643e-04]\n",
      " [-8.33548978e-03  2.15380373e-06  1.87444416e-09]\n",
      " [-8.33355729e-03  2.22337590e-07  8.61081206e-10]\n",
      " [-8.33334681e-03  1.25783775e-08  2.42020015e-10]\n",
      " [ 3.73807325e-06  1.17005722e-04 -8.45407788e-03]\n",
      " [ 8.36097868e-04 -1.05570443e-02  1.38761499e-03]\n",
      " [ 1.43897214e-05 -9.00414959e-03  6.56427292e-04]\n",
      " [-8.33357405e-03  2.38435831e-07  2.03747641e-09]\n",
      " [-8.33479036e-03  1.45470085e-06  1.59965585e-09]\n",
      " [ 4.23463644e-06 -8.34070798e-03  3.13937267e-06]\n",
      " [ 1.17421378e-05  5.10381535e-03 -1.34488922e-02]\n",
      " [ 1.03044931e-05  3.63450352e-04 -8.70708842e-03]\n",
      " [ 7.06932769e-06 -8.48423876e-03  1.43836631e-04]\n",
      " [ 2.66708184e-07  1.16418050e-06 -8.33476521e-03]\n",
      " [ 4.17765659e-05 -8.45710933e-03  8.19995621e-05]\n",
      " [ 9.30147603e-09  2.05983201e-06 -8.33540224e-03]\n",
      " [ 2.04299722e-04 -9.66531131e-03  1.12767785e-03]\n",
      " [-8.33432656e-03  9.92131845e-07  1.30458599e-09]\n",
      " [ 3.46401929e-09  3.32134960e-06 -8.33665859e-03]\n",
      " [ 4.06466097e-06 -8.34125374e-03  3.85483190e-06]\n",
      " [-8.33776128e-03  4.42574992e-06  1.97588812e-09]\n",
      " [-8.33382457e-03  4.88762169e-07  1.59382918e-09]\n",
      " [-8.33350606e-03  1.68013628e-07  5.06048581e-09]\n",
      " [ 7.03756359e-06 -8.34687613e-03  6.50468564e-06]\n",
      " [ 3.43651004e-06  8.07185424e-04 -9.14395601e-03]\n",
      " [-8.33395310e-03  6.16654063e-07  2.66772071e-09]\n",
      " [-8.37885588e-03  4.55168265e-05  5.57571012e-09]\n",
      " [-8.34295060e-03  9.59615227e-06  2.07244941e-08]\n",
      " [ 2.05966135e-05 -8.47771205e-03  1.23781807e-04]\n",
      " [-8.33595637e-03  2.62069580e-06  2.02903605e-09]\n",
      " [ 8.95269259e-05 -8.45892634e-03  3.60672602e-05]\n",
      " [ 6.25832058e-07  8.10587790e-06 -8.34206585e-03]\n",
      " [-8.33382271e-03  4.87456987e-07  1.18248433e-09]\n",
      " [ 9.21803985e-06 -8.41010176e-03  6.75511619e-05]\n",
      " [ 8.99985196e-07  3.58816251e-05 -8.37011635e-03]\n",
      " [-8.33337009e-03  3.57630583e-08  4.52265503e-10]\n",
      " [ 4.38463612e-05  1.29494176e-03 -9.67212208e-03]\n",
      " [ 3.73807325e-06  1.17005722e-04 -8.45407788e-03]\n",
      " [ 1.98228605e-07 -8.33930355e-03  5.77177479e-06]\n",
      " [ 4.43784375e-04 -1.01115294e-02  1.33441156e-03]\n",
      " [ 1.06203215e-05  6.38174752e-05 -8.40777252e-03]\n",
      " [ 4.24837526e-06 -8.49625841e-03  1.58676237e-04]\n",
      " [-8.33373237e-03  3.93938365e-07  4.43478987e-09]\n",
      " [ 4.37926356e-05 -8.38137046e-03  4.24315976e-06]\n",
      " [ 7.51037135e-07  1.14816008e-04 -8.44890065e-03]\n",
      " [-8.33614822e-03  2.81270604e-06  1.80831228e-09]\n",
      " [-8.33843276e-03  5.09786469e-06  1.56933411e-09]\n",
      " [ 4.96626171e-06 -8.34931061e-03  1.10100300e-05]\n",
      " [ 1.02715221e-05 -1.37077440e-02  5.36413817e-03]\n",
      " [-8.34237318e-03  9.03579257e-06  3.04292991e-09]\n",
      " [ 5.26360850e-07  4.51733331e-06 -8.33837688e-03]\n",
      " [-8.33470467e-03  1.36867504e-06  1.71530457e-09]\n",
      " [-8.33422039e-03  8.71410975e-07  1.54515547e-08]\n",
      " [ 1.71941734e-04 -1.48101728e-02  6.30489783e-03]\n",
      " [ 1.98003050e-04 -8.53829551e-03  6.95944664e-06]\n",
      " [ 2.29267002e-07  2.90030630e-06 -8.33646394e-03]\n",
      " [ 1.19533233e-05 -1.44388340e-02  6.09354768e-03]\n",
      " [ 5.73998341e-06  3.27762705e-03 -1.16166994e-02]\n",
      " [ 5.84898086e-09  1.15937360e-06 -8.33449885e-03]\n",
      " [ 1.08505255e-05 -8.45692866e-03  1.12745009e-04]\n",
      " [-8.33501760e-03  1.68173801e-06  1.77447368e-09]\n",
      " [-8.33357498e-03  2.41818128e-07  3.72334441e-10]\n",
      " [ 1.15886201e-06  2.95178709e-03 -1.12862810e-02]\n",
      " [ 1.42968508e-06  2.26285323e-04 -8.56104866e-03]\n",
      " [-8.33462272e-03  1.28773581e-06  1.83930970e-09]\n",
      " [-8.33439641e-03  1.06112145e-06  2.29019648e-09]\n",
      " [-8.33397172e-03  6.36620598e-07  1.14083409e-09]\n",
      " [ 2.80184918e-06 -1.15242768e-02  3.18814162e-03]\n",
      " [ 3.61730667e-06  2.09817372e-05 -8.35793372e-03]\n",
      " [-8.33343063e-03  9.60117319e-08  1.26563737e-09]\n",
      " [ 4.05234317e-07  2.10804355e-05 -8.35481938e-03]\n",
      " [ 5.89525825e-07  3.45525632e-06 -8.33737850e-03]\n",
      " [-8.33415892e-03  8.23348387e-07  1.15171150e-09]\n",
      " [ 2.37269251e-05 -8.93714465e-03  5.80083404e-04]\n",
      " [ 6.33803666e-06 -9.31477733e-03  9.75104398e-04]\n",
      " [ 8.98668986e-06  1.11536530e-03 -9.45768505e-03]\n",
      " [ 6.57523697e-06 -8.50114878e-03  1.61239892e-04]\n",
      " [ 1.60436764e-06  1.00923926e-05 -8.34503118e-03]\n",
      " [-8.33343528e-03  1.00786288e-07  9.16321907e-10]\n",
      " [ 7.36713446e-07  3.62383980e-05 -8.37030914e-03]\n",
      " [ 6.62006496e-05 -8.81098118e-03  4.11447283e-04]\n",
      " [ 2.46897866e-06  1.01802150e-04 -8.43760557e-03]\n",
      " [ 6.58383624e-06 -8.34106561e-03  1.14934028e-06]\n",
      " [ 1.63320990e-04 -8.73053726e-03  2.33882689e-04]\n",
      " [ 3.44014079e-05 -8.74498859e-03  3.77253251e-04]\n",
      " [-9.39849764e-03  1.06513395e-03  2.92220577e-08]\n",
      " [ 3.64305856e-06 -8.44497234e-03  1.07993656e-04]\n",
      " [ 1.41806040e-05 -8.44895467e-03  1.01439204e-04]\n",
      " [-8.33409466e-03  7.59676823e-07  1.35222666e-09]\n",
      " [ 1.68252256e-04 -8.58782046e-03  8.62348679e-05]\n",
      " [ 1.07529218e-07  6.44646425e-05 -8.39790609e-03]\n",
      " [ 2.34968024e-06  2.81542962e-05 -8.36383924e-03]\n",
      " [-8.33357405e-03  2.36969129e-07  2.97753000e-09]\n",
      " [ 2.06102341e-04 -8.54693539e-03  7.49763558e-06]\n",
      " [ 2.76337005e-07  1.52219775e-06 -8.33513215e-03]\n",
      " [ 1.78110020e-06  1.73125300e-03 -1.00663686e-02]\n",
      " [-8.33344273e-03  1.08551937e-07  4.14603962e-10]\n",
      " [ 1.26064009e-07  1.03098046e-06 -8.33449047e-03]\n",
      " [-8.35188758e-03  1.85510635e-05  3.20481686e-09]\n",
      " [ 9.11394181e-06 -9.26488824e-03  9.22441308e-04]\n",
      " [ 3.82608540e-08  3.69566515e-05 -8.37032776e-03]\n",
      " [ 3.16175556e-06  1.80730916e-04 -8.51722714e-03]\n",
      " [ 2.19154390e-05 -8.42756126e-03  7.23118210e-05]\n",
      " [ 4.61561649e-06  3.33732809e-04 -8.67168326e-03]\n",
      " [ 5.65380446e-07 -8.56723916e-03  2.33339058e-04]\n",
      " [ 5.16046111e-06 -8.39515217e-03  5.66583367e-05]\n",
      " [ 8.29806777e-06  8.14430387e-05 -8.42307508e-03]\n",
      " [ 3.29079667e-05  5.71627170e-04 -8.93786922e-03]\n",
      " [-8.35693721e-03  2.35992065e-05  4.94458208e-09]\n",
      " [ 6.35553442e-06 -8.37837160e-03  3.86824686e-05]\n",
      " [ 6.58949357e-05  1.27118058e-03 -9.67041031e-03]\n",
      " [-8.33439548e-03  1.06102129e-06  8.32523717e-10]\n",
      " [ 4.34735784e-06 -8.36368557e-03  2.60059696e-05]\n",
      " [ 1.00911507e-07  9.12783526e-06 -8.34256224e-03]]), 'npar_data': array([[  0.        , -13.63265   , -17.53558   ],\n",
      "       [  0.        , -12.491378  , -15.567899  ],\n",
      "       [ -6.918092  ,   0.        ,  -4.3084617 ],\n",
      "       [  0.        ,  -9.887976  , -15.537813  ],\n",
      "       [  0.        , -11.1715355 , -16.298786  ],\n",
      "       [ -9.7201185 ,  -3.887956  ,   0.        ],\n",
      "       [ -5.137661  ,   0.        ,  -2.9218557 ],\n",
      "       [  0.        ,  -8.260525  , -15.307203  ],\n",
      "       [  0.        , -10.53155   , -16.085314  ],\n",
      "       [  0.        , -13.403793  , -17.354507  ],\n",
      "       [ -7.6948533 ,  -4.2512007 ,   0.        ],\n",
      "       [ -1.9888743 ,   0.        ,  -1.4822782 ],\n",
      "       [ -6.2775817 ,   0.        ,  -2.457284  ],\n",
      "       [  0.        , -10.461645  , -15.224033  ],\n",
      "       [  0.        ,  -8.653044  , -15.465811  ],\n",
      "       [ -7.583836  ,   0.        ,  -7.8831105 ],\n",
      "       [ -6.0745597 ,   0.        ,  -0.46129736],\n",
      "       [ -6.6495514 ,  -3.0864887 ,   0.        ],\n",
      "       [ -7.053979  ,   0.        ,  -4.041066  ],\n",
      "       [-10.349447  ,  -8.87583   ,   0.        ],\n",
      "       [ -5.280719  ,   0.        ,  -4.6063404 ],\n",
      "       [-13.705353  ,  -8.305146  ,   0.        ],\n",
      "       [ -3.534271  ,   0.        ,  -1.8259435 ],\n",
      "       [  0.        ,  -9.035799  , -15.669769  ],\n",
      "       [-14.6929455 ,  -7.8272486 ,   0.        ],\n",
      "       [ -7.6247377 ,   0.        ,  -7.6777406 ],\n",
      "       [  0.        ,  -7.5400476 , -15.254225  ],\n",
      "       [  0.        ,  -9.743839  , -15.469576  ],\n",
      "       [  0.        , -10.811708  , -14.314291  ],\n",
      "       [ -7.0751305 ,   0.        ,  -7.1538696 ],\n",
      "       [ -7.6912255 ,  -2.2321286 ,   0.        ],\n",
      "       [  0.        ,  -9.511392  , -14.954475  ],\n",
      "       [  0.        ,  -5.204459  , -14.211877  ],\n",
      "       [  0.        ,  -6.765502  , -12.903303  ],\n",
      "       [ -5.985415  ,   0.        ,  -4.1920214 ],\n",
      "       [  0.        ,  -8.064264  , -15.227899  ],\n",
      "       [ -4.5182934 ,   0.        ,  -5.4274473 ],\n",
      "       [ -9.495644  ,  -6.934381  ,   0.        ],\n",
      "       [  0.        ,  -9.746513  , -15.768098  ],\n",
      "       [ -6.7976017 ,   0.        ,  -4.8058786 ],\n",
      "       [ -9.128972  ,  -5.44337   ,   0.        ],\n",
      "       [  0.        , -12.358854  , -16.729256  ],\n",
      "       [ -5.072194  ,  -1.6866648 ,   0.        ],\n",
      "       [ -7.6948533 ,  -4.2512007 ,   0.        ],\n",
      "       [-10.645637  ,   0.        ,  -7.2743225 ],\n",
      "       [ -2.6926656 ,   0.        ,  -1.5917587 ],\n",
      "       [ -6.6562767 ,  -4.863019  ,   0.        ],\n",
      "       [ -7.5617375 ,   0.        ,  -3.9414084 ],\n",
      "       [  0.        ,  -9.959532  , -14.446246  ],\n",
      "       [ -5.242772  ,   0.        ,  -7.5769296 ],\n",
      "       [ -9.300354  ,  -4.270723  ,   0.        ],\n",
      "       [  0.        ,  -7.993534  , -15.343042  ],\n",
      "       [  0.        ,  -7.398585  , -15.48451   ],\n",
      "       [ -7.4234324 ,   0.        ,  -6.627293  ],\n",
      "       [ -6.258116  ,  -0.59491026,   0.        ],\n",
      "       [  0.        ,  -6.82574   , -14.821868  ],\n",
      "       [ -9.669182  ,  -7.5194917 ,   0.        ],\n",
      "       [  0.        ,  -8.714011  , -15.396019  ],\n",
      "       [  0.        ,  -9.165554  , -13.197958  ],\n",
      "       [ -3.6019263 ,  -1.2226374 ,   0.        ],\n",
      "       [ -3.7148335 ,   0.        ,  -7.063016  ],\n",
      "       [-10.500511  ,  -7.9628267 ,   0.        ],\n",
      "       [ -6.2339764 ,  -1.0062011 ,   0.        ],\n",
      "       [ -6.7796807 ,  -0.43226215,   0.        ],\n",
      "       [-14.169367  ,  -8.879999  ,   0.        ],\n",
      "       [ -6.628863  ,   0.        ,  -4.2879477 ],\n",
      "       [  0.        ,  -8.507989  , -15.362068  ],\n",
      "       [  0.        , -10.447559  , -16.923708  ],\n",
      "       [ -8.443077  ,  -0.60034955,   0.        ],\n",
      "       [ -8.6428585 ,  -3.578516  ,   0.        ],\n",
      "       [  0.        ,  -8.774979  , -15.326229  ],\n",
      "       [  0.        ,  -8.968565  , -15.107009  ],\n",
      "       [  0.        ,  -9.479524  , -15.803938  ],\n",
      "       [ -7.5149937 ,   0.        ,  -0.47807983],\n",
      "       [ -7.7393327 ,  -5.98141   ,   0.        ],\n",
      "       [  0.        , -11.371292  , -15.700187  ],\n",
      "       [ -9.928727  ,  -5.977092  ,   0.        ],\n",
      "       [ -9.55597   ,  -7.7876368 ,   0.        ],\n",
      "       [  0.        ,  -9.222296  , -15.794426  ],\n",
      "       [ -5.786192  ,   0.        ,  -2.5896306 ],\n",
      "       [ -7.0561438 ,   0.        ,  -2.0201683 ],\n",
      "       [ -6.6873384 ,  -1.8661456 ,   0.        ],\n",
      "       [ -7.124365  ,   0.        ,  -3.9247823 ],\n",
      "       [ -8.5538845 ,  -6.7148323 ,   0.        ],\n",
      "       [  0.        , -11.32276   , -16.02315   ],\n",
      "       [ -9.329128  ,  -5.4334526 ,   0.        ],\n",
      "       [ -4.7763023 ,   0.        ,  -2.9493117 ],\n",
      "       [ -8.111623  ,  -4.392396  ,   0.        ],\n",
      "       [ -7.1424727 ,   0.        ,  -8.887902  ],\n",
      "       [ -3.8834636 ,   0.        ,  -3.5243614 ],\n",
      "       [ -5.439261  ,   0.        ,  -3.0444417 ],\n",
      "       [  0.        ,  -1.920404  , -12.424091  ],\n",
      "       [ -7.7217083 ,   0.        ,  -4.3324594 ],\n",
      "       [ -6.362172  ,   0.        ,  -4.3945875 ],\n",
      "       [  0.        ,  -9.30279   , -15.63393   ],\n",
      "       [ -3.87154   ,   0.        ,  -4.53993   ],\n",
      "       [-11.250233  ,  -4.854123  ,   0.        ],\n",
      "       [ -8.170073  ,  -5.6866517 ,   0.        ],\n",
      "       [  0.        , -10.467815  , -14.844651  ],\n",
      "       [ -3.6736798 ,   0.        ,  -6.987465  ],\n",
      "       [-10.313937  ,  -8.607648  ,   0.        ],\n",
      "       [ -8.217639  ,  -1.3382695 ,   0.        ],\n",
      "       [  0.        , -11.248532  , -16.816193  ],\n",
      "       [-11.0988455 ,  -8.99737   ,   0.        ],\n",
      "       [  0.        ,  -6.1052628 , -14.76889   ],\n",
      "       [ -6.6996703 ,   0.        ,  -2.0824518 ],\n",
      "       [-12.286898  ,  -5.413824  ,   0.        ],\n",
      "       [ -7.854577  ,  -3.8086953 ,   0.        ],\n",
      "       [ -5.9294558 ,   0.        ,  -4.7356596 ],\n",
      "       [ -7.457124  ,  -3.176229  ,   0.        ],\n",
      "       [ -9.569805  ,   0.        ,  -3.5470562 ],\n",
      "       [ -7.379547  ,   0.        ,  -4.983534  ],\n",
      "       [ -6.901169  ,  -4.6172876 ,   0.        ],\n",
      "       [ -5.458994  ,  -2.6042218 ,   0.        ],\n",
      "       [  0.        ,  -5.8639693 , -14.334645  ],\n",
      "       [ -7.1732736 ,   0.        ,  -5.3672132 ],\n",
      "       [ -4.665069  ,  -1.7054293 ,   0.        ],\n",
      "       [  0.        ,  -8.968659  , -16.11894   ],\n",
      "       [ -7.5548015 ,   0.        ,  -5.7660437 ],\n",
      "       [-11.320422  ,  -6.8155823 ,   0.        ]], dtype=float32), 'shape': (120, 3)}\n",
      "==================================\n",
      "19\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [21, 25], '_cg_ascend': [18], '_grad_f': tensor32([[-9.31322575e-09  8.33332445e-03  8.33332445e-03]\n",
      " [-3.25962901e-08  8.33330117e-03  8.33330117e-03]\n",
      " [ 8.21468234e-03 -1.18651427e-04  8.21468234e-03]\n",
      " [-4.24683094e-07  8.33290908e-03  8.33290908e-03]\n",
      " [-1.18277967e-07  8.33321549e-03  8.33321549e-03]\n",
      " [ 8.16555414e-03  8.16555414e-03 -1.67779624e-04]\n",
      " [ 7.86382332e-03 -4.69510444e-04  7.86382332e-03]\n",
      " [-2.15601176e-06  8.33117776e-03  8.33117776e-03]\n",
      " [-2.23517418e-07  8.33311025e-03  8.33311025e-03]\n",
      " [-1.30385160e-08  8.33332073e-03  8.33332073e-03]\n",
      " [ 8.21258966e-03  8.21258966e-03 -1.20744109e-04]\n",
      " [ 6.10962091e-03 -2.22371193e-03  6.10962091e-03]\n",
      " [ 7.66251748e-03 -6.70816284e-04  7.66251748e-03]\n",
      " [-2.40281224e-07  8.33309349e-03  8.33309349e-03]\n",
      " [-1.45658851e-06  8.33187718e-03  8.33187718e-03]\n",
      " [ 8.32595956e-03 -7.37421215e-06  8.32595956e-03]\n",
      " [ 5.10381535e-03  5.10381535e-03 -8.11394118e-03]\n",
      " [ 7.95957912e-03  7.95957912e-03 -3.73754650e-04]\n",
      " [ 8.18242878e-03 -1.50904991e-04  8.18242878e-03]\n",
      " [ 8.33190233e-03  8.33190233e-03 -1.43144280e-06]\n",
      " [ 8.20955820e-03 -1.23775564e-04  8.20955820e-03]\n",
      " [ 8.33126530e-03  8.33126530e-03 -2.06846744e-06]\n",
      " [ 7.00135622e-03 -1.33197755e-03  7.00135622e-03]\n",
      " [-9.92789865e-07  8.33234098e-03  8.33234098e-03]\n",
      " [ 8.33000895e-03  8.33000895e-03 -3.32482159e-06]\n",
      " [ 8.32541380e-03 -7.91996717e-06  8.32541380e-03]\n",
      " [-4.42750752e-06  8.32890626e-03  8.32890626e-03]\n",
      " [-4.90806997e-07  8.33284296e-03  8.33284296e-03]\n",
      " [-1.72294676e-07  8.33316147e-03  8.33316147e-03]\n",
      " [ 8.31979141e-03 -1.35423616e-05  8.31979141e-03]\n",
      " [ 7.52271200e-03  7.52271200e-03 -8.10621772e-04]\n",
      " [-6.19329512e-07  8.33271444e-03  8.33271444e-03]\n",
      " [-4.55221161e-05  8.28781165e-03  8.28781165e-03]\n",
      " [-9.61683691e-06  8.32371693e-03  8.32371693e-03]\n",
      " [ 8.18895549e-03 -1.44378282e-04  8.18895549e-03]\n",
      " [-2.62260437e-06  8.33071116e-03  8.33071116e-03]\n",
      " [ 8.20773933e-03 -1.25593506e-04  8.20773933e-03]\n",
      " [ 8.32460169e-03  8.32460169e-03 -8.73208046e-06]\n",
      " [-4.88944352e-07  8.33284482e-03  8.33284482e-03]\n",
      " [ 8.25656578e-03 -7.67679885e-05  8.25656578e-03]\n",
      " [ 8.29655118e-03  8.29655118e-03 -3.67825851e-05]\n",
      " [-3.63215804e-08  8.33329745e-03  8.33329745e-03]\n",
      " [ 6.99454499e-03  6.99454499e-03 -1.33878877e-03]\n",
      " [ 8.21258966e-03  8.21258966e-03 -1.20744109e-04]\n",
      " [ 8.32736399e-03 -5.96977770e-06  8.32736399e-03]\n",
      " [ 6.55513769e-03 -1.77819608e-03  6.55513769e-03]\n",
      " [ 8.25889502e-03  8.25889502e-03 -7.44387507e-05]\n",
      " [ 8.17040913e-03 -1.62924640e-04  8.17040913e-03]\n",
      " [-3.98606062e-07  8.33293516e-03  8.33293516e-03]\n",
      " [ 8.28529708e-03 -4.80366871e-05  8.28529708e-03]\n",
      " [ 8.21776688e-03  8.21776688e-03 -1.15566887e-04]\n",
      " [-2.81445682e-06  8.33051931e-03  8.33051931e-03]\n",
      " [-5.09992242e-06  8.32823291e-03  8.32823291e-03]\n",
      " [ 8.31735693e-03 -1.59768388e-05  8.31735693e-03]\n",
      " [ 5.36413817e-03 -9.74309817e-03  5.36413817e-03]\n",
      " [-9.03941691e-06  8.32429435e-03  8.32429435e-03]\n",
      " [ 8.32829066e-03  8.32829066e-03 -5.04311174e-06]\n",
      " [-1.37090683e-06  8.33196286e-03  8.33196286e-03]\n",
      " [-8.86619091e-07  8.33244715e-03  8.33244715e-03]\n",
      " [ 6.30489783e-03 -2.19962094e-02  6.30489783e-03]\n",
      " [ 8.12837202e-03 -2.04961747e-04  8.12837202e-03]\n",
      " [ 8.33020359e-03  8.33020359e-03 -3.13017517e-06]\n",
      " [ 6.09354768e-03 -1.66997090e-02  6.09354768e-03]\n",
      " [ 5.04996767e-03  5.04996767e-03 -3.28336610e-03]\n",
      " [ 8.33216868e-03  8.33216868e-03 -1.16508454e-06]\n",
      " [ 8.20973888e-03 -1.23594888e-04  8.20973888e-03]\n",
      " [-1.68383121e-06  8.33164994e-03  8.33164994e-03]\n",
      " [-2.41212547e-07  8.33309256e-03  8.33309256e-03]\n",
      " [ 5.38038695e-03  5.38038695e-03 -2.95294682e-03]\n",
      " [ 8.10561888e-03  8.10561888e-03 -2.27714889e-04]\n",
      " [-1.28895044e-06  8.33204482e-03  8.33204482e-03]\n",
      " [-1.06263906e-06  8.33227113e-03  8.33227113e-03]\n",
      " [-6.37955964e-07  8.33269581e-03  8.33269581e-03]\n",
      " [ 5.14239026e-03 -3.19094351e-03  5.14239026e-03]\n",
      " [ 8.30873381e-03  8.30873381e-03 -2.45999545e-05]\n",
      " [-9.68575478e-08  8.33323691e-03  8.33323691e-03]\n",
      " [ 8.31184816e-03  8.31184816e-03 -2.14856118e-05]\n",
      " [ 8.32928903e-03  8.32928903e-03 -4.04473394e-06]\n",
      " [-8.25151801e-07  8.33250862e-03  8.33250862e-03]\n",
      " [ 7.72952335e-03 -6.03810418e-04  7.72952335e-03]\n",
      " [ 7.35189067e-03 -9.81443096e-04  7.35189067e-03]\n",
      " [ 7.20898109e-03  7.20898109e-03 -1.12435175e-03]\n",
      " [ 8.16551875e-03 -1.67815015e-04  8.16551875e-03]\n",
      " [ 8.32163636e-03  8.32163636e-03 -1.16974115e-05]\n",
      " [-1.01514161e-07  8.33323225e-03  8.33323225e-03]\n",
      " [ 8.29635840e-03  8.29635840e-03 -3.69753689e-05]\n",
      " [ 7.85568450e-03 -4.77648340e-04  7.85568450e-03]\n",
      " [ 8.22906196e-03  8.22906196e-03 -1.04271807e-04]\n",
      " [ 8.32560007e-03 -7.73277134e-06  8.32560007e-03]\n",
      " [ 7.93613028e-03 -3.97203490e-04  7.93613028e-03]\n",
      " [ 7.92167895e-03 -4.11654823e-04  7.92167895e-03]\n",
      " [-1.06516387e-03  7.26816989e-03  7.26816989e-03]\n",
      " [ 8.22169706e-03 -1.11637637e-04  8.22169706e-03]\n",
      " [ 8.21771286e-03 -1.15620904e-04  8.21771286e-03]\n",
      " [-7.60890543e-07  8.33257288e-03  8.33257288e-03]\n",
      " [ 8.07884708e-03 -2.54486687e-04  8.07884708e-03]\n",
      " [ 8.26876145e-03  8.26876145e-03 -6.45723194e-05]\n",
      " [ 8.30283016e-03  8.30283016e-03 -3.05045396e-05]\n",
      " [-2.40281224e-07  8.33309349e-03  8.33309349e-03]\n",
      " [ 8.11973400e-03 -2.13600695e-04  8.11973400e-03]\n",
      " [ 8.33153538e-03  8.33153538e-03 -1.79838389e-06]\n",
      " [ 6.60029892e-03  6.60029892e-03 -1.73303485e-03]\n",
      " [-1.08964741e-07  8.33322480e-03  8.33322480e-03]\n",
      " [ 8.33217707e-03  8.33217707e-03 -1.15670264e-06]\n",
      " [-1.85538083e-05  8.31477996e-03  8.31477996e-03]\n",
      " [ 7.40177883e-03 -9.31554940e-04  7.40177883e-03]\n",
      " [ 8.29633977e-03  8.29633977e-03 -3.69939953e-05]\n",
      " [ 8.14944040e-03  8.14944040e-03 -1.83893368e-04]\n",
      " [ 8.23910628e-03 -9.42274928e-05  8.23910628e-03]\n",
      " [ 7.99498428e-03  7.99498428e-03 -3.38349491e-04]\n",
      " [ 8.09942838e-03 -2.33905390e-04  8.09942838e-03]\n",
      " [ 8.27151537e-03 -6.18183985e-05  8.27151537e-03]\n",
      " [ 8.24359246e-03  8.24359246e-03 -8.97413120e-05]\n",
      " [ 7.72879878e-03  7.72879878e-03 -6.04534987e-04]\n",
      " [-2.36034393e-05  8.30973033e-03  8.30973033e-03]\n",
      " [ 8.28829594e-03 -4.50378284e-05  8.28829594e-03]\n",
      " [ 6.99625770e-03  6.99625770e-03 -1.33707607e-03]\n",
      " [-1.06170774e-06  8.33227206e-03  8.33227206e-03]\n",
      " [ 8.30298010e-03 -3.03527340e-05  8.30298010e-03]\n",
      " [ 8.32410529e-03  8.32410529e-03 -9.22847539e-06]]), 'grad': tensor32([[-9.31322575e-09  8.33332445e-03  8.33332445e-03]\n",
      " [-3.25962901e-08  8.33330117e-03  8.33330117e-03]\n",
      " [ 8.21468234e-03 -1.18651427e-04  8.21468234e-03]\n",
      " [-4.24683094e-07  8.33290908e-03  8.33290908e-03]\n",
      " [-1.18277967e-07  8.33321549e-03  8.33321549e-03]\n",
      " [ 8.16555414e-03  8.16555414e-03 -1.67779624e-04]\n",
      " [ 7.86382332e-03 -4.69510444e-04  7.86382332e-03]\n",
      " [-2.15601176e-06  8.33117776e-03  8.33117776e-03]\n",
      " [-2.23517418e-07  8.33311025e-03  8.33311025e-03]\n",
      " [-1.30385160e-08  8.33332073e-03  8.33332073e-03]\n",
      " [ 8.21258966e-03  8.21258966e-03 -1.20744109e-04]\n",
      " [ 6.10962091e-03 -2.22371193e-03  6.10962091e-03]\n",
      " [ 7.66251748e-03 -6.70816284e-04  7.66251748e-03]\n",
      " [-2.40281224e-07  8.33309349e-03  8.33309349e-03]\n",
      " [-1.45658851e-06  8.33187718e-03  8.33187718e-03]\n",
      " [ 8.32595956e-03 -7.37421215e-06  8.32595956e-03]\n",
      " [ 5.10381535e-03  5.10381535e-03 -8.11394118e-03]\n",
      " [ 7.95957912e-03  7.95957912e-03 -3.73754650e-04]\n",
      " [ 8.18242878e-03 -1.50904991e-04  8.18242878e-03]\n",
      " [ 8.33190233e-03  8.33190233e-03 -1.43144280e-06]\n",
      " [ 8.20955820e-03 -1.23775564e-04  8.20955820e-03]\n",
      " [ 8.33126530e-03  8.33126530e-03 -2.06846744e-06]\n",
      " [ 7.00135622e-03 -1.33197755e-03  7.00135622e-03]\n",
      " [-9.92789865e-07  8.33234098e-03  8.33234098e-03]\n",
      " [ 8.33000895e-03  8.33000895e-03 -3.32482159e-06]\n",
      " [ 8.32541380e-03 -7.91996717e-06  8.32541380e-03]\n",
      " [-4.42750752e-06  8.32890626e-03  8.32890626e-03]\n",
      " [-4.90806997e-07  8.33284296e-03  8.33284296e-03]\n",
      " [-1.72294676e-07  8.33316147e-03  8.33316147e-03]\n",
      " [ 8.31979141e-03 -1.35423616e-05  8.31979141e-03]\n",
      " [ 7.52271200e-03  7.52271200e-03 -8.10621772e-04]\n",
      " [-6.19329512e-07  8.33271444e-03  8.33271444e-03]\n",
      " [-4.55221161e-05  8.28781165e-03  8.28781165e-03]\n",
      " [-9.61683691e-06  8.32371693e-03  8.32371693e-03]\n",
      " [ 8.18895549e-03 -1.44378282e-04  8.18895549e-03]\n",
      " [-2.62260437e-06  8.33071116e-03  8.33071116e-03]\n",
      " [ 8.20773933e-03 -1.25593506e-04  8.20773933e-03]\n",
      " [ 8.32460169e-03  8.32460169e-03 -8.73208046e-06]\n",
      " [-4.88944352e-07  8.33284482e-03  8.33284482e-03]\n",
      " [ 8.25656578e-03 -7.67679885e-05  8.25656578e-03]\n",
      " [ 8.29655118e-03  8.29655118e-03 -3.67825851e-05]\n",
      " [-3.63215804e-08  8.33329745e-03  8.33329745e-03]\n",
      " [ 6.99454499e-03  6.99454499e-03 -1.33878877e-03]\n",
      " [ 8.21258966e-03  8.21258966e-03 -1.20744109e-04]\n",
      " [ 8.32736399e-03 -5.96977770e-06  8.32736399e-03]\n",
      " [ 6.55513769e-03 -1.77819608e-03  6.55513769e-03]\n",
      " [ 8.25889502e-03  8.25889502e-03 -7.44387507e-05]\n",
      " [ 8.17040913e-03 -1.62924640e-04  8.17040913e-03]\n",
      " [-3.98606062e-07  8.33293516e-03  8.33293516e-03]\n",
      " [ 8.28529708e-03 -4.80366871e-05  8.28529708e-03]\n",
      " [ 8.21776688e-03  8.21776688e-03 -1.15566887e-04]\n",
      " [-2.81445682e-06  8.33051931e-03  8.33051931e-03]\n",
      " [-5.09992242e-06  8.32823291e-03  8.32823291e-03]\n",
      " [ 8.31735693e-03 -1.59768388e-05  8.31735693e-03]\n",
      " [ 5.36413817e-03 -9.74309817e-03  5.36413817e-03]\n",
      " [-9.03941691e-06  8.32429435e-03  8.32429435e-03]\n",
      " [ 8.32829066e-03  8.32829066e-03 -5.04311174e-06]\n",
      " [-1.37090683e-06  8.33196286e-03  8.33196286e-03]\n",
      " [-8.86619091e-07  8.33244715e-03  8.33244715e-03]\n",
      " [ 6.30489783e-03 -2.19962094e-02  6.30489783e-03]\n",
      " [ 8.12837202e-03 -2.04961747e-04  8.12837202e-03]\n",
      " [ 8.33020359e-03  8.33020359e-03 -3.13017517e-06]\n",
      " [ 6.09354768e-03 -1.66997090e-02  6.09354768e-03]\n",
      " [ 5.04996767e-03  5.04996767e-03 -3.28336610e-03]\n",
      " [ 8.33216868e-03  8.33216868e-03 -1.16508454e-06]\n",
      " [ 8.20973888e-03 -1.23594888e-04  8.20973888e-03]\n",
      " [-1.68383121e-06  8.33164994e-03  8.33164994e-03]\n",
      " [-2.41212547e-07  8.33309256e-03  8.33309256e-03]\n",
      " [ 5.38038695e-03  5.38038695e-03 -2.95294682e-03]\n",
      " [ 8.10561888e-03  8.10561888e-03 -2.27714889e-04]\n",
      " [-1.28895044e-06  8.33204482e-03  8.33204482e-03]\n",
      " [-1.06263906e-06  8.33227113e-03  8.33227113e-03]\n",
      " [-6.37955964e-07  8.33269581e-03  8.33269581e-03]\n",
      " [ 5.14239026e-03 -3.19094351e-03  5.14239026e-03]\n",
      " [ 8.30873381e-03  8.30873381e-03 -2.45999545e-05]\n",
      " [-9.68575478e-08  8.33323691e-03  8.33323691e-03]\n",
      " [ 8.31184816e-03  8.31184816e-03 -2.14856118e-05]\n",
      " [ 8.32928903e-03  8.32928903e-03 -4.04473394e-06]\n",
      " [-8.25151801e-07  8.33250862e-03  8.33250862e-03]\n",
      " [ 7.72952335e-03 -6.03810418e-04  7.72952335e-03]\n",
      " [ 7.35189067e-03 -9.81443096e-04  7.35189067e-03]\n",
      " [ 7.20898109e-03  7.20898109e-03 -1.12435175e-03]\n",
      " [ 8.16551875e-03 -1.67815015e-04  8.16551875e-03]\n",
      " [ 8.32163636e-03  8.32163636e-03 -1.16974115e-05]\n",
      " [-1.01514161e-07  8.33323225e-03  8.33323225e-03]\n",
      " [ 8.29635840e-03  8.29635840e-03 -3.69753689e-05]\n",
      " [ 7.85568450e-03 -4.77648340e-04  7.85568450e-03]\n",
      " [ 8.22906196e-03  8.22906196e-03 -1.04271807e-04]\n",
      " [ 8.32560007e-03 -7.73277134e-06  8.32560007e-03]\n",
      " [ 7.93613028e-03 -3.97203490e-04  7.93613028e-03]\n",
      " [ 7.92167895e-03 -4.11654823e-04  7.92167895e-03]\n",
      " [-1.06516387e-03  7.26816989e-03  7.26816989e-03]\n",
      " [ 8.22169706e-03 -1.11637637e-04  8.22169706e-03]\n",
      " [ 8.21771286e-03 -1.15620904e-04  8.21771286e-03]\n",
      " [-7.60890543e-07  8.33257288e-03  8.33257288e-03]\n",
      " [ 8.07884708e-03 -2.54486687e-04  8.07884708e-03]\n",
      " [ 8.26876145e-03  8.26876145e-03 -6.45723194e-05]\n",
      " [ 8.30283016e-03  8.30283016e-03 -3.05045396e-05]\n",
      " [-2.40281224e-07  8.33309349e-03  8.33309349e-03]\n",
      " [ 8.11973400e-03 -2.13600695e-04  8.11973400e-03]\n",
      " [ 8.33153538e-03  8.33153538e-03 -1.79838389e-06]\n",
      " [ 6.60029892e-03  6.60029892e-03 -1.73303485e-03]\n",
      " [-1.08964741e-07  8.33322480e-03  8.33322480e-03]\n",
      " [ 8.33217707e-03  8.33217707e-03 -1.15670264e-06]\n",
      " [-1.85538083e-05  8.31477996e-03  8.31477996e-03]\n",
      " [ 7.40177883e-03 -9.31554940e-04  7.40177883e-03]\n",
      " [ 8.29633977e-03  8.29633977e-03 -3.69939953e-05]\n",
      " [ 8.14944040e-03  8.14944040e-03 -1.83893368e-04]\n",
      " [ 8.23910628e-03 -9.42274928e-05  8.23910628e-03]\n",
      " [ 7.99498428e-03  7.99498428e-03 -3.38349491e-04]\n",
      " [ 8.09942838e-03 -2.33905390e-04  8.09942838e-03]\n",
      " [ 8.27151537e-03 -6.18183985e-05  8.27151537e-03]\n",
      " [ 8.24359246e-03  8.24359246e-03 -8.97413120e-05]\n",
      " [ 7.72879878e-03  7.72879878e-03 -6.04534987e-04]\n",
      " [-2.36034393e-05  8.30973033e-03  8.30973033e-03]\n",
      " [ 8.28829594e-03 -4.50378284e-05  8.28829594e-03]\n",
      " [ 6.99625770e-03  6.99625770e-03 -1.33707607e-03]\n",
      " [-1.06170774e-06  8.33227206e-03  8.33227206e-03]\n",
      " [ 8.30298010e-03 -3.03527340e-05  8.30298010e-03]\n",
      " [ 8.32410529e-03  8.32410529e-03 -9.22847539e-06]]), 'npar_data': array([[1.00000000e+00, 1.20064647e-06, 2.42322908e-08],\n",
      "       [1.00000000e+00, 3.75892409e-06, 1.73359425e-07],\n",
      "       [9.89716733e-04, 1.00000000e+00, 1.34542314e-02],\n",
      "       [1.00000000e+00, 5.07816367e-05, 1.78654304e-07],\n",
      "       [1.00000000e+00, 1.40690172e-05, 8.34693665e-08],\n",
      "       [6.00628809e-05, 2.04871800e-02, 1.00000000e+00],\n",
      "       [5.87140676e-03, 1.00000000e+00, 5.38336933e-02],\n",
      "       [1.00000000e+00, 2.58523331e-04, 2.24991496e-07],\n",
      "       [1.00000000e+00, 2.66812258e-05, 1.03332511e-07],\n",
      "       [1.00000000e+00, 1.50940753e-06, 2.90424467e-08],\n",
      "       [4.55163768e-04, 1.42471166e-02, 1.00000000e+00],\n",
      "       [1.36849388e-01, 1.00000000e+00, 2.27119654e-01],\n",
      "       [1.87793653e-03, 1.00000000e+00, 8.56673121e-02],\n",
      "       [1.00000000e+00, 2.86131235e-05, 2.44504207e-07],\n",
      "       [1.00000000e+00, 1.74594607e-04, 1.91992257e-07],\n",
      "       [5.08606434e-04, 1.00000000e+00, 3.77058372e-04],\n",
      "       [2.30065873e-03, 1.00000000e+00, 6.30465150e-01],\n",
      "       [1.29460276e-03, 4.56620045e-02, 1.00000000e+00],\n",
      "       [8.63964437e-04, 1.00000000e+00, 1.75787210e-02],\n",
      "       [3.20104773e-05, 1.39725656e-04, 1.00000000e+00],\n",
      "       [5.08877169e-03, 1.00000000e+00, 9.98830423e-03],\n",
      "       [1.11645420e-06, 2.47241202e-04, 1.00000000e+00],\n",
      "       [2.91800201e-02, 1.00000000e+00, 1.61065623e-01],\n",
      "       [1.00000000e+00, 1.19069999e-04, 1.56568959e-07],\n",
      "       [4.15848206e-07, 3.98721022e-04, 1.00000000e+00],\n",
      "       [4.88223275e-04, 1.00000000e+00, 4.63019882e-04],\n",
      "       [1.00000000e+00, 5.31372265e-04, 2.37232598e-07],\n",
      "       [1.00000000e+00, 5.86549140e-05, 1.91270757e-07],\n",
      "       [1.00000000e+00, 2.01620514e-05, 6.07270806e-07],\n",
      "       [8.45882227e-04, 1.00000000e+00, 7.81832787e-04],\n",
      "       [4.56817972e-04, 1.07299790e-01, 1.00000000e+00],\n",
      "       [1.00000000e+00, 7.40039832e-05, 3.20150264e-07],\n",
      "       [1.00000000e+00, 5.49201993e-03, 6.72760223e-07],\n",
      "       [1.00000000e+00, 1.15286862e-03, 2.48981246e-06],\n",
      "       [2.51516979e-03, 1.00000000e+00, 1.51157007e-02],\n",
      "       [1.00000000e+00, 3.14582488e-04, 2.43560976e-07],\n",
      "       [1.09076230e-02, 1.00000000e+00, 4.39429889e-03],\n",
      "       [7.51786210e-05, 9.73725633e-04, 1.00000000e+00],\n",
      "       [1.00000000e+00, 5.84982699e-05, 1.41906440e-07],\n",
      "       [1.11644960e-03, 1.00000000e+00, 8.18150863e-03],\n",
      "       [1.08477027e-04, 4.32488462e-03, 1.00000000e+00],\n",
      "       [1.00000000e+00, 4.29158536e-06, 5.42720926e-08],\n",
      "       [6.26865076e-03, 1.85135946e-01, 1.00000000e+00],\n",
      "       [4.55163768e-04, 1.42471166e-02, 1.00000000e+00],\n",
      "       [2.38044850e-05, 1.00000000e+00, 6.93109469e-04],\n",
      "       [6.77002370e-02, 1.00000000e+00, 2.03567281e-01],\n",
      "       [1.28592527e-03, 7.72712054e-03, 1.00000000e+00],\n",
      "       [5.19970956e-04, 1.00000000e+00, 1.94208436e-02],\n",
      "       [1.00000000e+00, 4.72748616e-05, 5.32200204e-07],\n",
      "       [5.28558437e-03, 1.00000000e+00, 5.12131257e-04],\n",
      "       [9.13918775e-05, 1.39716798e-02, 1.00000000e+00],\n",
      "       [1.00000000e+00, 3.37638747e-04, 2.17070777e-07],\n",
      "       [1.00000000e+00, 6.12118398e-04, 1.88435422e-07],\n",
      "       [5.97096165e-04, 1.00000000e+00, 1.32374140e-03],\n",
      "       [1.91485044e-03, 5.51612020e-01, 1.00000000e+00],\n",
      "       [1.00000000e+00, 1.08547253e-03, 3.65548090e-07],\n",
      "       [6.32015435e-05, 5.42408205e-04, 1.00000000e+00],\n",
      "       [1.00000000e+00, 1.64268014e-04, 2.05870407e-07],\n",
      "       [1.00000000e+00, 1.04580438e-04, 1.85438387e-06],\n",
      "       [2.72711366e-02, 2.94452548e-01, 1.00000000e+00],\n",
      "       [2.43594963e-02, 1.00000000e+00, 8.56191968e-04],\n",
      "       [2.75223774e-05, 3.48167523e-04, 1.00000000e+00],\n",
      "       [1.96163612e-03, 3.65605205e-01, 1.00000000e+00],\n",
      "       [1.13663764e-03, 6.49039209e-01, 1.00000000e+00],\n",
      "       [7.01975807e-07, 1.39144278e-04, 1.00000000e+00],\n",
      "       [1.32166513e-03, 1.00000000e+00, 1.37330806e-02],\n",
      "       [1.00000000e+00, 2.01849340e-04, 2.12979870e-07],\n",
      "       [1.00000000e+00, 2.90190128e-05, 4.46814248e-08],\n",
      "       [2.15386361e-04, 5.48619866e-01, 1.00000000e+00],\n",
      "       [1.76381975e-04, 2.79170945e-02, 1.00000000e+00],\n",
      "       [1.00000000e+00, 1.54552195e-04, 2.20751303e-07],\n",
      "       [1.00000000e+00, 1.27350810e-04, 2.74858621e-07],\n",
      "       [1.00000000e+00, 7.64003198e-05, 1.36910572e-07],\n",
      "       [5.44853450e-04, 1.00000000e+00, 6.19972706e-01],\n",
      "       [4.35361959e-04, 2.52526300e-03, 1.00000000e+00],\n",
      "       [1.00000000e+00, 1.15215407e-05, 1.51878240e-07],\n",
      "       [4.87538164e-05, 2.53619114e-03, 1.00000000e+00],\n",
      "       [7.07774452e-05, 4.14832088e-04, 1.00000000e+00],\n",
      "       [1.00000000e+00, 9.88115862e-05, 1.38219065e-07],\n",
      "       [3.06964922e-03, 1.00000000e+00, 7.50477612e-02],\n",
      "       [8.62096145e-04, 1.00000000e+00, 1.32633150e-01],\n",
      "       [1.24659634e-03, 1.54718861e-01, 1.00000000e+00],\n",
      "       [8.05244257e-04, 1.00000000e+00, 1.97464358e-02],\n",
      "       [1.92794731e-04, 1.21278944e-03, 1.00000000e+00],\n",
      "       [1.00000000e+00, 1.20945015e-05, 1.09959963e-07],\n",
      "       [8.87996139e-05, 4.36798856e-03, 1.00000000e+00],\n",
      "       [8.42710119e-03, 1.00000000e+00, 5.23757376e-02],\n",
      "       [3.00031592e-04, 1.23710521e-02, 1.00000000e+00],\n",
      "       [7.90794205e-04, 1.00000000e+00, 1.38048941e-04],\n",
      "       [2.05794238e-02, 1.00000000e+00, 2.94706207e-02],\n",
      "       [4.34269151e-03, 1.00000000e+00, 4.76228893e-02],\n",
      "       [1.00000000e+00, 1.46547750e-01, 4.02055230e-06],\n",
      "       [4.43102996e-04, 1.00000000e+00, 1.31352022e-02],\n",
      "       [1.72561442e-03, 1.00000000e+00, 1.23439701e-02],\n",
      "       [1.00000000e+00, 9.11695388e-05, 1.62282006e-07],\n",
      "       [2.08262708e-02, 1.00000000e+00, 1.06741553e-02],\n",
      "       [1.30042718e-05, 7.79616693e-03, 1.00000000e+00],\n",
      "       [2.82997498e-04, 3.39092757e-03, 1.00000000e+00],\n",
      "       [1.00000000e+00, 2.84371145e-05, 3.57313894e-07],\n",
      "       [2.53828932e-02, 1.00000000e+00, 9.23384388e-04],\n",
      "       [3.31675983e-05, 1.82703152e-04, 1.00000000e+00],\n",
      "       [2.69851444e-04, 2.62299180e-01, 1.00000000e+00],\n",
      "       [1.00000000e+00, 1.30264025e-05, 4.97531225e-08],\n",
      "       [1.51297809e-05, 1.23734819e-04, 1.00000000e+00],\n",
      "       [1.00000000e+00, 2.23109499e-03, 3.85436152e-07],\n",
      "       [1.23131776e-03, 1.00000000e+00, 1.24624275e-01],\n",
      "       [4.61177524e-06, 4.45457315e-03, 1.00000000e+00],\n",
      "       [3.87972104e-04, 2.21770946e-02, 1.00000000e+00],\n",
      "       [2.65992922e-03, 1.00000000e+00, 8.77665821e-03],\n",
      "       [5.77314000e-04, 4.17427719e-02, 1.00000000e+00],\n",
      "       [6.98049844e-05, 1.00000000e+00, 2.88093239e-02],\n",
      "       [6.23883388e-04, 1.00000000e+00, 6.84981328e-03],\n",
      "       [1.00660825e-03, 9.87955648e-03, 1.00000000e+00],\n",
      "       [4.25783731e-03, 7.39606768e-02, 1.00000000e+00],\n",
      "       [1.00000000e+00, 2.83994852e-03, 5.95035203e-07],\n",
      "       [7.66808342e-04, 1.00000000e+00, 4.66711959e-03],\n",
      "       [9.41859744e-03, 1.81694359e-01, 1.00000000e+00],\n",
      "       [1.00000000e+00, 1.27338775e-04, 9.99155674e-08],\n",
      "       [5.23590075e-04, 1.00000000e+00, 3.13212466e-03],\n",
      "       [1.21228049e-05, 1.09655457e-03, 1.00000000e+00]], dtype=float32), 'shape': (120, 3)}\n",
      "==================================\n",
      "20\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [21], '_cg_ascend': [], '_grad_f': tensor32([[0.33530843]\n",
      " [0.3290638 ]\n",
      " [0.3356278 ]]), 'grad': tensor32([[0.33530843]\n",
      " [0.3290638 ]\n",
      " [0.3356278 ]]), 'npar_data': array([[1.],\n",
      "       [1.],\n",
      "       [1.]], dtype=float32), 'shape': (3, 1)}\n",
      "==================================\n",
      "21\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [23], '_cg_ascend': [19, 20], '_grad_f': tensor32([[0.00833332]\n",
      " [0.0083333 ]\n",
      " [0.00821468]\n",
      " [0.00833291]\n",
      " [0.00833322]\n",
      " [0.00816555]\n",
      " [0.00786382]\n",
      " [0.00833118]\n",
      " [0.00833311]\n",
      " [0.00833332]\n",
      " [0.00821259]\n",
      " [0.00610962]\n",
      " [0.00766252]\n",
      " [0.00833309]\n",
      " [0.00833188]\n",
      " [0.00832596]\n",
      " [0.00510382]\n",
      " [0.00795958]\n",
      " [0.00818243]\n",
      " [0.0083319 ]\n",
      " [0.00820956]\n",
      " [0.00833127]\n",
      " [0.00700136]\n",
      " [0.00833234]\n",
      " [0.00833001]\n",
      " [0.00832541]\n",
      " [0.00832891]\n",
      " [0.00833284]\n",
      " [0.00833316]\n",
      " [0.00831979]\n",
      " [0.00752271]\n",
      " [0.00833271]\n",
      " [0.00828781]\n",
      " [0.00832372]\n",
      " [0.00818896]\n",
      " [0.00833071]\n",
      " [0.00820774]\n",
      " [0.0083246 ]\n",
      " [0.00833284]\n",
      " [0.00825657]\n",
      " [0.00829655]\n",
      " [0.0083333 ]\n",
      " [0.00699454]\n",
      " [0.00821259]\n",
      " [0.00832736]\n",
      " [0.00655514]\n",
      " [0.0082589 ]\n",
      " [0.00817041]\n",
      " [0.00833294]\n",
      " [0.0082853 ]\n",
      " [0.00821777]\n",
      " [0.00833052]\n",
      " [0.00832823]\n",
      " [0.00831736]\n",
      " [0.00536414]\n",
      " [0.00832429]\n",
      " [0.00832829]\n",
      " [0.00833196]\n",
      " [0.00833245]\n",
      " [0.0063049 ]\n",
      " [0.00812837]\n",
      " [0.0083302 ]\n",
      " [0.00609355]\n",
      " [0.00504997]\n",
      " [0.00833217]\n",
      " [0.00820974]\n",
      " [0.00833165]\n",
      " [0.00833309]\n",
      " [0.00538039]\n",
      " [0.00810562]\n",
      " [0.00833204]\n",
      " [0.00833227]\n",
      " [0.0083327 ]\n",
      " [0.00514239]\n",
      " [0.00830873]\n",
      " [0.00833324]\n",
      " [0.00831185]\n",
      " [0.00832929]\n",
      " [0.00833251]\n",
      " [0.00772952]\n",
      " [0.00735189]\n",
      " [0.00720898]\n",
      " [0.00816552]\n",
      " [0.00832164]\n",
      " [0.00833323]\n",
      " [0.00829636]\n",
      " [0.00785568]\n",
      " [0.00822906]\n",
      " [0.0083256 ]\n",
      " [0.00793613]\n",
      " [0.00792168]\n",
      " [0.00726817]\n",
      " [0.0082217 ]\n",
      " [0.00821771]\n",
      " [0.00833257]\n",
      " [0.00807885]\n",
      " [0.00826876]\n",
      " [0.00830283]\n",
      " [0.00833309]\n",
      " [0.00811973]\n",
      " [0.00833154]\n",
      " [0.0066003 ]\n",
      " [0.00833322]\n",
      " [0.00833218]\n",
      " [0.00831478]\n",
      " [0.00740178]\n",
      " [0.00829634]\n",
      " [0.00814944]\n",
      " [0.00823911]\n",
      " [0.00799498]\n",
      " [0.00809943]\n",
      " [0.00827152]\n",
      " [0.00824359]\n",
      " [0.0077288 ]\n",
      " [0.00830973]\n",
      " [0.0082883 ]\n",
      " [0.00699626]\n",
      " [0.00833227]\n",
      " [0.00830298]\n",
      " [0.00832411]]), 'grad': tensor32([[0.00833332]\n",
      " [0.0083333 ]\n",
      " [0.00821468]\n",
      " [0.00833291]\n",
      " [0.00833322]\n",
      " [0.00816555]\n",
      " [0.00786382]\n",
      " [0.00833118]\n",
      " [0.00833311]\n",
      " [0.00833332]\n",
      " [0.00821259]\n",
      " [0.00610962]\n",
      " [0.00766252]\n",
      " [0.00833309]\n",
      " [0.00833188]\n",
      " [0.00832596]\n",
      " [0.00510382]\n",
      " [0.00795958]\n",
      " [0.00818243]\n",
      " [0.0083319 ]\n",
      " [0.00820956]\n",
      " [0.00833127]\n",
      " [0.00700136]\n",
      " [0.00833234]\n",
      " [0.00833001]\n",
      " [0.00832541]\n",
      " [0.00832891]\n",
      " [0.00833284]\n",
      " [0.00833316]\n",
      " [0.00831979]\n",
      " [0.00752271]\n",
      " [0.00833271]\n",
      " [0.00828781]\n",
      " [0.00832372]\n",
      " [0.00818896]\n",
      " [0.00833071]\n",
      " [0.00820774]\n",
      " [0.0083246 ]\n",
      " [0.00833284]\n",
      " [0.00825657]\n",
      " [0.00829655]\n",
      " [0.0083333 ]\n",
      " [0.00699454]\n",
      " [0.00821259]\n",
      " [0.00832736]\n",
      " [0.00655514]\n",
      " [0.0082589 ]\n",
      " [0.00817041]\n",
      " [0.00833294]\n",
      " [0.0082853 ]\n",
      " [0.00821777]\n",
      " [0.00833052]\n",
      " [0.00832823]\n",
      " [0.00831736]\n",
      " [0.00536414]\n",
      " [0.00832429]\n",
      " [0.00832829]\n",
      " [0.00833196]\n",
      " [0.00833245]\n",
      " [0.0063049 ]\n",
      " [0.00812837]\n",
      " [0.0083302 ]\n",
      " [0.00609355]\n",
      " [0.00504997]\n",
      " [0.00833217]\n",
      " [0.00820974]\n",
      " [0.00833165]\n",
      " [0.00833309]\n",
      " [0.00538039]\n",
      " [0.00810562]\n",
      " [0.00833204]\n",
      " [0.00833227]\n",
      " [0.0083327 ]\n",
      " [0.00514239]\n",
      " [0.00830873]\n",
      " [0.00833324]\n",
      " [0.00831185]\n",
      " [0.00832929]\n",
      " [0.00833251]\n",
      " [0.00772952]\n",
      " [0.00735189]\n",
      " [0.00720898]\n",
      " [0.00816552]\n",
      " [0.00832164]\n",
      " [0.00833323]\n",
      " [0.00829636]\n",
      " [0.00785568]\n",
      " [0.00822906]\n",
      " [0.0083256 ]\n",
      " [0.00793613]\n",
      " [0.00792168]\n",
      " [0.00726817]\n",
      " [0.0082217 ]\n",
      " [0.00821771]\n",
      " [0.00833257]\n",
      " [0.00807885]\n",
      " [0.00826876]\n",
      " [0.00830283]\n",
      " [0.00833309]\n",
      " [0.00811973]\n",
      " [0.00833154]\n",
      " [0.0066003 ]\n",
      " [0.00833322]\n",
      " [0.00833218]\n",
      " [0.00831478]\n",
      " [0.00740178]\n",
      " [0.00829634]\n",
      " [0.00814944]\n",
      " [0.00823911]\n",
      " [0.00799498]\n",
      " [0.00809943]\n",
      " [0.00827152]\n",
      " [0.00824359]\n",
      " [0.0077288 ]\n",
      " [0.00830973]\n",
      " [0.0082883 ]\n",
      " [0.00699626]\n",
      " [0.00833227]\n",
      " [0.00830298]\n",
      " [0.00832411]]), 'npar_data': array([[1.0000012],\n",
      "       [1.0000039],\n",
      "       [1.0144439],\n",
      "       [1.0000509],\n",
      "       [1.0000142],\n",
      "       [1.0205473],\n",
      "       [1.0597051],\n",
      "       [1.0002588],\n",
      "       [1.0000268],\n",
      "       [1.0000015],\n",
      "       [1.0147023],\n",
      "       [1.3639691],\n",
      "       [1.0875452],\n",
      "       [1.0000288],\n",
      "       [1.0001749],\n",
      "       [1.0008856],\n",
      "       [1.6327658],\n",
      "       [1.0469567],\n",
      "       [1.0184426],\n",
      "       [1.0001718],\n",
      "       [1.0150771],\n",
      "       [1.0002483],\n",
      "       [1.1902456],\n",
      "       [1.0001192],\n",
      "       [1.0003991],\n",
      "       [1.0009513],\n",
      "       [1.0005316],\n",
      "       [1.0000589],\n",
      "       [1.0000207],\n",
      "       [1.0016277],\n",
      "       [1.1077566],\n",
      "       [1.0000744],\n",
      "       [1.0054927],\n",
      "       [1.0011554],\n",
      "       [1.0176309],\n",
      "       [1.0003148],\n",
      "       [1.015302 ],\n",
      "       [1.0010489],\n",
      "       [1.0000587],\n",
      "       [1.0092978],\n",
      "       [1.0044334],\n",
      "       [1.0000043],\n",
      "       [1.1914046],\n",
      "       [1.0147023],\n",
      "       [1.0007169],\n",
      "       [1.2712675],\n",
      "       [1.009013 ],\n",
      "       [1.0199409],\n",
      "       [1.0000478],\n",
      "       [1.0057977],\n",
      "       [1.0140631],\n",
      "       [1.0003378],\n",
      "       [1.0006124],\n",
      "       [1.0019208],\n",
      "       [1.5535269],\n",
      "       [1.0010859],\n",
      "       [1.0006056],\n",
      "       [1.0001645],\n",
      "       [1.0001065],\n",
      "       [1.3217237],\n",
      "       [1.0252156],\n",
      "       [1.0003757],\n",
      "       [1.3675668],\n",
      "       [1.6501758],\n",
      "       [1.0001398],\n",
      "       [1.0150547],\n",
      "       [1.0002021],\n",
      "       [1.000029 ],\n",
      "       [1.5488353],\n",
      "       [1.0280935],\n",
      "       [1.0001547],\n",
      "       [1.0001276],\n",
      "       [1.0000765],\n",
      "       [1.6205176],\n",
      "       [1.0029607],\n",
      "       [1.0000117],\n",
      "       [1.0025849],\n",
      "       [1.0004857],\n",
      "       [1.000099 ],\n",
      "       [1.0781174],\n",
      "       [1.1334953],\n",
      "       [1.1559654],\n",
      "       [1.0205517],\n",
      "       [1.0014056],\n",
      "       [1.0000122],\n",
      "       [1.0044568],\n",
      "       [1.0608029],\n",
      "       [1.0126711],\n",
      "       [1.0009289],\n",
      "       [1.05005  ],\n",
      "       [1.0519656],\n",
      "       [1.1465518],\n",
      "       [1.0135783],\n",
      "       [1.0140697],\n",
      "       [1.0000913],\n",
      "       [1.0315003],\n",
      "       [1.0078092],\n",
      "       [1.0036739],\n",
      "       [1.0000288],\n",
      "       [1.0263063],\n",
      "       [1.0002159],\n",
      "       [1.2625691],\n",
      "       [1.000013 ],\n",
      "       [1.0001389],\n",
      "       [1.0022315],\n",
      "       [1.1258556],\n",
      "       [1.0044591],\n",
      "       [1.0225651],\n",
      "       [1.0114366],\n",
      "       [1.0423201],\n",
      "       [1.0288792],\n",
      "       [1.0074737],\n",
      "       [1.0108862],\n",
      "       [1.0782185],\n",
      "       [1.0028405],\n",
      "       [1.0054339],\n",
      "       [1.191113 ],\n",
      "       [1.0001274],\n",
      "       [1.0036557],\n",
      "       [1.0011086]], dtype=float32), 'shape': (120, 1)}\n",
      "==================================\n",
      "22\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [23], '_cg_ascend': [], '_grad_f': tensor32([[0.3333333 0.3416667 0.325    ]]), 'grad': tensor32([[0.3333333 0.3416667 0.325    ]]), 'npar_data': array([[1., 1., 1.]], dtype=float32), 'shape': (1, 3)}\n",
      "==================================\n",
      "23\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [24], '_cg_ascend': [21, 22], '_grad_f': tensor32([[0.00833332 0.         0.        ]\n",
      " [0.0083333  0.         0.        ]\n",
      " [0.         0.00821468 0.        ]\n",
      " [0.00833291 0.         0.        ]\n",
      " [0.00833322 0.         0.        ]\n",
      " [0.         0.         0.00816555]\n",
      " [0.         0.00786382 0.        ]\n",
      " [0.00833118 0.         0.        ]\n",
      " [0.00833311 0.         0.        ]\n",
      " [0.00833332 0.         0.        ]\n",
      " [0.         0.         0.00821259]\n",
      " [0.         0.00610962 0.        ]\n",
      " [0.         0.00766252 0.        ]\n",
      " [0.00833309 0.         0.        ]\n",
      " [0.00833188 0.         0.        ]\n",
      " [0.         0.00832596 0.        ]\n",
      " [0.         0.         0.00510382]\n",
      " [0.         0.         0.00795958]\n",
      " [0.         0.00818243 0.        ]\n",
      " [0.         0.         0.0083319 ]\n",
      " [0.         0.00820956 0.        ]\n",
      " [0.         0.         0.00833127]\n",
      " [0.         0.00700136 0.        ]\n",
      " [0.00833234 0.         0.        ]\n",
      " [0.         0.         0.00833001]\n",
      " [0.         0.00832541 0.        ]\n",
      " [0.00832891 0.         0.        ]\n",
      " [0.00833284 0.         0.        ]\n",
      " [0.00833316 0.         0.        ]\n",
      " [0.         0.00831979 0.        ]\n",
      " [0.         0.         0.00752271]\n",
      " [0.00833271 0.         0.        ]\n",
      " [0.00828781 0.         0.        ]\n",
      " [0.00832372 0.         0.        ]\n",
      " [0.         0.00818896 0.        ]\n",
      " [0.00833071 0.         0.        ]\n",
      " [0.         0.00820774 0.        ]\n",
      " [0.         0.         0.0083246 ]\n",
      " [0.00833284 0.         0.        ]\n",
      " [0.         0.00825657 0.        ]\n",
      " [0.         0.         0.00829655]\n",
      " [0.0083333  0.         0.        ]\n",
      " [0.         0.         0.00699454]\n",
      " [0.         0.         0.00821259]\n",
      " [0.         0.00832736 0.        ]\n",
      " [0.         0.00655514 0.        ]\n",
      " [0.         0.         0.0082589 ]\n",
      " [0.         0.00817041 0.        ]\n",
      " [0.00833294 0.         0.        ]\n",
      " [0.         0.0082853  0.        ]\n",
      " [0.         0.         0.00821777]\n",
      " [0.00833052 0.         0.        ]\n",
      " [0.00832823 0.         0.        ]\n",
      " [0.         0.00831736 0.        ]\n",
      " [0.         0.00536414 0.        ]\n",
      " [0.00832429 0.         0.        ]\n",
      " [0.         0.         0.00832829]\n",
      " [0.00833196 0.         0.        ]\n",
      " [0.00833245 0.         0.        ]\n",
      " [0.         0.0063049  0.        ]\n",
      " [0.         0.00812837 0.        ]\n",
      " [0.         0.         0.0083302 ]\n",
      " [0.         0.00609355 0.        ]\n",
      " [0.         0.         0.00504997]\n",
      " [0.         0.         0.00833217]\n",
      " [0.         0.00820974 0.        ]\n",
      " [0.00833165 0.         0.        ]\n",
      " [0.00833309 0.         0.        ]\n",
      " [0.         0.         0.00538039]\n",
      " [0.         0.         0.00810562]\n",
      " [0.00833204 0.         0.        ]\n",
      " [0.00833227 0.         0.        ]\n",
      " [0.0083327  0.         0.        ]\n",
      " [0.         0.00514239 0.        ]\n",
      " [0.         0.         0.00830873]\n",
      " [0.00833324 0.         0.        ]\n",
      " [0.         0.         0.00831185]\n",
      " [0.         0.         0.00832929]\n",
      " [0.00833251 0.         0.        ]\n",
      " [0.         0.00772952 0.        ]\n",
      " [0.         0.00735189 0.        ]\n",
      " [0.         0.         0.00720898]\n",
      " [0.         0.00816552 0.        ]\n",
      " [0.         0.         0.00832164]\n",
      " [0.00833323 0.         0.        ]\n",
      " [0.         0.         0.00829636]\n",
      " [0.         0.00785568 0.        ]\n",
      " [0.         0.         0.00822906]\n",
      " [0.         0.0083256  0.        ]\n",
      " [0.         0.00793613 0.        ]\n",
      " [0.         0.00792168 0.        ]\n",
      " [0.00726817 0.         0.        ]\n",
      " [0.         0.0082217  0.        ]\n",
      " [0.         0.00821771 0.        ]\n",
      " [0.00833257 0.         0.        ]\n",
      " [0.         0.00807885 0.        ]\n",
      " [0.         0.         0.00826876]\n",
      " [0.         0.         0.00830283]\n",
      " [0.00833309 0.         0.        ]\n",
      " [0.         0.00811973 0.        ]\n",
      " [0.         0.         0.00833154]\n",
      " [0.         0.         0.0066003 ]\n",
      " [0.00833322 0.         0.        ]\n",
      " [0.         0.         0.00833218]\n",
      " [0.00831478 0.         0.        ]\n",
      " [0.         0.00740178 0.        ]\n",
      " [0.         0.         0.00829634]\n",
      " [0.         0.         0.00814944]\n",
      " [0.         0.00823911 0.        ]\n",
      " [0.         0.         0.00799498]\n",
      " [0.         0.00809943 0.        ]\n",
      " [0.         0.00827152 0.        ]\n",
      " [0.         0.         0.00824359]\n",
      " [0.         0.         0.0077288 ]\n",
      " [0.00830973 0.         0.        ]\n",
      " [0.         0.0082883  0.        ]\n",
      " [0.         0.         0.00699626]\n",
      " [0.00833227 0.         0.        ]\n",
      " [0.         0.00830298 0.        ]\n",
      " [0.         0.         0.00832411]]), 'grad': tensor32([[0.00833332 0.         0.        ]\n",
      " [0.0083333  0.         0.        ]\n",
      " [0.         0.00821468 0.        ]\n",
      " [0.00833291 0.         0.        ]\n",
      " [0.00833322 0.         0.        ]\n",
      " [0.         0.         0.00816555]\n",
      " [0.         0.00786382 0.        ]\n",
      " [0.00833118 0.         0.        ]\n",
      " [0.00833311 0.         0.        ]\n",
      " [0.00833332 0.         0.        ]\n",
      " [0.         0.         0.00821259]\n",
      " [0.         0.00610962 0.        ]\n",
      " [0.         0.00766252 0.        ]\n",
      " [0.00833309 0.         0.        ]\n",
      " [0.00833188 0.         0.        ]\n",
      " [0.         0.00832596 0.        ]\n",
      " [0.         0.         0.00510382]\n",
      " [0.         0.         0.00795958]\n",
      " [0.         0.00818243 0.        ]\n",
      " [0.         0.         0.0083319 ]\n",
      " [0.         0.00820956 0.        ]\n",
      " [0.         0.         0.00833127]\n",
      " [0.         0.00700136 0.        ]\n",
      " [0.00833234 0.         0.        ]\n",
      " [0.         0.         0.00833001]\n",
      " [0.         0.00832541 0.        ]\n",
      " [0.00832891 0.         0.        ]\n",
      " [0.00833284 0.         0.        ]\n",
      " [0.00833316 0.         0.        ]\n",
      " [0.         0.00831979 0.        ]\n",
      " [0.         0.         0.00752271]\n",
      " [0.00833271 0.         0.        ]\n",
      " [0.00828781 0.         0.        ]\n",
      " [0.00832372 0.         0.        ]\n",
      " [0.         0.00818896 0.        ]\n",
      " [0.00833071 0.         0.        ]\n",
      " [0.         0.00820774 0.        ]\n",
      " [0.         0.         0.0083246 ]\n",
      " [0.00833284 0.         0.        ]\n",
      " [0.         0.00825657 0.        ]\n",
      " [0.         0.         0.00829655]\n",
      " [0.0083333  0.         0.        ]\n",
      " [0.         0.         0.00699454]\n",
      " [0.         0.         0.00821259]\n",
      " [0.         0.00832736 0.        ]\n",
      " [0.         0.00655514 0.        ]\n",
      " [0.         0.         0.0082589 ]\n",
      " [0.         0.00817041 0.        ]\n",
      " [0.00833294 0.         0.        ]\n",
      " [0.         0.0082853  0.        ]\n",
      " [0.         0.         0.00821777]\n",
      " [0.00833052 0.         0.        ]\n",
      " [0.00832823 0.         0.        ]\n",
      " [0.         0.00831736 0.        ]\n",
      " [0.         0.00536414 0.        ]\n",
      " [0.00832429 0.         0.        ]\n",
      " [0.         0.         0.00832829]\n",
      " [0.00833196 0.         0.        ]\n",
      " [0.00833245 0.         0.        ]\n",
      " [0.         0.0063049  0.        ]\n",
      " [0.         0.00812837 0.        ]\n",
      " [0.         0.         0.0083302 ]\n",
      " [0.         0.00609355 0.        ]\n",
      " [0.         0.         0.00504997]\n",
      " [0.         0.         0.00833217]\n",
      " [0.         0.00820974 0.        ]\n",
      " [0.00833165 0.         0.        ]\n",
      " [0.00833309 0.         0.        ]\n",
      " [0.         0.         0.00538039]\n",
      " [0.         0.         0.00810562]\n",
      " [0.00833204 0.         0.        ]\n",
      " [0.00833227 0.         0.        ]\n",
      " [0.0083327  0.         0.        ]\n",
      " [0.         0.00514239 0.        ]\n",
      " [0.         0.         0.00830873]\n",
      " [0.00833324 0.         0.        ]\n",
      " [0.         0.         0.00831185]\n",
      " [0.         0.         0.00832929]\n",
      " [0.00833251 0.         0.        ]\n",
      " [0.         0.00772952 0.        ]\n",
      " [0.         0.00735189 0.        ]\n",
      " [0.         0.         0.00720898]\n",
      " [0.         0.00816552 0.        ]\n",
      " [0.         0.         0.00832164]\n",
      " [0.00833323 0.         0.        ]\n",
      " [0.         0.         0.00829636]\n",
      " [0.         0.00785568 0.        ]\n",
      " [0.         0.         0.00822906]\n",
      " [0.         0.0083256  0.        ]\n",
      " [0.         0.00793613 0.        ]\n",
      " [0.         0.00792168 0.        ]\n",
      " [0.00726817 0.         0.        ]\n",
      " [0.         0.0082217  0.        ]\n",
      " [0.         0.00821771 0.        ]\n",
      " [0.00833257 0.         0.        ]\n",
      " [0.         0.00807885 0.        ]\n",
      " [0.         0.         0.00826876]\n",
      " [0.         0.         0.00830283]\n",
      " [0.00833309 0.         0.        ]\n",
      " [0.         0.00811973 0.        ]\n",
      " [0.         0.         0.00833154]\n",
      " [0.         0.         0.0066003 ]\n",
      " [0.00833322 0.         0.        ]\n",
      " [0.         0.         0.00833218]\n",
      " [0.00831478 0.         0.        ]\n",
      " [0.         0.00740178 0.        ]\n",
      " [0.         0.         0.00829634]\n",
      " [0.         0.         0.00814944]\n",
      " [0.         0.00823911 0.        ]\n",
      " [0.         0.         0.00799498]\n",
      " [0.         0.00809943 0.        ]\n",
      " [0.         0.00827152 0.        ]\n",
      " [0.         0.         0.00824359]\n",
      " [0.         0.         0.0077288 ]\n",
      " [0.00830973 0.         0.        ]\n",
      " [0.         0.0082883  0.        ]\n",
      " [0.         0.         0.00699626]\n",
      " [0.00833227 0.         0.        ]\n",
      " [0.         0.00830298 0.        ]\n",
      " [0.         0.         0.00832411]]), 'npar_data': array([[1.0000012, 1.0000012, 1.0000012],\n",
      "       [1.0000039, 1.0000039, 1.0000039],\n",
      "       [1.0144439, 1.0144439, 1.0144439],\n",
      "       [1.0000509, 1.0000509, 1.0000509],\n",
      "       [1.0000142, 1.0000142, 1.0000142],\n",
      "       [1.0205473, 1.0205473, 1.0205473],\n",
      "       [1.0597051, 1.0597051, 1.0597051],\n",
      "       [1.0002588, 1.0002588, 1.0002588],\n",
      "       [1.0000268, 1.0000268, 1.0000268],\n",
      "       [1.0000015, 1.0000015, 1.0000015],\n",
      "       [1.0147023, 1.0147023, 1.0147023],\n",
      "       [1.3639691, 1.3639691, 1.3639691],\n",
      "       [1.0875452, 1.0875452, 1.0875452],\n",
      "       [1.0000288, 1.0000288, 1.0000288],\n",
      "       [1.0001749, 1.0001749, 1.0001749],\n",
      "       [1.0008856, 1.0008856, 1.0008856],\n",
      "       [1.6327658, 1.6327658, 1.6327658],\n",
      "       [1.0469567, 1.0469567, 1.0469567],\n",
      "       [1.0184426, 1.0184426, 1.0184426],\n",
      "       [1.0001718, 1.0001718, 1.0001718],\n",
      "       [1.0150771, 1.0150771, 1.0150771],\n",
      "       [1.0002483, 1.0002483, 1.0002483],\n",
      "       [1.1902456, 1.1902456, 1.1902456],\n",
      "       [1.0001192, 1.0001192, 1.0001192],\n",
      "       [1.0003991, 1.0003991, 1.0003991],\n",
      "       [1.0009513, 1.0009513, 1.0009513],\n",
      "       [1.0005316, 1.0005316, 1.0005316],\n",
      "       [1.0000589, 1.0000589, 1.0000589],\n",
      "       [1.0000207, 1.0000207, 1.0000207],\n",
      "       [1.0016277, 1.0016277, 1.0016277],\n",
      "       [1.1077566, 1.1077566, 1.1077566],\n",
      "       [1.0000744, 1.0000744, 1.0000744],\n",
      "       [1.0054927, 1.0054927, 1.0054927],\n",
      "       [1.0011554, 1.0011554, 1.0011554],\n",
      "       [1.0176309, 1.0176309, 1.0176309],\n",
      "       [1.0003148, 1.0003148, 1.0003148],\n",
      "       [1.015302 , 1.015302 , 1.015302 ],\n",
      "       [1.0010489, 1.0010489, 1.0010489],\n",
      "       [1.0000587, 1.0000587, 1.0000587],\n",
      "       [1.0092978, 1.0092978, 1.0092978],\n",
      "       [1.0044334, 1.0044334, 1.0044334],\n",
      "       [1.0000043, 1.0000043, 1.0000043],\n",
      "       [1.1914046, 1.1914046, 1.1914046],\n",
      "       [1.0147023, 1.0147023, 1.0147023],\n",
      "       [1.0007169, 1.0007169, 1.0007169],\n",
      "       [1.2712675, 1.2712675, 1.2712675],\n",
      "       [1.009013 , 1.009013 , 1.009013 ],\n",
      "       [1.0199409, 1.0199409, 1.0199409],\n",
      "       [1.0000478, 1.0000478, 1.0000478],\n",
      "       [1.0057977, 1.0057977, 1.0057977],\n",
      "       [1.0140631, 1.0140631, 1.0140631],\n",
      "       [1.0003378, 1.0003378, 1.0003378],\n",
      "       [1.0006124, 1.0006124, 1.0006124],\n",
      "       [1.0019208, 1.0019208, 1.0019208],\n",
      "       [1.5535269, 1.5535269, 1.5535269],\n",
      "       [1.0010859, 1.0010859, 1.0010859],\n",
      "       [1.0006056, 1.0006056, 1.0006056],\n",
      "       [1.0001645, 1.0001645, 1.0001645],\n",
      "       [1.0001065, 1.0001065, 1.0001065],\n",
      "       [1.3217237, 1.3217237, 1.3217237],\n",
      "       [1.0252156, 1.0252156, 1.0252156],\n",
      "       [1.0003757, 1.0003757, 1.0003757],\n",
      "       [1.3675668, 1.3675668, 1.3675668],\n",
      "       [1.6501758, 1.6501758, 1.6501758],\n",
      "       [1.0001398, 1.0001398, 1.0001398],\n",
      "       [1.0150547, 1.0150547, 1.0150547],\n",
      "       [1.0002021, 1.0002021, 1.0002021],\n",
      "       [1.000029 , 1.000029 , 1.000029 ],\n",
      "       [1.5488353, 1.5488353, 1.5488353],\n",
      "       [1.0280935, 1.0280935, 1.0280935],\n",
      "       [1.0001547, 1.0001547, 1.0001547],\n",
      "       [1.0001276, 1.0001276, 1.0001276],\n",
      "       [1.0000765, 1.0000765, 1.0000765],\n",
      "       [1.6205176, 1.6205176, 1.6205176],\n",
      "       [1.0029607, 1.0029607, 1.0029607],\n",
      "       [1.0000117, 1.0000117, 1.0000117],\n",
      "       [1.0025849, 1.0025849, 1.0025849],\n",
      "       [1.0004857, 1.0004857, 1.0004857],\n",
      "       [1.000099 , 1.000099 , 1.000099 ],\n",
      "       [1.0781174, 1.0781174, 1.0781174],\n",
      "       [1.1334953, 1.1334953, 1.1334953],\n",
      "       [1.1559654, 1.1559654, 1.1559654],\n",
      "       [1.0205517, 1.0205517, 1.0205517],\n",
      "       [1.0014056, 1.0014056, 1.0014056],\n",
      "       [1.0000122, 1.0000122, 1.0000122],\n",
      "       [1.0044568, 1.0044568, 1.0044568],\n",
      "       [1.0608029, 1.0608029, 1.0608029],\n",
      "       [1.0126711, 1.0126711, 1.0126711],\n",
      "       [1.0009289, 1.0009289, 1.0009289],\n",
      "       [1.05005  , 1.05005  , 1.05005  ],\n",
      "       [1.0519656, 1.0519656, 1.0519656],\n",
      "       [1.1465518, 1.1465518, 1.1465518],\n",
      "       [1.0135783, 1.0135783, 1.0135783],\n",
      "       [1.0140697, 1.0140697, 1.0140697],\n",
      "       [1.0000913, 1.0000913, 1.0000913],\n",
      "       [1.0315003, 1.0315003, 1.0315003],\n",
      "       [1.0078092, 1.0078092, 1.0078092],\n",
      "       [1.0036739, 1.0036739, 1.0036739],\n",
      "       [1.0000288, 1.0000288, 1.0000288],\n",
      "       [1.0263063, 1.0263063, 1.0263063],\n",
      "       [1.0002159, 1.0002159, 1.0002159],\n",
      "       [1.2625691, 1.2625691, 1.2625691],\n",
      "       [1.000013 , 1.000013 , 1.000013 ],\n",
      "       [1.0001389, 1.0001389, 1.0001389],\n",
      "       [1.0022315, 1.0022315, 1.0022315],\n",
      "       [1.1258556, 1.1258556, 1.1258556],\n",
      "       [1.0044591, 1.0044591, 1.0044591],\n",
      "       [1.0225651, 1.0225651, 1.0225651],\n",
      "       [1.0114366, 1.0114366, 1.0114366],\n",
      "       [1.0423201, 1.0423201, 1.0423201],\n",
      "       [1.0288792, 1.0288792, 1.0288792],\n",
      "       [1.0074737, 1.0074737, 1.0074737],\n",
      "       [1.0108862, 1.0108862, 1.0108862],\n",
      "       [1.0782185, 1.0782185, 1.0782185],\n",
      "       [1.0028405, 1.0028405, 1.0028405],\n",
      "       [1.0054339, 1.0054339, 1.0054339],\n",
      "       [1.191113 , 1.191113 , 1.191113 ],\n",
      "       [1.0001274, 1.0001274, 1.0001274],\n",
      "       [1.0036557, 1.0036557, 1.0036557],\n",
      "       [1.0011086, 1.0011086, 1.0011086]], dtype=float32), 'shape': (120, 3)}\n",
      "==================================\n",
      "24\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [25], '_cg_ascend': [23], '_grad_f': tensor32([[-0.00833334  0.          0.        ]\n",
      " [-0.00833337  0.          0.        ]\n",
      " [ 0.         -0.0084537   0.        ]\n",
      " [-0.00833376  0.          0.        ]\n",
      " [-0.00833345  0.          0.        ]\n",
      " [ 0.          0.         -0.00850456]\n",
      " [ 0.         -0.00883088  0.        ]\n",
      " [-0.00833549  0.          0.        ]\n",
      " [-0.00833356  0.          0.        ]\n",
      " [-0.00833335  0.          0.        ]\n",
      " [ 0.          0.         -0.00845585]\n",
      " [ 0.         -0.01136641  0.        ]\n",
      " [ 0.         -0.00906288  0.        ]\n",
      " [-0.00833357  0.          0.        ]\n",
      " [-0.00833479  0.          0.        ]\n",
      " [ 0.         -0.00834071  0.        ]\n",
      " [ 0.          0.         -0.01360638]\n",
      " [ 0.          0.         -0.00872464]\n",
      " [ 0.         -0.00848702  0.        ]\n",
      " [ 0.          0.         -0.00833477]\n",
      " [ 0.         -0.00845898  0.        ]\n",
      " [ 0.          0.         -0.0083354 ]\n",
      " [ 0.         -0.00991871  0.        ]\n",
      " [-0.00833433  0.          0.        ]\n",
      " [ 0.          0.         -0.00833666]\n",
      " [ 0.         -0.00834126  0.        ]\n",
      " [-0.00833776  0.          0.        ]\n",
      " [-0.00833382  0.          0.        ]\n",
      " [-0.00833351  0.          0.        ]\n",
      " [ 0.         -0.0083469   0.        ]\n",
      " [ 0.          0.         -0.00923131]\n",
      " [-0.00833395  0.          0.        ]\n",
      " [-0.00837911  0.          0.        ]\n",
      " [-0.00834296  0.          0.        ]\n",
      " [ 0.         -0.00848026  0.        ]\n",
      " [-0.00833596  0.          0.        ]\n",
      " [ 0.         -0.00846085  0.        ]\n",
      " [ 0.          0.         -0.00834208]\n",
      " [-0.00833382  0.          0.        ]\n",
      " [ 0.         -0.00841082  0.        ]\n",
      " [ 0.          0.         -0.00837028]\n",
      " [-0.00833337  0.          0.        ]\n",
      " [ 0.          0.         -0.00992837]\n",
      " [ 0.          0.         -0.00845585]\n",
      " [ 0.         -0.00833931  0.        ]\n",
      " [ 0.         -0.0105939   0.        ]\n",
      " [ 0.          0.         -0.00840844]\n",
      " [ 0.         -0.00849951  0.        ]\n",
      " [-0.00833373  0.          0.        ]\n",
      " [ 0.         -0.00838165  0.        ]\n",
      " [ 0.          0.         -0.00845053]\n",
      " [-0.00833615  0.          0.        ]\n",
      " [-0.00833844  0.          0.        ]\n",
      " [ 0.         -0.00834934  0.        ]\n",
      " [ 0.         -0.01294606  0.        ]\n",
      " [-0.00834238  0.          0.        ]\n",
      " [ 0.          0.         -0.00833838]\n",
      " [-0.0083347   0.          0.        ]\n",
      " [-0.00833422  0.          0.        ]\n",
      " [ 0.         -0.01101436  0.        ]\n",
      " [ 0.         -0.00854346  0.        ]\n",
      " [ 0.          0.         -0.00833646]\n",
      " [ 0.         -0.01139639  0.        ]\n",
      " [ 0.          0.         -0.01375147]\n",
      " [ 0.          0.         -0.0083345 ]\n",
      " [ 0.         -0.00845879  0.        ]\n",
      " [-0.00833502  0.          0.        ]\n",
      " [-0.00833357  0.          0.        ]\n",
      " [ 0.          0.         -0.01290696]\n",
      " [ 0.          0.         -0.00856745]\n",
      " [-0.00833462  0.          0.        ]\n",
      " [-0.0083344   0.          0.        ]\n",
      " [-0.00833397  0.          0.        ]\n",
      " [ 0.         -0.01350431  0.        ]\n",
      " [ 0.          0.         -0.00835801]\n",
      " [-0.00833343  0.          0.        ]\n",
      " [ 0.          0.         -0.00835488]\n",
      " [ 0.          0.         -0.00833738]\n",
      " [-0.00833416  0.          0.        ]\n",
      " [ 0.         -0.00898431  0.        ]\n",
      " [ 0.         -0.00944579  0.        ]\n",
      " [ 0.          0.         -0.00963305]\n",
      " [ 0.         -0.0085046   0.        ]\n",
      " [ 0.          0.         -0.00834505]\n",
      " [-0.00833344  0.          0.        ]\n",
      " [ 0.          0.         -0.00837047]\n",
      " [ 0.         -0.00884002  0.        ]\n",
      " [ 0.          0.         -0.00843893]\n",
      " [ 0.         -0.00834107  0.        ]\n",
      " [ 0.         -0.00875042  0.        ]\n",
      " [ 0.         -0.00876638  0.        ]\n",
      " [-0.0095546   0.          0.        ]\n",
      " [ 0.         -0.00844649  0.        ]\n",
      " [ 0.         -0.00845058  0.        ]\n",
      " [-0.00833409  0.          0.        ]\n",
      " [ 0.         -0.00859584  0.        ]\n",
      " [ 0.          0.         -0.00839841]\n",
      " [ 0.          0.         -0.00836395]\n",
      " [-0.00833357  0.          0.        ]\n",
      " [ 0.         -0.00855255  0.        ]\n",
      " [ 0.          0.         -0.00833513]\n",
      " [ 0.          0.         -0.01052141]\n",
      " [-0.00833344  0.          0.        ]\n",
      " [ 0.          0.         -0.00833449]\n",
      " [-0.00835193  0.          0.        ]\n",
      " [ 0.         -0.00938213  0.        ]\n",
      " [ 0.          0.         -0.00837049]\n",
      " [ 0.          0.         -0.00852138]\n",
      " [ 0.         -0.00842864  0.        ]\n",
      " [ 0.          0.         -0.008686  ]\n",
      " [ 0.         -0.00857399  0.        ]\n",
      " [ 0.         -0.00839562  0.        ]\n",
      " [ 0.          0.         -0.00842405]\n",
      " [ 0.          0.         -0.00898515]\n",
      " [-0.00835701  0.          0.        ]\n",
      " [ 0.         -0.00837862  0.        ]\n",
      " [ 0.          0.         -0.00992594]\n",
      " [-0.0083344   0.          0.        ]\n",
      " [ 0.         -0.0083638   0.        ]\n",
      " [ 0.          0.         -0.00834257]]), 'grad': tensor32([[-0.00833334  0.          0.        ]\n",
      " [-0.00833337  0.          0.        ]\n",
      " [ 0.         -0.0084537   0.        ]\n",
      " [-0.00833376  0.          0.        ]\n",
      " [-0.00833345  0.          0.        ]\n",
      " [ 0.          0.         -0.00850456]\n",
      " [ 0.         -0.00883088  0.        ]\n",
      " [-0.00833549  0.          0.        ]\n",
      " [-0.00833356  0.          0.        ]\n",
      " [-0.00833335  0.          0.        ]\n",
      " [ 0.          0.         -0.00845585]\n",
      " [ 0.         -0.01136641  0.        ]\n",
      " [ 0.         -0.00906288  0.        ]\n",
      " [-0.00833357  0.          0.        ]\n",
      " [-0.00833479  0.          0.        ]\n",
      " [ 0.         -0.00834071  0.        ]\n",
      " [ 0.          0.         -0.01360638]\n",
      " [ 0.          0.         -0.00872464]\n",
      " [ 0.         -0.00848702  0.        ]\n",
      " [ 0.          0.         -0.00833477]\n",
      " [ 0.         -0.00845898  0.        ]\n",
      " [ 0.          0.         -0.0083354 ]\n",
      " [ 0.         -0.00991871  0.        ]\n",
      " [-0.00833433  0.          0.        ]\n",
      " [ 0.          0.         -0.00833666]\n",
      " [ 0.         -0.00834126  0.        ]\n",
      " [-0.00833776  0.          0.        ]\n",
      " [-0.00833382  0.          0.        ]\n",
      " [-0.00833351  0.          0.        ]\n",
      " [ 0.         -0.0083469   0.        ]\n",
      " [ 0.          0.         -0.00923131]\n",
      " [-0.00833395  0.          0.        ]\n",
      " [-0.00837911  0.          0.        ]\n",
      " [-0.00834296  0.          0.        ]\n",
      " [ 0.         -0.00848026  0.        ]\n",
      " [-0.00833596  0.          0.        ]\n",
      " [ 0.         -0.00846085  0.        ]\n",
      " [ 0.          0.         -0.00834208]\n",
      " [-0.00833382  0.          0.        ]\n",
      " [ 0.         -0.00841082  0.        ]\n",
      " [ 0.          0.         -0.00837028]\n",
      " [-0.00833337  0.          0.        ]\n",
      " [ 0.          0.         -0.00992837]\n",
      " [ 0.          0.         -0.00845585]\n",
      " [ 0.         -0.00833931  0.        ]\n",
      " [ 0.         -0.0105939   0.        ]\n",
      " [ 0.          0.         -0.00840844]\n",
      " [ 0.         -0.00849951  0.        ]\n",
      " [-0.00833373  0.          0.        ]\n",
      " [ 0.         -0.00838165  0.        ]\n",
      " [ 0.          0.         -0.00845053]\n",
      " [-0.00833615  0.          0.        ]\n",
      " [-0.00833844  0.          0.        ]\n",
      " [ 0.         -0.00834934  0.        ]\n",
      " [ 0.         -0.01294606  0.        ]\n",
      " [-0.00834238  0.          0.        ]\n",
      " [ 0.          0.         -0.00833838]\n",
      " [-0.0083347   0.          0.        ]\n",
      " [-0.00833422  0.          0.        ]\n",
      " [ 0.         -0.01101436  0.        ]\n",
      " [ 0.         -0.00854346  0.        ]\n",
      " [ 0.          0.         -0.00833646]\n",
      " [ 0.         -0.01139639  0.        ]\n",
      " [ 0.          0.         -0.01375147]\n",
      " [ 0.          0.         -0.0083345 ]\n",
      " [ 0.         -0.00845879  0.        ]\n",
      " [-0.00833502  0.          0.        ]\n",
      " [-0.00833357  0.          0.        ]\n",
      " [ 0.          0.         -0.01290696]\n",
      " [ 0.          0.         -0.00856745]\n",
      " [-0.00833462  0.          0.        ]\n",
      " [-0.0083344   0.          0.        ]\n",
      " [-0.00833397  0.          0.        ]\n",
      " [ 0.         -0.01350431  0.        ]\n",
      " [ 0.          0.         -0.00835801]\n",
      " [-0.00833343  0.          0.        ]\n",
      " [ 0.          0.         -0.00835488]\n",
      " [ 0.          0.         -0.00833738]\n",
      " [-0.00833416  0.          0.        ]\n",
      " [ 0.         -0.00898431  0.        ]\n",
      " [ 0.         -0.00944579  0.        ]\n",
      " [ 0.          0.         -0.00963305]\n",
      " [ 0.         -0.0085046   0.        ]\n",
      " [ 0.          0.         -0.00834505]\n",
      " [-0.00833344  0.          0.        ]\n",
      " [ 0.          0.         -0.00837047]\n",
      " [ 0.         -0.00884002  0.        ]\n",
      " [ 0.          0.         -0.00843893]\n",
      " [ 0.         -0.00834107  0.        ]\n",
      " [ 0.         -0.00875042  0.        ]\n",
      " [ 0.         -0.00876638  0.        ]\n",
      " [-0.0095546   0.          0.        ]\n",
      " [ 0.         -0.00844649  0.        ]\n",
      " [ 0.         -0.00845058  0.        ]\n",
      " [-0.00833409  0.          0.        ]\n",
      " [ 0.         -0.00859584  0.        ]\n",
      " [ 0.          0.         -0.00839841]\n",
      " [ 0.          0.         -0.00836395]\n",
      " [-0.00833357  0.          0.        ]\n",
      " [ 0.         -0.00855255  0.        ]\n",
      " [ 0.          0.         -0.00833513]\n",
      " [ 0.          0.         -0.01052141]\n",
      " [-0.00833344  0.          0.        ]\n",
      " [ 0.          0.         -0.00833449]\n",
      " [-0.00835193  0.          0.        ]\n",
      " [ 0.         -0.00938213  0.        ]\n",
      " [ 0.          0.         -0.00837049]\n",
      " [ 0.          0.         -0.00852138]\n",
      " [ 0.         -0.00842864  0.        ]\n",
      " [ 0.          0.         -0.008686  ]\n",
      " [ 0.         -0.00857399  0.        ]\n",
      " [ 0.         -0.00839562  0.        ]\n",
      " [ 0.          0.         -0.00842405]\n",
      " [ 0.          0.         -0.00898515]\n",
      " [-0.00835701  0.          0.        ]\n",
      " [ 0.         -0.00837862  0.        ]\n",
      " [ 0.          0.         -0.00992594]\n",
      " [-0.0083344   0.          0.        ]\n",
      " [ 0.         -0.0083638   0.        ]\n",
      " [ 0.          0.         -0.00834257]]), 'npar_data': array([[0.9999988 , 0.9999988 , 0.9999988 ],\n",
      "       [0.99999607, 0.99999607, 0.99999607],\n",
      "       [0.98576176, 0.98576176, 0.98576176],\n",
      "       [0.9999491 , 0.9999491 , 0.9999491 ],\n",
      "       [0.9999858 , 0.9999858 , 0.9999858 ],\n",
      "       [0.97986645, 0.97986645, 0.97986645],\n",
      "       [0.9436587 , 0.9436587 , 0.9436587 ],\n",
      "       [0.99974126, 0.99974126, 0.99974126],\n",
      "       [0.9999732 , 0.9999732 , 0.9999732 ],\n",
      "       [0.99999845, 0.99999845, 0.99999845],\n",
      "       [0.9855107 , 0.9855107 , 0.9855107 ],\n",
      "       [0.7331544 , 0.7331544 , 0.7331544 ],\n",
      "       [0.919502  , 0.919502  , 0.919502  ],\n",
      "       [0.99997115, 0.99997115, 0.99997115],\n",
      "       [0.9998252 , 0.9998252 , 0.9998252 ],\n",
      "       [0.99911517, 0.99911517, 0.99911517],\n",
      "       [0.6124577 , 0.6124577 , 0.6124577 ],\n",
      "       [0.95514935, 0.95514935, 0.95514935],\n",
      "       [0.98189133, 0.98189133, 0.98189133],\n",
      "       [0.9998282 , 0.9998282 , 0.9998282 ],\n",
      "       [0.9851468 , 0.9851468 , 0.9851468 ],\n",
      "       [0.99975175, 0.99975175, 0.99975175],\n",
      "       [0.8401627 , 0.8401627 , 0.8401627 ],\n",
      "       [0.9998808 , 0.9998808 , 0.9998808 ],\n",
      "       [0.99960107, 0.99960107, 0.99960107],\n",
      "       [0.9990496 , 0.9990496 , 0.9990496 ],\n",
      "       [0.99946874, 0.99946874, 0.99946874],\n",
      "       [0.9999411 , 0.9999411 , 0.9999411 ],\n",
      "       [0.99997926, 0.99997926, 0.99997926],\n",
      "       [0.99837494, 0.99837494, 0.99837494],\n",
      "       [0.9027254 , 0.9027254 , 0.9027254 ],\n",
      "       [0.9999256 , 0.9999256 , 0.9999256 ],\n",
      "       [0.9945373 , 0.9945373 , 0.9945373 ],\n",
      "       [0.99884593, 0.99884593, 0.99884593],\n",
      "       [0.98267454, 0.98267454, 0.98267454],\n",
      "       [0.9996853 , 0.9996853 , 0.9996853 ],\n",
      "       [0.98492867, 0.98492867, 0.98492867],\n",
      "       [0.99895215, 0.99895215, 0.99895215],\n",
      "       [0.99994135, 0.99994135, 0.99994135],\n",
      "       [0.9907878 , 0.9907878 , 0.9907878 ],\n",
      "       [0.99558616, 0.99558616, 0.99558616],\n",
      "       [0.9999957 , 0.9999957 , 0.9999957 ],\n",
      "       [0.83934546, 0.83934546, 0.83934546],\n",
      "       [0.9855107 , 0.9855107 , 0.9855107 ],\n",
      "       [0.9992836 , 0.9992836 , 0.9992836 ],\n",
      "       [0.7866165 , 0.7866165 , 0.7866165 ],\n",
      "       [0.99106747, 0.99106747, 0.99106747],\n",
      "       [0.980449  , 0.980449  , 0.980449  ],\n",
      "       [0.9999522 , 0.9999522 , 0.9999522 ],\n",
      "       [0.9942357 , 0.9942357 , 0.9942357 ],\n",
      "       [0.9861319 , 0.9861319 , 0.9861319 ],\n",
      "       [0.9996623 , 0.9996623 , 0.9996623 ],\n",
      "       [0.999388  , 0.999388  , 0.999388  ],\n",
      "       [0.9980829 , 0.9980829 , 0.9980829 ],\n",
      "       [0.6436966 , 0.6436966 , 0.6436966 ],\n",
      "       [0.9989153 , 0.9989153 , 0.9989153 ],\n",
      "       [0.9993948 , 0.9993948 , 0.9993948 ],\n",
      "       [0.9998355 , 0.9998355 , 0.9998355 ],\n",
      "       [0.99989355, 0.99989355, 0.99989355],\n",
      "       [0.7565878 , 0.7565878 , 0.7565878 ],\n",
      "       [0.97540456, 0.97540456, 0.97540456],\n",
      "       [0.9996244 , 0.9996244 , 0.9996244 ],\n",
      "       [0.73122567, 0.73122567, 0.73122567],\n",
      "       [0.605996  , 0.605996  , 0.605996  ],\n",
      "       [0.99986017, 0.99986017, 0.99986017],\n",
      "       [0.9851686 , 0.9851686 , 0.9851686 ],\n",
      "       [0.999798  , 0.999798  , 0.999798  ],\n",
      "       [0.99997103, 0.99997103, 0.99997103],\n",
      "       [0.64564645, 0.64564645, 0.64564645],\n",
      "       [0.9726742 , 0.9726742 , 0.9726742 ],\n",
      "       [0.99984527, 0.99984527, 0.99984527],\n",
      "       [0.99987245, 0.99987245, 0.99987245],\n",
      "       [0.99992347, 0.99992347, 0.99992347],\n",
      "       [0.61708677, 0.61708677, 0.61708677],\n",
      "       [0.9970481 , 0.9970481 , 0.9970481 ],\n",
      "       [0.9999883 , 0.9999883 , 0.9999883 ],\n",
      "       [0.99742174, 0.99742174, 0.99742174],\n",
      "       [0.9995146 , 0.9995146 , 0.9995146 ],\n",
      "       [0.99990106, 0.99990106, 0.99990106],\n",
      "       [0.9275428 , 0.9275428 , 0.9275428 ],\n",
      "       [0.8822268 , 0.8822268 , 0.8822268 ],\n",
      "       [0.86507773, 0.86507773, 0.86507773],\n",
      "       [0.9798622 , 0.9798622 , 0.9798622 ],\n",
      "       [0.9985964 , 0.9985964 , 0.9985964 ],\n",
      "       [0.99998784, 0.99998784, 0.99998784],\n",
      "       [0.99556303, 0.99556303, 0.99556303],\n",
      "       [0.94268215, 0.94268215, 0.94268215],\n",
      "       [0.98748744, 0.98748744, 0.98748744],\n",
      "       [0.99907196, 0.99907196, 0.99907196],\n",
      "       [0.9523356 , 0.9523356 , 0.9523356 ],\n",
      "       [0.95060146, 0.95060146, 0.95060146],\n",
      "       [0.87218034, 0.87218034, 0.87218034],\n",
      "       [0.9866036 , 0.9866036 , 0.9866036 ],\n",
      "       [0.9861255 , 0.9861255 , 0.9861255 ],\n",
      "       [0.9999087 , 0.9999087 , 0.9999087 ],\n",
      "       [0.9694616 , 0.9694616 , 0.9694616 ],\n",
      "       [0.99225134, 0.99225134, 0.99225134],\n",
      "       [0.99633956, 0.99633956, 0.99633956],\n",
      "       [0.99997115, 0.99997115, 0.99997115],\n",
      "       [0.97436804, 0.97436804, 0.97436804],\n",
      "       [0.9997842 , 0.9997842 , 0.9997842 ],\n",
      "       [0.7920359 , 0.7920359 , 0.7920359 ],\n",
      "       [0.999987  , 0.999987  , 0.999987  ],\n",
      "       [0.9998611 , 0.9998611 , 0.9998611 ],\n",
      "       [0.99777347, 0.99777347, 0.99777347],\n",
      "       [0.8882134 , 0.8882134 , 0.8882134 ],\n",
      "       [0.99556065, 0.99556065, 0.99556065],\n",
      "       [0.9779328 , 0.9779328 , 0.9779328 ],\n",
      "       [0.98869276, 0.98869276, 0.98869276],\n",
      "       [0.95939815, 0.95939815, 0.95939815],\n",
      "       [0.97193146, 0.97193146, 0.97193146],\n",
      "       [0.9925817 , 0.9925817 , 0.9925817 ],\n",
      "       [0.98923105, 0.98923105, 0.98923105],\n",
      "       [0.92745584, 0.92745584, 0.92745584],\n",
      "       [0.9971675 , 0.9971675 , 0.9971675 ],\n",
      "       [0.99459547, 0.99459547, 0.99459547],\n",
      "       [0.8395509 , 0.8395509 , 0.8395509 ],\n",
      "       [0.99987257, 0.99987257, 0.99987257],\n",
      "       [0.9963576 , 0.9963576 , 0.9963576 ],\n",
      "       [0.9988926 , 0.9988926 , 0.9988926 ]], dtype=float32), 'shape': (120, 3)}\n",
      "==================================\n",
      "25\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [27], '_cg_ascend': [19, 24], '_grad_f': tensor32([[-0.00833334  0.          0.        ]\n",
      " [-0.00833337  0.          0.        ]\n",
      " [ 0.         -0.0084537   0.        ]\n",
      " [-0.00833376  0.          0.        ]\n",
      " [-0.00833345  0.          0.        ]\n",
      " [ 0.          0.         -0.00850456]\n",
      " [ 0.         -0.00883088  0.        ]\n",
      " [-0.00833549  0.          0.        ]\n",
      " [-0.00833356  0.          0.        ]\n",
      " [-0.00833335  0.          0.        ]\n",
      " [ 0.          0.         -0.00845585]\n",
      " [ 0.         -0.01136641  0.        ]\n",
      " [ 0.         -0.00906288  0.        ]\n",
      " [-0.00833357  0.          0.        ]\n",
      " [-0.00833479  0.          0.        ]\n",
      " [ 0.         -0.00834071  0.        ]\n",
      " [ 0.          0.         -0.0215815 ]\n",
      " [ 0.          0.         -0.00872464]\n",
      " [ 0.         -0.00848702  0.        ]\n",
      " [ 0.          0.         -0.00833477]\n",
      " [ 0.         -0.00845898  0.        ]\n",
      " [ 0.          0.         -0.0083354 ]\n",
      " [ 0.         -0.00991871  0.        ]\n",
      " [-0.00833433  0.          0.        ]\n",
      " [ 0.          0.         -0.00833666]\n",
      " [ 0.         -0.00834126  0.        ]\n",
      " [-0.00833776  0.          0.        ]\n",
      " [-0.00833382  0.          0.        ]\n",
      " [-0.00833351  0.          0.        ]\n",
      " [ 0.         -0.0083469   0.        ]\n",
      " [ 0.          0.         -0.00923131]\n",
      " [-0.00833395  0.          0.        ]\n",
      " [-0.00837911  0.          0.        ]\n",
      " [-0.00834296  0.          0.        ]\n",
      " [ 0.         -0.00848026  0.        ]\n",
      " [-0.00833596  0.          0.        ]\n",
      " [ 0.         -0.00846085  0.        ]\n",
      " [ 0.          0.         -0.00834208]\n",
      " [-0.00833382  0.          0.        ]\n",
      " [ 0.         -0.00841082  0.        ]\n",
      " [ 0.          0.         -0.00837028]\n",
      " [-0.00833337  0.          0.        ]\n",
      " [ 0.          0.         -0.00992837]\n",
      " [ 0.          0.         -0.00845585]\n",
      " [ 0.         -0.00833931  0.        ]\n",
      " [ 0.         -0.0105939   0.        ]\n",
      " [ 0.          0.         -0.00840844]\n",
      " [ 0.         -0.00849951  0.        ]\n",
      " [-0.00833373  0.          0.        ]\n",
      " [ 0.         -0.00838165  0.        ]\n",
      " [ 0.          0.         -0.00845053]\n",
      " [-0.00833615  0.          0.        ]\n",
      " [-0.00833844  0.          0.        ]\n",
      " [ 0.         -0.00834934  0.        ]\n",
      " [ 0.         -0.0234695   0.        ]\n",
      " [-0.00834238  0.          0.        ]\n",
      " [ 0.          0.         -0.00833838]\n",
      " [-0.0083347   0.          0.        ]\n",
      " [-0.00833422  0.          0.        ]\n",
      " [ 0.         -0.03740624  0.        ]\n",
      " [ 0.         -0.00854346  0.        ]\n",
      " [ 0.          0.         -0.00833646]\n",
      " [ 0.         -0.0311713   0.        ]\n",
      " [ 0.          0.         -0.01375147]\n",
      " [ 0.          0.         -0.0083345 ]\n",
      " [ 0.         -0.00845879  0.        ]\n",
      " [-0.00833502  0.          0.        ]\n",
      " [-0.00833357  0.          0.        ]\n",
      " [ 0.          0.         -0.01290696]\n",
      " [ 0.          0.         -0.00856745]\n",
      " [-0.00833462  0.          0.        ]\n",
      " [-0.0083344   0.          0.        ]\n",
      " [-0.00833397  0.          0.        ]\n",
      " [ 0.         -0.01350431  0.        ]\n",
      " [ 0.          0.         -0.00835801]\n",
      " [-0.00833343  0.          0.        ]\n",
      " [ 0.          0.         -0.00835488]\n",
      " [ 0.          0.         -0.00833738]\n",
      " [-0.00833416  0.          0.        ]\n",
      " [ 0.         -0.00898431  0.        ]\n",
      " [ 0.         -0.00944579  0.        ]\n",
      " [ 0.          0.         -0.00963305]\n",
      " [ 0.         -0.0085046   0.        ]\n",
      " [ 0.          0.         -0.00834505]\n",
      " [-0.00833344  0.          0.        ]\n",
      " [ 0.          0.         -0.00837047]\n",
      " [ 0.         -0.00884002  0.        ]\n",
      " [ 0.          0.         -0.00843893]\n",
      " [ 0.         -0.00834107  0.        ]\n",
      " [ 0.         -0.00875042  0.        ]\n",
      " [ 0.         -0.00876638  0.        ]\n",
      " [-0.0095546   0.          0.        ]\n",
      " [ 0.         -0.00844649  0.        ]\n",
      " [ 0.         -0.00845058  0.        ]\n",
      " [-0.00833409  0.          0.        ]\n",
      " [ 0.         -0.00859584  0.        ]\n",
      " [ 0.          0.         -0.00839841]\n",
      " [ 0.          0.         -0.00836395]\n",
      " [-0.00833357  0.          0.        ]\n",
      " [ 0.         -0.00855255  0.        ]\n",
      " [ 0.          0.         -0.00833513]\n",
      " [ 0.          0.         -0.01052141]\n",
      " [-0.00833344  0.          0.        ]\n",
      " [ 0.          0.         -0.00833449]\n",
      " [-0.00835193  0.          0.        ]\n",
      " [ 0.         -0.00938213  0.        ]\n",
      " [ 0.          0.         -0.00837049]\n",
      " [ 0.          0.         -0.00852138]\n",
      " [ 0.         -0.00842864  0.        ]\n",
      " [ 0.          0.         -0.008686  ]\n",
      " [ 0.         -0.00857399  0.        ]\n",
      " [ 0.         -0.00839562  0.        ]\n",
      " [ 0.          0.         -0.00842405]\n",
      " [ 0.          0.         -0.00898515]\n",
      " [-0.00835701  0.          0.        ]\n",
      " [ 0.         -0.00837862  0.        ]\n",
      " [ 0.          0.         -0.00992594]\n",
      " [-0.0083344   0.          0.        ]\n",
      " [ 0.         -0.0083638   0.        ]\n",
      " [ 0.          0.         -0.00834257]]), 'grad': tensor32([[-0.00833334  0.          0.        ]\n",
      " [-0.00833337  0.          0.        ]\n",
      " [ 0.         -0.0084537   0.        ]\n",
      " [-0.00833376  0.          0.        ]\n",
      " [-0.00833345  0.          0.        ]\n",
      " [ 0.          0.         -0.00850456]\n",
      " [ 0.         -0.00883088  0.        ]\n",
      " [-0.00833549  0.          0.        ]\n",
      " [-0.00833356  0.          0.        ]\n",
      " [-0.00833335  0.          0.        ]\n",
      " [ 0.          0.         -0.00845585]\n",
      " [ 0.         -0.01136641  0.        ]\n",
      " [ 0.         -0.00906288  0.        ]\n",
      " [-0.00833357  0.          0.        ]\n",
      " [-0.00833479  0.          0.        ]\n",
      " [ 0.         -0.00834071  0.        ]\n",
      " [ 0.          0.         -0.0215815 ]\n",
      " [ 0.          0.         -0.00872464]\n",
      " [ 0.         -0.00848702  0.        ]\n",
      " [ 0.          0.         -0.00833477]\n",
      " [ 0.         -0.00845898  0.        ]\n",
      " [ 0.          0.         -0.0083354 ]\n",
      " [ 0.         -0.00991871  0.        ]\n",
      " [-0.00833433  0.          0.        ]\n",
      " [ 0.          0.         -0.00833666]\n",
      " [ 0.         -0.00834126  0.        ]\n",
      " [-0.00833776  0.          0.        ]\n",
      " [-0.00833382  0.          0.        ]\n",
      " [-0.00833351  0.          0.        ]\n",
      " [ 0.         -0.0083469   0.        ]\n",
      " [ 0.          0.         -0.00923131]\n",
      " [-0.00833395  0.          0.        ]\n",
      " [-0.00837911  0.          0.        ]\n",
      " [-0.00834296  0.          0.        ]\n",
      " [ 0.         -0.00848026  0.        ]\n",
      " [-0.00833596  0.          0.        ]\n",
      " [ 0.         -0.00846085  0.        ]\n",
      " [ 0.          0.         -0.00834208]\n",
      " [-0.00833382  0.          0.        ]\n",
      " [ 0.         -0.00841082  0.        ]\n",
      " [ 0.          0.         -0.00837028]\n",
      " [-0.00833337  0.          0.        ]\n",
      " [ 0.          0.         -0.00992837]\n",
      " [ 0.          0.         -0.00845585]\n",
      " [ 0.         -0.00833931  0.        ]\n",
      " [ 0.         -0.0105939   0.        ]\n",
      " [ 0.          0.         -0.00840844]\n",
      " [ 0.         -0.00849951  0.        ]\n",
      " [-0.00833373  0.          0.        ]\n",
      " [ 0.         -0.00838165  0.        ]\n",
      " [ 0.          0.         -0.00845053]\n",
      " [-0.00833615  0.          0.        ]\n",
      " [-0.00833844  0.          0.        ]\n",
      " [ 0.         -0.00834934  0.        ]\n",
      " [ 0.         -0.0234695   0.        ]\n",
      " [-0.00834238  0.          0.        ]\n",
      " [ 0.          0.         -0.00833838]\n",
      " [-0.0083347   0.          0.        ]\n",
      " [-0.00833422  0.          0.        ]\n",
      " [ 0.         -0.03740624  0.        ]\n",
      " [ 0.         -0.00854346  0.        ]\n",
      " [ 0.          0.         -0.00833646]\n",
      " [ 0.         -0.0311713   0.        ]\n",
      " [ 0.          0.         -0.01375147]\n",
      " [ 0.          0.         -0.0083345 ]\n",
      " [ 0.         -0.00845879  0.        ]\n",
      " [-0.00833502  0.          0.        ]\n",
      " [-0.00833357  0.          0.        ]\n",
      " [ 0.          0.         -0.01290696]\n",
      " [ 0.          0.         -0.00856745]\n",
      " [-0.00833462  0.          0.        ]\n",
      " [-0.0083344   0.          0.        ]\n",
      " [-0.00833397  0.          0.        ]\n",
      " [ 0.         -0.01350431  0.        ]\n",
      " [ 0.          0.         -0.00835801]\n",
      " [-0.00833343  0.          0.        ]\n",
      " [ 0.          0.         -0.00835488]\n",
      " [ 0.          0.         -0.00833738]\n",
      " [-0.00833416  0.          0.        ]\n",
      " [ 0.         -0.00898431  0.        ]\n",
      " [ 0.         -0.00944579  0.        ]\n",
      " [ 0.          0.         -0.00963305]\n",
      " [ 0.         -0.0085046   0.        ]\n",
      " [ 0.          0.         -0.00834505]\n",
      " [-0.00833344  0.          0.        ]\n",
      " [ 0.          0.         -0.00837047]\n",
      " [ 0.         -0.00884002  0.        ]\n",
      " [ 0.          0.         -0.00843893]\n",
      " [ 0.         -0.00834107  0.        ]\n",
      " [ 0.         -0.00875042  0.        ]\n",
      " [ 0.         -0.00876638  0.        ]\n",
      " [-0.0095546   0.          0.        ]\n",
      " [ 0.         -0.00844649  0.        ]\n",
      " [ 0.         -0.00845058  0.        ]\n",
      " [-0.00833409  0.          0.        ]\n",
      " [ 0.         -0.00859584  0.        ]\n",
      " [ 0.          0.         -0.00839841]\n",
      " [ 0.          0.         -0.00836395]\n",
      " [-0.00833357  0.          0.        ]\n",
      " [ 0.         -0.00855255  0.        ]\n",
      " [ 0.          0.         -0.00833513]\n",
      " [ 0.          0.         -0.01052141]\n",
      " [-0.00833344  0.          0.        ]\n",
      " [ 0.          0.         -0.00833449]\n",
      " [-0.00835193  0.          0.        ]\n",
      " [ 0.         -0.00938213  0.        ]\n",
      " [ 0.          0.         -0.00837049]\n",
      " [ 0.          0.         -0.00852138]\n",
      " [ 0.         -0.00842864  0.        ]\n",
      " [ 0.          0.         -0.008686  ]\n",
      " [ 0.         -0.00857399  0.        ]\n",
      " [ 0.         -0.00839562  0.        ]\n",
      " [ 0.          0.         -0.00842405]\n",
      " [ 0.          0.         -0.00898515]\n",
      " [-0.00835701  0.          0.        ]\n",
      " [ 0.         -0.00837862  0.        ]\n",
      " [ 0.          0.         -0.00992594]\n",
      " [-0.0083344   0.          0.        ]\n",
      " [ 0.         -0.0083638   0.        ]\n",
      " [ 0.          0.         -0.00834257]]), 'npar_data': array([[9.99998808e-01, 1.20064499e-06, 2.42322624e-08],\n",
      "       [9.99996066e-01, 3.75890932e-06, 1.73358742e-07],\n",
      "       [9.75624891e-04, 9.85761762e-01, 1.32626668e-02],\n",
      "       [9.99949098e-01, 5.07790501e-05, 1.78645209e-07],\n",
      "       [9.99985814e-01, 1.40688180e-05, 8.34681799e-08],\n",
      "       [5.88536022e-05, 2.00747009e-02, 9.79866445e-01],\n",
      "       [5.54060424e-03, 9.43658710e-01, 5.08006327e-02],\n",
      "       [9.99741256e-01, 2.58456450e-04, 2.24933274e-07],\n",
      "       [9.99973178e-01, 2.66805109e-05, 1.03329739e-07],\n",
      "       [9.99998450e-01, 1.50940514e-06, 2.90424023e-08],\n",
      "       [4.48568753e-04, 1.40406862e-02, 9.85510707e-01],\n",
      "       [1.00331731e-01, 7.33154416e-01, 1.66513771e-01],\n",
      "       [1.72676647e-03, 9.19502020e-01, 7.87712634e-02],\n",
      "       [9.99971151e-01, 2.86122977e-05, 2.44497159e-07],\n",
      "       [9.99825180e-01, 1.74564077e-04, 1.91958691e-07],\n",
      "       [5.08156430e-04, 9.99115169e-01, 3.76724725e-04],\n",
      "       [1.40905613e-03, 6.12457693e-01, 3.86133224e-01],\n",
      "       [1.23653898e-03, 4.36140336e-02, 9.55149353e-01],\n",
      "       [8.48319207e-04, 9.81891334e-01, 1.72603931e-02],\n",
      "       [3.20049803e-05, 1.39701660e-04, 9.99828219e-01],\n",
      "       [5.01318742e-03, 9.85146821e-01, 9.83994640e-03],\n",
      "       [1.11617703e-06, 2.47179822e-04, 9.99751747e-01],\n",
      "       [2.45159641e-02, 8.40162694e-01, 1.35321334e-01],\n",
      "       [9.99880791e-01, 1.19055803e-04, 1.56550300e-07],\n",
      "       [4.15682308e-07, 3.98561970e-04, 9.99601066e-01],\n",
      "       [4.87759273e-04, 9.99049604e-01, 4.62579832e-04],\n",
      "       [9.99468744e-01, 5.31089958e-04, 2.37106562e-07],\n",
      "       [9.99941111e-01, 5.86514616e-05, 1.91259488e-07],\n",
      "       [9.99979258e-01, 2.01616331e-05, 6.07258187e-07],\n",
      "       [8.44507595e-04, 9.98374939e-01, 7.80562288e-04],\n",
      "       [4.12381196e-04, 9.68622491e-02, 9.02725399e-01],\n",
      "       [9.99925613e-01, 7.39984753e-05, 3.20126446e-07],\n",
      "       [9.94537294e-01, 5.46201877e-03, 6.69085125e-07],\n",
      "       [9.98845935e-01, 1.15153810e-03, 2.48693914e-06],\n",
      "       [2.47159321e-03, 9.82674539e-01, 1.48538146e-02],\n",
      "       [9.99685287e-01, 3.14483477e-04, 2.43484322e-07],\n",
      "       [1.07432306e-02, 9.84928668e-01, 4.32807114e-03],\n",
      "       [7.50998443e-05, 9.72705311e-04, 9.98952150e-01],\n",
      "       [9.99941349e-01, 5.84948393e-05, 1.41898113e-07],\n",
      "       [1.10616465e-03, 9.90787804e-01, 8.10613856e-03],\n",
      "       [1.07998225e-04, 4.30579530e-03, 9.95586157e-01],\n",
      "       [9.99995708e-01, 4.29156671e-06, 5.42718581e-08],\n",
      "       [5.26156370e-03, 1.55393019e-01, 8.39345455e-01],\n",
      "       [4.48568753e-04, 1.40406862e-02, 9.85510707e-01],\n",
      "       [2.37874319e-05, 9.99283612e-01, 6.92612957e-04],\n",
      "       [5.32541238e-02, 7.86616504e-01, 1.60129383e-01],\n",
      "       [1.27443869e-03, 7.65809789e-03, 9.91067469e-01],\n",
      "       [5.09804988e-04, 9.80449021e-01, 1.90411471e-02],\n",
      "       [9.99952197e-01, 4.72726024e-05, 5.32174738e-07],\n",
      "       [5.25511662e-03, 9.94235694e-01, 5.09179197e-04],\n",
      "       [9.01244493e-05, 1.37779191e-02, 9.86131907e-01],\n",
      "       [9.99662280e-01, 3.37524718e-04, 2.16997464e-07],\n",
      "       [9.99387980e-01, 6.11743773e-04, 1.88320101e-07],\n",
      "       [5.95951453e-04, 9.98082876e-01, 1.32120366e-03],\n",
      "       [1.23258273e-03, 3.55070800e-01, 6.43696606e-01],\n",
      "       [9.98915315e-01, 1.08429510e-03, 3.65151578e-07],\n",
      "       [6.31632938e-05, 5.42079913e-04, 9.99394774e-01],\n",
      "       [9.99835491e-01, 1.64240992e-04, 2.05836542e-07],\n",
      "       [9.99893546e-01, 1.04569306e-04, 1.85418651e-06],\n",
      "       [2.06330102e-02, 2.22779199e-01, 7.56587803e-01],\n",
      "       [2.37603635e-02, 9.75404561e-01, 8.35133542e-04],\n",
      "       [2.75120401e-05, 3.48036730e-04, 9.99624372e-01],\n",
      "       [1.43439870e-03, 2.67339915e-01, 7.31225669e-01],\n",
      "       [6.88797852e-04, 3.93315166e-01, 6.05996013e-01],\n",
      "       [7.01877639e-07, 1.39124822e-04, 9.99860168e-01],\n",
      "       [1.30206300e-03, 9.85168576e-01, 1.35293994e-02],\n",
      "       [9.99798000e-01, 2.01808565e-04, 2.12936854e-07],\n",
      "       [9.99971032e-01, 2.90181724e-05, 4.46801316e-08],\n",
      "       [1.39063442e-04, 3.54214460e-01, 6.45646453e-01],\n",
      "       [1.71562191e-04, 2.71542370e-02, 9.72674191e-01],\n",
      "       [9.99845266e-01, 1.54528287e-04, 2.20717141e-07],\n",
      "       [9.99872446e-01, 1.27334570e-04, 2.74823549e-07],\n",
      "       [9.99923468e-01, 7.63944699e-05, 1.36900098e-07],\n",
      "       [3.36221856e-04, 6.17086768e-01, 3.82576942e-01],\n",
      "       [4.34076792e-04, 2.51780869e-03, 9.97048080e-01],\n",
      "       [9.99988317e-01, 1.15214061e-05, 1.51876463e-07],\n",
      "       [4.86281169e-05, 2.52965209e-03, 9.97421741e-01],\n",
      "       [7.07430881e-05, 4.14630718e-04, 9.99514580e-01],\n",
      "       [9.99901056e-01, 9.88018073e-05, 1.38205394e-07],\n",
      "       [2.84723099e-03, 9.27542806e-01, 6.96100146e-02],\n",
      "       [7.60564348e-04, 8.82226825e-01, 1.17012523e-01],\n",
      "       [1.07840274e-03, 1.33843839e-01, 8.65077734e-01],\n",
      "       [7.89028418e-04, 9.79862213e-01, 1.93487871e-02],\n",
      "       [1.92524123e-04, 1.21108710e-03, 9.98596370e-01],\n",
      "       [9.99987841e-01, 1.20943541e-05, 1.09958627e-07],\n",
      "       [8.84056135e-05, 4.34860773e-03, 9.95563030e-01],\n",
      "       [7.94407818e-03, 9.42682147e-01, 4.93736714e-02],\n",
      "       [2.96277431e-04, 1.22162588e-02, 9.87487435e-01],\n",
      "       [7.90060323e-04, 9.99071956e-01, 1.37920826e-04],\n",
      "       [1.95985176e-02, 9.52335596e-01, 2.80659217e-02],\n",
      "       [4.12816880e-03, 9.50601459e-01, 4.52703871e-02],\n",
      "       [8.72180343e-01, 1.27816066e-01, 3.50664664e-06],\n",
      "       [4.37167007e-04, 9.86603618e-01, 1.29592381e-02],\n",
      "       [1.70167245e-03, 9.86125529e-01, 1.21727036e-02],\n",
      "       [9.99908686e-01, 9.11612151e-05, 1.62267185e-07],\n",
      "       [2.01902706e-02, 9.69461620e-01, 1.03481840e-02],\n",
      "       [1.29035061e-05, 7.73575716e-03, 9.92251337e-01],\n",
      "       [2.81961606e-04, 3.37851536e-03, 9.96339560e-01],\n",
      "       [9.99971151e-01, 2.84362941e-05, 3.57303577e-07],\n",
      "       [2.47322805e-02, 9.74368036e-01, 8.99716222e-04],\n",
      "       [3.31604388e-05, 1.82663716e-04, 9.99784172e-01],\n",
      "       [2.13732026e-04, 2.07750365e-01, 7.92035878e-01],\n",
      "       [9.99987006e-01, 1.30262333e-05, 4.97524759e-08],\n",
      "       [1.51276799e-05, 1.23717633e-04, 9.99861121e-01],\n",
      "       [9.97773468e-01, 2.22612731e-03, 3.84577959e-07],\n",
      "       [1.09367294e-03, 8.88213396e-01, 1.10692948e-01],\n",
      "       [4.59130206e-06, 4.43479791e-03, 9.95560646e-01],\n",
      "       [3.79410660e-04, 2.16877088e-02, 9.77932811e-01],\n",
      "       [2.62985285e-03, 9.88692760e-01, 8.67741834e-03],\n",
      "       [5.53874008e-04, 4.00479399e-02, 9.59398150e-01],\n",
      "       [6.78456636e-05, 9.71931458e-01, 2.80006882e-02],\n",
      "       [6.19255239e-04, 9.92581725e-01, 6.79899938e-03],\n",
      "       [9.95768118e-04, 9.77316406e-03, 9.89231050e-01],\n",
      "       [3.94895626e-03, 6.85952604e-02, 9.27455842e-01],\n",
      "       [9.97167528e-01, 2.83190445e-03, 5.93349796e-07],\n",
      "       [7.62664073e-04, 9.94595468e-01, 4.64189611e-03],\n",
      "       [7.90739246e-03, 1.52541667e-01, 8.39550912e-01],\n",
      "       [9.99872565e-01, 1.27322550e-04, 9.99028344e-08],\n",
      "       [5.21682960e-04, 9.96357620e-01, 3.12071620e-03],\n",
      "       [1.21093799e-05, 1.09534024e-03, 9.98892605e-01]], dtype=float32), 'shape': (120, 3)}\n",
      "==================================\n",
      "26\n",
      "1e-08\n",
      "==================================\n",
      "27\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [28], '_cg_ascend': [25], '_grad_f': tensor32([[-0.00833334  0.          0.        ]\n",
      " [-0.00833337  0.          0.        ]\n",
      " [ 0.         -0.0084537   0.        ]\n",
      " [-0.00833376  0.          0.        ]\n",
      " [-0.00833345  0.          0.        ]\n",
      " [ 0.          0.         -0.00850456]\n",
      " [ 0.         -0.00883088  0.        ]\n",
      " [-0.00833549  0.          0.        ]\n",
      " [-0.00833356  0.          0.        ]\n",
      " [-0.00833335  0.          0.        ]\n",
      " [ 0.          0.         -0.00845585]\n",
      " [ 0.         -0.01136641  0.        ]\n",
      " [ 0.         -0.00906288  0.        ]\n",
      " [-0.00833357  0.          0.        ]\n",
      " [-0.00833479  0.          0.        ]\n",
      " [ 0.         -0.00834071  0.        ]\n",
      " [ 0.          0.         -0.0215815 ]\n",
      " [ 0.          0.         -0.00872464]\n",
      " [ 0.         -0.00848702  0.        ]\n",
      " [ 0.          0.         -0.00833477]\n",
      " [ 0.         -0.00845898  0.        ]\n",
      " [ 0.          0.         -0.0083354 ]\n",
      " [ 0.         -0.00991871  0.        ]\n",
      " [-0.00833433  0.          0.        ]\n",
      " [ 0.          0.         -0.00833666]\n",
      " [ 0.         -0.00834126  0.        ]\n",
      " [-0.00833776  0.          0.        ]\n",
      " [-0.00833382  0.          0.        ]\n",
      " [-0.00833351  0.          0.        ]\n",
      " [ 0.         -0.0083469   0.        ]\n",
      " [ 0.          0.         -0.00923131]\n",
      " [-0.00833395  0.          0.        ]\n",
      " [-0.00837911  0.          0.        ]\n",
      " [-0.00834296  0.          0.        ]\n",
      " [ 0.         -0.00848026  0.        ]\n",
      " [-0.00833596  0.          0.        ]\n",
      " [ 0.         -0.00846085  0.        ]\n",
      " [ 0.          0.         -0.00834208]\n",
      " [-0.00833382  0.          0.        ]\n",
      " [ 0.         -0.00841082  0.        ]\n",
      " [ 0.          0.         -0.00837028]\n",
      " [-0.00833337  0.          0.        ]\n",
      " [ 0.          0.         -0.00992837]\n",
      " [ 0.          0.         -0.00845585]\n",
      " [ 0.         -0.00833931  0.        ]\n",
      " [ 0.         -0.0105939   0.        ]\n",
      " [ 0.          0.         -0.00840844]\n",
      " [ 0.         -0.00849951  0.        ]\n",
      " [-0.00833373  0.          0.        ]\n",
      " [ 0.         -0.00838165  0.        ]\n",
      " [ 0.          0.         -0.00845053]\n",
      " [-0.00833615  0.          0.        ]\n",
      " [-0.00833844  0.          0.        ]\n",
      " [ 0.         -0.00834934  0.        ]\n",
      " [ 0.         -0.0234695   0.        ]\n",
      " [-0.00834238  0.          0.        ]\n",
      " [ 0.          0.         -0.00833838]\n",
      " [-0.0083347   0.          0.        ]\n",
      " [-0.00833422  0.          0.        ]\n",
      " [ 0.         -0.03740624  0.        ]\n",
      " [ 0.         -0.00854346  0.        ]\n",
      " [ 0.          0.         -0.00833646]\n",
      " [ 0.         -0.0311713   0.        ]\n",
      " [ 0.          0.         -0.01375147]\n",
      " [ 0.          0.         -0.0083345 ]\n",
      " [ 0.         -0.00845879  0.        ]\n",
      " [-0.00833502  0.          0.        ]\n",
      " [-0.00833357  0.          0.        ]\n",
      " [ 0.          0.         -0.01290696]\n",
      " [ 0.          0.         -0.00856745]\n",
      " [-0.00833462  0.          0.        ]\n",
      " [-0.0083344   0.          0.        ]\n",
      " [-0.00833397  0.          0.        ]\n",
      " [ 0.         -0.01350431  0.        ]\n",
      " [ 0.          0.         -0.00835801]\n",
      " [-0.00833343  0.          0.        ]\n",
      " [ 0.          0.         -0.00835488]\n",
      " [ 0.          0.         -0.00833738]\n",
      " [-0.00833416  0.          0.        ]\n",
      " [ 0.         -0.00898431  0.        ]\n",
      " [ 0.         -0.00944579  0.        ]\n",
      " [ 0.          0.         -0.00963305]\n",
      " [ 0.         -0.0085046   0.        ]\n",
      " [ 0.          0.         -0.00834505]\n",
      " [-0.00833344  0.          0.        ]\n",
      " [ 0.          0.         -0.00837047]\n",
      " [ 0.         -0.00884002  0.        ]\n",
      " [ 0.          0.         -0.00843893]\n",
      " [ 0.         -0.00834107  0.        ]\n",
      " [ 0.         -0.00875042  0.        ]\n",
      " [ 0.         -0.00876638  0.        ]\n",
      " [-0.0095546   0.          0.        ]\n",
      " [ 0.         -0.00844649  0.        ]\n",
      " [ 0.         -0.00845058  0.        ]\n",
      " [-0.00833409  0.          0.        ]\n",
      " [ 0.         -0.00859584  0.        ]\n",
      " [ 0.          0.         -0.00839841]\n",
      " [ 0.          0.         -0.00836395]\n",
      " [-0.00833357  0.          0.        ]\n",
      " [ 0.         -0.00855255  0.        ]\n",
      " [ 0.          0.         -0.00833513]\n",
      " [ 0.          0.         -0.01052141]\n",
      " [-0.00833344  0.          0.        ]\n",
      " [ 0.          0.         -0.00833449]\n",
      " [-0.00835193  0.          0.        ]\n",
      " [ 0.         -0.00938213  0.        ]\n",
      " [ 0.          0.         -0.00837049]\n",
      " [ 0.          0.         -0.00852138]\n",
      " [ 0.         -0.00842864  0.        ]\n",
      " [ 0.          0.         -0.008686  ]\n",
      " [ 0.         -0.00857399  0.        ]\n",
      " [ 0.         -0.00839562  0.        ]\n",
      " [ 0.          0.         -0.00842405]\n",
      " [ 0.          0.         -0.00898515]\n",
      " [-0.00835701  0.          0.        ]\n",
      " [ 0.         -0.00837862  0.        ]\n",
      " [ 0.          0.         -0.00992594]\n",
      " [-0.0083344   0.          0.        ]\n",
      " [ 0.         -0.0083638   0.        ]\n",
      " [ 0.          0.         -0.00834257]]), 'grad': tensor32([[-0.00833334  0.          0.        ]\n",
      " [-0.00833337  0.          0.        ]\n",
      " [ 0.         -0.0084537   0.        ]\n",
      " [-0.00833376  0.          0.        ]\n",
      " [-0.00833345  0.          0.        ]\n",
      " [ 0.          0.         -0.00850456]\n",
      " [ 0.         -0.00883088  0.        ]\n",
      " [-0.00833549  0.          0.        ]\n",
      " [-0.00833356  0.          0.        ]\n",
      " [-0.00833335  0.          0.        ]\n",
      " [ 0.          0.         -0.00845585]\n",
      " [ 0.         -0.01136641  0.        ]\n",
      " [ 0.         -0.00906288  0.        ]\n",
      " [-0.00833357  0.          0.        ]\n",
      " [-0.00833479  0.          0.        ]\n",
      " [ 0.         -0.00834071  0.        ]\n",
      " [ 0.          0.         -0.0215815 ]\n",
      " [ 0.          0.         -0.00872464]\n",
      " [ 0.         -0.00848702  0.        ]\n",
      " [ 0.          0.         -0.00833477]\n",
      " [ 0.         -0.00845898  0.        ]\n",
      " [ 0.          0.         -0.0083354 ]\n",
      " [ 0.         -0.00991871  0.        ]\n",
      " [-0.00833433  0.          0.        ]\n",
      " [ 0.          0.         -0.00833666]\n",
      " [ 0.         -0.00834126  0.        ]\n",
      " [-0.00833776  0.          0.        ]\n",
      " [-0.00833382  0.          0.        ]\n",
      " [-0.00833351  0.          0.        ]\n",
      " [ 0.         -0.0083469   0.        ]\n",
      " [ 0.          0.         -0.00923131]\n",
      " [-0.00833395  0.          0.        ]\n",
      " [-0.00837911  0.          0.        ]\n",
      " [-0.00834296  0.          0.        ]\n",
      " [ 0.         -0.00848026  0.        ]\n",
      " [-0.00833596  0.          0.        ]\n",
      " [ 0.         -0.00846085  0.        ]\n",
      " [ 0.          0.         -0.00834208]\n",
      " [-0.00833382  0.          0.        ]\n",
      " [ 0.         -0.00841082  0.        ]\n",
      " [ 0.          0.         -0.00837028]\n",
      " [-0.00833337  0.          0.        ]\n",
      " [ 0.          0.         -0.00992837]\n",
      " [ 0.          0.         -0.00845585]\n",
      " [ 0.         -0.00833931  0.        ]\n",
      " [ 0.         -0.0105939   0.        ]\n",
      " [ 0.          0.         -0.00840844]\n",
      " [ 0.         -0.00849951  0.        ]\n",
      " [-0.00833373  0.          0.        ]\n",
      " [ 0.         -0.00838165  0.        ]\n",
      " [ 0.          0.         -0.00845053]\n",
      " [-0.00833615  0.          0.        ]\n",
      " [-0.00833844  0.          0.        ]\n",
      " [ 0.         -0.00834934  0.        ]\n",
      " [ 0.         -0.0234695   0.        ]\n",
      " [-0.00834238  0.          0.        ]\n",
      " [ 0.          0.         -0.00833838]\n",
      " [-0.0083347   0.          0.        ]\n",
      " [-0.00833422  0.          0.        ]\n",
      " [ 0.         -0.03740624  0.        ]\n",
      " [ 0.         -0.00854346  0.        ]\n",
      " [ 0.          0.         -0.00833646]\n",
      " [ 0.         -0.0311713   0.        ]\n",
      " [ 0.          0.         -0.01375147]\n",
      " [ 0.          0.         -0.0083345 ]\n",
      " [ 0.         -0.00845879  0.        ]\n",
      " [-0.00833502  0.          0.        ]\n",
      " [-0.00833357  0.          0.        ]\n",
      " [ 0.          0.         -0.01290696]\n",
      " [ 0.          0.         -0.00856745]\n",
      " [-0.00833462  0.          0.        ]\n",
      " [-0.0083344   0.          0.        ]\n",
      " [-0.00833397  0.          0.        ]\n",
      " [ 0.         -0.01350431  0.        ]\n",
      " [ 0.          0.         -0.00835801]\n",
      " [-0.00833343  0.          0.        ]\n",
      " [ 0.          0.         -0.00835488]\n",
      " [ 0.          0.         -0.00833738]\n",
      " [-0.00833416  0.          0.        ]\n",
      " [ 0.         -0.00898431  0.        ]\n",
      " [ 0.         -0.00944579  0.        ]\n",
      " [ 0.          0.         -0.00963305]\n",
      " [ 0.         -0.0085046   0.        ]\n",
      " [ 0.          0.         -0.00834505]\n",
      " [-0.00833344  0.          0.        ]\n",
      " [ 0.          0.         -0.00837047]\n",
      " [ 0.         -0.00884002  0.        ]\n",
      " [ 0.          0.         -0.00843893]\n",
      " [ 0.         -0.00834107  0.        ]\n",
      " [ 0.         -0.00875042  0.        ]\n",
      " [ 0.         -0.00876638  0.        ]\n",
      " [-0.0095546   0.          0.        ]\n",
      " [ 0.         -0.00844649  0.        ]\n",
      " [ 0.         -0.00845058  0.        ]\n",
      " [-0.00833409  0.          0.        ]\n",
      " [ 0.         -0.00859584  0.        ]\n",
      " [ 0.          0.         -0.00839841]\n",
      " [ 0.          0.         -0.00836395]\n",
      " [-0.00833357  0.          0.        ]\n",
      " [ 0.         -0.00855255  0.        ]\n",
      " [ 0.          0.         -0.00833513]\n",
      " [ 0.          0.         -0.01052141]\n",
      " [-0.00833344  0.          0.        ]\n",
      " [ 0.          0.         -0.00833449]\n",
      " [-0.00835193  0.          0.        ]\n",
      " [ 0.         -0.00938213  0.        ]\n",
      " [ 0.          0.         -0.00837049]\n",
      " [ 0.          0.         -0.00852138]\n",
      " [ 0.         -0.00842864  0.        ]\n",
      " [ 0.          0.         -0.008686  ]\n",
      " [ 0.         -0.00857399  0.        ]\n",
      " [ 0.         -0.00839562  0.        ]\n",
      " [ 0.          0.         -0.00842405]\n",
      " [ 0.          0.         -0.00898515]\n",
      " [-0.00835701  0.          0.        ]\n",
      " [ 0.         -0.00837862  0.        ]\n",
      " [ 0.          0.         -0.00992594]\n",
      " [-0.0083344   0.          0.        ]\n",
      " [ 0.         -0.0083638   0.        ]\n",
      " [ 0.          0.         -0.00834257]]), 'npar_data': array([[9.99998808e-01, 1.21064500e-06, 3.42322615e-08],\n",
      "       [9.99996066e-01, 3.76890921e-06, 1.83358736e-07],\n",
      "       [9.75634903e-04, 9.85761762e-01, 1.32626770e-02],\n",
      "       [9.99949098e-01, 5.07890509e-05, 1.88645203e-07],\n",
      "       [9.99985814e-01, 1.40788179e-05, 9.34681808e-08],\n",
      "       [5.88636030e-05, 2.00747102e-02, 9.79866445e-01],\n",
      "       [5.54061402e-03, 9.43658710e-01, 5.08006439e-02],\n",
      "       [9.99741256e-01, 2.58466462e-04, 2.34933268e-07],\n",
      "       [9.99973178e-01, 2.66905117e-05, 1.13329740e-07],\n",
      "       [9.99998450e-01, 1.51940515e-06, 3.90424013e-08],\n",
      "       [4.48578765e-04, 1.40406964e-02, 9.85510707e-01],\n",
      "       [1.00331739e-01, 7.33154416e-01, 1.66513786e-01],\n",
      "       [1.72677648e-03, 9.19502020e-01, 7.87712708e-02],\n",
      "       [9.99971151e-01, 2.86222985e-05, 2.54497166e-07],\n",
      "       [9.99825180e-01, 1.74574074e-04, 2.01958684e-07],\n",
      "       [5.08166442e-04, 9.99115169e-01, 3.76734737e-04],\n",
      "       [1.40906614e-03, 6.12457693e-01, 3.86133224e-01],\n",
      "       [1.23654900e-03, 4.36140448e-02, 9.55149353e-01],\n",
      "       [8.48329219e-04, 9.81891334e-01, 1.72604024e-02],\n",
      "       [3.20149811e-05, 1.39711658e-04, 9.99828219e-01],\n",
      "       [5.01319719e-03, 9.85146821e-01, 9.83995665e-03],\n",
      "       [1.12617704e-06, 2.47189833e-04, 9.99751747e-01],\n",
      "       [2.45159734e-02, 8.40162694e-01, 1.35321349e-01],\n",
      "       [9.99880791e-01, 1.19065800e-04, 1.66550294e-07],\n",
      "       [4.25682316e-07, 3.98571981e-04, 9.99601066e-01],\n",
      "       [4.87769285e-04, 9.99049604e-01, 4.62589844e-04],\n",
      "       [9.99468744e-01, 5.31099970e-04, 2.47106556e-07],\n",
      "       [9.99941111e-01, 5.86614624e-05, 2.01259482e-07],\n",
      "       [9.99979258e-01, 2.01716339e-05, 6.17258195e-07],\n",
      "       [8.44517606e-04, 9.98374939e-01, 7.80572300e-04],\n",
      "       [4.12391208e-04, 9.68622565e-02, 9.02725399e-01],\n",
      "       [9.99925613e-01, 7.40084724e-05, 3.30126454e-07],\n",
      "       [9.94537294e-01, 5.46202855e-03, 6.79085133e-07],\n",
      "       [9.98845935e-01, 1.15154812e-03, 2.49693903e-06],\n",
      "       [2.47160322e-03, 9.82674539e-01, 1.48538249e-02],\n",
      "       [9.99685287e-01, 3.14493489e-04, 2.53484330e-07],\n",
      "       [1.07432408e-02, 9.84928668e-01, 4.32808092e-03],\n",
      "       [7.51098414e-05, 9.72715323e-04, 9.98952150e-01],\n",
      "       [9.99941349e-01, 5.85048401e-05, 1.51898107e-07],\n",
      "       [1.10617466e-03, 9.90787804e-01, 8.10614880e-03],\n",
      "       [1.08008222e-04, 4.30580508e-03, 9.95586157e-01],\n",
      "       [9.99995708e-01, 4.30156661e-06, 6.42718589e-08],\n",
      "       [5.26157347e-03, 1.55393034e-01, 8.39345455e-01],\n",
      "       [4.48578765e-04, 1.40406964e-02, 9.85510707e-01],\n",
      "       [2.37974327e-05, 9.99283612e-01, 6.92622969e-04],\n",
      "       [5.32541350e-02, 7.86616504e-01, 1.60129398e-01],\n",
      "       [1.27444870e-03, 7.65810767e-03, 9.91067469e-01],\n",
      "       [5.09815000e-04, 9.80449021e-01, 1.90411564e-02],\n",
      "       [9.99952197e-01, 4.72826032e-05, 5.42174746e-07],\n",
      "       [5.25512639e-03, 9.94235694e-01, 5.09189209e-04],\n",
      "       [9.01344465e-05, 1.37779294e-02, 9.86131907e-01],\n",
      "       [9.99662280e-01, 3.37534730e-04, 2.26997457e-07],\n",
      "       [9.99387980e-01, 6.11753785e-04, 1.98320095e-07],\n",
      "       [5.95961465e-04, 9.98082876e-01, 1.32121367e-03],\n",
      "       [1.23259274e-03, 3.55070800e-01, 6.43696606e-01],\n",
      "       [9.98915315e-01, 1.08430511e-03, 3.75151586e-07],\n",
      "       [6.31732910e-05, 5.42089925e-04, 9.99394774e-01],\n",
      "       [9.99835491e-01, 1.64250989e-04, 2.15836536e-07],\n",
      "       [9.99893546e-01, 1.04579303e-04, 1.86418652e-06],\n",
      "       [2.06330195e-02, 2.22779214e-01, 7.56587803e-01],\n",
      "       [2.37603728e-02, 9.75404561e-01, 8.35143554e-04],\n",
      "       [2.75220409e-05, 3.48046742e-04, 9.99624372e-01],\n",
      "       [1.43440871e-03, 2.67339915e-01, 7.31225669e-01],\n",
      "       [6.88807864e-04, 3.93315166e-01, 6.05996013e-01],\n",
      "       [7.11877647e-07, 1.39134820e-04, 9.99860168e-01],\n",
      "       [1.30207301e-03, 9.85168576e-01, 1.35294097e-02],\n",
      "       [9.99798000e-01, 2.01818562e-04, 2.22936848e-07],\n",
      "       [9.99971032e-01, 2.90281732e-05, 5.46801324e-08],\n",
      "       [1.39073440e-04, 3.54214460e-01, 6.45646453e-01],\n",
      "       [1.71572188e-04, 2.71542463e-02, 9.72674191e-01],\n",
      "       [9.99845266e-01, 1.54538284e-04, 2.30717134e-07],\n",
      "       [9.99872446e-01, 1.27344567e-04, 2.84823557e-07],\n",
      "       [9.99923468e-01, 7.64044671e-05, 1.46900092e-07],\n",
      "       [3.36231868e-04, 6.17086768e-01, 3.82576942e-01],\n",
      "       [4.34086804e-04, 2.51781871e-03, 9.97048080e-01],\n",
      "       [9.99988317e-01, 1.15314060e-05, 1.61876457e-07],\n",
      "       [4.86381177e-05, 2.52966210e-03, 9.97421741e-01],\n",
      "       [7.07530853e-05, 4.14640730e-04, 9.99514580e-01],\n",
      "       [9.99901056e-01, 9.88118045e-05, 1.48205388e-07],\n",
      "       [2.84724100e-03, 9.27542806e-01, 6.96100220e-02],\n",
      "       [7.60574359e-04, 8.82226825e-01, 1.17012531e-01],\n",
      "       [1.07841275e-03, 1.33843854e-01, 8.65077734e-01],\n",
      "       [7.89038430e-04, 9.79862213e-01, 1.93487965e-02],\n",
      "       [1.92534120e-04, 1.21109711e-03, 9.98596370e-01],\n",
      "       [9.99987841e-01, 1.21043540e-05, 1.19958628e-07],\n",
      "       [8.84156107e-05, 4.34861751e-03, 9.95563030e-01],\n",
      "       [7.94408843e-03, 9.42682147e-01, 4.93736826e-02],\n",
      "       [2.96287442e-04, 1.22162690e-02, 9.87487435e-01],\n",
      "       [7.90070335e-04, 9.99071956e-01, 1.37930823e-04],\n",
      "       [1.95985269e-02, 9.52335596e-01, 2.80659311e-02],\n",
      "       [4.12817858e-03, 9.50601459e-01, 4.52703983e-02],\n",
      "       [8.72180343e-01, 1.27816081e-01, 3.51664653e-06],\n",
      "       [4.37177019e-04, 9.86603618e-01, 1.29592484e-02],\n",
      "       [1.70168246e-03, 9.86125529e-01, 1.21727139e-02],\n",
      "       [9.99908686e-01, 9.11712123e-05, 1.72267178e-07],\n",
      "       [2.01902799e-02, 9.69461620e-01, 1.03481943e-02],\n",
      "       [1.29135060e-05, 7.73576694e-03, 9.92251337e-01],\n",
      "       [2.81971617e-04, 3.37852538e-03, 9.96339560e-01],\n",
      "       [9.99971151e-01, 2.84462949e-05, 3.67303585e-07],\n",
      "       [2.47322898e-02, 9.74368036e-01, 8.99726234e-04],\n",
      "       [3.31704396e-05, 1.82673713e-04, 9.99784172e-01],\n",
      "       [2.13742023e-04, 2.07750380e-01, 7.92035878e-01],\n",
      "       [9.99987006e-01, 1.30362332e-05, 5.97524732e-08],\n",
      "       [1.51376798e-05, 1.23727630e-04, 9.99861121e-01],\n",
      "       [9.97773468e-01, 2.22613732e-03, 3.94577967e-07],\n",
      "       [1.09368295e-03, 8.88213396e-01, 1.10692956e-01],\n",
      "       [4.60130195e-06, 4.43480769e-03, 9.95560646e-01],\n",
      "       [3.79420671e-04, 2.16877181e-02, 9.77932811e-01],\n",
      "       [2.62986287e-03, 9.88692760e-01, 8.67742859e-03],\n",
      "       [5.53884020e-04, 4.00479510e-02, 9.59398150e-01],\n",
      "       [6.78556607e-05, 9.71931458e-01, 2.80006975e-02],\n",
      "       [6.19265251e-04, 9.92581725e-01, 6.79900916e-03],\n",
      "       [9.95778129e-04, 9.77317430e-03, 9.89231050e-01],\n",
      "       [3.94896604e-03, 6.85952678e-02, 9.27455842e-01],\n",
      "       [9.97167528e-01, 2.83191446e-03, 6.03349804e-07],\n",
      "       [7.62674084e-04, 9.94595468e-01, 4.64190589e-03],\n",
      "       [7.90740270e-03, 1.52541682e-01, 8.39550912e-01],\n",
      "       [9.99872565e-01, 1.27332547e-04, 1.09902835e-07],\n",
      "       [5.21692971e-04, 9.96357620e-01, 3.12072621e-03],\n",
      "       [1.21193798e-05, 1.09535025e-03, 9.98892605e-01]], dtype=float32), 'shape': (120, 3)}\n",
      "==================================\n",
      "28\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [30], '_cg_ascend': [27], '_grad_f': tensor32([[-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]]), 'grad': tensor32([[-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]\n",
      " [-0.00833333  0.          0.        ]\n",
      " [ 0.         -0.00833333  0.        ]\n",
      " [ 0.          0.         -0.00833333]]), 'npar_data': array([[-1.19209369e-06, -1.36243572e+01, -1.71900978e+01],\n",
      "       [-3.93391429e-06, -1.24887247e+01, -1.55118217e+01],\n",
      "       [-6.93242216e+00, -1.43405749e-02, -4.32280159e+00],\n",
      "       [-5.09036618e-05, -9.88782978e+00, -1.54833975e+01],\n",
      "       [-1.41860055e-05, -1.11708393e+01, -1.61856441e+01],\n",
      "       [-9.74028778e+00, -3.90829444e+00, -2.03389972e-02],\n",
      "       [-5.19565010e+00, -5.79907149e-02, -2.97984624e+00],\n",
      "       [-2.58777232e-04, -8.26074505e+00, -1.52639647e+01],\n",
      "       [-2.68224503e-05, -1.05312023e+01, -1.59929638e+01],\n",
      "       [-1.54972190e-06, -1.33971920e+01, -1.70586185e+01],\n",
      "       [-7.70942640e+00, -4.26579523e+00, -1.45952888e-02],\n",
      "       [-2.29927325e+00, -3.10398966e-01, -1.79267716e+00],\n",
      "       [-6.36149883e+00, -8.39230493e-02, -2.54120684e+00],\n",
      "       [-2.88490646e-05, -1.04613247e+01, -1.51839762e+01],\n",
      "       [-1.74835703e-04, -8.65316105e+00, -1.54152031e+01],\n",
      "       [-7.58470154e+00, -8.85222631e-04, -7.88396931e+00],\n",
      "       [-6.56482792e+00, -4.90275413e-01, -9.51572835e-01],\n",
      "       [-6.69543076e+00, -3.13237596e+00, -4.58875597e-02],\n",
      "       [-7.07224178e+00, -1.82746351e-02, -4.05934048e+00],\n",
      "       [-1.03493071e+01, -8.87592983e+00, -1.71795342e-04],\n",
      "       [-5.29568148e+00, -1.49645917e-02, -4.62130404e+00],\n",
      "       [-1.36966820e+01, -8.30535412e+00, -2.48284166e-04],\n",
      "       [-3.70843053e+00, -1.74159721e-01, -2.00010300e+00],\n",
      "       [-1.19216398e-04, -9.03583431e+00, -1.56079683e+01],\n",
      "       [-1.46695728e+01, -7.82762241e+00, -3.99013486e-04],\n",
      "       [-7.62566805e+00, -9.50847985e-04, -7.67866993e+00],\n",
      "       [-5.31397352e-04, -7.54056025e+00, -1.52134466e+01],\n",
      "       [-5.88911207e-05, -9.74372768e+00, -1.54186707e+01],\n",
      "       [-2.07426310e-05, -1.08112335e+01, -1.42979784e+01],\n",
      "       [-7.07674503e+00, -1.62638293e-03, -7.15548325e+00],\n",
      "       [-7.79353809e+00, -2.33446527e+00, -1.02336861e-01],\n",
      "       [-7.43893688e-05, -9.51133060e+00, -1.49237900e+01],\n",
      "       [-5.47768129e-03, -5.20993519e+00, -1.42025194e+01],\n",
      "       [-1.15473161e-03, -6.76664829e+00, -1.29004450e+01],\n",
      "       [-6.00288820e+00, -1.74773037e-02, -4.20949793e+00],\n",
      "       [-3.14762059e-04, -8.06454754e+00, -1.51879635e+01],\n",
      "       [-4.53347874e+00, -1.51860584e-02, -5.44263124e+00],\n",
      "       [-9.49655914e+00, -6.93541908e+00, -1.04839902e-03],\n",
      "       [-5.86526912e-05, -9.74640083e+00, -1.57000561e+01],\n",
      "       [-6.80684757e+00, -9.25489143e-03, -4.81513262e+00],\n",
      "       [-9.13330364e+00, -5.44779110e+00, -4.42361273e-03],\n",
      "       [-4.29154352e-06, -1.23565311e+01, -1.65601444e+01],\n",
      "       [-5.24732494e+00, -1.86179769e+00, -1.75132915e-01],\n",
      "       [-7.70942640e+00, -4.26579523e+00, -1.45952888e-02],\n",
      "       [-1.06459332e+01, -7.16644980e-04, -7.27502489e+00],\n",
      "       [-2.93267989e+00, -2.40014419e-01, -1.83177304e+00],\n",
      "       [-6.66524172e+00, -4.87199020e+00, -8.97266436e-03],\n",
      "       [-7.58146286e+00, -1.97446272e-02, -3.96115255e+00],\n",
      "       [-4.78040674e-05, -9.95936775e+00, -1.44276772e+01],\n",
      "       [-5.24855137e+00, -5.78098325e-03, -7.58269072e+00],\n",
      "       [-9.31420803e+00, -4.28468752e+00, -1.39651531e-02],\n",
      "       [-3.37776932e-04, -7.99384212e+00, -1.52983274e+01],\n",
      "       [-6.12207805e-04, -7.39918089e+00, -1.54333839e+01],\n",
      "       [-7.42533445e+00, -1.91896386e-03, -6.62920475e+00],\n",
      "       [-6.69863558e+00, -1.03543806e+00, -4.40527767e-01],\n",
      "       [-1.08527404e-03, -6.82681608e+00, -1.47959356e+01],\n",
      "       [-9.66962910e+00, -7.52007866e+00, -6.05408801e-04],\n",
      "       [-1.64522367e-04, -8.71411514e+00, -1.53487444e+01],\n",
      "       [-1.06459564e-04, -9.16556454e+00, -1.31926861e+01],\n",
      "       [-3.88086271e+00, -1.50157404e+00, -2.78936654e-01],\n",
      "       [-3.73973608e+00, -2.49029584e-02, -7.08790684e+00],\n",
      "       [-1.05005236e+01, -7.96317387e+00, -3.75699019e-04],\n",
      "       [-6.54700279e+00, -1.31923437e+00, -3.13033164e-01],\n",
      "       [-7.28054810e+00, -9.33144033e-01, -5.00881910e-01],\n",
      "       [-1.41553602e+01, -8.88006687e+00, -1.39842276e-04],\n",
      "       [-6.64379787e+00, -1.49425101e-02, -4.30288935e+00],\n",
      "       [-2.02020557e-04, -8.50814152e+00, -1.53163776e+01],\n",
      "       [-2.89682775e-05, -1.04472437e+01, -1.67217655e+01],\n",
      "       [-8.88050842e+00, -1.03785276e+00, -4.37503189e-01],\n",
      "       [-8.67050648e+00, -3.60622191e+00, -2.77061015e-02],\n",
      "       [-1.54745634e-04, -8.77506828e+00, -1.52820730e+01],\n",
      "       [-1.27562074e-04, -8.96861362e+00, -1.50713959e+01],\n",
      "       [-7.65352888e-05, -9.47946930e+00, -1.57335129e+01],\n",
      "       [-7.99770975e+00, -4.82745647e-01, -9.60825443e-01],\n",
      "       [-7.74226618e+00, -5.98436260e+00, -2.95628561e-03],\n",
      "       [-1.16825786e-05, -1.13704367e+01, -1.56364326e+01],\n",
      "       [-9.93110275e+00, -5.97966957e+00, -2.58158799e-03],\n",
      "       [-9.55631447e+00, -7.78809834e+00, -4.85538098e-04],\n",
      "       [-9.89486070e-05, -9.22229385e+00, -1.57246666e+01],\n",
      "       [-5.86140490e+00, -7.52163306e-02, -2.66484666e+00],\n",
      "       [-7.18143654e+00, -1.25306070e-01, -2.14547420e+00],\n",
      "       [-6.83226490e+00, -2.01108146e+00, -1.44935906e-01],\n",
      "       [-7.14469576e+00, -2.03433167e-02, -3.94512510e+00],\n",
      "       [-8.55523682e+00, -6.71622849e+00, -1.40461582e-03],\n",
      "       [-1.21594221e-05, -1.13219452e+01, -1.59361191e+01],\n",
      "       [-9.33346176e+00, -5.43789721e+00, -4.44684224e-03],\n",
      "       [-4.83532715e+00, -5.90261184e-02, -3.00833774e+00],\n",
      "       [-8.12418079e+00, -4.40498686e+00, -1.25915064e-02],\n",
      "       [-7.14338875e+00, -9.28475230e-04, -8.88875866e+00],\n",
      "       [-3.93230081e+00, -4.88377921e-02, -3.57319880e+00],\n",
      "       [-5.48991919e+00, -5.06603792e-02, -3.09510183e+00],\n",
      "       [-1.36759058e-01, -2.05716300e+00, -1.25580025e+01],\n",
      "       [-7.73517227e+00, -1.34869236e-02, -4.34594536e+00],\n",
      "       [-6.37613773e+00, -1.39716212e-02, -4.40855837e+00],\n",
      "       [-9.13184849e-05, -9.30277157e+00, -1.55742188e+01],\n",
      "       [-3.90255404e+00, -3.10143940e-02, -4.57094336e+00],\n",
      "       [-1.12572365e+01, -4.86190081e+00, -7.77884014e-03],\n",
      "       [-8.17370415e+00, -5.69031620e+00, -3.66715621e-03],\n",
      "       [-2.88490646e-05, -1.04674931e+01, -1.48170776e+01],\n",
      "       [-3.69964552e+00, -2.59661879e-02, -7.01342010e+00],\n",
      "       [-1.03138514e+01, -8.60780907e+00, -2.15851716e-04],\n",
      "       [-8.45074081e+00, -1.57141805e+00, -2.33148575e-01],\n",
      "       [-1.29938962e-05, -1.12477779e+01, -1.66330547e+01],\n",
      "       [-1.10983238e+01, -8.99742794e+00, -1.38888470e-04],\n",
      "       [-2.22901395e-03, -6.10748720e+00, -1.47454491e+01],\n",
      "       [-6.81820440e+00, -1.18543252e-01, -2.20099497e+00],\n",
      "       [-1.22891712e+01, -5.41827106e+00, -4.44923760e-03],\n",
      "       [-7.87686491e+00, -3.83100915e+00, -2.23143119e-02],\n",
      "       [-5.94082355e+00, -1.13716526e-02, -4.74703026e+00],\n",
      "       [-7.49855518e+00, -3.21767783e+00, -4.14491147e-02],\n",
      "       [-9.59812737e+00, -2.84699947e-02, -3.57552576e+00],\n",
      "       [-7.38697672e+00, -7.44592724e-03, -4.99097824e+00],\n",
      "       [-6.91198587e+00, -4.62811375e+00, -1.08273551e-02],\n",
      "       [-5.53430128e+00, -2.67953181e+00, -7.53100961e-02],\n",
      "       [-2.83649145e-03, -5.86680222e+00, -1.43207684e+01],\n",
      "       [-7.17867994e+00, -5.41918911e-03, -5.37263012e+00],\n",
      "       [-4.83995581e+00, -1.88031745e+00, -1.74888164e-01],\n",
      "       [-1.27442836e-04, -8.96870804e+00, -1.60236683e+01],\n",
      "       [-7.55843115e+00, -3.64902988e-03, -5.76968956e+00],\n",
      "       [-1.13207045e+01, -6.81668091e+00, -1.10800820e-03]], dtype=float32), 'shape': (120, 3)}\n",
      "==================================\n",
      "29\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [30], '_cg_ascend': [], '_grad_f': tensor32([[9.93411486e-09 1.13536313e-01 1.43250823e-01]\n",
      " [3.27826193e-08 1.04072712e-01 1.29265189e-01]\n",
      " [5.77701889e-02 1.19504795e-04 3.60233486e-02]\n",
      " [4.24197196e-07 8.23985860e-02 1.29028320e-01]\n",
      " [1.18216718e-07 9.30903330e-02 1.34880379e-01]\n",
      " [8.11690688e-02 3.25691216e-02 1.69491657e-04]\n",
      " [4.32970859e-02 4.83255979e-04 2.48320531e-02]\n",
      " [2.15647697e-06 6.88395426e-02 1.27199709e-01]\n",
      " [2.23520431e-07 8.77600238e-02 1.33274704e-01]\n",
      " [1.29143496e-08 1.11643270e-01 1.42155156e-01]\n",
      " [6.42452240e-02 3.55482958e-02 1.21627410e-04]\n",
      " [1.91606116e-02 2.58665811e-03 1.49389775e-02]\n",
      " [5.30124940e-02 6.99358759e-04 2.11767256e-02]\n",
      " [2.40408895e-07 8.71777087e-02 1.26533136e-01]\n",
      " [1.45696424e-06 7.21096769e-02 1.28460035e-01]\n",
      " [6.32058531e-02 7.37685559e-06 6.56997487e-02]\n",
      " [5.47069013e-02 4.08562878e-03 7.92977400e-03]\n",
      " [5.57952598e-02 2.61031352e-02 3.82396363e-04]\n",
      " [5.89353517e-02 1.52288630e-04 3.38278376e-02]\n",
      " [8.62442330e-02 7.39660859e-02 1.43162788e-06]\n",
      " [4.41306829e-02 1.24704937e-04 3.85108702e-02]\n",
      " [1.14139020e-01 6.92112893e-02 2.06903474e-06]\n",
      " [3.09035890e-02 1.45133107e-03 1.66675262e-02]\n",
      " [9.93470053e-07 7.52986223e-02 1.30066410e-01]\n",
      " [1.22246444e-01 6.52301908e-02 3.32511263e-06]\n",
      " [6.35472387e-02 7.92373339e-06 6.39889166e-02]\n",
      " [4.42831151e-06 6.28380030e-02 1.26778722e-01]\n",
      " [4.90759362e-07 8.11977386e-02 1.28488928e-01]\n",
      " [1.72855266e-07 9.00936201e-02 1.19149826e-01]\n",
      " [5.89728765e-02 1.35531918e-05 5.96290305e-02]\n",
      " [6.49461523e-02 1.94538776e-02 8.52807192e-04]\n",
      " [6.19911418e-07 7.92610943e-02 1.24364920e-01]\n",
      " [4.56473463e-05 4.34161276e-02 1.18354335e-01]\n",
      " [9.62276408e-06 5.63887395e-02 1.07503712e-01]\n",
      " [5.00240698e-02 1.45644211e-04 3.50791514e-02]\n",
      " [2.62301728e-06 6.72045648e-02 1.26566365e-01]\n",
      " [3.77789922e-02 1.26550498e-04 4.53552641e-02]\n",
      " [7.91379958e-02 5.77951632e-02 8.73665886e-06]\n",
      " [4.88772457e-07 8.12200084e-02 1.30833805e-01]\n",
      " [5.67237325e-02 7.71240957e-05 4.01261076e-02]\n",
      " [7.61108696e-02 4.53982614e-02 3.68634428e-05]\n",
      " [3.57628629e-08 1.02971099e-01 1.38001204e-01]\n",
      " [4.37277108e-02 1.55149819e-02 1.45944103e-03]\n",
      " [6.42452240e-02 3.55482958e-02 1.21627410e-04]\n",
      " [8.87161121e-02 5.97204189e-06 6.06252104e-02]\n",
      " [2.44389996e-02 2.00012024e-03 1.52647765e-02]\n",
      " [5.55436835e-02 4.05999199e-02 7.47722079e-05]\n",
      " [6.31788597e-02 1.64538564e-04 3.30096073e-02]\n",
      " [3.98367263e-07 8.29947367e-02 1.20230652e-01]\n",
      " [4.37379293e-02 4.81748611e-05 6.31890893e-02]\n",
      " [7.76184052e-02 3.57057303e-02 1.16376279e-04]\n",
      " [2.81480789e-06 6.66153580e-02 1.27486065e-01]\n",
      " [5.10173186e-06 6.16598427e-02 1.28611535e-01]\n",
      " [6.18777908e-02 1.59913670e-05 5.52433766e-02]\n",
      " [5.58219664e-02 8.62865057e-03 3.67106497e-03]\n",
      " [9.04395074e-06 5.68901375e-02 1.23299472e-01]\n",
      " [8.05802494e-02 6.26673251e-02 5.04507352e-06]\n",
      " [1.37101983e-06 7.26176277e-02 1.27906203e-01]\n",
      " [8.87163083e-07 7.63797089e-02 1.09939054e-01]\n",
      " [3.23405229e-02 1.25131179e-02 2.32447218e-03]\n",
      " [3.11644692e-02 2.07524659e-04 5.90658933e-02]\n",
      " [8.75043646e-02 6.63597882e-02 3.13082523e-06]\n",
      " [5.45583591e-02 1.09936204e-02 2.60860985e-03]\n",
      " [6.06712364e-02 7.77620077e-03 4.17401595e-03]\n",
      " [1.17961340e-01 7.40005597e-02 1.16535239e-06]\n",
      " [5.53649850e-02 1.24520928e-04 3.58574130e-02]\n",
      " [1.68350471e-06 7.09011853e-02 1.27636492e-01]\n",
      " [2.41402319e-07 8.70603696e-02 1.39348060e-01]\n",
      " [7.40042403e-02 8.64877366e-03 3.64586012e-03]\n",
      " [7.22542256e-02 3.00518516e-02 2.30884194e-04]\n",
      " [1.28954707e-06 7.31255710e-02 1.27350613e-01]\n",
      " [1.06301729e-06 7.47384503e-02 1.25594974e-01]\n",
      " [6.37794130e-07 7.89955780e-02 1.31112620e-01]\n",
      " [6.66475818e-02 4.02288046e-03 8.00687913e-03]\n",
      " [6.45188913e-02 4.98696901e-02 2.46357140e-05]\n",
      " [9.73548282e-08 9.47536454e-02 1.30303606e-01]\n",
      " [8.27591941e-02 4.98305820e-02 2.15132350e-05]\n",
      " [7.96359554e-02 6.49008229e-02 4.04615093e-06]\n",
      " [8.24571771e-07 7.68524557e-02 1.31038889e-01]\n",
      " [4.88450415e-02 6.26802794e-04 2.22070571e-02]\n",
      " [5.98453060e-02 1.04421726e-03 1.78789534e-02]\n",
      " [5.69355451e-02 1.67590138e-02 1.20779930e-03]\n",
      " [5.95391355e-02 1.69527644e-04 3.28760445e-02]\n",
      " [7.12936446e-02 5.59685752e-02 1.17051322e-05]\n",
      " [1.01328524e-07 9.43495482e-02 1.32800996e-01]\n",
      " [7.77788535e-02 4.53158133e-02 3.70570197e-05]\n",
      " [4.02943939e-02 4.91884362e-04 2.50694826e-02]\n",
      " [6.77015111e-02 3.67082246e-02 1.04929226e-04]\n",
      " [5.95282428e-02 7.73729425e-06 7.40729943e-02]\n",
      " [3.27691734e-02 4.06981620e-04 2.97766589e-02]\n",
      " [4.57493290e-02 4.22169862e-04 2.57925168e-02]\n",
      " [1.13965885e-03 1.71430260e-02 1.04650028e-01]\n",
      " [6.44597709e-02 1.12391033e-04 3.62162143e-02]\n",
      " [5.31344824e-02 1.16430179e-04 3.67379896e-02]\n",
      " [7.60987405e-07 7.75230974e-02 1.29785165e-01]\n",
      " [3.25212851e-02 2.58453307e-04 3.80911976e-02]\n",
      " [9.38103124e-02 4.05158438e-02 6.48236746e-05]\n",
      " [6.81142062e-02 4.74193059e-02 3.05596368e-05]\n",
      " [2.40408895e-07 8.72291103e-02 1.23475656e-01]\n",
      " [3.08303814e-02 2.16384913e-04 5.84451705e-02]\n",
      " [8.59487653e-02 7.17317462e-02 1.79876440e-06]\n",
      " [7.04228431e-02 1.30951507e-02 1.94290490e-03]\n",
      " [1.08282471e-07 9.37314853e-02 1.38608798e-01]\n",
      " [9.24860388e-02 7.49785677e-02 1.15740397e-06]\n",
      " [1.85751178e-05 5.08957282e-02 1.22878745e-01]\n",
      " [5.68183735e-02 9.87860491e-04 1.83416251e-02]\n",
      " [1.02409765e-01 4.51522619e-02 3.70769812e-05]\n",
      " [6.56405464e-02 3.19250785e-02 1.85952609e-04]\n",
      " [4.95068654e-02 9.47637745e-05 3.95585857e-02]\n",
      " [6.24879636e-02 2.68139839e-02 3.45409295e-04]\n",
      " [7.99843967e-02 2.37249973e-04 2.97960490e-02]\n",
      " [6.15581423e-02 6.20493956e-05 4.15914878e-02]\n",
      " [5.75998835e-02 3.85676175e-02 9.02279644e-05]\n",
      " [4.61191796e-02 2.23294329e-02 6.27584173e-04]\n",
      " [2.36374308e-05 4.88900207e-02 1.19339742e-01]\n",
      " [5.98223358e-02 4.51599117e-05 4.47719209e-02]\n",
      " [4.03329656e-02 1.56693123e-02 1.45740143e-03]\n",
      " [1.06202367e-06 7.47392401e-02 1.33530572e-01]\n",
      " [6.29869327e-02 3.04085843e-05 4.80807498e-02]\n",
      " [9.43392068e-02 5.68056777e-02 9.23340212e-06]]), 'grad': tensor32([[9.93411486e-09 1.13536313e-01 1.43250823e-01]\n",
      " [3.27826193e-08 1.04072712e-01 1.29265189e-01]\n",
      " [5.77701889e-02 1.19504795e-04 3.60233486e-02]\n",
      " [4.24197196e-07 8.23985860e-02 1.29028320e-01]\n",
      " [1.18216718e-07 9.30903330e-02 1.34880379e-01]\n",
      " [8.11690688e-02 3.25691216e-02 1.69491657e-04]\n",
      " [4.32970859e-02 4.83255979e-04 2.48320531e-02]\n",
      " [2.15647697e-06 6.88395426e-02 1.27199709e-01]\n",
      " [2.23520431e-07 8.77600238e-02 1.33274704e-01]\n",
      " [1.29143496e-08 1.11643270e-01 1.42155156e-01]\n",
      " [6.42452240e-02 3.55482958e-02 1.21627410e-04]\n",
      " [1.91606116e-02 2.58665811e-03 1.49389775e-02]\n",
      " [5.30124940e-02 6.99358759e-04 2.11767256e-02]\n",
      " [2.40408895e-07 8.71777087e-02 1.26533136e-01]\n",
      " [1.45696424e-06 7.21096769e-02 1.28460035e-01]\n",
      " [6.32058531e-02 7.37685559e-06 6.56997487e-02]\n",
      " [5.47069013e-02 4.08562878e-03 7.92977400e-03]\n",
      " [5.57952598e-02 2.61031352e-02 3.82396363e-04]\n",
      " [5.89353517e-02 1.52288630e-04 3.38278376e-02]\n",
      " [8.62442330e-02 7.39660859e-02 1.43162788e-06]\n",
      " [4.41306829e-02 1.24704937e-04 3.85108702e-02]\n",
      " [1.14139020e-01 6.92112893e-02 2.06903474e-06]\n",
      " [3.09035890e-02 1.45133107e-03 1.66675262e-02]\n",
      " [9.93470053e-07 7.52986223e-02 1.30066410e-01]\n",
      " [1.22246444e-01 6.52301908e-02 3.32511263e-06]\n",
      " [6.35472387e-02 7.92373339e-06 6.39889166e-02]\n",
      " [4.42831151e-06 6.28380030e-02 1.26778722e-01]\n",
      " [4.90759362e-07 8.11977386e-02 1.28488928e-01]\n",
      " [1.72855266e-07 9.00936201e-02 1.19149826e-01]\n",
      " [5.89728765e-02 1.35531918e-05 5.96290305e-02]\n",
      " [6.49461523e-02 1.94538776e-02 8.52807192e-04]\n",
      " [6.19911418e-07 7.92610943e-02 1.24364920e-01]\n",
      " [4.56473463e-05 4.34161276e-02 1.18354335e-01]\n",
      " [9.62276408e-06 5.63887395e-02 1.07503712e-01]\n",
      " [5.00240698e-02 1.45644211e-04 3.50791514e-02]\n",
      " [2.62301728e-06 6.72045648e-02 1.26566365e-01]\n",
      " [3.77789922e-02 1.26550498e-04 4.53552641e-02]\n",
      " [7.91379958e-02 5.77951632e-02 8.73665886e-06]\n",
      " [4.88772457e-07 8.12200084e-02 1.30833805e-01]\n",
      " [5.67237325e-02 7.71240957e-05 4.01261076e-02]\n",
      " [7.61108696e-02 4.53982614e-02 3.68634428e-05]\n",
      " [3.57628629e-08 1.02971099e-01 1.38001204e-01]\n",
      " [4.37277108e-02 1.55149819e-02 1.45944103e-03]\n",
      " [6.42452240e-02 3.55482958e-02 1.21627410e-04]\n",
      " [8.87161121e-02 5.97204189e-06 6.06252104e-02]\n",
      " [2.44389996e-02 2.00012024e-03 1.52647765e-02]\n",
      " [5.55436835e-02 4.05999199e-02 7.47722079e-05]\n",
      " [6.31788597e-02 1.64538564e-04 3.30096073e-02]\n",
      " [3.98367263e-07 8.29947367e-02 1.20230652e-01]\n",
      " [4.37379293e-02 4.81748611e-05 6.31890893e-02]\n",
      " [7.76184052e-02 3.57057303e-02 1.16376279e-04]\n",
      " [2.81480789e-06 6.66153580e-02 1.27486065e-01]\n",
      " [5.10173186e-06 6.16598427e-02 1.28611535e-01]\n",
      " [6.18777908e-02 1.59913670e-05 5.52433766e-02]\n",
      " [5.58219664e-02 8.62865057e-03 3.67106497e-03]\n",
      " [9.04395074e-06 5.68901375e-02 1.23299472e-01]\n",
      " [8.05802494e-02 6.26673251e-02 5.04507352e-06]\n",
      " [1.37101983e-06 7.26176277e-02 1.27906203e-01]\n",
      " [8.87163083e-07 7.63797089e-02 1.09939054e-01]\n",
      " [3.23405229e-02 1.25131179e-02 2.32447218e-03]\n",
      " [3.11644692e-02 2.07524659e-04 5.90658933e-02]\n",
      " [8.75043646e-02 6.63597882e-02 3.13082523e-06]\n",
      " [5.45583591e-02 1.09936204e-02 2.60860985e-03]\n",
      " [6.06712364e-02 7.77620077e-03 4.17401595e-03]\n",
      " [1.17961340e-01 7.40005597e-02 1.16535239e-06]\n",
      " [5.53649850e-02 1.24520928e-04 3.58574130e-02]\n",
      " [1.68350471e-06 7.09011853e-02 1.27636492e-01]\n",
      " [2.41402319e-07 8.70603696e-02 1.39348060e-01]\n",
      " [7.40042403e-02 8.64877366e-03 3.64586012e-03]\n",
      " [7.22542256e-02 3.00518516e-02 2.30884194e-04]\n",
      " [1.28954707e-06 7.31255710e-02 1.27350613e-01]\n",
      " [1.06301729e-06 7.47384503e-02 1.25594974e-01]\n",
      " [6.37794130e-07 7.89955780e-02 1.31112620e-01]\n",
      " [6.66475818e-02 4.02288046e-03 8.00687913e-03]\n",
      " [6.45188913e-02 4.98696901e-02 2.46357140e-05]\n",
      " [9.73548282e-08 9.47536454e-02 1.30303606e-01]\n",
      " [8.27591941e-02 4.98305820e-02 2.15132350e-05]\n",
      " [7.96359554e-02 6.49008229e-02 4.04615093e-06]\n",
      " [8.24571771e-07 7.68524557e-02 1.31038889e-01]\n",
      " [4.88450415e-02 6.26802794e-04 2.22070571e-02]\n",
      " [5.98453060e-02 1.04421726e-03 1.78789534e-02]\n",
      " [5.69355451e-02 1.67590138e-02 1.20779930e-03]\n",
      " [5.95391355e-02 1.69527644e-04 3.28760445e-02]\n",
      " [7.12936446e-02 5.59685752e-02 1.17051322e-05]\n",
      " [1.01328524e-07 9.43495482e-02 1.32800996e-01]\n",
      " [7.77788535e-02 4.53158133e-02 3.70570197e-05]\n",
      " [4.02943939e-02 4.91884362e-04 2.50694826e-02]\n",
      " [6.77015111e-02 3.67082246e-02 1.04929226e-04]\n",
      " [5.95282428e-02 7.73729425e-06 7.40729943e-02]\n",
      " [3.27691734e-02 4.06981620e-04 2.97766589e-02]\n",
      " [4.57493290e-02 4.22169862e-04 2.57925168e-02]\n",
      " [1.13965885e-03 1.71430260e-02 1.04650028e-01]\n",
      " [6.44597709e-02 1.12391033e-04 3.62162143e-02]\n",
      " [5.31344824e-02 1.16430179e-04 3.67379896e-02]\n",
      " [7.60987405e-07 7.75230974e-02 1.29785165e-01]\n",
      " [3.25212851e-02 2.58453307e-04 3.80911976e-02]\n",
      " [9.38103124e-02 4.05158438e-02 6.48236746e-05]\n",
      " [6.81142062e-02 4.74193059e-02 3.05596368e-05]\n",
      " [2.40408895e-07 8.72291103e-02 1.23475656e-01]\n",
      " [3.08303814e-02 2.16384913e-04 5.84451705e-02]\n",
      " [8.59487653e-02 7.17317462e-02 1.79876440e-06]\n",
      " [7.04228431e-02 1.30951507e-02 1.94290490e-03]\n",
      " [1.08282471e-07 9.37314853e-02 1.38608798e-01]\n",
      " [9.24860388e-02 7.49785677e-02 1.15740397e-06]\n",
      " [1.85751178e-05 5.08957282e-02 1.22878745e-01]\n",
      " [5.68183735e-02 9.87860491e-04 1.83416251e-02]\n",
      " [1.02409765e-01 4.51522619e-02 3.70769812e-05]\n",
      " [6.56405464e-02 3.19250785e-02 1.85952609e-04]\n",
      " [4.95068654e-02 9.47637745e-05 3.95585857e-02]\n",
      " [6.24879636e-02 2.68139839e-02 3.45409295e-04]\n",
      " [7.99843967e-02 2.37249973e-04 2.97960490e-02]\n",
      " [6.15581423e-02 6.20493956e-05 4.15914878e-02]\n",
      " [5.75998835e-02 3.85676175e-02 9.02279644e-05]\n",
      " [4.61191796e-02 2.23294329e-02 6.27584173e-04]\n",
      " [2.36374308e-05 4.88900207e-02 1.19339742e-01]\n",
      " [5.98223358e-02 4.51599117e-05 4.47719209e-02]\n",
      " [4.03329656e-02 1.56693123e-02 1.45740143e-03]\n",
      " [1.06202367e-06 7.47392401e-02 1.33530572e-01]\n",
      " [6.29869327e-02 3.04085843e-05 4.80807498e-02]\n",
      " [9.43392068e-02 5.68056777e-02 9.23340212e-06]]), 'npar_data': array([[1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.]], dtype=float32), 'shape': (120, 3)}\n",
      "==================================\n",
      "30\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [32], '_cg_ascend': [29, 28], '_grad_f': tensor32([[-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]]), 'grad': tensor32([[-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]\n",
      " [-0.00833333 -0.00833333 -0.00833333]]), 'npar_data': array([[-1.19209369e-06, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-3.93391429e-06, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -1.43405749e-02, -0.00000000e+00],\n",
      "       [-5.09036618e-05, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-1.41860055e-05, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -2.03389972e-02],\n",
      "       [-0.00000000e+00, -5.79907149e-02, -0.00000000e+00],\n",
      "       [-2.58777232e-04, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-2.68224503e-05, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-1.54972190e-06, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -1.45952888e-02],\n",
      "       [-0.00000000e+00, -3.10398966e-01, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -8.39230493e-02, -0.00000000e+00],\n",
      "       [-2.88490646e-05, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-1.74835703e-04, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -8.85222631e-04, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -9.51572835e-01],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -4.58875597e-02],\n",
      "       [-0.00000000e+00, -1.82746351e-02, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -1.71795342e-04],\n",
      "       [-0.00000000e+00, -1.49645917e-02, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -2.48284166e-04],\n",
      "       [-0.00000000e+00, -1.74159721e-01, -0.00000000e+00],\n",
      "       [-1.19216398e-04, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -3.99013486e-04],\n",
      "       [-0.00000000e+00, -9.50847985e-04, -0.00000000e+00],\n",
      "       [-5.31397352e-04, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-5.88911207e-05, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-2.07426310e-05, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -1.62638293e-03, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -1.02336861e-01],\n",
      "       [-7.43893688e-05, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-5.47768129e-03, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-1.15473161e-03, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -1.74773037e-02, -0.00000000e+00],\n",
      "       [-3.14762059e-04, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -1.51860584e-02, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -1.04839902e-03],\n",
      "       [-5.86526912e-05, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -9.25489143e-03, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -4.42361273e-03],\n",
      "       [-4.29154352e-06, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -1.75132915e-01],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -1.45952888e-02],\n",
      "       [-0.00000000e+00, -7.16644980e-04, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -2.40014419e-01, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -8.97266436e-03],\n",
      "       [-0.00000000e+00, -1.97446272e-02, -0.00000000e+00],\n",
      "       [-4.78040674e-05, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -5.78098325e-03, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -1.39651531e-02],\n",
      "       [-3.37776932e-04, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-6.12207805e-04, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -1.91896386e-03, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -1.03543806e+00, -0.00000000e+00],\n",
      "       [-1.08527404e-03, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -6.05408801e-04],\n",
      "       [-1.64522367e-04, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-1.06459564e-04, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -1.50157404e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -2.49029584e-02, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -3.75699019e-04],\n",
      "       [-0.00000000e+00, -1.31923437e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -5.00881910e-01],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -1.39842276e-04],\n",
      "       [-0.00000000e+00, -1.49425101e-02, -0.00000000e+00],\n",
      "       [-2.02020557e-04, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-2.89682775e-05, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -4.37503189e-01],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -2.77061015e-02],\n",
      "       [-1.54745634e-04, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-1.27562074e-04, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-7.65352888e-05, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -4.82745647e-01, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -2.95628561e-03],\n",
      "       [-1.16825786e-05, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -2.58158799e-03],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -4.85538098e-04],\n",
      "       [-9.89486070e-05, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -7.52163306e-02, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -1.25306070e-01, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -1.44935906e-01],\n",
      "       [-0.00000000e+00, -2.03433167e-02, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -1.40461582e-03],\n",
      "       [-1.21594221e-05, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -4.44684224e-03],\n",
      "       [-0.00000000e+00, -5.90261184e-02, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -1.25915064e-02],\n",
      "       [-0.00000000e+00, -9.28475230e-04, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -4.88377921e-02, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -5.06603792e-02, -0.00000000e+00],\n",
      "       [-1.36759058e-01, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -1.34869236e-02, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -1.39716212e-02, -0.00000000e+00],\n",
      "       [-9.13184849e-05, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -3.10143940e-02, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -7.77884014e-03],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -3.66715621e-03],\n",
      "       [-2.88490646e-05, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -2.59661879e-02, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -2.15851716e-04],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -2.33148575e-01],\n",
      "       [-1.29938962e-05, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -1.38888470e-04],\n",
      "       [-2.22901395e-03, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -1.18543252e-01, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -4.44923760e-03],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -2.23143119e-02],\n",
      "       [-0.00000000e+00, -1.13716526e-02, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -4.14491147e-02],\n",
      "       [-0.00000000e+00, -2.84699947e-02, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -7.44592724e-03, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -1.08273551e-02],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -7.53100961e-02],\n",
      "       [-2.83649145e-03, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -5.41918911e-03, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -1.74888164e-01],\n",
      "       [-1.27442836e-04, -0.00000000e+00, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -3.64902988e-03, -0.00000000e+00],\n",
      "       [-0.00000000e+00, -0.00000000e+00, -1.10800820e-03]], dtype=float32), 'shape': (120, 3)}\n",
      "==================================\n",
      "31\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [32], '_cg_ascend': [], '_grad_f': tensor32([[0.0012794 ]\n",
      " [0.05005086]\n",
      " [0.02554665]]), 'grad': tensor32([[0.0012794 ]\n",
      " [0.05005086]\n",
      " [0.02554665]]), 'npar_data': array([[1.],\n",
      "       [1.],\n",
      "       [1.]], dtype=float32), 'shape': (3, 1)}\n",
      "==================================\n",
      "32\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [34], '_cg_ascend': [30, 31], '_grad_f': tensor32([[-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]]), 'grad': tensor32([[-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]\n",
      " [-0.00833333]]), 'npar_data': array([[-1.19209369e-06],\n",
      "       [-3.93391429e-06],\n",
      "       [-1.43405749e-02],\n",
      "       [-5.09036618e-05],\n",
      "       [-1.41860055e-05],\n",
      "       [-2.03389972e-02],\n",
      "       [-5.79907149e-02],\n",
      "       [-2.58777232e-04],\n",
      "       [-2.68224503e-05],\n",
      "       [-1.54972190e-06],\n",
      "       [-1.45952888e-02],\n",
      "       [-3.10398966e-01],\n",
      "       [-8.39230493e-02],\n",
      "       [-2.88490646e-05],\n",
      "       [-1.74835703e-04],\n",
      "       [-8.85222631e-04],\n",
      "       [-9.51572835e-01],\n",
      "       [-4.58875597e-02],\n",
      "       [-1.82746351e-02],\n",
      "       [-1.71795342e-04],\n",
      "       [-1.49645917e-02],\n",
      "       [-2.48284166e-04],\n",
      "       [-1.74159721e-01],\n",
      "       [-1.19216398e-04],\n",
      "       [-3.99013486e-04],\n",
      "       [-9.50847985e-04],\n",
      "       [-5.31397352e-04],\n",
      "       [-5.88911207e-05],\n",
      "       [-2.07426310e-05],\n",
      "       [-1.62638293e-03],\n",
      "       [-1.02336861e-01],\n",
      "       [-7.43893688e-05],\n",
      "       [-5.47768129e-03],\n",
      "       [-1.15473161e-03],\n",
      "       [-1.74773037e-02],\n",
      "       [-3.14762059e-04],\n",
      "       [-1.51860584e-02],\n",
      "       [-1.04839902e-03],\n",
      "       [-5.86526912e-05],\n",
      "       [-9.25489143e-03],\n",
      "       [-4.42361273e-03],\n",
      "       [-4.29154352e-06],\n",
      "       [-1.75132915e-01],\n",
      "       [-1.45952888e-02],\n",
      "       [-7.16644980e-04],\n",
      "       [-2.40014419e-01],\n",
      "       [-8.97266436e-03],\n",
      "       [-1.97446272e-02],\n",
      "       [-4.78040674e-05],\n",
      "       [-5.78098325e-03],\n",
      "       [-1.39651531e-02],\n",
      "       [-3.37776932e-04],\n",
      "       [-6.12207805e-04],\n",
      "       [-1.91896386e-03],\n",
      "       [-1.03543806e+00],\n",
      "       [-1.08527404e-03],\n",
      "       [-6.05408801e-04],\n",
      "       [-1.64522367e-04],\n",
      "       [-1.06459564e-04],\n",
      "       [-1.50157404e+00],\n",
      "       [-2.49029584e-02],\n",
      "       [-3.75699019e-04],\n",
      "       [-1.31923437e+00],\n",
      "       [-5.00881910e-01],\n",
      "       [-1.39842276e-04],\n",
      "       [-1.49425101e-02],\n",
      "       [-2.02020557e-04],\n",
      "       [-2.89682775e-05],\n",
      "       [-4.37503189e-01],\n",
      "       [-2.77061015e-02],\n",
      "       [-1.54745634e-04],\n",
      "       [-1.27562074e-04],\n",
      "       [-7.65352888e-05],\n",
      "       [-4.82745647e-01],\n",
      "       [-2.95628561e-03],\n",
      "       [-1.16825786e-05],\n",
      "       [-2.58158799e-03],\n",
      "       [-4.85538098e-04],\n",
      "       [-9.89486070e-05],\n",
      "       [-7.52163306e-02],\n",
      "       [-1.25306070e-01],\n",
      "       [-1.44935906e-01],\n",
      "       [-2.03433167e-02],\n",
      "       [-1.40461582e-03],\n",
      "       [-1.21594221e-05],\n",
      "       [-4.44684224e-03],\n",
      "       [-5.90261184e-02],\n",
      "       [-1.25915064e-02],\n",
      "       [-9.28475230e-04],\n",
      "       [-4.88377921e-02],\n",
      "       [-5.06603792e-02],\n",
      "       [-1.36759058e-01],\n",
      "       [-1.34869236e-02],\n",
      "       [-1.39716212e-02],\n",
      "       [-9.13184849e-05],\n",
      "       [-3.10143940e-02],\n",
      "       [-7.77884014e-03],\n",
      "       [-3.66715621e-03],\n",
      "       [-2.88490646e-05],\n",
      "       [-2.59661879e-02],\n",
      "       [-2.15851716e-04],\n",
      "       [-2.33148575e-01],\n",
      "       [-1.29938962e-05],\n",
      "       [-1.38888470e-04],\n",
      "       [-2.22901395e-03],\n",
      "       [-1.18543252e-01],\n",
      "       [-4.44923760e-03],\n",
      "       [-2.23143119e-02],\n",
      "       [-1.13716526e-02],\n",
      "       [-4.14491147e-02],\n",
      "       [-2.84699947e-02],\n",
      "       [-7.44592724e-03],\n",
      "       [-1.08273551e-02],\n",
      "       [-7.53100961e-02],\n",
      "       [-2.83649145e-03],\n",
      "       [-5.41918911e-03],\n",
      "       [-1.74888164e-01],\n",
      "       [-1.27442836e-04],\n",
      "       [-3.64902988e-03],\n",
      "       [-1.10800820e-03]], dtype=float32), 'shape': (120, 1)}\n",
      "==================================\n",
      "33\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [34], '_cg_ascend': [], '_grad_f': tensor32([[9.93411486e-09 3.27826193e-08 1.19504795e-04 4.24197196e-07\n",
      "  1.18216718e-07 1.69491657e-04 4.83255979e-04 2.15647697e-06\n",
      "  2.23520431e-07 1.29143496e-08 1.21627410e-04 2.58665811e-03\n",
      "  6.99358759e-04 2.40408895e-07 1.45696424e-06 7.37685559e-06\n",
      "  7.92977400e-03 3.82396363e-04 1.52288630e-04 1.43162788e-06\n",
      "  1.24704937e-04 2.06903474e-06 1.45133107e-03 9.93470053e-07\n",
      "  3.32511263e-06 7.92373339e-06 4.42831151e-06 4.90759362e-07\n",
      "  1.72855266e-07 1.35531918e-05 8.52807192e-04 6.19911418e-07\n",
      "  4.56473463e-05 9.62276408e-06 1.45644211e-04 2.62301728e-06\n",
      "  1.26550498e-04 8.73665886e-06 4.88772457e-07 7.71240957e-05\n",
      "  3.68634428e-05 3.57628629e-08 1.45944103e-03 1.21627410e-04\n",
      "  5.97204189e-06 2.00012024e-03 7.47722079e-05 1.64538564e-04\n",
      "  3.98367263e-07 4.81748611e-05 1.16376279e-04 2.81480789e-06\n",
      "  5.10173186e-06 1.59913670e-05 8.62865057e-03 9.04395074e-06\n",
      "  5.04507352e-06 1.37101983e-06 8.87163083e-07 1.25131179e-02\n",
      "  2.07524659e-04 3.13082523e-06 1.09936204e-02 4.17401595e-03\n",
      "  1.16535239e-06 1.24520928e-04 1.68350471e-06 2.41402319e-07\n",
      "  3.64586012e-03 2.30884194e-04 1.28954707e-06 1.06301729e-06\n",
      "  6.37794130e-07 4.02288046e-03 2.46357140e-05 9.73548282e-08\n",
      "  2.15132350e-05 4.04615093e-06 8.24571771e-07 6.26802794e-04\n",
      "  1.04421726e-03 1.20779930e-03 1.69527644e-04 1.17051322e-05\n",
      "  1.01328524e-07 3.70570197e-05 4.91884362e-04 1.04929226e-04\n",
      "  7.73729425e-06 4.06981620e-04 4.22169862e-04 1.13965885e-03\n",
      "  1.12391033e-04 1.16430179e-04 7.60987405e-07 2.58453307e-04\n",
      "  6.48236746e-05 3.05596368e-05 2.40408895e-07 2.16384913e-04\n",
      "  1.79876440e-06 1.94290490e-03 1.08282471e-07 1.15740397e-06\n",
      "  1.85751178e-05 9.87860491e-04 3.70769812e-05 1.85952609e-04\n",
      "  9.47637745e-05 3.45409295e-04 2.37249973e-04 6.20493956e-05\n",
      "  9.02279644e-05 6.27584173e-04 2.36374308e-05 4.51599117e-05\n",
      "  1.45740143e-03 1.06202367e-06 3.04085843e-05 9.23340212e-06]]), 'grad': tensor32([[9.93411486e-09 3.27826193e-08 1.19504795e-04 4.24197196e-07\n",
      "  1.18216718e-07 1.69491657e-04 4.83255979e-04 2.15647697e-06\n",
      "  2.23520431e-07 1.29143496e-08 1.21627410e-04 2.58665811e-03\n",
      "  6.99358759e-04 2.40408895e-07 1.45696424e-06 7.37685559e-06\n",
      "  7.92977400e-03 3.82396363e-04 1.52288630e-04 1.43162788e-06\n",
      "  1.24704937e-04 2.06903474e-06 1.45133107e-03 9.93470053e-07\n",
      "  3.32511263e-06 7.92373339e-06 4.42831151e-06 4.90759362e-07\n",
      "  1.72855266e-07 1.35531918e-05 8.52807192e-04 6.19911418e-07\n",
      "  4.56473463e-05 9.62276408e-06 1.45644211e-04 2.62301728e-06\n",
      "  1.26550498e-04 8.73665886e-06 4.88772457e-07 7.71240957e-05\n",
      "  3.68634428e-05 3.57628629e-08 1.45944103e-03 1.21627410e-04\n",
      "  5.97204189e-06 2.00012024e-03 7.47722079e-05 1.64538564e-04\n",
      "  3.98367263e-07 4.81748611e-05 1.16376279e-04 2.81480789e-06\n",
      "  5.10173186e-06 1.59913670e-05 8.62865057e-03 9.04395074e-06\n",
      "  5.04507352e-06 1.37101983e-06 8.87163083e-07 1.25131179e-02\n",
      "  2.07524659e-04 3.13082523e-06 1.09936204e-02 4.17401595e-03\n",
      "  1.16535239e-06 1.24520928e-04 1.68350471e-06 2.41402319e-07\n",
      "  3.64586012e-03 2.30884194e-04 1.28954707e-06 1.06301729e-06\n",
      "  6.37794130e-07 4.02288046e-03 2.46357140e-05 9.73548282e-08\n",
      "  2.15132350e-05 4.04615093e-06 8.24571771e-07 6.26802794e-04\n",
      "  1.04421726e-03 1.20779930e-03 1.69527644e-04 1.17051322e-05\n",
      "  1.01328524e-07 3.70570197e-05 4.91884362e-04 1.04929226e-04\n",
      "  7.73729425e-06 4.06981620e-04 4.22169862e-04 1.13965885e-03\n",
      "  1.12391033e-04 1.16430179e-04 7.60987405e-07 2.58453307e-04\n",
      "  6.48236746e-05 3.05596368e-05 2.40408895e-07 2.16384913e-04\n",
      "  1.79876440e-06 1.94290490e-03 1.08282471e-07 1.15740397e-06\n",
      "  1.85751178e-05 9.87860491e-04 3.70769812e-05 1.85952609e-04\n",
      "  9.47637745e-05 3.45409295e-04 2.37249973e-04 6.20493956e-05\n",
      "  9.02279644e-05 6.27584173e-04 2.36374308e-05 4.51599117e-05\n",
      "  1.45740143e-03 1.06202367e-06 3.04085843e-05 9.23340212e-06]]), 'npar_data': array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32), 'shape': (1, 120)}\n",
      "==================================\n",
      "34\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [36], '_cg_ascend': [33, 32], '_grad_f': tensor32([[-0.00833333]]), 'grad': tensor32([[-0.00833333]]), 'npar_data': array([[-9.22523]], dtype=float32), 'shape': (1, 1)}\n",
      "==================================\n",
      "35\n",
      "120\n",
      "==================================\n",
      "36\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [37], '_cg_ascend': [34], '_grad_f': tensor32([[-1.]]), 'grad': tensor32([[-1.]]), 'npar_data': array([[-0.07687692]], dtype=float32), 'shape': (1, 1)}\n",
      "==================================\n",
      "37\n",
      "{'tensortype': 'tensor32', 'with_grad': True, '_cg_descend': [], '_cg_ascend': [36], '_grad_f': tensor32([[1.]]), 'grad': tensor32([[1.]]), 'npar_data': array([[0.07687692]], dtype=float32), 'shape': (1, 1)}\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for i in cg._nodelist:\n",
    "    print(counter)\n",
    "    counter+=1\n",
    "    if type(i).__name__ == 'mytensor' or type(i).__name__ == 'mytensorloss' or type(i).__name__ == 'myparameter':\n",
    "        print(i.__dict__)\n",
    "        print('==================================')\n",
    "    else:\n",
    "        print(i)\n",
    "        print('==================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._nodelist.index(softmax(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.0245e-08,  1.0005e-08,  2.0194e-10],\n",
       "         [-3.2596e-08,  3.1324e-08,  1.4447e-09],\n",
       "         [ 8.1302e-06, -1.1865e-04,  1.1052e-04],\n",
       "         [-4.2375e-07,  4.2316e-07,  1.4887e-09],\n",
       "         [-1.1828e-07,  1.1724e-07,  6.9557e-10],\n",
       "         [ 4.9045e-07,  1.6729e-04, -1.6778e-04],\n",
       "         [ 4.6172e-05, -4.6951e-04,  4.2334e-04],\n",
       "         [-2.1560e-06,  2.1538e-06,  1.8744e-09],\n",
       "         [-2.2352e-07,  2.2234e-07,  8.6108e-10],\n",
       "         [-1.3039e-08,  1.2578e-08,  2.4202e-10],\n",
       "         [ 3.7381e-06,  1.1701e-04, -1.2074e-04],\n",
       "         [ 8.3610e-04, -2.2237e-03,  1.3876e-03],\n",
       "         [ 1.4390e-05, -6.7082e-04,  6.5643e-04],\n",
       "         [-2.4028e-07,  2.3844e-07,  2.0375e-09],\n",
       "         [-1.4566e-06,  1.4547e-06,  1.5997e-09],\n",
       "         [ 4.2346e-06, -7.3733e-06,  3.1394e-06],\n",
       "         [ 1.1742e-05,  5.1038e-03, -5.1156e-03],\n",
       "         [ 1.0304e-05,  3.6345e-04, -3.7376e-04],\n",
       "         [ 7.0693e-06, -1.5091e-04,  1.4384e-04],\n",
       "         [ 2.6671e-07,  1.1642e-06, -1.4314e-06],\n",
       "         [ 4.1777e-05, -1.2378e-04,  8.2000e-05],\n",
       "         [ 9.3015e-09,  2.0598e-06, -2.0685e-06],\n",
       "         [ 2.0430e-04, -1.3320e-03,  1.1277e-03],\n",
       "         [-9.9372e-07,  9.9213e-07,  1.3046e-09],\n",
       "         [ 3.4640e-09,  3.3213e-06, -3.3248e-06],\n",
       "         [ 4.0647e-06, -7.9200e-06,  3.8548e-06],\n",
       "         [-4.4275e-06,  4.4258e-06,  1.9759e-09],\n",
       "         [-4.9081e-07,  4.8876e-07,  1.5938e-09],\n",
       "         [-1.7323e-07,  1.6801e-07,  5.0605e-09],\n",
       "         [ 7.0376e-06, -1.3542e-05,  6.5047e-06],\n",
       "         [ 3.4365e-06,  8.0719e-04, -8.1062e-04],\n",
       "         [-6.2026e-07,  6.1665e-07,  2.6677e-09],\n",
       "         [-4.5522e-05,  4.5517e-05,  5.5757e-09],\n",
       "         [-9.6168e-06,  9.5962e-06,  2.0724e-08],\n",
       "         [ 2.0597e-05, -1.4438e-04,  1.2378e-04],\n",
       "         [-2.6226e-06,  2.6207e-06,  2.0290e-09],\n",
       "         [ 8.9527e-05, -1.2559e-04,  3.6067e-05],\n",
       "         [ 6.2583e-07,  8.1059e-06, -8.7321e-06],\n",
       "         [-4.8894e-07,  4.8746e-07,  1.1825e-09],\n",
       "         [ 9.2180e-06, -7.6768e-05,  6.7551e-05],\n",
       "         [ 8.9999e-07,  3.5882e-05, -3.6782e-05],\n",
       "         [-3.5390e-08,  3.5763e-08,  4.5227e-10],\n",
       "         [ 4.3846e-05,  1.2949e-03, -1.3388e-03],\n",
       "         [ 3.7381e-06,  1.1701e-04, -1.2074e-04],\n",
       "         [ 1.9823e-07, -5.9698e-06,  5.7718e-06],\n",
       "         [ 4.4378e-04, -1.7782e-03,  1.3344e-03],\n",
       "         [ 1.0620e-05,  6.3817e-05, -7.4438e-05],\n",
       "         [ 4.2484e-06, -1.6292e-04,  1.5868e-04],\n",
       "         [-3.9861e-07,  3.9394e-07,  4.4348e-09],\n",
       "         [ 4.3793e-05, -4.8036e-05,  4.2432e-06],\n",
       "         [ 7.5104e-07,  1.1482e-04, -1.1557e-04],\n",
       "         [-2.8145e-06,  2.8127e-06,  1.8083e-09],\n",
       "         [-5.0999e-06,  5.0979e-06,  1.5693e-09],\n",
       "         [ 4.9663e-06, -1.5976e-05,  1.1010e-05],\n",
       "         [ 1.0272e-05, -5.3744e-03,  5.3641e-03],\n",
       "         [-9.0394e-06,  9.0358e-06,  3.0429e-09],\n",
       "         [ 5.2636e-07,  4.5173e-06, -5.0431e-06],\n",
       "         [-1.3709e-06,  1.3687e-06,  1.7153e-09],\n",
       "         [-8.8755e-07,  8.7141e-07,  1.5452e-08],\n",
       "         [ 1.7194e-04, -6.4768e-03,  6.3049e-03],\n",
       "         [ 1.9800e-04, -2.0496e-04,  6.9594e-06],\n",
       "         [ 2.2927e-07,  2.9003e-06, -3.1302e-06],\n",
       "         [ 1.1953e-05, -6.1055e-03,  6.0935e-03],\n",
       "         [ 5.7400e-06,  3.2776e-03, -3.2834e-03],\n",
       "         [ 5.8490e-09,  1.1594e-06, -1.1651e-06],\n",
       "         [ 1.0851e-05, -1.2359e-04,  1.1275e-04],\n",
       "         [-1.6829e-06,  1.6817e-06,  1.7745e-09],\n",
       "         [-2.4121e-07,  2.4182e-07,  3.7233e-10],\n",
       "         [ 1.1589e-06,  2.9518e-03, -2.9529e-03],\n",
       "         [ 1.4297e-06,  2.2629e-04, -2.2771e-04],\n",
       "         [-1.2899e-06,  1.2877e-06,  1.8393e-09],\n",
       "         [-1.0626e-06,  1.0611e-06,  2.2902e-09],\n",
       "         [-6.3796e-07,  6.3662e-07,  1.1408e-09],\n",
       "         [ 2.8018e-06, -3.1909e-03,  3.1881e-03],\n",
       "         [ 3.6173e-06,  2.0982e-05, -2.4599e-05],\n",
       "         [-9.7789e-08,  9.6012e-08,  1.2656e-09],\n",
       "         [ 4.0523e-07,  2.1080e-05, -2.1486e-05],\n",
       "         [ 5.8953e-07,  3.4553e-06, -4.0447e-06],\n",
       "         [-8.2422e-07,  8.2335e-07,  1.1517e-09],\n",
       "         [ 2.3727e-05, -6.0381e-04,  5.8008e-04],\n",
       "         [ 6.3380e-06, -9.8144e-04,  9.7510e-04],\n",
       "         [ 8.9867e-06,  1.1154e-03, -1.1244e-03],\n",
       "         [ 6.5752e-06, -1.6782e-04,  1.6124e-04],\n",
       "         [ 1.6044e-06,  1.0092e-05, -1.1696e-05],\n",
       "         [-1.0151e-07,  1.0079e-07,  9.1632e-10],\n",
       "         [ 7.3671e-07,  3.6238e-05, -3.6974e-05],\n",
       "         [ 6.6201e-05, -4.7765e-04,  4.1145e-04],\n",
       "         [ 2.4690e-06,  1.0180e-04, -1.0427e-04],\n",
       "         [ 6.5838e-06, -7.7337e-06,  1.1493e-06],\n",
       "         [ 1.6332e-04, -3.9720e-04,  2.3388e-04],\n",
       "         [ 3.4401e-05, -4.1165e-04,  3.7725e-04],\n",
       "         [-1.0652e-03,  1.0651e-03,  2.9222e-08],\n",
       "         [ 3.6431e-06, -1.1164e-04,  1.0799e-04],\n",
       "         [ 1.4181e-05, -1.1562e-04,  1.0144e-04],\n",
       "         [-7.6089e-07,  7.5968e-07,  1.3522e-09],\n",
       "         [ 1.6825e-04, -2.5449e-04,  8.6235e-05],\n",
       "         [ 1.0753e-07,  6.4465e-05, -6.4572e-05],\n",
       "         [ 2.3497e-06,  2.8154e-05, -3.0504e-05],\n",
       "         [-2.4028e-07,  2.3697e-07,  2.9775e-09],\n",
       "         [ 2.0610e-04, -2.1360e-04,  7.4976e-06],\n",
       "         [ 2.7634e-07,  1.5222e-06, -1.7984e-06],\n",
       "         [ 1.7811e-06,  1.7313e-03, -1.7330e-03],\n",
       "         [-1.0803e-07,  1.0855e-07,  4.1460e-10],\n",
       "         [ 1.2606e-07,  1.0310e-06, -1.1576e-06],\n",
       "         [-1.8555e-05,  1.8551e-05,  3.2048e-09],\n",
       "         [ 9.1139e-06, -9.3155e-04,  9.2244e-04],\n",
       "         [ 3.8261e-08,  3.6957e-05, -3.6995e-05],\n",
       "         [ 3.1618e-06,  1.8073e-04, -1.8389e-04],\n",
       "         [ 2.1915e-05, -9.4227e-05,  7.2312e-05],\n",
       "         [ 4.6156e-06,  3.3373e-04, -3.3835e-04],\n",
       "         [ 5.6538e-07, -2.3390e-04,  2.3334e-04],\n",
       "         [ 5.1605e-06, -6.1819e-05,  5.6658e-05],\n",
       "         [ 8.2981e-06,  8.1443e-05, -8.9741e-05],\n",
       "         [ 3.2908e-05,  5.7163e-04, -6.0454e-04],\n",
       "         [-2.3604e-05,  2.3599e-05,  4.9446e-09],\n",
       "         [ 6.3555e-06, -4.5038e-05,  3.8682e-05],\n",
       "         [ 6.5895e-05,  1.2712e-03, -1.3371e-03],\n",
       "         [-1.0617e-06,  1.0610e-06,  8.3252e-10],\n",
       "         [ 4.3474e-06, -3.0353e-05,  2.6006e-05],\n",
       "         [ 1.0091e-07,  9.1278e-06, -9.2285e-06]]),)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_torchloss_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from': 18, 'to': 19, 'forward': {'op': 'mytensor.exp'}}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._computegraph__find_edges(18,19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999996"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.016666666*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python&Conda_Env\\Python3.9(Global)\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  \n",
    "y = iris.target  \n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_one_hot = encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax output:\n",
      " tensor([0.0900, 0.2447, 0.6652], grad_fn=<SoftmaxBackward0>)\n",
      "Gradient of x:\n",
      " tensor([0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=0)\n",
    "s = softmax(x)\n",
    "\n",
    "\n",
    "loss = s.sum()  \n",
    "\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "\n",
    "print(\"Softmax output:\\n\", s)\n",
    "print(\"Gradient of x:\\n\", x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor32([[ 2.718282   7.3890557 20.085537 ]])\n",
      "tensor32([[30.192875]])\n",
      "tensor32([[30.192875 30.192875 30.192875]])\n",
      "tensor32([[0.0331204 0.0331204 0.0331204]])\n",
      "tensor32([[0.09003058 0.24472846 0.66524094]])\n"
     ]
    }
   ],
   "source": [
    "import MyTensor as MT\n",
    "import MyNN as MN\n",
    "import Loss\n",
    "myten=MT.mytensor([[1.0, 2.0, 3.0]])\n",
    "Mysoft_res=MN.my_softmax()(myten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mloss\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lf(Loss.loss):\n",
    "    def __init__(self,comment=None):\n",
    "        super().__init__(comment)\n",
    "    def _loss(self, softmax=None, label=None):\n",
    "        return MT.dot(softmax,MT.ones((3,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lf1 = Lf()\n",
    "Lf1(Mysoft_res,None)\n",
    "Lf1.backward(mode='force')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class '__main__.Lf'>: 1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor32([[0. 0. 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myten._grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "cg = MT.mytensor.computegraph\n",
    "simple_DiG=nx.DiGraph()\n",
    "for i in cg._edgelist:\n",
    "    simple_DiG.add_edge(i['from'],i['to'])\n",
    "nx.draw_networkx(simple_DiG,pos=nx.spring_layout(simple_DiG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._nodelist.index(Lf1._tensorloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from': 0, 'to': 1, 'forward': {'op': 'mytensor.exp'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._computegraph__find_edges(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tensortype': 'tensor32',\n",
       " 'with_grad': True,\n",
       " '_cg_descend': [3, 8, 9],\n",
       " '_cg_ascend': [0],\n",
       " '_grad_f': tensor32([[0. 0. 0.]]),\n",
       " 'grad': tensor32([[0. 0. 0.]]),\n",
       " 'npar_data': array([[ 2.718282 ,  7.3890557, 20.085537 ]], dtype=float32),\n",
       " 'shape': (1, 3)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg._nodelist[1].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
